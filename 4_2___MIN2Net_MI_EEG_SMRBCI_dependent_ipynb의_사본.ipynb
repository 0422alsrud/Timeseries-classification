{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0422alsrud/Timeseries-classification/blob/main/4_2___MIN2Net_MI_EEG_SMRBCI_dependent_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "TyuGaaagIg8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz\n",
        "!tar xvfz Python-3.6.9.tgz\n",
        "!Python-3.6.9/configure\n",
        "!make\n",
        "!sudo make install\n",
        "\n",
        "# !pip install Python==3.6.9\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!which python\n",
        "!python --version\n",
        "\n",
        "#구글 코랩에 디폴트로 깔려 있는 python 3.6과 매칭이 되는 미니콘다를 깔아야 함\n",
        "#그 미니콘다 버전은 4.5.4\n",
        "!echo $PYTHONPATH\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0sFW9BeRY_C",
        "outputId": "6e40fc50-6f92-4fff-b193-596510066632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_decomp_ldl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_decomp_polar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_decomp_qz.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_expm_frechet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_generate_pyx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_interpolative_backend.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_matfuncs_inv_ssq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_matfuncs_sqrtm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_procrustes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_sketches.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_solvers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_testutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/blas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_cholesky.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_lu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_qr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_schur.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_svd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/flinalg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/interpolative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/lapack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/matfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/misc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/special_matrices.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/src'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/src/id_dist'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/src/id_dist/doc'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/src/lapack_deprecations'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_blas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_cython_blas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_cython_lapack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_cholesky.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_cossin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_ldl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_polar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_update.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_fblas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_interpolative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_lapack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_matfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_procrustes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_sketches.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_solve_toeplitz.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_solvers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_special_matrices.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/misc'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/doccer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/misc/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/tests/test_doccer.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/ndimage'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/_ni_docstrings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/filters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/fourier.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/interpolation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/measurements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/morphology.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_c_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_datatypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_filters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_measurements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_morphology.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_ndimage.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_splines.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/odr'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/_add_newdocs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/models.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/odrpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/odr/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/tests/test_odr.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_basinhopping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_constraints.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_differentialevolution.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_dual_annealing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_hessian_update_strategy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog_ip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog_rs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog_simplex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsap.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/bvls.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/dogbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/least_squares.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/lsq_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/trf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/trf_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_minimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_nnls.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_numdiff.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_remove_redundancy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_root.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_root_scalar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo_lib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo_lib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo_lib/sobol_seq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo_lib/triangulation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_spectral.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trlib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trlib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trlib/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/canonical_constraint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/equality_constrained_sqp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/projections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/qp_subproblem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/report.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/test_canonical_constraint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/test_projections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/test_qp_subproblem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/test_report.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tr_interior_point.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_dogleg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_exact.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_krylov.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_ncg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_tstutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/cobyla.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/cython_optimize'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/cython_optimize/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/lbfgsb_src'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/linesearch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/minpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/nonlin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/slsqp.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__basinhopping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__differential_evolution.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__dual_annealing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__linprog_clean_inputs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__numdiff.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__remove_redundancy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__root.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__shgo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__spectral.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_cobyla.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_constraint_conversion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_constraints.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_cython_optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_differentiable_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_hessian_update_strategy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_lbfgsb_hessinv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_lbfgsb_setulb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_least_squares.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_linear_assignment.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_linesearch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_linprog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_lsq_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_lsq_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_minimize_constrained.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_minpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_nnls.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_nonlin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_slsqp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_tnc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_trustregion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_trustregion_exact.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_trustregion_krylov.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_zeros.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tnc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/zeros.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/signal'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_arraytools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_max_len_seq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_peak_finding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_savitzky_golay.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_upfirdn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/bsplines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/filter_design.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/fir_filter_design.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/lti_conversion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/ltisys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/signaltools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/spectral.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/signal/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/mpsig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_array_tools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_bsplines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_cont2discrete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_dltisys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_filter_design.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_fir_filter_design.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_ltisys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_max_len_seq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_peak_finding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_savitzky_golay.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_signaltools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_spectral.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_upfirdn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_waveforms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_wavelets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_windows.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/waveforms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/wavelets.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/signal/windows'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/windows/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/windows/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/windows/windows.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/_index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/_matrix_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/bsr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/compressed.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/construct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/coo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csc.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/_laplacian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/_validation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_connected_components.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_conversions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_flow.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_graph_laplacian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_matching.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_reordering.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_shortest_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_spanning_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_traversal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/dia.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/dok.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/extract.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/generate_sparsetools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/lil.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/_expm_multiply.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/_norm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/_onenormest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/SuperLU'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/_add_newdocs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/linsolve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/tests/test_linsolve.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/ARPACK'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/tests/test_arpack.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/lobpcg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/tests/test_lobpcg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/interface.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/_gcrotmk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/iterative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/lgmres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/lsmr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/lsqr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/minres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/demo_lgmres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_gcrotmk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_iterative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_lgmres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_lsmr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_lsqr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_minres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/matfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_expm_multiply.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_interface.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_matfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_norm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_onenormest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_pydata_sparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/sparsetools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/spfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/sputils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_construct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_csc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_csr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_extract.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_matrix_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_sparsetools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_spfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_sputils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/_geometric_slerp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/_plotutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/_procrustes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/_spherical_voronoi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/kdtree.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/qhull_src'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test__plotutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test__procrustes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_distance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_hausdorff.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_kdtree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_qhull.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_slerp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_spherical_voronoi.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/_rotation_groups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/_rotation_spline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/rotation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests/test_rotation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests/test_rotation_groups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests/test_rotation_spline.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/special'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_ellip_harm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_generate_pyx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_lambertw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_logsumexp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_mptestutils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/expn_asy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/gammainc_asy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/gammainc_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/lambertw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/loggamma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/struve_convergence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/wrightomega.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/zetac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_spherical_bessel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_testutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/add_newdocs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/orthogonal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/sf_error.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/spfun_stats.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/special/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/special/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_bdtr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_boxcox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_cdflib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_cython_special.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_digamma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_ellip_harm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_erfinv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_exponential_integrals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_faddeeva.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_gamma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_gammainc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_hypergeometric.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_kolmogorov.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_lambertw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_log_softmax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_loggamma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_logit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_logsumexp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_mpmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_nan_inputs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_ndtr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_orthogonal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_orthogonal_eval.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_owens_t.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_pcf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_pdtr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_precompute_expn_asy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_precompute_gammainc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_precompute_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_round.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_sf_error.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_sici.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_spence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_spfun_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_sph_harm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_spherical_bessel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_trig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_wrightomega.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_zeta.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_binned_statistic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_discrete_distns.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_distr_params.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_hypotests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_ksstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_multivariate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_rvs_sampling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_tukeylambda_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_wilcoxon_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/contingency.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/distributions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/kde.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/morestats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/mstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/mstats_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/mstats_extras.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/stats.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/common_tests.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/data'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/data/nist_anova'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/data/nist_linregress'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_binned_statistic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_contingency.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_continuous_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_discrete_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_discrete_distns.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_distributions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_fit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_kdeoth.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_morestats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_mstats_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_mstats_extras.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_multivariate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_rank.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_tukeylambda_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy-1.5.4.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy.libs'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_deprecation_warning.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_distutils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/_msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/archive_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/bcppcompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/ccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/cmd.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist_dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist_msi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist_rpm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist_wininst.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build_py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/clean.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_egg_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_lib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/py37compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/register.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/upload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/cygwinccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/debug.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/dep_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/dir_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/dist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/errors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/extension.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/fancy_getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/file_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/log.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/msvc9compiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/py35compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/py38compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/text_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/unixccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/versionpredicate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_imp.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_vendor'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/more_itertools'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/more_itertools/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/more_itertools/more.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/more_itertools/recipes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/ordered_set.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/__about__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/_compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/_structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/_typing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/markers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/requirements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/specifiers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/pyparsing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/archive_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/build_meta.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/command'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/alias.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/bdist_egg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/bdist_rpm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/build_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/build_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/build_py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/develop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/dist_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/easy_install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/egg_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/install_egg_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/install_lib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/install_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/py36compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/register.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/rotate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/saveopts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/setopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/test.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/upload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/upload_docs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/dep_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/depends.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/dist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/errors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/extension.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/extern'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/extern/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/glob.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/installer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/launch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/monkey.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/msvc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/namespaces.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/package_index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/py34compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/sandbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/unicode_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/wheel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/windows_support.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools-40.6.2.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools-58.0.4-py3.6.egg-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/six-1.16.0.dist-info'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/six.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/__check_build'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/__check_build/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/__check_build/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/_build_utils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_build_utils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_build_utils/openmp_helpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_build_utils/pre_build_helpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_distributor_init.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/_loss'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_loss/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_loss/glm_distribution.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/_loss/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_loss/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_loss/tests/test_glm_distribution.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_min_dependencies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/calibration.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/cluster'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_affinity_propagation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_agglomerative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_bicluster.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_birch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_dbscan.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_feature_agglomeration.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_kmeans.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_mean_shift.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_optics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_spectral.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_affinity_propagation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_bicluster.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_birch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_dbscan.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_feature_agglomeration.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_hierarchical.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_k_means.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_mean_shift.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_optics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_spectral.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/compose'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/_target.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/compose/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/tests/test_column_transformer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/tests/test_target.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/covariance'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_elliptic_envelope.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_empirical_covariance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_graph_lasso.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_robust_covariance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_shrunk_covariance.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/test_covariance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/test_elliptic_envelope.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/test_graphical_lasso.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/test_robust_covariance.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/_pls.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/tests/test_pls.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_california_housing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_covtype.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_kddcup99.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_lfw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_olivetti_faces.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_openml.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_rcv1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_samples_generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_species_distributions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_svmlight_format_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_twenty_newsgroups.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/data'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/descr'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/images'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/1'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/1119'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/2'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/292'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/3'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/40589'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/40675'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/40945'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/40966'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/561'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/61'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/62'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_20news.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_california_housing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_covtype.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_kddcup99.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_lfw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_olivetti_faces.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_openml.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_rcv1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_samples_generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_svmlight_format.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/decomposition'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_dict_learning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_factor_analysis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_incremental_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_kernel_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_lda.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_sparse_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_truncated_svd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_dict_learning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_factor_analysis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_fastica.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_incremental_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_kernel_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_nmf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_online_lda.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_sparse_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_truncated_svd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/dummy.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/ensemble'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_bagging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_forest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_gb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_gb_losses.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/binning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/predictor.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_binning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_bitset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_grower.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_histogram.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_monotonic_contraints.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_predictor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_warm_start.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_iforest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_stacking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_voting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_weight_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_bagging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_forest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_gradient_boosting_loss_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_iforest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_stacking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_voting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_weight_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/exceptions.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/experimental'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/enable_halving_search_cv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/enable_iterative_imputer.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests/test_enable_hist_gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests/test_enable_iterative_imputer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests/test_enable_successive_halving.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/externals'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/_arff.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/_lobpcg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/_pep562.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/_pilutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/_dict_vectorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/_hash.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/_stop_words.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/image.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/test_dict_vectorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/test_feature_hasher.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/test_image.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/test_text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_from_model.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_mutual_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_rfe.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_sequential.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_variance_threshold.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_chi2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_feature_select.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_from_model.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_mutual_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_rfe.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_sequential.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_variance_threshold.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/_gpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/_gpr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/kernels.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/_mini_sequence_kernel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/test_gpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/test_gpr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/test_kernels.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/impute'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/_iterative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/_knn.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/test_impute.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/test_knn.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/inspection'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_partial_dependence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_permutation_importance.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/partial_dependence.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/tests/test_plot_partial_dependence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/inspection/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/tests/test_partial_dependence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/tests/test_permutation_importance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/isotonic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/kernel_approximation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/kernel_ridge.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/linear_model'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_bayes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/glm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/link.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/tests/test_glm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/tests/test_link.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_huber.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_least_angle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_omp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_passive_aggressive.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_perceptron.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_ransac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_sag.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_theil_sen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_bayes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_huber.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_least_angle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_logistic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_omp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_passive_aggressive.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_perceptron.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_ransac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_ridge.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_sag.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_sgd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_sparse_coordinate_descent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_theil_sen.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/manifold'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_isomap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_locally_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_mds.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_spectral_embedding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_t_sne.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_isomap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_locally_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_mds.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_spectral_embedding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_t_sne.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_classification.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/confusion_matrix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/det_curve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/precision_recall_curve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/roc_curve.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_confusion_matrix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_curve_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_det_curve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_precision_recall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_roc_curve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_ranking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_scorer.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/_bicluster.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/_supervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/_unsupervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/test_bicluster.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/test_supervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/test_unsupervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/pairwise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_classification.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_pairwise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_ranking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_score_objects.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/mixture'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/_bayesian_mixture.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/_gaussian_mixture.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests/test_bayesian_mixture.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests/test_gaussian_mixture.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests/test_mixture.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/model_selection'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search_successive_halving.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_split.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/test_search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/test_split.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/test_successive_halving.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/test_validation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/multiclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/multioutput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/naive_bayes.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/neighbors'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_classification.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_graph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_kde.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_lof.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_nca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_nearest_centroid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_unsupervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_ball_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_dist_metrics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_graph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_kd_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_kde.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_lof.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_nca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_nearest_centroid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_neighbors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_neighbors_pipeline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_neighbors_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_quad_tree.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/neural_network'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_rbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_stochastic_optimizers.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/test_mlp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/test_rbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/test_stochastic_optimizers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/pipeline.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_label.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_discretization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_encoders.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_function_transformer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_label.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/random_projection.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/_label_propagation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/_self_training.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/tests/test_label_propagation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/tests/test_self_training.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/svm'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/_bounds.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/_classes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests/test_bounds.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests/test_sparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests/test_svm.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_calibration.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_check_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_discriminant_analysis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_docstring_parameters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_dummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_init.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_isotonic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_kernel_approximation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_kernel_ridge.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_metaestimators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_min_dependencies_readme.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_multiclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_multioutput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_naive_bayes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_pipeline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_random_projection.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/tree'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/_classes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/_export.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/_reingold_tilford.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests/test_export.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests/test_reingold_tilford.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests/test_tree.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/utils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_arpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_encode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_estimator_html_repr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_joblib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_mask.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_mocking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_show_versions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_testing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/class_weight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/estimator_checks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/extmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/fixes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/graph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/metaestimators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/multiclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/sparsefuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/stats.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/conftest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_arpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_arrayfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_class_weight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_cython_blas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_deprecation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_encode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_estimator_checks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_estimator_html_repr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_extmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_fast_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_fixes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_metaestimators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_mocking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_multiclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_murmurhash.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_parallel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_seq_dataset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_shortest_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_show_versions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_sparsefuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_testing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_validation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/socks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sockshandler.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/gelu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/hardshrink.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/lisht.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/mish.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/rrelu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/softshrink.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/sparsemax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/tanhshrink.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks/average_model_checkpoint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks/time_stopping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks/tqdm_progress_bar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/activations'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/image'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/layers'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/seq2seq'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/text'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/color_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/compose_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/connected_components.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/cutout_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/dense_image_warp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/distance_transform.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/distort_image_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/filters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/interpolate_spline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/resampler_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/sparse_image_warp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/transform_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/translate_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/gelu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/maxout.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/multihead_attention.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/netvlad.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/normalizations.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/optical_flow.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/poincare.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/polynomial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/sparsemax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/tlu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/wrappers.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/contrastive.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/focal_loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/giou_loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/lifted.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/metric_learning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/npairs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/quantiles.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/sparsemax_loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/triplet.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/cohens_kappa.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/f_scores.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/hamming.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/matthews_correlation_coefficient.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/multilabel_confusion_matrix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/r_square.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/average_wrapper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/conditional_gradient.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/cyclical_learning_rate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/lamb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/lazy_adam.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/lookahead.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/moving_average.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/novograd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/rectified_adam.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/stochastic_weight_averaging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/weight_decay_optimizers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/yogi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/options.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/register.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/rnn'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/rnn/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/rnn/cell.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/attention_wrapper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/basic_decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/beam_search_decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/sampler.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/testing'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/testing/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/testing/serialization.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text/crf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text/parse_time_op.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text/skip_gram_ops.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/ensure_tf_install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/keras_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/resource_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons-0.9.1.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/test_data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/test_data/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/test_data/env_metadata'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/test_data/env_metadata/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/test_pycosat.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/threadpoolctl-3.1.0.dist-info'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/threadpoolctl.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tqdm'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_dist_ver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_monitor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_tqdm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_tqdm_gui.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_tqdm_pandas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/asyncio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/auto.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/autonotebook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/cli.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tqdm/contrib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/bells.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/concurrent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/discord.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/itertools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/logging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/telegram.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/utils_worker.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/dask.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/gui.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/keras.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/notebook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/rich.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/std.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/tk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tqdm-4.63.0.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/typeguard'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/typeguard/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/typeguard/importhook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/typeguard/pytest_plugin.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/typeguard-2.13.3.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/_collections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/contrib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_appengine_environ.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_securetransport'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_securetransport/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_securetransport/bindings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_securetransport/low_level.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/appengine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/ntlmpool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/securetransport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/socks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/fields.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/filepost.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/packages'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/packages/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/packages/backports'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/packages/backports/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/packages/backports/makefile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/poolmanager.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/request.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/response.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/util'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/proxy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/queue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/request.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/response.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/ssl_.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/ssl_match_hostname.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/ssltransport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/timeout.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/url.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/wait.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3-1.26.8.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wget-3.2.dist-info'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wget.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/bdist_wheel.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel/cli'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/cli/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/cli/convert.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/cli/pack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/cli/unpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/macosx_libfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/metadata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/pkginfo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/util.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel/vendored'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/vendored/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel/vendored/packaging'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/vendored/packaging/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/vendored/packaging/_typing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/vendored/packaging/tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/wheelfile.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel-0.37.1-py3.9.egg-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/xontrib'...\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -Wi -OO /usr/local/lib/python3.6/compileall.py \\\n",
            "\t-d /usr/local/lib/python3.6/site-packages -f \\\n",
            "\t-x badsyntax /usr/local/lib/python3.6/site-packages\n",
            "Listing '/usr/local/lib/python3.6/site-packages'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/OpenSSL'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/OpenSSL/SSL.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/OpenSSL/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/OpenSSL/_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/OpenSSL/crypto.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/OpenSSL/debug.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/OpenSSL/rand.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/OpenSSL/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/PySocks-1.7.1.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/_distutils_hack'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/_distutils_hack/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/_distutils_hack/override.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/brotli'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/brotli/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/brotli/brotli.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/brotli/build.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/brotlipy-0.7.0-py3.6.egg-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/certifi'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/certifi/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/certifi/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/certifi/core.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/certifi-2021.5.30-py3.6.egg-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cffi'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/backend_ctypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/cffi_opcode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/commontypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/cparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/error.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/ffiplatform.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/lock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/model.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/pkgconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/recompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/setuptools_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/vengine_cpy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/vengine_gen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cffi/verifier.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cffi-1.14.6.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/charset_normalizer'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/api.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/charset_normalizer/assets'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/assets/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/cd.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/charset_normalizer/cli'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/cli/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/cli/normalizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/constant.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/legacy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/md.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/models.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/charset_normalizer/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/charset_normalizer-2.0.4.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/colorama'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/colorama/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/colorama/ansi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/colorama/ansitowin32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/colorama/initialise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/colorama/win32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/colorama/winterm.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/colorama-0.4.4.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/appdirs.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/_vendor'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/_vendor/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/_vendor/boltons'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/_vendor/boltons/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/_vendor/boltons/timeutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/_vendor/five.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/_vendor/six.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/collection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/configuration.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/crypt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/decorators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/deprecation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/entity.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/factory.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/ish.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/logz.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/packaging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/auxlib/type_coercion.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor/boltons'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/boltons/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/boltons/setutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/boltons/timeutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/cpuinfo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/distro.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/frozendict.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor/toolz'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/toolz/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/toolz/compatibility.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/toolz/dicttoolz.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/toolz/itertoolz.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/toolz/recipes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/toolz/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/_main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/_monitor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/_tqdm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/asyncio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/auto.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/cli.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/contrib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/contrib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/contrib/concurrent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/contrib/itertools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/std.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/tqdm/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor/urllib3'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/urllib3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/urllib3/exceptions.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/_vendor/urllib3/util'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/urllib3/util/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/_vendor/urllib3/util/url.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/activate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/api.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/base'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/base/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/base/constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/base/context.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/base/exceptions.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/cli'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/activate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/conda_argparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/find_commands.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_clean.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_compare.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_create.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_init.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_list.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_package.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_pip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_remove.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_run.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/main_update.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/parsers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/cli/python_api.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/common'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/_logic.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/common/_os'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/_os/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/_os/linux.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/_os/unix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/_os/windows.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/configuration.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/cuda.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/decorators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/disk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/logic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/path.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/common/pkg_formats'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/pkg_formats/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/pkg_formats/python.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/serialize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/signals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/toposort.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/common/url.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/compat.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/core'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/envs_manager.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/initialize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/link.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/package_cache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/package_cache_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/path_actions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/portability.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/prefix_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/solve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/core/subdir_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/exports.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/gateways'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/anaconda_client.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/gateways/connection'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/connection/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/gateways/connection/adapters'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/connection/adapters/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/connection/adapters/ftp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/connection/adapters/localfs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/connection/adapters/s3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/connection/download.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/connection/session.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/gateways/disk'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/disk/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/disk/create.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/disk/delete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/disk/link.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/disk/permissions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/disk/read.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/disk/test.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/disk/update.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/logging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/gateways/subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/history.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/instructions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/lock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/misc.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/models'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/channel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/dist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/enums.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/leased_path_entry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/match_spec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/package_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/prefix_graph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/records.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/models/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/plan.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/resolve.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell/Library'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell/Library/bin'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell/Scripts'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell/bin'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell/condabin'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell/etc'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell/etc/fish'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell/etc/fish/conf.d'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda/shell/etc/profile.d'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda-4.10.3-py3.6.egg-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda_env'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda_env/cli'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/main_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/main_create.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/main_export.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/main_list.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/main_remove.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/main_update.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/cli/main_vars.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/env.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/exceptions.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda_env/installers'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/installers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/installers/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/installers/conda.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/installers/pip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/pip_util.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda_env/specs'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/specs/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/specs/binstar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/specs/notebook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/specs/requirements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_env/specs/yaml_file.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda_package_handling'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/archive_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/cli.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/conda_fmt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/interface.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/tarball.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/conda_package_handling/validate.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/conda_package_handling-1.7.3.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/__about__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/fernet.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/_oid.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/interfaces.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/aead.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/backend.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/ciphers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/cmac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/decode_asn1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/dh.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/dsa.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/ec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/ed25519.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/ed448.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/encode_asn1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/hashes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/hmac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/poly1305.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/rsa.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/x25519.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/x448.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/x509.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/bindings'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/bindings/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/bindings/_rust'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/bindings/openssl'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/bindings/openssl/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/bindings/openssl/_conditional.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/bindings/openssl/binding.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/_asymmetric.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/_cipheralgorithm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/_serialization.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/dh.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/dsa.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/ec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/ed25519.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/ed448.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/padding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/rsa.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/x25519.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/asymmetric/x448.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/ciphers'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/ciphers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/ciphers/aead.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/ciphers/algorithms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/ciphers/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/ciphers/modes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/cmac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/constant_time.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/hashes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/hmac.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/kdf'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/kdf/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/kdf/concatkdf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/kdf/hkdf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/kdf/kbkdf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/kdf/pbkdf2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/kdf/scrypt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/kdf/x963kdf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/keywrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/padding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/poly1305.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/serialization'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/serialization/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/serialization/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/serialization/pkcs12.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/serialization/pkcs7.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/serialization/ssh.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/twofactor'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/twofactor/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/twofactor/hotp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/hazmat/primitives/twofactor/totp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography/x509'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/x509/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/x509/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/x509/certificate_transparency.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/x509/extensions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/x509/general_name.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/x509/name.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/x509/ocsp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/cryptography/x509/oid.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/cryptography-35.0.0.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/idna'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/idna/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/idna/codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/idna/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/idna/core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/idna/idnadata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/idna/intranges.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/idna/package_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/idna/uts46data.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/idna-3.3.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/joblib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/_cloudpickle_wrapper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/_dask.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/_deprecated_format_stack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/_deprecated_my_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/_memmapping_reducer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/_multiprocessing_helpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/_parallel_backends.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/_store_backends.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/backports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/compressor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/disk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/executor.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/joblib/externals'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/joblib/externals/cloudpickle'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/cloudpickle/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/cloudpickle/cloudpickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/cloudpickle/cloudpickle_fast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/cloudpickle/compat.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/joblib/externals/loky'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/_base.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/_posix_reduction.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/_posix_wait.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/_win_reduction.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/_win_wait.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/compat_posix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/compat_win32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/context.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/fork_exec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/managers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/popen_loky_posix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/popen_loky_win32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/process.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/queues.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/reduction.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/resource_tracker.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semlock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/synchronize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/cloudpickle_wrapper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/initializers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/externals/loky/reusable_executor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/format_stack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/func_inspect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/hashing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/logger.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/memory.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/my_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/numpy_pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/numpy_pickle_compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/numpy_pickle_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/parallel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/pool.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/joblib/test'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/common.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/joblib/test/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/data/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/data/create_numpy_pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_backports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_cloudpickle_wrapper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_dask.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_deprecated_objects.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_disk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_format_stack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_func_inspect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_func_inspect_special_encoding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_hashing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_init.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_logger.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_memmapping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_memory.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_missing_multiprocessing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_my_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_numpy_pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_numpy_pickle_compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_numpy_pickle_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_parallel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_store_backends.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_testing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/test/testutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/joblib/testing.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/joblib-1.1.1.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/min2net'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/loss.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/min2net/model'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/model/DeepConvNet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/model/EEGNet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/model/MIN2Net.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/model/MIN2Net_without_decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/model/MIN2Net_without_triplet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/model/SVM.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/model/SpectralSpatialCNN.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/model/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/min2net/preprocessing'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/BCIC2a'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/BCIC2a/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/BCIC2a/fbcsp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/BCIC2a/raw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/BCIC2a/spectral_spatial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/BCIC2a/time_domain.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/FBCSP.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/OpenBMI'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/OpenBMI/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/OpenBMI/fbcsp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/OpenBMI/raw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/OpenBMI/spectral_spatial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/OpenBMI/time_domain.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/SMR_BCI'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/SMR_BCI/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/SMR_BCI/fbcsp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/SMR_BCI/raw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/SMR_BCI/spectral_spatial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/SMR_BCI/time_domain.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/SpectralSpatialMapping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/preprocessing/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/min2net/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/min2net-1.0.1.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/__config__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/_distributor_init.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/_globals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/_pytesttester.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/compat'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/compat/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/compat/_inspect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/compat/py3k.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/compat/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/compat/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/compat/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/compat/tests/test_compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/core'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_add_newdocs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_asarray.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_dtype.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_dtype_ctypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_internal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_methods.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_string_helpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_type_aliases.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/_ufunc_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/arrayprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/cversions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/defchararray.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/einsumfunc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/fromnumeric.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/function_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/generate_numpy_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/getlimits.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/core/include'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/core/include/numpy'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/core/include/numpy/random'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/core/lib'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/core/lib/npy-pkg-config'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/machar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/memmap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/multiarray.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/numerictypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/overrides.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/records.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/setup_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/shape_base.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/core/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/_locales.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/core/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test__exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_arrayprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_conversion_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_cpu_features.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_datetime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_defchararray.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_deprecations.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_dtype.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_einsum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_errstate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_extint128.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_function_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_getlimits.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_half.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_indexerrors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_indexing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_item_selection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_longdouble.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_machar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_mem_overlap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_memmap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_multiarray.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_nditer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_numeric.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_numerictypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_overrides.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_print.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_protocols.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_records.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_scalar_ctors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_scalar_methods.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_scalarbuffer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_scalarinherit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_scalarmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_scalarprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_shape_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_ufunc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_umath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_umath_accuracy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_umath_complex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/tests/test_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/umath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/core/umath_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ctypeslib.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/distutils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/__config__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/_shell_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/ccompiler.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/distutils/command'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/autodist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/bdist_rpm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/build_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/build_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/build_py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/build_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/build_src.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/config_compiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/develop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/egg_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/install_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/install_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/install_headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/command/sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/conv_template.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/cpuinfo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/exec_command.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/extension.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/absoft.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/compaq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/environment.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/g95.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/gnu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/hpux.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/ibm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/intel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/lahey.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/mips.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/nag.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/none.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/nv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/pathf95.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/pg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/sun.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/fcompiler/vast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/from_template.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/intelccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/lib2def.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/line_endings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/log.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/distutils/mingw'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/mingw32ccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/misc_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/msvc9compiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/npy_pkg_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/numpy_distribution.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/pathccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/system_info.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_exec_command.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_fcompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_fcompiler_gnu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_fcompiler_intel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_fcompiler_nagfor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_from_template.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_mingw32ccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_misc_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_npy_pkg_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_shell_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/tests/test_system_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/distutils/unixccompiler.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/doc'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/basics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/broadcasting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/byteswapping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/creation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/dispatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/glossary.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/indexing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/internals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/misc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/structured_arrays.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/subclassing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/doc/ufuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/dual.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/__version__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/auxfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/capi_maps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/cb_rules.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/cfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/common_rules.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/crackfortran.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/diagnose.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/f2py2e.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/f2py_testing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/f90mod_rules.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/func2subr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/rules.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/src'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src/array_from_pyobj'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src/assumed_shape'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src/common'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src/kind'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src/mixed'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src/parameter'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src/regression'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src/size'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/src/string'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_array_from_pyobj.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_assumed_shape.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_block_docstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_callback.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_compile_function.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_crackfortran.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_kind.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_mixed.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_parameter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_quoted_character.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_return_character.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_return_complex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_return_integer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_return_logical.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_return_real.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_semicolon_split.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_size.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/test_string.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/tests/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/f2py/use_rules.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/fft'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/fft/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/fft/_pocketfft.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/fft/helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/fft/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/fft/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/fft/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/fft/tests/test_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/fft/tests/test_pocketfft.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/lib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/_datasource.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/_iotools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/arraypad.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/arraysetops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/arrayterator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/financial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/format.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/function_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/histograms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/index_tricks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/mixins.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/nanfunctions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/npyio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/polynomial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/recfunctions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/scimath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/shape_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/stride_tricks.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/lib/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test__datasource.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test__iotools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test__version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_arraypad.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_arraysetops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_arrayterator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_financial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_format.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_function_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_histograms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_index_tricks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_mixins.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_nanfunctions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_packbits.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_polynomial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_recfunctions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_shape_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_stride_tricks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_twodim_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_type_check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_ufunclike.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/tests/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/twodim_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/type_check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/ufunclike.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/user_array.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/lib/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/linalg'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/linalg/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/linalg/linalg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/linalg/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/linalg/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/linalg/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/linalg/tests/test_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/linalg/tests/test_deprecations.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/linalg/tests/test_linalg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/linalg/tests/test_regression.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/ma'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/bench.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/extras.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/mrecords.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/ma/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/tests/test_core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/tests/test_deprecations.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/tests/test_extras.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/tests/test_mrecords.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/tests/test_old_ma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/tests/test_subclassing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/testutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/ma/timer_comparison.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matlib.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/matrixlib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/tests/test_defmatrix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/tests/test_interaction.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/tests/test_masked_matrix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/tests/test_matrix_linalg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/tests/test_multiarray.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/tests/test_numeric.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/matrixlib/tests/test_regression.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/polynomial'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/_polybase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/chebyshev.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/hermite.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/hermite_e.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/laguerre.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/legendre.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/polynomial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/polyutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/test_chebyshev.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/test_classes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/test_hermite.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/test_hermite_e.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/test_laguerre.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/test_legendre.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/test_polynomial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/test_polyutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/polynomial/tests/test_printing.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/random'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/random/_examples'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/random/_examples/cffi'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/_examples/cffi/extending.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/_examples/cffi/parse.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/random/_examples/cython'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/_examples/cython/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/random/_examples/numba'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/_examples/numba/extending.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/_examples/numba/extending_distributions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/_pickle.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/random/lib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/random/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/random/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/data/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_direct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_extending.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_generator_mt19937.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_generator_mt19937_regressions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_randomstate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_randomstate_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_seed_sequence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/random/tests/test_smoke.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/testing'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/testing/_private'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/_private/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/_private/decorators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/_private/noseclasses.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/_private/nosetester.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/_private/parameterized.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/_private/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/print_coercion_tables.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/testing/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/tests/test_decorators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/tests/test_doctesting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/tests/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/testing/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/tests/test_ctypeslib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/tests/test_matlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/tests/test_numpy_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/tests/test_public_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/tests/test_reloading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/tests/test_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/tests/test_warnings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/numpy/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy-1.19.5.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/numpy.libs'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/build_env.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cache.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/cli'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/autocompletion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/base_command.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/cmdoptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/command_context.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/main_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/progress_bars.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/req_command.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/spinners.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/cli/status_codes.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/commands'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/cache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/completion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/configuration.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/debug.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/download.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/freeze.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/hash.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/list.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/show.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/uninstall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/commands/wheel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/configuration.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/distributions'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/distributions/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/distributions/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/distributions/installed.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/distributions/sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/distributions/wheel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/exceptions.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/index'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/index/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/index/collector.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/index/package_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/index/sources.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/locations'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/locations/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/locations/_distutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/locations/_sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/locations/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/main.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/metadata'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/metadata/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/metadata/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/metadata/pkg_resources.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/models'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/candidate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/direct_url.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/format_control.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/link.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/scheme.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/search_scope.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/selection_prefs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/target_python.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/models/wheel.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/network'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/network/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/network/auth.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/network/cache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/network/download.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/network/lazy_wheel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/network/session.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/network/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/network/xmlrpc.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/operations'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/build'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/build/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/build/metadata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/build/metadata_legacy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/build/wheel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/build/wheel_legacy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/freeze.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/install'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/install/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/install/editable_legacy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/install/legacy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/install/wheel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/operations/prepare.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/pyproject.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/req'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/req/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/req/constructors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/req/req_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/req/req_install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/req/req_set.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/req/req_tracker.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/req/req_uninstall.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/base.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/legacy'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/legacy/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/legacy/resolver.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/candidates.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/factory.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/provider.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/reporter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/requirements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/resolver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/self_outdated_check.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/utils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/_log.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/appdirs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/compatibility_tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/datetime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/deprecation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/direct_url_helpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/distutils_args.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/encoding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/entrypoints.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/filesystem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/filetypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/glibc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/hashes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/inject_securetransport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/logging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/misc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/models.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/packaging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/parallel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/pkg_resources.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/setuptools_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/temp_dir.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/unpacking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/urls.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/virtualenv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/utils/wheel.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_internal/vcs'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/vcs/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/vcs/bazaar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/vcs/git.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/vcs/mercurial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/vcs/subversion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/vcs/versioncontrol.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_internal/wheel_builder.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/appdirs.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/_cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/adapter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/cache.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/caches'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/caches/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/caches/redis_cache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/controller.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/filewrapper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/heuristics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/serialize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/cachecontrol/wrapper.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/certifi'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/certifi/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/certifi/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/certifi/core.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/big5freq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/big5prober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/chardistribution.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/charsetgroupprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/charsetprober.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/cli'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/cli/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/cli/chardetect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/codingstatemachine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/cp949prober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/enums.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/escprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/escsm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/eucjpprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/euckrfreq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/euckrprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/euctwfreq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/euctwprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/gb2312freq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/gb2312prober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/hebrewprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/jisfreq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/jpcntx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/langbulgarianmodel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/langgreekmodel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/langhebrewmodel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/langhungarianmodel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/langrussianmodel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/langthaimodel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/langturkishmodel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/latin1prober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/mbcharsetprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/mbcsgroupprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/mbcssm.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/metadata'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/metadata/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/metadata/languages.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/sbcharsetprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/sbcsgroupprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/sjisprober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/universaldetector.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/utf8prober.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/chardet/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/colorama'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/colorama/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/colorama/ansi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/colorama/ansitowin32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/colorama/initialise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/colorama/win32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/colorama/winterm.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/_backport'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/_backport/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/_backport/misc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/_backport/shutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/_backport/sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/_backport/tarfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/database.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/locators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/manifest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/markers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/metadata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/resources.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distlib/wheel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/distro.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/_ihatexml.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/_inputstream.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/_tokenizer.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/_trie'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/_trie/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/_trie/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/_trie/py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/constants.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/filters'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/filters/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/filters/alphabeticalattributes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/filters/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/filters/inject_meta_charset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/filters/lint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/filters/optionaltags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/filters/sanitizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/filters/whitespace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/html5parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/serializer.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treeadapters'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treeadapters/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treeadapters/genshi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treeadapters/sax.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treebuilders'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treebuilders/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treebuilders/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treebuilders/dom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treebuilders/etree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treebuilders/etree_lxml.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treewalkers'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treewalkers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treewalkers/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treewalkers/dom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treewalkers/etree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treewalkers/etree_lxml.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/html5lib/treewalkers/genshi.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/idna'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/idna/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/idna/codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/idna/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/idna/core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/idna/idnadata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/idna/intranges.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/idna/package_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/idna/uts46data.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/msgpack'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/msgpack/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/msgpack/_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/msgpack/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/msgpack/ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/msgpack/fallback.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/__about__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/_manylinux.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/_musllinux.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/_structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/markers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/requirements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/specifiers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/packaging/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/_in_process.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/colorlog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/dirtools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/envbuild.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/in_process'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/in_process/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/in_process/_in_process.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/meta.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/wrappers.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pkg_resources/py31compat.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/progress'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/progress/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/progress/bar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/progress/counter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/progress/spinner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/pyparsing.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/__version__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/_internal_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/adapters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/auth.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/certs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/cookies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/hooks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/models.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/packages.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/sessions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/status_codes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/resolvelib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/resolvelib/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/resolvelib/compat'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/resolvelib/compat/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/resolvelib/compat/collections_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/resolvelib/providers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/resolvelib/reporters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/resolvelib/resolvers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/resolvelib/structs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/six.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/_asyncio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/after.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/before.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/before_sleep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/nap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/retry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/stop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/tornadoweb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tenacity/wait.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/tomli'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tomli/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tomli/_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/tomli/_re.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/_collections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/connectionpool.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/_appengine_environ.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/_securetransport'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/_securetransport/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/_securetransport/bindings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/appengine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/ntlmpool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/securetransport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/contrib/socks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/fields.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/filepost.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/packages'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/packages/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/packages/backports'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/packages/backports/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/packages/backports/makefile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/packages/six.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/packages/ssl_match_hostname'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/packages/ssl_match_hostname/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/packages/ssl_match_hostname/_implementation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/poolmanager.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/request.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/response.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/proxy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/queue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/request.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/response.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/retry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/ssl_.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/ssltransport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/timeout.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/url.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/urllib3/util/wait.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip/_vendor/webencodings'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/webencodings/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/webencodings/labels.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/webencodings/mklabels.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/webencodings/tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pip/_vendor/webencodings/x_user_defined.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip-18.1.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pip-21.2.2-py3.6.egg-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pkg_resources'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/appdirs.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/__about__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/_compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/_structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/_typing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/markers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/requirements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/specifiers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/_vendor/pyparsing.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pkg_resources/extern'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/extern/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pkg_resources/tests'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pkg_resources/tests/data'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pkg_resources/tests/data/my-test-package-source'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pkg_resources/tests/data/my-test-package-source/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pyOpenSSL-22.0.0.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pycparser'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/_ast_gen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/_build_tables.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/ast_transforms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/c_ast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/c_generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/c_lexer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/c_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/lextab.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pycparser/ply'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/ply/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/ply/cpp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/ply/ctokens.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/ply/lex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/ply/yacc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/ply/ygen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/plyparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/pycparser/yacctab.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/pycparser-2.21.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/requests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/__version__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/_internal_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/adapters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/auth.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/certs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/cookies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/hooks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/models.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/packages.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/sessions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/status_codes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/requests/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/requests-2.27.1.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/ruamel_yaml'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/anchor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/comments.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/composer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/configobjwalker.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/constructor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/cyaml.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/dumper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/emitter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/error.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/events.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/ruamel_yaml/ext'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/ext/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/nodes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/reader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/representer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/resolver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/scalarbool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/scalarfloat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/scalarint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/scalarstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/scanner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/serializer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/timestamp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/tokens.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/ruamel_yaml/util.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/ruamel_yaml_conda-0.15.100.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scikit_learn-0.24.2.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scikit_learn.libs'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/__config__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/_build_utils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_build_utils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_build_utils/_fortran.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_build_utils/compiler_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_build_utils/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_build_utils/system_info.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/_build_utils/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_build_utils/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_build_utils/tests/test_circular_imports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_build_utils/tests/test_scipy_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_distributor_init.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/_lib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_ccallback.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_gcutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_pep440.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_testutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_threadsafety.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_tmpdirs.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/_lib/_uarray'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_uarray/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_uarray/_backend.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_uarray/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/decorator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/deprecation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/doccer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test__gcutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test__pep440.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test__testutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test__threadsafety.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test__util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test_ccallback.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test_deprecation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test_import_cycles.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test_tmpdirs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/tests/test_warnings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/_lib/uarray.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/cluster'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/cluster/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/cluster/hierarchy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/cluster/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/cluster/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/cluster/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/cluster/tests/hierarchy_test_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/cluster/tests/test_hierarchy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/cluster/tests/test_vq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/cluster/vq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/constants'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/constants/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/constants/codata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/constants/constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/constants/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/constants/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/constants/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/constants/tests/test_codata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/constants/tests/test_constants.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/fft'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_backend.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_debug_backends.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_helper.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft/basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft/helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft/realtransforms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft/tests/test_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_pocketfft/tests/test_real_transforms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/_realtransforms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/fft/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/tests/mock_backend.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/tests/test_backend.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/tests/test_fft_function.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/tests/test_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/tests/test_multithreading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/tests/test_numpy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fft/tests/test_real_transforms.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/fftpack'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/pseudo_diffs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/realtransforms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/fftpack/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/tests/gen_fftw_ref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/tests/gendata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/tests/test_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/tests/test_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/tests/test_import.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/tests/test_pseudo_diffs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/fftpack/tests/test_real_transforms.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/integrate'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_bvp.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/bdf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/dop853_coefficients.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/ivp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/lsoda.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/radau.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/rk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/tests/test_ivp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ivp/tests/test_rk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_ode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_quad_vec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/_quadrature.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/odepack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/quadpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/integrate/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/tests/test__quad_vec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/tests/test_banded_ode_solvers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/tests/test_bvp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/tests/test_integrate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/tests/test_odeint_jac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/tests/test_quadpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/integrate/tests/test_quadrature.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/interpolate'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/_bsplines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/_cubic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/_fitpack_impl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/_pade.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/fitpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/fitpack2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/interpnd_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/interpolate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/ndgriddata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/polyint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/rbf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_bsplines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_fitpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_fitpack2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_gil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_interpnd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_interpolate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_ndgriddata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_pade.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_polyint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_rbf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/interpolate/tests/test_regression.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/_fortran.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/arff'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/arff/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/arff/arffread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/arff/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/arff/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/arff/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/arff/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/arff/tests/test_arffread.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/harwell_boeing'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/harwell_boeing/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/harwell_boeing/_fortran_format_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/harwell_boeing/hb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/harwell_boeing/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/harwell_boeing/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/harwell_boeing/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/harwell_boeing/tests/test_fortran_format.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/harwell_boeing/tests/test_hb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/idl.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/matlab'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/byteordercodes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/mio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/mio4.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/mio5.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/mio5_params.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/miobase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/test_byteordercodes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/test_mio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/test_mio5_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/test_mio_funcs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/test_mio_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/test_miobase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/test_pathological.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/matlab/tests/test_streams.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/mmio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/netcdf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/io/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/tests/test_fortran.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/tests/test_idl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/tests/test_mmio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/tests/test_netcdf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/tests/test_paths.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/tests/test_wavfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/io/wavfile.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_cython_signature_generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_decomp_cossin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_decomp_ldl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_decomp_polar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_decomp_qz.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_expm_frechet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_generate_pyx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_interpolative_backend.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_matfuncs_inv_ssq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_matfuncs_sqrtm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_procrustes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_sketches.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_solvers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/_testutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/blas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_cholesky.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_lu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_qr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_schur.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/decomp_svd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/flinalg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/interpolative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/lapack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/matfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/misc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/special_matrices.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/src'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/src/id_dist'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/src/id_dist/doc'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/src/lapack_deprecations'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_blas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_cython_blas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_cython_lapack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_cholesky.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_cossin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_ldl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_polar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_decomp_update.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_fblas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_interpolative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_lapack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_matfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_procrustes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_sketches.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_solve_toeplitz.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_solvers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/linalg/tests/test_special_matrices.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/misc'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/doccer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/misc/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/misc/tests/test_doccer.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/ndimage'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/_ni_docstrings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/filters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/fourier.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/interpolation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/measurements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/morphology.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_c_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_datatypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_filters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_measurements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_morphology.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_ndimage.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/ndimage/tests/test_splines.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/odr'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/_add_newdocs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/models.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/odrpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/odr/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/odr/tests/test_odr.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_basinhopping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_constraints.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_differentialevolution.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_dual_annealing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_hessian_update_strategy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog_ip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog_rs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog_simplex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_linprog_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsap.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/bvls.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/dogbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/least_squares.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/lsq_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/trf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_lsq/trf_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_minimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_nnls.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_numdiff.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_remove_redundancy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_root.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_root_scalar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo_lib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo_lib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo_lib/sobol_seq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_shgo_lib/triangulation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_spectral.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trlib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trlib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trlib/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/canonical_constraint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/equality_constrained_sqp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/projections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/qp_subproblem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/report.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/test_canonical_constraint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/test_projections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/test_qp_subproblem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tests/test_report.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_constr/tr_interior_point.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_dogleg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_exact.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_krylov.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_trustregion_ncg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/_tstutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/cobyla.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/cython_optimize'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/cython_optimize/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/lbfgsb_src'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/linesearch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/minpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/nonlin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/slsqp.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__basinhopping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__differential_evolution.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__dual_annealing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__linprog_clean_inputs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__numdiff.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__remove_redundancy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__root.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__shgo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test__spectral.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_cobyla.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_constraint_conversion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_constraints.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_cython_optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_differentiable_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_hessian_update_strategy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_lbfgsb_hessinv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_lbfgsb_setulb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_least_squares.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_linear_assignment.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_linesearch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_linprog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_lsq_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_lsq_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_minimize_constrained.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_minpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_nnls.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_nonlin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_slsqp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_tnc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_trustregion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_trustregion_exact.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_trustregion_krylov.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tests/test_zeros.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/tnc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/optimize/zeros.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/signal'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_arraytools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_max_len_seq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_peak_finding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_savitzky_golay.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/_upfirdn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/bsplines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/filter_design.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/fir_filter_design.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/lti_conversion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/ltisys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/signaltools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/spectral.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/signal/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/mpsig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_array_tools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_bsplines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_cont2discrete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_dltisys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_filter_design.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_fir_filter_design.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_ltisys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_max_len_seq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_peak_finding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_savitzky_golay.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_signaltools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_spectral.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_upfirdn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_waveforms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_wavelets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/tests/test_windows.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/waveforms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/wavelets.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/signal/windows'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/windows/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/windows/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/signal/windows/windows.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/_index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/_matrix_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/bsr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/compressed.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/construct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/coo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csc.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/_laplacian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/_validation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_connected_components.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_conversions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_flow.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_graph_laplacian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_matching.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_reordering.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_shortest_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_spanning_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csgraph/tests/test_traversal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/csr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/dia.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/dok.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/extract.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/generate_sparsetools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/lil.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/_expm_multiply.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/_norm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/_onenormest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/SuperLU'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/_add_newdocs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/linsolve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/dsolve/tests/test_linsolve.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/ARPACK'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/arpack/tests/test_arpack.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/lobpcg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/lobpcg/tests/test_lobpcg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/eigen/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/interface.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/_gcrotmk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/iterative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/lgmres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/lsmr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/lsqr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/minres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/demo_lgmres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_gcrotmk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_iterative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_lgmres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_lsmr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_lsqr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_minres.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/tests/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/matfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_expm_multiply.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_interface.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_matfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_norm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_onenormest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/linalg/tests/test_pydata_sparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/sparsetools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/spfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/sputils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_construct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_csc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_csr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_extract.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_matrix_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_sparsetools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_spfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/sparse/tests/test_sputils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/_geometric_slerp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/_plotutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/_procrustes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/_spherical_voronoi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/kdtree.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/qhull_src'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test__plotutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test__procrustes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_distance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_hausdorff.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_kdtree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_qhull.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_slerp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/tests/test_spherical_voronoi.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/_rotation_groups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/_rotation_spline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/rotation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests/test_rotation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests/test_rotation_groups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/spatial/transform/tests/test_rotation_spline.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/special'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_ellip_harm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_generate_pyx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_lambertw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_logsumexp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_mptestutils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/expn_asy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/gammainc_asy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/gammainc_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/lambertw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/loggamma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/struve_convergence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/wrightomega.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_precompute/zetac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_spherical_bessel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/_testutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/add_newdocs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/orthogonal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/sf_error.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/spfun_stats.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/special/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/special/tests/data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_bdtr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_boxcox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_cdflib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_cython_special.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_digamma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_ellip_harm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_erfinv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_exponential_integrals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_faddeeva.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_gamma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_gammainc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_hypergeometric.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_kolmogorov.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_lambertw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_log_softmax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_loggamma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_logit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_logsumexp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_mpmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_nan_inputs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_ndtr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_orthogonal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_orthogonal_eval.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_owens_t.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_pcf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_pdtr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_precompute_expn_asy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_precompute_gammainc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_precompute_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_round.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_sf_error.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_sici.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_spence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_spfun_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_sph_harm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_spherical_bessel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_trig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_wrightomega.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/special/tests/test_zeta.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_binned_statistic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_discrete_distns.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_distr_params.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_hypotests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_ksstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_multivariate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_rvs_sampling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_stats_mstats_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_tukeylambda_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/_wilcoxon_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/contingency.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/distributions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/kde.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/morestats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/mstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/mstats_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/mstats_extras.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/stats.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/common_tests.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/data'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/data/nist_anova'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/data/nist_linregress'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_binned_statistic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_contingency.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_continuous_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_discrete_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_discrete_distns.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_distributions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_fit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_kdeoth.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_morestats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_mstats_basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_mstats_extras.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_multivariate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_rank.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/stats/tests/test_tukeylambda_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/scipy/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy-1.5.4.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/scipy.libs'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_deprecation_warning.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_distutils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/_msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/archive_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/bcppcompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/ccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/cmd.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist_dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist_msi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist_rpm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/bdist_wininst.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build_py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/build_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/clean.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_egg_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_lib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/install_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/py37compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/register.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/command/upload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/cygwinccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/debug.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/dep_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/dir_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/dist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/errors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/extension.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/fancy_getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/file_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/log.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/msvc9compiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/py35compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/py38compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/text_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/unixccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_distutils/versionpredicate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_imp.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_vendor'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/more_itertools'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/more_itertools/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/more_itertools/more.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/more_itertools/recipes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/ordered_set.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/__about__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/_compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/_structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/_typing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/markers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/requirements.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/specifiers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/packaging/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/_vendor/pyparsing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/archive_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/build_meta.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/command'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/alias.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/bdist_egg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/bdist_rpm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/build_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/build_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/build_py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/develop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/dist_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/easy_install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/egg_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/install_egg_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/install_lib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/install_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/py36compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/register.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/rotate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/saveopts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/setopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/test.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/upload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/command/upload_docs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/dep_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/depends.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/dist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/errors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/extension.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools/extern'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/extern/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/glob.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/installer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/launch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/monkey.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/msvc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/namespaces.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/package_index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/py34compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/sandbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/unicode_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/wheel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/setuptools/windows_support.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools-40.6.2.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/setuptools-58.0.4-py3.6.egg-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/six-1.16.0.dist-info'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/six.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/__check_build'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/__check_build/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/__check_build/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/_build_utils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_build_utils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_build_utils/openmp_helpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_build_utils/pre_build_helpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_distributor_init.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/_loss'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_loss/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_loss/glm_distribution.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/_loss/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_loss/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_loss/tests/test_glm_distribution.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/_min_dependencies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/calibration.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/cluster'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_affinity_propagation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_agglomerative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_bicluster.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_birch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_dbscan.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_feature_agglomeration.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_kmeans.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_mean_shift.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_optics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/_spectral.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_affinity_propagation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_bicluster.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_birch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_dbscan.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_feature_agglomeration.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_hierarchical.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_k_means.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_mean_shift.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_optics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cluster/tests/test_spectral.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/compose'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/_target.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/compose/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/tests/test_column_transformer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/compose/tests/test_target.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/covariance'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_elliptic_envelope.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_empirical_covariance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_graph_lasso.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_robust_covariance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/_shrunk_covariance.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/test_covariance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/test_elliptic_envelope.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/test_graphical_lasso.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/covariance/tests/test_robust_covariance.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/_pls.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/cross_decomposition/tests/test_pls.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_california_housing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_covtype.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_kddcup99.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_lfw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_olivetti_faces.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_openml.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_rcv1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_samples_generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_species_distributions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_svmlight_format_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/_twenty_newsgroups.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/data'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/descr'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/images'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/1'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/1119'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/2'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/292'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/3'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/40589'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/40675'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/40945'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/40966'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/561'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/61'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/data/openml/62'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_20news.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_california_housing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_covtype.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_kddcup99.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_lfw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_olivetti_faces.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_openml.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_rcv1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_samples_generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/datasets/tests/test_svmlight_format.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/decomposition'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_dict_learning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_factor_analysis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_incremental_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_kernel_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_lda.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_nmf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_sparse_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/_truncated_svd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_dict_learning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_factor_analysis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_fastica.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_incremental_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_kernel_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_nmf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_online_lda.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_sparse_pca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/decomposition/tests/test_truncated_svd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/dummy.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/ensemble'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_bagging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_forest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_gb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_gb_losses.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/binning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/predictor.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_binning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_bitset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_grower.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_histogram.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_monotonic_contraints.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_predictor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_warm_start.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_iforest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_stacking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_voting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_weight_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_bagging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_forest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_gradient_boosting_loss_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_iforest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_stacking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_voting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/ensemble/tests/test_weight_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/exceptions.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/experimental'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/enable_halving_search_cv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/enable_iterative_imputer.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests/test_enable_hist_gradient_boosting.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests/test_enable_iterative_imputer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/experimental/tests/test_enable_successive_halving.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/externals'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/_arff.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/_lobpcg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/_pep562.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/_pilutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/externals/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/_dict_vectorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/_hash.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/_stop_words.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/image.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/test_dict_vectorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/test_feature_hasher.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/test_image.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/tests/test_text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_from_model.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_mutual_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_rfe.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_sequential.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/_variance_threshold.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_chi2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_feature_select.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_from_model.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_mutual_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_rfe.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_sequential.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/tests/test_variance_threshold.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/_gpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/_gpr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/kernels.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/_mini_sequence_kernel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/test_gpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/test_gpr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/tests/test_kernels.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/impute'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/_iterative.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/_knn.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/test_impute.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/impute/tests/test_knn.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/inspection'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_partial_dependence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_permutation_importance.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/partial_dependence.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/_plot/tests/test_plot_partial_dependence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/inspection/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/tests/test_partial_dependence.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/inspection/tests/test_permutation_importance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/isotonic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/kernel_approximation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/kernel_ridge.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/linear_model'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_bayes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/glm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/link.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/tests/test_glm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_glm/tests/test_link.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_huber.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_least_angle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_omp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_passive_aggressive.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_perceptron.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_ransac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_sag.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_theil_sen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_bayes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_huber.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_least_angle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_logistic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_omp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_passive_aggressive.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_perceptron.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_ransac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_ridge.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_sag.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_sgd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_sparse_coordinate_descent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/linear_model/tests/test_theil_sen.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/manifold'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_isomap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_locally_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_mds.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_spectral_embedding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/_t_sne.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_isomap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_locally_linear.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_mds.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_spectral_embedding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/manifold/tests/test_t_sne.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_classification.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/confusion_matrix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/det_curve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/precision_recall_curve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/roc_curve.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_confusion_matrix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_curve_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_det_curve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_precision_recall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_plot/tests/test_plot_roc_curve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_ranking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/_scorer.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/_bicluster.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/_supervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/_unsupervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/test_bicluster.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/test_supervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/cluster/tests/test_unsupervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/pairwise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_classification.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_pairwise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_ranking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/metrics/tests/test_score_objects.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/mixture'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/_bayesian_mixture.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/_gaussian_mixture.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests/test_bayesian_mixture.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests/test_gaussian_mixture.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/mixture/tests/test_mixture.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/model_selection'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search_successive_halving.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_split.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/test_search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/test_split.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/test_successive_halving.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/model_selection/tests/test_validation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/multiclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/multioutput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/naive_bayes.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/neighbors'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_classification.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_graph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_kde.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_lof.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_nca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_nearest_centroid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/_unsupervised.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_ball_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_dist_metrics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_graph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_kd_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_kde.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_lof.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_nca.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_nearest_centroid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_neighbors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_neighbors_pipeline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_neighbors_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neighbors/tests/test_quad_tree.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/neural_network'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_rbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_stochastic_optimizers.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/test_mlp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/test_rbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/neural_network/tests/test_stochastic_optimizers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/pipeline.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_label.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_discretization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_encoders.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_function_transformer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/tests/test_label.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/random_projection.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/_label_propagation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/_self_training.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/tests/test_label_propagation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/semi_supervised/tests/test_self_training.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/svm'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/_bounds.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/_classes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests/test_bounds.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests/test_sparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/svm/tests/test_svm.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_calibration.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_check_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_common.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_discriminant_analysis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_docstring_parameters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_dummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_init.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_isotonic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_kernel_approximation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_kernel_ridge.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_metaestimators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_min_dependencies_readme.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_multiclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_multioutput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_naive_bayes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_pipeline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tests/test_random_projection.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/tree'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/_classes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/_export.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/_reingold_tilford.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/setup.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests/test_export.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests/test_reingold_tilford.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/tree/tests/test_tree.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/utils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_arpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_encode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_estimator_html_repr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_joblib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_mask.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_mocking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_show_versions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/_testing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/class_weight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/estimator_checks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/extmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/fixes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/graph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/metaestimators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/multiclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/sparsefuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/stats.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/conftest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_arpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_arrayfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_class_weight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_cython_blas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_deprecation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_encode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_estimator_checks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_estimator_html_repr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_extmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_fast_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_fixes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_metaestimators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_mocking.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_multiclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_murmurhash.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_optimize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_parallel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_seq_dataset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_shortest_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_show_versions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_sparsefuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_stats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_testing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/tests/test_validation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/socks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/sockshandler.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/gelu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/hardshrink.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/lisht.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/mish.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/rrelu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/softshrink.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/sparsemax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/activations/tanhshrink.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks/average_model_checkpoint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks/time_stopping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/callbacks/tqdm_progress_bar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/conftest.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/activations'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/image'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/layers'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/seq2seq'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/custom_ops/text'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/color_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/compose_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/connected_components.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/cutout_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/dense_image_warp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/distance_transform.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/distort_image_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/filters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/interpolate_spline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/resampler_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/sparse_image_warp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/transform_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/translate_ops.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/image/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/gelu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/maxout.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/multihead_attention.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/netvlad.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/normalizations.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/optical_flow.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/poincare.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/polynomial.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/sparsemax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/tlu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/layers/wrappers.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/contrastive.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/focal_loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/giou_loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/lifted.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/metric_learning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/npairs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/quantiles.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/sparsemax_loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/losses/triplet.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/cohens_kappa.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/f_scores.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/hamming.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/matthews_correlation_coefficient.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/multilabel_confusion_matrix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/r_square.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/metrics/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/average_wrapper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/conditional_gradient.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/cyclical_learning_rate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/lamb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/lazy_adam.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/lookahead.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/moving_average.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/novograd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/rectified_adam.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/stochastic_weight_averaging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/weight_decay_optimizers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/optimizers/yogi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/options.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/register.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/rnn'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/rnn/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/rnn/cell.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/attention_wrapper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/basic_decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/beam_search_decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/loss.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/seq2seq/sampler.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/testing'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/testing/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/testing/serialization.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text/crf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text/parse_time_op.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/text/skip_gram_ops.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/ensure_tf_install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/keras_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/resource_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tensorflow_addons/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tensorflow_addons-0.9.1.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/test_data'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/test_data/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/test_data/env_metadata'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/test_data/env_metadata/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/test_pycosat.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/threadpoolctl-3.1.0.dist-info'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/threadpoolctl.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tqdm'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_dist_ver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_monitor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_tqdm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_tqdm_gui.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_tqdm_pandas.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/asyncio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/auto.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/autonotebook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/cli.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tqdm/contrib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/bells.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/concurrent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/discord.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/itertools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/logging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/telegram.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/contrib/utils_worker.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/dask.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/gui.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/keras.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/notebook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/rich.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/std.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/tk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/tqdm/version.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/tqdm-4.63.0.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/typeguard'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/typeguard/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/typeguard/importhook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/typeguard/pytest_plugin.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/typeguard-2.13.3.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/_collections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/contrib'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_appengine_environ.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_securetransport'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_securetransport/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_securetransport/bindings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/_securetransport/low_level.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/appengine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/ntlmpool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/securetransport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/contrib/socks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/fields.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/filepost.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/packages'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/packages/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/packages/backports'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/packages/backports/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/packages/backports/makefile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/poolmanager.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/request.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/response.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3/util'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/proxy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/queue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/request.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/response.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/ssl_.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/ssl_match_hostname.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/ssltransport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/timeout.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/url.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/urllib3/util/wait.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/urllib3-1.26.8.dist-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wget-3.2.dist-info'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wget.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/bdist_wheel.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel/cli'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/cli/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/cli/convert.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/cli/pack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/cli/unpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/macosx_libfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/metadata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/pkginfo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/util.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel/vendored'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/vendored/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel/vendored/packaging'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/vendored/packaging/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/vendored/packaging/_typing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/vendored/packaging/tags.py'...\n",
            "Compiling '/usr/local/lib/python3.6/site-packages/wheel/wheelfile.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/wheel-0.37.1-py3.9.egg-info'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages/xontrib'...\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -m lib2to3.pgen2.driver /usr/local/lib/python3.6/lib2to3/Grammar.txt\n",
            "Generating grammar tables from /usr/local/lib/python3.6/lib2to3/Grammar.txt\n",
            "Writing grammar tables to /usr/local/lib/python3.6/lib2to3/Grammar3.6.9.final.0.pickle\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -m lib2to3.pgen2.driver /usr/local/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "Generating grammar tables from /usr/local/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "Writing grammar tables to /usr/local/lib/python3.6/lib2to3/PatternGrammar3.6.9.final.0.pickle\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/Python-ast.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/Python.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/abstract.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/accu.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/asdl.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/ast.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bitset.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bltinmodule.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/boolobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bytearrayobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bytes_methods.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bytesobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/cellobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/ceval.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/classobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/code.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/codecs.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/compile.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/complexobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/datetime.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/descrobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/dictobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/dtoa.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/dynamic_annotations.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/enumobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/errcode.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/eval.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/fileobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/fileutils.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/floatobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/frameobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/funcobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/genobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/graminit.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/grammar.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/import.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/intrcheck.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/iterobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/listobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/longintrepr.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/longobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/marshal.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/memoryobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/metagrammar.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/methodobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/modsupport.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/moduleobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/namespaceobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/node.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/object.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/objimpl.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/odictobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/opcode.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/osdefs.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/osmodule.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/parsetok.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/patchlevel.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pgen.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pgenheaders.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/py_curses.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyarena.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyatomic.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pycapsule.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyctype.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pydebug.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pydtrace.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyerrors.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyexpat.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyfpe.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pygetopt.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyhash.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pylifecycle.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pymacconfig.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pymacro.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pymath.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pymem.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyport.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pystate.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pystrcmp.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pystrhex.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pystrtod.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pythonrun.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pythread.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pytime.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/rangeobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/setobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/sliceobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/structmember.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/structseq.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/symtable.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/sysmodule.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/token.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/traceback.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/tupleobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/typeslots.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/ucnhash.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/unicodeobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/warnings.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/weakrefobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 pyconfig.h /usr/local/include/python3.6m/pyconfig.h\n",
            "/usr/bin/install -c -m 644 Modules/config.c /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/config.c\n",
            "/usr/bin/install -c -m 644 Programs/python.o /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/python.o\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Modules/config.c.in /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/config.c.in\n",
            "/usr/bin/install -c -m 644 Makefile /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/Makefile\n",
            "/usr/bin/install -c -m 644 Modules/Setup /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/Setup\n",
            "/usr/bin/install -c -m 644 Modules/Setup.local /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/Setup.local\n",
            "/usr/bin/install -c -m 644 Modules/Setup.config /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/Setup.config\n",
            "/usr/bin/install -c -m 644 Misc/python.pc /usr/local/lib/pkgconfig/python-3.6.pc\n",
            "/usr/bin/install -c Python-3.6.9/Modules/makesetup /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/makesetup\n",
            "/usr/bin/install -c Python-3.6.9/install-sh /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/install-sh\n",
            "/usr/bin/install -c python-config.py /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/python-config.py\n",
            "/usr/bin/install -c python-config /usr/local/bin/python3.6m-config\n",
            "./python -E Python-3.6.9/setup.py install \\\n",
            "   \t--prefix=/usr/local \\\n",
            "\t--install-scripts=/usr/local/bin \\\n",
            "\t--install-platlib=/usr/local/lib/python3.6/lib-dynload \\\n",
            "\t--root=/\n",
            "running install\n",
            "running build\n",
            "running build_ext\n",
            "\n",
            "Python build finished successfully!\n",
            "The necessary bits to build these optional modules were not found:\n",
            "_dbm                  _gdbm                                    \n",
            "To find the necessary bits, look in setup.py in detect_modules() for the module's name.\n",
            "\n",
            "The following modules found by detect_modules() in setup.py, have been\n",
            "built by the Makefile instead, as configured by the Setup files:\n",
            "atexit                pwd                   time               \n",
            "running build_scripts\n",
            "copying and adjusting /content/Python-3.6.9/Tools/scripts/pydoc3 -> build/scripts-3.6\n",
            "copying and adjusting /content/Python-3.6.9/Tools/scripts/idle3 -> build/scripts-3.6\n",
            "copying and adjusting /content/Python-3.6.9/Tools/scripts/2to3 -> build/scripts-3.6\n",
            "copying and adjusting /content/Python-3.6.9/Tools/scripts/pyvenv -> build/scripts-3.6\n",
            "changing mode of build/scripts-3.6/pydoc3 from 644 to 755\n",
            "changing mode of build/scripts-3.6/idle3 from 644 to 755\n",
            "changing mode of build/scripts-3.6/2to3 from 644 to 755\n",
            "changing mode of build/scripts-3.6/pyvenv from 644 to 755\n",
            "renaming build/scripts-3.6/pydoc3 to build/scripts-3.6/pydoc3.6\n",
            "renaming build/scripts-3.6/idle3 to build/scripts-3.6/idle3.6\n",
            "renaming build/scripts-3.6/2to3 to build/scripts-3.6/2to3-3.6\n",
            "renaming build/scripts-3.6/pyvenv to build/scripts-3.6/pyvenv-3.6\n",
            "running install_lib\n",
            "copying build/lib.linux-x86_64-3.6/grp.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_lsprof.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/nis.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_bisect.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sha512.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/select.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/xxlimited.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/ossaudiodev.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_testimportmultiple.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_pickle.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_heapq.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sysconfigdata_m_linux_x86_64-linux-gnu.py -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_random.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_json.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/readline.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_struct.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/resource.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_posixsubprocess.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/cmath.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_ctypes.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_datetime.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_csv.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_blake2.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_testbuffer.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_ssl.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_md5.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_testcapi.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_testmultiphase.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_jp.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sha1.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/pyexpat.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_curses_panel.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_tkinter.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/zlib.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sqlite3.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_tw.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_lzma.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/array.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_crypt.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/parser.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/termios.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/syslog.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/spwd.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/fcntl.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_bz2.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/audioop.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_multiprocessing.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_cn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "creating /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "copying build/lib.linux-x86_64-3.6/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.opt-1.pyc -> /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "copying build/lib.linux-x86_64-3.6/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.opt-2.pyc -> /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "copying build/lib.linux-x86_64-3.6/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.pyc -> /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "copying build/lib.linux-x86_64-3.6/_sha256.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_ctypes_test.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_socket.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_elementtree.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_asyncio.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_hk.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/math.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/unicodedata.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/mmap.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_hashlib.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_decimal.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_iso2022.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_opcode.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_curses.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/binascii.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sha3.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_multibytecodec.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_kr.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/grp.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_lsprof.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/nis.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_bisect.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sha512.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/select.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/xxlimited.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/ossaudiodev.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_testimportmultiple.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_pickle.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_heapq.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sysconfigdata_m_linux_x86_64-linux-gnu.py to 644\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_random.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_json.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/readline.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_struct.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/resource.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_posixsubprocess.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/cmath.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_datetime.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_csv.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_blake2.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_testbuffer.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_ssl.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_md5.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_testcapi.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_testmultiphase.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_jp.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sha1.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/pyexpat.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_curses_panel.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_tkinter.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/zlib.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sqlite3.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_tw.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_lzma.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/array.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_crypt.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/parser.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/termios.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/syslog.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/spwd.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/fcntl.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_bz2.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/audioop.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_multiprocessing.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_cn.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.opt-1.pyc to 644\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.opt-2.pyc to 644\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.pyc to 644\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sha256.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_ctypes_test.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_socket.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_elementtree.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_asyncio.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_hk.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/math.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/unicodedata.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/mmap.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_hashlib.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_decimal.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_iso2022.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_opcode.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_curses.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/binascii.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sha3.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_multibytecodec.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_kr.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/ to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/__pycache__ to 755\n",
            "running install_scripts\n",
            "copying build/scripts-3.6/2to3-3.6 -> /usr/local/bin\n",
            "copying build/scripts-3.6/idle3.6 -> /usr/local/bin\n",
            "copying build/scripts-3.6/pydoc3.6 -> /usr/local/bin\n",
            "copying build/scripts-3.6/pyvenv-3.6 -> /usr/local/bin\n",
            "changing mode of /usr/local/bin/2to3-3.6 to 755\n",
            "changing mode of /usr/local/bin/idle3.6 to 755\n",
            "changing mode of /usr/local/bin/pydoc3.6 to 755\n",
            "changing mode of /usr/local/bin/pyvenv-3.6 to 755\n",
            "rm /usr/local/lib/python3.6/lib-dynload/_sysconfigdata_m_linux_x86_64-linux-gnu.py\n",
            "rm -r /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Misc/python.man \\\n",
            "\t/usr/local/share/man/man1/python3.6.1\n",
            "if test ! -d /usr/local/lib/pkgconfig; then \\\n",
            "\techo \"Creating directory /usr/local/lib/pkgconfig\"; \\\n",
            "\t/usr/bin/install -c -d -m 755 /usr/local/lib/pkgconfig; \\\n",
            "fi\n",
            "if test -f /usr/local/bin/python3 -o -h /usr/local/bin/python3; \\\n",
            "then rm -f /usr/local/bin/python3; \\\n",
            "else true; \\\n",
            "fi\n",
            "(cd /usr/local/bin; ln -s python3.6 python3)\n",
            "if test \"3.6\" != \"3.6m\"; then \\\n",
            "\trm -f /usr/local/bin/python3.6-config; \\\n",
            "\t(cd /usr/local/bin; ln -s python3.6m-config python3.6-config); \\\n",
            "\trm -f /usr/local/lib/pkgconfig/python-3.6m.pc; \\\n",
            "\t(cd /usr/local/lib/pkgconfig; ln -s python-3.6.pc python-3.6m.pc); \\\n",
            "fi\n",
            "rm -f /usr/local/bin/python3-config\n",
            "(cd /usr/local/bin; ln -s python3.6-config python3-config)\n",
            "rm -f /usr/local/lib/pkgconfig/python3.pc\n",
            "(cd /usr/local/lib/pkgconfig; ln -s python-3.6.pc python3.pc)\n",
            "rm -f /usr/local/bin/idle3\n",
            "(cd /usr/local/bin; ln -s idle3.6 idle3)\n",
            "rm -f /usr/local/bin/pydoc3\n",
            "(cd /usr/local/bin; ln -s pydoc3.6 pydoc3)\n",
            "rm -f /usr/local/bin/2to3\n",
            "(cd /usr/local/bin; ln -s 2to3-3.6 2to3)\n",
            "rm -f /usr/local/bin/pyvenv\n",
            "(cd /usr/local/bin; ln -s pyvenv-3.6 pyvenv)\n",
            "if test \"x\" != \"x\" ; then \\\n",
            "\trm -f /usr/local/bin/python3-32; \\\n",
            "\t(cd /usr/local/bin; ln -s python3.6-32 python3-32) \\\n",
            "fi\n",
            "rm -f /usr/local/share/man/man1/python3.1\n",
            "(cd /usr/local/share/man/man1; ln -s python3.6.1 python3.1)\n",
            "if test \"xupgrade\" != \"xno\"  ; then \\\n",
            "\tcase upgrade in \\\n",
            "\t\tupgrade) ensurepip=\"--upgrade\" ;; \\\n",
            "\t\tinstall|*) ensurepip=\"\" ;; \\\n",
            "\tesac; \\\n",
            "\t ./python -E -m ensurepip \\\n",
            "\t\t$ensurepip --root=/ ; \\\n",
            "fi\n",
            "Looking in links: /tmp/tmpjklxob35\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/site-packages (58.0.4)\n",
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/site-packages (21.2.2)\n",
            "Mounted at /content/drive\n",
            "/usr/local/bin/python\n",
            "Python 3.6.9\n",
            "/env/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9Z-e7Nd1P8x",
        "outputId": "3794891b-7d9e-4dd7-c550-b419e2563ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "unlinking: ca-certificates-2022.10.11-h06a4308_0\n",
            "unlinking: certifi-2021.5.30-py36h06a4308_0\n",
            "unlinking: cffi-1.14.6-py36h400218f_0\n",
            "unlinking: conda-4.10.3-py36h06a4308_0\n",
            "unlinking: cryptography-35.0.0-py36hd23ed53_0\n",
            "unlinking: idna-3.3-pyhd3eb1b0_0\n",
            "unlinking: libffi-3.3-he6710b0_2\n",
            "unlinking: libgcc-ng-11.2.0-h1234567_1\n",
            "unlinking: libstdcxx-ng-11.2.0-h1234567_1\n",
            "unlinking: ncurses-6.3-h5eee18b_3\n",
            "unlinking: openssl-1.1.1s-h7f8727e_0\n",
            "unlinking: pip-21.2.2-py36h06a4308_0\n",
            "unlinking: pycosat-0.6.3-py36h27cfd23_0\n",
            "unlinking: pycparser-2.21-pyhd3eb1b0_0\n",
            "unlinking: pyopenssl-22.0.0-pyhd3eb1b0_0\n",
            "unlinking: pysocks-1.7.1-py36h06a4308_0\n",
            "unlinking: python-3.6.13-h12debd9_1\n",
            "unlinking: readline-8.2-h5eee18b_0\n",
            "unlinking: requests-2.27.1-pyhd3eb1b0_0\n",
            "unlinking: ruamel_yaml-0.15.100-py36h27cfd23_0\n",
            "unlinking: setuptools-58.0.4-py36h06a4308_0\n",
            "unlinking: six-1.16.0-pyhd3eb1b0_1\n",
            "unlinking: sqlite-3.40.0-h5082296_0\n",
            "unlinking: tk-8.6.12-h1ccaba5_0\n",
            "unlinking: urllib3-1.26.8-pyhd3eb1b0_0\n",
            "unlinking: wheel-0.37.1-pyhd3eb1b0_0\n",
            "unlinking: xz-5.2.8-h5eee18b_0\n",
            "unlinking: yaml-0.2.5-h7b6447c_0\n",
            "unlinking: zlib-1.2.13-h5eee18b_0\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2022-12-13 13:02:51--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2022-12-13 13:02:51--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh.1’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 4.74M 12s\n",
            "    50K .......... .......... .......... .......... ..........  0% 4.77M 12s\n",
            "   100K .......... .......... .......... .......... ..........  0% 14.5M 9s\n",
            "   150K .......... .......... .......... .......... ..........  0% 13.3M 8s\n",
            "   200K .......... .......... .......... .......... ..........  0% 12.2M 7s\n",
            "   250K .......... .......... .......... .......... ..........  0% 23.3M 6s\n",
            "   300K .......... .......... .......... .......... ..........  0% 17.4M 6s\n",
            "   350K .......... .......... .......... .......... ..........  0% 21.1M 5s\n",
            "   400K .......... .......... .......... .......... ..........  0% 17.3M 5s\n",
            "   450K .......... .......... .......... .......... ..........  0% 26.4M 5s\n",
            "   500K .......... .......... .......... .......... ..........  0% 80.0M 5s\n",
            "   550K .......... .......... .......... .......... ..........  1% 33.9M 4s\n",
            "   600K .......... .......... .......... .......... ..........  1% 34.2M 4s\n",
            "   650K .......... .......... .......... .......... ..........  1% 52.8M 4s\n",
            "   700K .......... .......... .......... .......... ..........  1% 84.1M 4s\n",
            "   750K .......... .......... .......... .......... ..........  1% 38.9M 3s\n",
            "   800K .......... .......... .......... .......... ..........  1% 38.7M 3s\n",
            "   850K .......... .......... .......... .......... ..........  1% 40.6M 3s\n",
            "   900K .......... .......... .......... .......... ..........  1% 59.9M 3s\n",
            "   950K .......... .......... .......... .......... ..........  1% 94.3M 3s\n",
            "  1000K .......... .......... .......... .......... ..........  1% 49.7M 3s\n",
            "  1050K .......... .......... .......... .......... ..........  1% 61.3M 3s\n",
            "  1100K .......... .......... .......... .......... ..........  2%  198M 3s\n",
            "  1150K .......... .......... .......... .......... ..........  2% 49.4M 3s\n",
            "  1200K .......... .......... .......... .......... ..........  2% 54.9M 3s\n",
            "  1250K .......... .......... .......... .......... ..........  2% 71.5M 2s\n",
            "  1300K .......... .......... .......... .......... ..........  2% 60.9M 2s\n",
            "  1350K .......... .......... .......... .......... ..........  2%  209M 2s\n",
            "  1400K .......... .......... .......... .......... ..........  2% 79.3M 2s\n",
            "  1450K .......... .......... .......... .......... ..........  2% 71.5M 2s\n",
            "  1500K .......... .......... .......... .......... ..........  2% 83.7M 2s\n",
            "  1550K .......... .......... .......... .......... ..........  2% 73.1M 2s\n",
            "  1600K .......... .......... .......... .......... ..........  2%  279M 2s\n",
            "  1650K .......... .......... .......... .......... ..........  2% 94.7M 2s\n",
            "  1700K .......... .......... .......... .......... ..........  3% 92.5M 2s\n",
            "  1750K .......... .......... .......... .......... ..........  3% 83.8M 2s\n",
            "  1800K .......... .......... .......... .......... ..........  3%  339M 2s\n",
            "  1850K .......... .......... .......... .......... ..........  3%  132M 2s\n",
            "  1900K .......... .......... .......... .......... ..........  3% 89.2M 2s\n",
            "  1950K .......... .......... .......... .......... ..........  3%  104M 2s\n",
            "  2000K .......... .......... .......... .......... ..........  3%  105M 2s\n",
            "  2050K .......... .......... .......... .......... ..........  3%  195M 2s\n",
            "  2100K .......... .......... .......... .......... ..........  3%  198M 2s\n",
            "  2150K .......... .......... .......... .......... ..........  3%  118M 2s\n",
            "  2200K .......... .......... .......... .......... ..........  3%  123M 2s\n",
            "  2250K .......... .......... .......... .......... ..........  4%  266M 2s\n",
            "  2300K .......... .......... .......... .......... ..........  4%  120M 2s\n",
            "  2350K .......... .......... .......... .......... ..........  4%  117M 2s\n",
            "  2400K .......... .......... .......... .......... ..........  4%  159M 2s\n",
            "  2450K .......... .......... .......... .......... ..........  4%  169M 1s\n",
            "  2500K .......... .......... .......... .......... ..........  4%  232M 1s\n",
            "  2550K .......... .......... .......... .......... ..........  4%  149M 1s\n",
            "  2600K .......... .......... .......... .......... ..........  4%  141M 1s\n",
            "  2650K .......... .......... .......... .......... ..........  4%  131M 1s\n",
            "  2700K .......... .......... .......... .......... ..........  4%  186M 1s\n",
            "  2750K .......... .......... .......... .......... ..........  4%  144M 1s\n",
            "  2800K .......... .......... .......... .......... ..........  4%  266M 1s\n",
            "  2850K .......... .......... .......... .......... ..........  5%  165M 1s\n",
            "  2900K .......... .......... .......... .......... ..........  5%  147M 1s\n",
            "  2950K .......... .......... .......... .......... ..........  5%  156M 1s\n",
            "  3000K .......... .......... .......... .......... ..........  5%  248M 1s\n",
            "  3050K .......... .......... .......... .......... ..........  5%  179M 1s\n",
            "  3100K .......... .......... .......... .......... ..........  5%  197M 1s\n",
            "  3150K .......... .......... .......... .......... ..........  5%  146M 1s\n",
            "  3200K .......... .......... .......... .......... ..........  5%  191M 1s\n",
            "  3250K .......... .......... .......... .......... ..........  5%  220M 1s\n",
            "  3300K .......... .......... .......... .......... ..........  5%  210M 1s\n",
            "  3350K .......... .......... .......... .......... ..........  5%  179M 1s\n",
            "  3400K .......... .......... .......... .......... ..........  6%  179M 1s\n",
            "  3450K .......... .......... .......... .......... ..........  6%  209M 1s\n",
            "  3500K .......... .......... .......... .......... ..........  6%  207M 1s\n",
            "  3550K .......... .......... .......... .......... ..........  6%  151M 1s\n",
            "  3600K .......... .......... .......... .......... ..........  6%  199M 1s\n",
            "  3650K .......... .......... .......... .......... ..........  6%  253M 1s\n",
            "  3700K .......... .......... .......... .......... ..........  6%  178M 1s\n",
            "  3750K .......... .......... .......... .......... ..........  6%  164M 1s\n",
            "  3800K .......... .......... .......... .......... ..........  6%  207M 1s\n",
            "  3850K .......... .......... .......... .......... ..........  6%  208M 1s\n",
            "  3900K .......... .......... .......... .......... ..........  6%  192M 1s\n",
            "  3950K .......... .......... .......... .......... ..........  7%  146M 1s\n",
            "  4000K .......... .......... .......... .......... ..........  7%  184M 1s\n",
            "  4050K .......... .......... .......... .......... ..........  7%  196M 1s\n",
            "  4100K .......... .......... .......... .......... ..........  7%  198M 1s\n",
            "  4150K .......... .......... .......... .......... ..........  7%  176M 1s\n",
            "  4200K .......... .......... .......... .......... ..........  7%  184M 1s\n",
            "  4250K .......... .......... .......... .......... ..........  7%  167M 1s\n",
            "  4300K .......... .......... .......... .......... ..........  7%  185M 1s\n",
            "  4350K .......... .......... .......... .......... ..........  7%  167M 1s\n",
            "  4400K .......... .......... .......... .......... ..........  7%  160M 1s\n",
            "  4450K .......... .......... .......... .......... ..........  7%  177M 1s\n",
            "  4500K .......... .......... .......... .......... ..........  7%  190M 1s\n",
            "  4550K .......... .......... .......... .......... ..........  8%  155M 1s\n",
            "  4600K .......... .......... .......... .......... ..........  8%  184M 1s\n",
            "  4650K .......... .......... .......... .......... ..........  8%  162M 1s\n",
            "  4700K .......... .......... .......... .......... ..........  8%  167M 1s\n",
            "  4750K .......... .......... .......... .......... ..........  8% 90.5M 1s\n",
            "  4800K .......... .......... .......... .......... ..........  8%  173M 1s\n",
            "  4850K .......... .......... .......... .......... ..........  8%  181M 1s\n",
            "  4900K .......... .......... .......... .......... ..........  8%  155M 1s\n",
            "  4950K .......... .......... .......... .......... ..........  8%  192M 1s\n",
            "  5000K .......... .......... .......... .......... ..........  8%  260M 1s\n",
            "  5050K .......... .......... .......... .......... ..........  8%  254M 1s\n",
            "  5100K .......... .......... .......... .......... ..........  9%  264M 1s\n",
            "  5150K .......... .......... .......... .......... ..........  9%  167M 1s\n",
            "  5200K .......... .......... .......... .......... ..........  9%  168M 1s\n",
            "  5250K .......... .......... .......... .......... ..........  9%  165M 1s\n",
            "  5300K .......... .......... .......... .......... ..........  9%  167M 1s\n",
            "  5350K .......... .......... .......... .......... ..........  9%  158M 1s\n",
            "  5400K .......... .......... .......... .......... ..........  9%  190M 1s\n",
            "  5450K .......... .......... .......... .......... ..........  9%  194M 1s\n",
            "  5500K .......... .......... .......... .......... ..........  9%  196M 1s\n",
            "  5550K .......... .......... .......... .......... ..........  9%  142M 1s\n",
            "  5600K .......... .......... .......... .......... ..........  9%  192M 1s\n",
            "  5650K .......... .......... .......... .......... ..........  9%  213M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 10%  213M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 10%  235M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 10%  303M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 10%  353M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 10%  361M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 10%  227M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 10%  262M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 10%  271M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 10%  271M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 10%  283M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 10%  304M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 11%  325M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 11%  385M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 11% 11.2M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 11%  272M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 11%  262M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 11%  166M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 11%  225M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 11%  335M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 11%  352M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 11%  357M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 11%  237M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 11%  241M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 12%  266M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 12%  356M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 12%  335M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 12%  380M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 12%  366M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 12%  392M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 12% 53.6M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 12%  197M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 12%  273M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 12%  357M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 12%  346M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 13%  383M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 13%  259M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 13%  377M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 13% 12.4M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 13%  214M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 13%  200M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 13%  248M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 13%  195M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 13%  214M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 13%  290M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 13%  320M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 14%  287M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 14%  266M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 14%  351M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 14%  380M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 14%  296M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 14%  275M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 14%  386M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 14%  344M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 14%  242M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 14%  336M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 14% 22.1M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 14%  127M 1s\n",
            "  8550K .......... .......... .......... .......... .......... 15%  136M 1s\n",
            "  8600K .......... .......... .......... .......... .......... 15%  222M 1s\n",
            "  8650K .......... .......... .......... .......... .......... 15%  275M 1s\n",
            "  8700K .......... .......... .......... .......... .......... 15%  278M 1s\n",
            "  8750K .......... .......... .......... .......... .......... 15%  261M 1s\n",
            "  8800K .......... .......... .......... .......... .......... 15%  275M 1s\n",
            "  8850K .......... .......... .......... .......... .......... 15%  241M 1s\n",
            "  8900K .......... .......... .......... .......... .......... 15%  249M 1s\n",
            "  8950K .......... .......... .......... .......... .......... 15% 44.5M 1s\n",
            "  9000K .......... .......... .......... .......... .......... 15%  272M 1s\n",
            "  9050K .......... .......... .......... .......... .......... 15%  241M 1s\n",
            "  9100K .......... .......... .......... .......... .......... 16%  212M 1s\n",
            "  9150K .......... .......... .......... .......... .......... 16%  210M 1s\n",
            "  9200K .......... .......... .......... .......... .......... 16%  265M 1s\n",
            "  9250K .......... .......... .......... .......... .......... 16%  260M 1s\n",
            "  9300K .......... .......... .......... .......... .......... 16%  183M 1s\n",
            "  9350K .......... .......... .......... .......... .......... 16%  207M 1s\n",
            "  9400K .......... .......... .......... .......... .......... 16%  226M 1s\n",
            "  9450K .......... .......... .......... .......... .......... 16%  233M 1s\n",
            "  9500K .......... .......... .......... .......... .......... 16%  259M 1s\n",
            "  9550K .......... .......... .......... .......... .......... 16% 69.6M 1s\n",
            "  9600K .......... .......... .......... .......... .......... 16%  247M 1s\n",
            "  9650K .......... .......... .......... .......... .......... 16%  160M 1s\n",
            "  9700K .......... .......... .......... .......... .......... 17%  152M 1s\n",
            "  9750K .......... .......... .......... .......... .......... 17%  147M 1s\n",
            "  9800K .......... .......... .......... .......... .......... 17% 74.3M 1s\n",
            "  9850K .......... .......... .......... .......... .......... 17%  177M 1s\n",
            "  9900K .......... .......... .......... .......... .......... 17%  178M 1s\n",
            "  9950K .......... .......... .......... .......... .......... 17%  127M 1s\n",
            " 10000K .......... .......... .......... .......... .......... 17%  197M 1s\n",
            " 10050K .......... .......... .......... .......... .......... 17% 33.2M 1s\n",
            " 10100K .......... .......... .......... .......... .......... 17%  274M 1s\n",
            " 10150K .......... .......... .......... .......... .......... 17%  291M 1s\n",
            " 10200K .......... .......... .......... .......... .......... 17%  308M 1s\n",
            " 10250K .......... .......... .......... .......... .......... 18%  296M 1s\n",
            " 10300K .......... .......... .......... .......... .......... 18%  236M 1s\n",
            " 10350K .......... .......... .......... .......... .......... 18%  167M 1s\n",
            " 10400K .......... .......... .......... .......... .......... 18%  192M 1s\n",
            " 10450K .......... .......... .......... .......... .......... 18% 69.0M 1s\n",
            " 10500K .......... .......... .......... .......... .......... 18%  175M 1s\n",
            " 10550K .......... .......... .......... .......... .......... 18%  173M 1s\n",
            " 10600K .......... .......... .......... .......... .......... 18%  122M 1s\n",
            " 10650K .......... .......... .......... .......... .......... 18%  240M 1s\n",
            " 10700K .......... .......... .......... .......... .......... 18%  144M 1s\n",
            " 10750K .......... .......... .......... .......... .......... 18%  111M 1s\n",
            " 10800K .......... .......... .......... .......... .......... 19%  280M 1s\n",
            " 10850K .......... .......... .......... .......... .......... 19%  129M 1s\n",
            " 10900K .......... .......... .......... .......... .......... 19%  228M 1s\n",
            " 10950K .......... .......... .......... .......... .......... 19%  153M 1s\n",
            " 11000K .......... .......... .......... .......... .......... 19% 96.7M 1s\n",
            " 11050K .......... .......... .......... .......... .......... 19%  164M 1s\n",
            " 11100K .......... .......... .......... .......... .......... 19%  277M 1s\n",
            " 11150K .......... .......... .......... .......... .......... 19% 61.3M 1s\n",
            " 11200K .......... .......... .......... .......... .......... 19%  298M 1s\n",
            " 11250K .......... .......... .......... .......... .......... 19%  351M 1s\n",
            " 11300K .......... .......... .......... .......... .......... 19% 52.5M 1s\n",
            " 11350K .......... .......... .......... .......... .......... 19%  282M 1s\n",
            " 11400K .......... .......... .......... .......... .......... 20%  312M 1s\n",
            " 11450K .......... .......... .......... .......... .......... 20%  271M 0s\n",
            " 11500K .......... .......... .......... .......... .......... 20%  169M 0s\n",
            " 11550K .......... .......... .......... .......... .......... 20% 38.4M 0s\n",
            " 11600K .......... .......... .......... .......... .......... 20%  153M 0s\n",
            " 11650K .......... .......... .......... .......... .......... 20%  168M 0s\n",
            " 11700K .......... .......... .......... .......... .......... 20%  222M 0s\n",
            " 11750K .......... .......... .......... .......... .......... 20% 46.1M 0s\n",
            " 11800K .......... .......... .......... .......... .......... 20%  203M 0s\n",
            " 11850K .......... .......... .......... .......... .......... 20%  140M 0s\n",
            " 11900K .......... .......... .......... .......... .......... 20%  183M 0s\n",
            " 11950K .......... .......... .......... .......... .......... 21%  169M 0s\n",
            " 12000K .......... .......... .......... .......... .......... 21%  130M 0s\n",
            " 12050K .......... .......... .......... .......... .......... 21%  254M 0s\n",
            " 12100K .......... .......... .......... .......... .......... 21%  117M 0s\n",
            " 12150K .......... .......... .......... .......... .......... 21%  147M 0s\n",
            " 12200K .......... .......... .......... .......... .......... 21%  193M 0s\n",
            " 12250K .......... .......... .......... .......... .......... 21% 9.69M 0s\n",
            " 12300K .......... .......... .......... .......... .......... 21%  276M 0s\n",
            " 12350K .......... .......... .......... .......... .......... 21%  282M 0s\n",
            " 12400K .......... .......... .......... .......... .......... 21%  321M 0s\n",
            " 12450K .......... .......... .......... .......... .......... 21%  294M 0s\n",
            " 12500K .......... .......... .......... .......... .......... 21%  361M 0s\n",
            " 12550K .......... .......... .......... .......... .......... 22%  302M 0s\n",
            " 12600K .......... .......... .......... .......... .......... 22%  300M 0s\n",
            " 12650K .......... .......... .......... .......... .......... 22%  341M 0s\n",
            " 12700K .......... .......... .......... .......... .......... 22%  372M 0s\n",
            " 12750K .......... .......... .......... .......... .......... 22%  318M 0s\n",
            " 12800K .......... .......... .......... .......... .......... 22%  358M 0s\n",
            " 12850K .......... .......... .......... .......... .......... 22%  391M 0s\n",
            " 12900K .......... .......... .......... .......... .......... 22%  383M 0s\n",
            " 12950K .......... .......... .......... .......... .......... 22%  326M 0s\n",
            " 13000K .......... .......... .......... .......... .......... 22% 10.2M 0s\n",
            " 13050K .......... .......... .......... .......... .......... 22%  272M 0s\n",
            " 13100K .......... .......... .......... .......... .......... 23%  307M 0s\n",
            " 13150K .......... .......... .......... .......... .......... 23%  277M 0s\n",
            " 13200K .......... .......... .......... .......... .......... 23%  296M 0s\n",
            " 13250K .......... .......... .......... .......... .......... 23%  344M 0s\n",
            " 13300K .......... .......... .......... .......... .......... 23%  352M 0s\n",
            " 13350K .......... .......... .......... .......... .......... 23%  289M 0s\n",
            " 13400K .......... .......... .......... .......... .......... 23%  329M 0s\n",
            " 13450K .......... .......... .......... .......... .......... 23%  309M 0s\n",
            " 13500K .......... .......... .......... .......... .......... 23%  319M 0s\n",
            " 13550K .......... .......... .......... .......... .......... 23%  288M 0s\n",
            " 13600K .......... .......... .......... .......... .......... 23%  357M 0s\n",
            " 13650K .......... .......... .......... .......... .......... 23%  372M 0s\n",
            " 13700K .......... .......... .......... .......... .......... 24%  340M 0s\n",
            " 13750K .......... .......... .......... .......... .......... 24%  319M 0s\n",
            " 13800K .......... .......... .......... .......... .......... 24%  349M 0s\n",
            " 13850K .......... .......... .......... .......... .......... 24%  382M 0s\n",
            " 13900K .......... .......... .......... .......... .......... 24%  381M 0s\n",
            " 13950K .......... .......... .......... .......... .......... 24%  331M 0s\n",
            " 14000K .......... .......... .......... .......... .......... 24%  373M 0s\n",
            " 14050K .......... .......... .......... .......... .......... 24%  325M 0s\n",
            " 14100K .......... .......... .......... .......... .......... 24%  328M 0s\n",
            " 14150K .......... .......... .......... .......... .......... 24%  332M 0s\n",
            " 14200K .......... .......... .......... .......... .......... 24%  352M 0s\n",
            " 14250K .......... .......... .......... .......... .......... 25%  273M 0s\n",
            " 14300K .......... .......... .......... .......... .......... 25%  349M 0s\n",
            " 14350K .......... .......... .......... .......... .......... 25%  294M 0s\n",
            " 14400K .......... .......... .......... .......... .......... 25%  293M 0s\n",
            " 14450K .......... .......... .......... .......... .......... 25%  331M 0s\n",
            " 14500K .......... .......... .......... .......... .......... 25%  341M 0s\n",
            " 14550K .......... .......... .......... .......... .......... 25%  258M 0s\n",
            " 14600K .......... .......... .......... .......... .......... 25% 6.23M 0s\n",
            " 14650K .......... .......... .......... .......... .......... 25%  300M 0s\n",
            " 14700K .......... .......... .......... .......... .......... 25%  388M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 25%  251M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 26%  309M 0s\n",
            " 14850K .......... .......... .......... .......... .......... 26%  349M 0s\n",
            " 14900K .......... .......... .......... .......... .......... 26%  327M 0s\n",
            " 14950K .......... .......... .......... .......... .......... 26%  312M 0s\n",
            " 15000K .......... .......... .......... .......... .......... 26%  302M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 26%  376M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 26%  378M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 26%  195M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 26%  303M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 26%  326M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 26%  319M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 26%  327M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 27%  327M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 27%  251M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 27%  320M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 27%  255M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 27%  339M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 27%  383M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 27%  395M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 27%  316M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 27%  333M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 27%  357M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 27%  383M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 28%  311M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 28%  382M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 28%  387M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 28% 27.3M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 28%  275M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 28%  353M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 28%  279M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 28%  316M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 28%  270M 0s\n",
            " 16400K .......... .......... .......... .......... .......... 28%  308M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 28%  348M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 28%  327M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 29%  260M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 29%  362M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 29%  372M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 29%  347M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 29%  278M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 29%  354M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 29%  141M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 29% 58.3M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 29%  153M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 29% 88.1M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 29%  332M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 30%  138M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 30% 87.7M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 30%  145M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 30%  219M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 30%  157M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 30%  157M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 30%  185M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 30% 56.1M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 30%  190M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 30%  108M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 30%  139M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 30%  186M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 31%  111M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 31%  143M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 31%  143M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 31%  135M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 31%  151M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 31%  132M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 31%  118M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 31% 16.5M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 31%  326M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 31%  238M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 31%  316M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 32%  369M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 32%  386M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 32%  291M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 32%  158M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 32%  378M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 32% 89.5M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 32% 97.3M 0s\n",
            " 18600K .......... .......... .......... .......... .......... 32% 85.0M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 32% 75.0M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 32%  166M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 32% 66.0M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 33% 95.4M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 33% 20.1M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 33% 51.3M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 33%  106M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 33% 72.8M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 33% 99.4M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 33% 56.8M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 33%  107M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 33% 74.8M 0s\n",
            " 19250K .......... .......... .......... .......... .......... 33%  104M 0s\n",
            " 19300K .......... .......... .......... .......... .......... 33% 67.8M 0s\n",
            " 19350K .......... .......... .......... .......... .......... 33%  117M 0s\n",
            " 19400K .......... .......... .......... .......... .......... 34% 91.0M 0s\n",
            " 19450K .......... .......... .......... .......... .......... 34%  118M 0s\n",
            " 19500K .......... .......... .......... .......... .......... 34% 63.9M 0s\n",
            " 19550K .......... .......... .......... .......... .......... 34% 12.9M 0s\n",
            " 19600K .......... .......... .......... .......... .......... 34%  302M 0s\n",
            " 19650K .......... .......... .......... .......... .......... 34%  336M 0s\n",
            " 19700K .......... .......... .......... .......... .......... 34%  329M 0s\n",
            " 19750K .......... .......... .......... .......... .......... 34%  259M 0s\n",
            " 19800K .......... .......... .......... .......... .......... 34%  363M 0s\n",
            " 19850K .......... .......... .......... .......... .......... 34%  383M 0s\n",
            " 19900K .......... .......... .......... .......... .......... 34%  388M 0s\n",
            " 19950K .......... .......... .......... .......... .......... 35% 15.9M 0s\n",
            " 20000K .......... .......... .......... .......... .......... 35%  270M 0s\n",
            " 20050K .......... .......... .......... .......... .......... 35%  319M 0s\n",
            " 20100K .......... .......... .......... .......... .......... 35%  292M 0s\n",
            " 20150K .......... .......... .......... .......... .......... 35%  296M 0s\n",
            " 20200K .......... .......... .......... .......... .......... 35%  374M 0s\n",
            " 20250K .......... .......... .......... .......... .......... 35%  388M 0s\n",
            " 20300K .......... .......... .......... .......... .......... 35%  382M 0s\n",
            " 20350K .......... .......... .......... .......... .......... 35% 49.9M 0s\n",
            " 20400K .......... .......... .......... .......... .......... 35%  340M 0s\n",
            " 20450K .......... .......... .......... .......... .......... 35%  350M 0s\n",
            " 20500K .......... .......... .......... .......... .......... 35%  253M 0s\n",
            " 20550K .......... .......... .......... .......... .......... 36%  100M 0s\n",
            " 20600K .......... .......... .......... .......... .......... 36% 78.7M 0s\n",
            " 20650K .......... .......... .......... .......... .......... 36% 64.5M 0s\n",
            " 20700K .......... .......... .......... .......... .......... 36%  112M 0s\n",
            " 20750K .......... .......... .......... .......... .......... 36% 80.4M 0s\n",
            " 20800K .......... .......... .......... .......... .......... 36% 98.2M 0s\n",
            " 20850K .......... .......... .......... .......... .......... 36%  100M 0s\n",
            " 20900K .......... .......... .......... .......... .......... 36% 78.7M 0s\n",
            " 20950K .......... .......... .......... .......... .......... 36% 89.8M 0s\n",
            " 21000K .......... .......... .......... .......... .......... 36% 77.5M 0s\n",
            " 21050K .......... .......... .......... .......... .......... 36%  112M 0s\n",
            " 21100K .......... .......... .......... .......... .......... 37% 49.8M 0s\n",
            " 21150K .......... .......... .......... .......... .......... 37%  141M 0s\n",
            " 21200K .......... .......... .......... .......... .......... 37% 89.7M 0s\n",
            " 21250K .......... .......... .......... .......... .......... 37% 90.9M 0s\n",
            " 21300K .......... .......... .......... .......... .......... 37% 92.3M 0s\n",
            " 21350K .......... .......... .......... .......... .......... 37% 96.7M 0s\n",
            " 21400K .......... .......... .......... .......... .......... 37% 94.7M 0s\n",
            " 21450K .......... .......... .......... .......... .......... 37%  108M 0s\n",
            " 21500K .......... .......... .......... .......... .......... 37% 87.1M 0s\n",
            " 21550K .......... .......... .......... .......... .......... 37% 79.4M 0s\n",
            " 21600K .......... .......... .......... .......... .......... 37%  102M 0s\n",
            " 21650K .......... .......... .......... .......... .......... 38% 55.4M 0s\n",
            " 21700K .......... .......... .......... .......... .......... 38% 99.1M 0s\n",
            " 21750K .......... .......... .......... .......... .......... 38% 65.1M 0s\n",
            " 21800K .......... .......... .......... .......... .......... 38%  140M 0s\n",
            " 21850K .......... .......... .......... .......... .......... 38%  102M 0s\n",
            " 21900K .......... .......... .......... .......... .......... 38% 86.6M 0s\n",
            " 21950K .......... .......... .......... .......... .......... 38% 81.9M 0s\n",
            " 22000K .......... .......... .......... .......... .......... 38% 81.7M 0s\n",
            " 22050K .......... .......... .......... .......... .......... 38% 87.1M 0s\n",
            " 22100K .......... .......... .......... .......... .......... 38% 91.6M 0s\n",
            " 22150K .......... .......... .......... .......... .......... 38% 93.3M 0s\n",
            " 22200K .......... .......... .......... .......... .......... 38% 88.4M 0s\n",
            " 22250K .......... .......... .......... .......... .......... 39% 99.7M 0s\n",
            " 22300K .......... .......... .......... .......... .......... 39% 90.1M 0s\n",
            " 22350K .......... .......... .......... .......... .......... 39% 73.2M 0s\n",
            " 22400K .......... .......... .......... .......... .......... 39% 97.3M 0s\n",
            " 22450K .......... .......... .......... .......... .......... 39% 77.6M 0s\n",
            " 22500K .......... .......... .......... .......... .......... 39% 90.6M 0s\n",
            " 22550K .......... .......... .......... .......... .......... 39% 75.2M 0s\n",
            " 22600K .......... .......... .......... .......... .......... 39% 83.3M 0s\n",
            " 22650K .......... .......... .......... .......... .......... 39%  103M 0s\n",
            " 22700K .......... .......... .......... .......... .......... 39% 95.9M 0s\n",
            " 22750K .......... .......... .......... .......... .......... 39% 62.0M 0s\n",
            " 22800K .......... .......... .......... .......... .......... 40% 84.4M 0s\n",
            " 22850K .......... .......... .......... .......... .......... 40% 62.2M 0s\n",
            " 22900K .......... .......... .......... .......... .......... 40% 99.0M 0s\n",
            " 22950K .......... .......... .......... .......... .......... 40% 93.3M 0s\n",
            " 23000K .......... .......... .......... .......... .......... 40% 75.3M 0s\n",
            " 23050K .......... .......... .......... .......... .......... 40%  117M 0s\n",
            " 23100K .......... .......... .......... .......... .......... 40% 45.3M 0s\n",
            " 23150K .......... .......... .......... .......... .......... 40% 66.3M 0s\n",
            " 23200K .......... .......... .......... .......... .......... 40%  254M 0s\n",
            " 23250K .......... .......... .......... .......... .......... 40%  203M 0s\n",
            " 23300K .......... .......... .......... .......... .......... 40%  103M 0s\n",
            " 23350K .......... .......... .......... .......... .......... 40% 78.5M 0s\n",
            " 23400K .......... .......... .......... .......... .......... 41% 33.3M 0s\n",
            " 23450K .......... .......... .......... .......... .......... 41%  245M 0s\n",
            " 23500K .......... .......... .......... .......... .......... 41%  260M 0s\n",
            " 23550K .......... .......... .......... .......... .......... 41%  138M 0s\n",
            " 23600K .......... .......... .......... .......... .......... 41%  114M 0s\n",
            " 23650K .......... .......... .......... .......... .......... 41% 66.8M 0s\n",
            " 23700K .......... .......... .......... .......... .......... 41%  116M 0s\n",
            " 23750K .......... .......... .......... .......... .......... 41% 80.0M 0s\n",
            " 23800K .......... .......... .......... .......... .......... 41% 85.6M 0s\n",
            " 23850K .......... .......... .......... .......... .......... 41%  128M 0s\n",
            " 23900K .......... .......... .......... .......... .......... 41%  160M 0s\n",
            " 23950K .......... .......... .......... .......... .......... 42%  138M 0s\n",
            " 24000K .......... .......... .......... .......... .......... 42%  142M 0s\n",
            " 24050K .......... .......... .......... .......... .......... 42%  151M 0s\n",
            " 24100K .......... .......... .......... .......... .......... 42%  183M 0s\n",
            " 24150K .......... .......... .......... .......... .......... 42%  120M 0s\n",
            " 24200K .......... .......... .......... .......... .......... 42%  149M 0s\n",
            " 24250K .......... .......... .......... .......... .......... 42%  183M 0s\n",
            " 24300K .......... .......... .......... .......... .......... 42%  157M 0s\n",
            " 24350K .......... .......... .......... .......... .......... 42% 57.2M 0s\n",
            " 24400K .......... .......... .......... .......... .......... 42%  156M 0s\n",
            " 24450K .......... .......... .......... .......... .......... 42%  141M 0s\n",
            " 24500K .......... .......... .......... .......... .......... 42%  163M 0s\n",
            " 24550K .......... .......... .......... .......... .......... 43%  151M 0s\n",
            " 24600K .......... .......... .......... .......... .......... 43%  164M 0s\n",
            " 24650K .......... .......... .......... .......... .......... 43%  130M 0s\n",
            " 24700K .......... .......... .......... .......... .......... 43%  193M 0s\n",
            " 24750K .......... .......... .......... .......... .......... 43%  106M 0s\n",
            " 24800K .......... .......... .......... .......... .......... 43%  220M 0s\n",
            " 24850K .......... .......... .......... .......... .......... 43%  194M 0s\n",
            " 24900K .......... .......... .......... .......... .......... 43%  184M 0s\n",
            " 24950K .......... .......... .......... .......... .......... 43%  144M 0s\n",
            " 25000K .......... .......... .......... .......... .......... 43%  210M 0s\n",
            " 25050K .......... .......... .......... .......... .......... 43%  125M 0s\n",
            " 25100K .......... .......... .......... .......... .......... 44% 71.2M 0s\n",
            " 25150K .......... .......... .......... .......... .......... 44%  136M 0s\n",
            " 25200K .......... .......... .......... .......... .......... 44%  150M 0s\n",
            " 25250K .......... .......... .......... .......... .......... 44% 18.8M 0s\n",
            " 25300K .......... .......... .......... .......... .......... 44%  282M 0s\n",
            " 25350K .......... .......... .......... .......... .......... 44% 8.28M 0s\n",
            " 25400K .......... .......... .......... .......... .......... 44%  362M 0s\n",
            " 25450K .......... .......... .......... .......... .......... 44%  194M 0s\n",
            " 25500K .......... .......... .......... .......... .......... 44%  224M 0s\n",
            " 25550K .......... .......... .......... .......... .......... 44%  170M 0s\n",
            " 25600K .......... .......... .......... .......... .......... 44%  292M 0s\n",
            " 25650K .......... .......... .......... .......... .......... 45%  378M 0s\n",
            " 25700K .......... .......... .......... .......... .......... 45%  362M 0s\n",
            " 25750K .......... .......... .......... .......... .......... 45%  344M 0s\n",
            " 25800K .......... .......... .......... .......... .......... 45%  366M 0s\n",
            " 25850K .......... .......... .......... .......... .......... 45%  390M 0s\n",
            " 25900K .......... .......... .......... .......... .......... 45%  369M 0s\n",
            " 25950K .......... .......... .......... .......... .......... 45%  322M 0s\n",
            " 26000K .......... .......... .......... .......... .......... 45%  390M 0s\n",
            " 26050K .......... .......... .......... .......... .......... 45%  348M 0s\n",
            " 26100K .......... .......... .......... .......... .......... 45%  393M 0s\n",
            " 26150K .......... .......... .......... .......... .......... 45%  344M 0s\n",
            " 26200K .......... .......... .......... .......... .......... 45%  390M 0s\n",
            " 26250K .......... .......... .......... .......... .......... 46%  378M 0s\n",
            " 26300K .......... .......... .......... .......... .......... 46%  373M 0s\n",
            " 26350K .......... .......... .......... .......... .......... 46%  328M 0s\n",
            " 26400K .......... .......... .......... .......... .......... 46% 35.6M 0s\n",
            " 26450K .......... .......... .......... .......... .......... 46%  219M 0s\n",
            " 26500K .......... .......... .......... .......... .......... 46%  231M 0s\n",
            " 26550K .......... .......... .......... .......... .......... 46%  177M 0s\n",
            " 26600K .......... .......... .......... .......... .......... 46%  306M 0s\n",
            " 26650K .......... .......... .......... .......... .......... 46%  363M 0s\n",
            " 26700K .......... .......... .......... .......... .......... 46%  341M 0s\n",
            " 26750K .......... .......... .......... .......... .......... 46%  323M 0s\n",
            " 26800K .......... .......... .......... .......... .......... 47%  372M 0s\n",
            " 26850K .......... .......... .......... .......... .......... 47%  391M 0s\n",
            " 26900K .......... .......... .......... .......... .......... 47%  323M 0s\n",
            " 26950K .......... .......... .......... .......... .......... 47%  291M 0s\n",
            " 27000K .......... .......... .......... .......... .......... 47% 91.0M 0s\n",
            " 27050K .......... .......... .......... .......... .......... 47%  251M 0s\n",
            " 27100K .......... .......... .......... .......... .......... 47%  254M 0s\n",
            " 27150K .......... .......... .......... .......... .......... 47%  264M 0s\n",
            " 27200K .......... .......... .......... .......... .......... 47%  385M 0s\n",
            " 27250K .......... .......... .......... .......... .......... 47%  325M 0s\n",
            " 27300K .......... .......... .......... .......... .......... 47%  331M 0s\n",
            " 27350K .......... .......... .......... .......... .......... 47%  342M 0s\n",
            " 27400K .......... .......... .......... .......... .......... 48%  101M 0s\n",
            " 27450K .......... .......... .......... .......... .......... 48%  110M 0s\n",
            " 27500K .......... .......... .......... .......... .......... 48%  189M 0s\n",
            " 27550K .......... .......... .......... .......... .......... 48%  117M 0s\n",
            " 27600K .......... .......... .......... .......... .......... 48%  119M 0s\n",
            " 27650K .......... .......... .......... .......... .......... 48%  150M 0s\n",
            " 27700K .......... .......... .......... .......... .......... 48% 81.4M 0s\n",
            " 27750K .......... .......... .......... .......... .......... 48% 11.6M 0s\n",
            " 27800K .......... .......... .......... .......... .......... 48%  187M 0s\n",
            " 27850K .......... .......... .......... .......... .......... 48%  213M 0s\n",
            " 27900K .......... .......... .......... .......... .......... 48%  236M 0s\n",
            " 27950K .......... .......... .......... .......... .......... 49%  206M 0s\n",
            " 28000K .......... .......... .......... .......... .......... 49%  234M 0s\n",
            " 28050K .......... .......... .......... .......... .......... 49%  223M 0s\n",
            " 28100K .......... .......... .......... .......... .......... 49%  232M 0s\n",
            " 28150K .......... .......... .......... .......... .......... 49%  191M 0s\n",
            " 28200K .......... .......... .......... .......... .......... 49%  247M 0s\n",
            " 28250K .......... .......... .......... .......... .......... 49%  220M 0s\n",
            " 28300K .......... .......... .......... .......... .......... 49%  251M 0s\n",
            " 28350K .......... .......... .......... .......... .......... 49%  207M 0s\n",
            " 28400K .......... .......... .......... .......... .......... 49% 10.5M 0s\n",
            " 28450K .......... .......... .......... .......... .......... 49%  211M 0s\n",
            " 28500K .......... .......... .......... .......... .......... 50%  219M 0s\n",
            " 28550K .......... .......... .......... .......... .......... 50%  207M 0s\n",
            " 28600K .......... .......... .......... .......... .......... 50%  206M 0s\n",
            " 28650K .......... .......... .......... .......... .......... 50%  237M 0s\n",
            " 28700K .......... .......... .......... .......... .......... 50%  242M 0s\n",
            " 28750K .......... .......... .......... .......... .......... 50%  204M 0s\n",
            " 28800K .......... .......... .......... .......... .......... 50%  236M 0s\n",
            " 28850K .......... .......... .......... .......... .......... 50%  234M 0s\n",
            " 28900K .......... .......... .......... .......... .......... 50%  241M 0s\n",
            " 28950K .......... .......... .......... .......... .......... 50%  208M 0s\n",
            " 29000K .......... .......... .......... .......... .......... 50%  232M 0s\n",
            " 29050K .......... .......... .......... .......... .......... 50%  208M 0s\n",
            " 29100K .......... .......... .......... .......... .......... 51%  236M 0s\n",
            " 29150K .......... .......... .......... .......... .......... 51%  179M 0s\n",
            " 29200K .......... .......... .......... .......... .......... 51%  249M 0s\n",
            " 29250K .......... .......... .......... .......... .......... 51%  269M 0s\n",
            " 29300K .......... .......... .......... .......... .......... 51%  247M 0s\n",
            " 29350K .......... .......... .......... .......... .......... 51%  238M 0s\n",
            " 29400K .......... .......... .......... .......... .......... 51%  264M 0s\n",
            " 29450K .......... .......... .......... .......... .......... 51%  271M 0s\n",
            " 29500K .......... .......... .......... .......... .......... 51%  259M 0s\n",
            " 29550K .......... .......... .......... .......... .......... 51%  131M 0s\n",
            " 29600K .......... .......... .......... .......... .......... 51%  218M 0s\n",
            " 29650K .......... .......... .......... .......... .......... 52%  215M 0s\n",
            " 29700K .......... .......... .......... .......... .......... 52%  217M 0s\n",
            " 29750K .......... .......... .......... .......... .......... 52%  184M 0s\n",
            " 29800K .......... .......... .......... .......... .......... 52%  224M 0s\n",
            " 29850K .......... .......... .......... .......... .......... 52%  211M 0s\n",
            " 29900K .......... .......... .......... .......... .......... 52%  217M 0s\n",
            " 29950K .......... .......... .......... .......... .......... 52% 50.3M 0s\n",
            " 30000K .......... .......... .......... .......... .......... 52%  200M 0s\n",
            " 30050K .......... .......... .......... .......... .......... 52%  248M 0s\n",
            " 30100K .......... .......... .......... .......... .......... 52%  209M 0s\n",
            " 30150K .......... .......... .......... .......... .......... 52%  191M 0s\n",
            " 30200K .......... .......... .......... .......... .......... 52%  204M 0s\n",
            " 30250K .......... .......... .......... .......... .......... 53%  217M 0s\n",
            " 30300K .......... .......... .......... .......... .......... 53%  247M 0s\n",
            " 30350K .......... .......... .......... .......... .......... 53%  132M 0s\n",
            " 30400K .......... .......... .......... .......... .......... 53%  137M 0s\n",
            " 30450K .......... .......... .......... .......... .......... 53% 40.9M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 53% 94.5M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 53% 24.7M 0s\n",
            " 30600K .......... .......... .......... .......... .......... 53%  205M 0s\n",
            " 30650K .......... .......... .......... .......... .......... 53%  214M 0s\n",
            " 30700K .......... .......... .......... .......... .......... 53%  227M 0s\n",
            " 30750K .......... .......... .......... .......... .......... 53%  209M 0s\n",
            " 30800K .......... .......... .......... .......... .......... 54%  263M 0s\n",
            " 30850K .......... .......... .......... .......... .......... 54%  254M 0s\n",
            " 30900K .......... .......... .......... .......... .......... 54%  272M 0s\n",
            " 30950K .......... .......... .......... .......... .......... 54%  205M 0s\n",
            " 31000K .......... .......... .......... .......... .......... 54%  243M 0s\n",
            " 31050K .......... .......... .......... .......... .......... 54%  210M 0s\n",
            " 31100K .......... .......... .......... .......... .......... 54%  255M 0s\n",
            " 31150K .......... .......... .......... .......... .......... 54%  210M 0s\n",
            " 31200K .......... .......... .......... .......... .......... 54%  172M 0s\n",
            " 31250K .......... .......... .......... .......... .......... 54% 55.5M 0s\n",
            " 31300K .......... .......... .......... .......... .......... 54% 23.2M 0s\n",
            " 31350K .......... .......... .......... .......... .......... 54%  270M 0s\n",
            " 31400K .......... .......... .......... .......... .......... 55%  316M 0s\n",
            " 31450K .......... .......... .......... .......... .......... 55%  309M 0s\n",
            " 31500K .......... .......... .......... .......... .......... 55%  305M 0s\n",
            " 31550K .......... .......... .......... .......... .......... 55%  260M 0s\n",
            " 31600K .......... .......... .......... .......... .......... 55%  349M 0s\n",
            " 31650K .......... .......... .......... .......... .......... 55%  353M 0s\n",
            " 31700K .......... .......... .......... .......... .......... 55%  344M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 55%  287M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 55%  382M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 55%  295M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 55%  326M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 56%  271M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 56%  179M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 56%  203M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 56%  173M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 56%  131M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 56%  202M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 56%  191M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 56%  185M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 56%  116M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 56%  216M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 56%  161M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 57%  102M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 57%  144M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 57%  129M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 57% 50.7M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 57%  228M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 57%  284M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 57%  205M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 57%  150M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 57%  163M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 57% 77.7M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 57%  338M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 57%  136M 0s\n",
            " 33100K .......... .......... .......... .......... .......... 58%  235M 0s\n",
            " 33150K .......... .......... .......... .......... .......... 58%  123M 0s\n",
            " 33200K .......... .......... .......... .......... .......... 58%  165M 0s\n",
            " 33250K .......... .......... .......... .......... .......... 58% 82.9M 0s\n",
            " 33300K .......... .......... .......... .......... .......... 58%  129M 0s\n",
            " 33350K .......... .......... .......... .......... .......... 58%  124M 0s\n",
            " 33400K .......... .......... .......... .......... .......... 58%  150M 0s\n",
            " 33450K .......... .......... .......... .......... .......... 58%  154M 0s\n",
            " 33500K .......... .......... .......... .......... .......... 58%  115M 0s\n",
            " 33550K .......... .......... .......... .......... .......... 58% 55.4M 0s\n",
            " 33600K .......... .......... .......... .......... .......... 58%  181M 0s\n",
            " 33650K .......... .......... .......... .......... .......... 59%  154M 0s\n",
            " 33700K .......... .......... .......... .......... .......... 59%  176M 0s\n",
            " 33750K .......... .......... .......... .......... .......... 59%  176M 0s\n",
            " 33800K .......... .......... .......... .......... .......... 59%  179M 0s\n",
            " 33850K .......... .......... .......... .......... .......... 59%  192M 0s\n",
            " 33900K .......... .......... .......... .......... .......... 59%  149M 0s\n",
            " 33950K .......... .......... .......... .......... .......... 59%  128M 0s\n",
            " 34000K .......... .......... .......... .......... .......... 59%  123M 0s\n",
            " 34050K .......... .......... .......... .......... .......... 59% 70.1M 0s\n",
            " 34100K .......... .......... .......... .......... .......... 59% 93.6M 0s\n",
            " 34150K .......... .......... .......... .......... .......... 59% 48.8M 0s\n",
            " 34200K .......... .......... .......... .......... .......... 59% 69.4M 0s\n",
            " 34250K .......... .......... .......... .......... .......... 60%  104M 0s\n",
            " 34300K .......... .......... .......... .......... .......... 60% 46.5M 0s\n",
            " 34350K .......... .......... .......... .......... .......... 60%  185M 0s\n",
            " 34400K .......... .......... .......... .......... .......... 60%  101M 0s\n",
            " 34450K .......... .......... .......... .......... .......... 60%  101M 0s\n",
            " 34500K .......... .......... .......... .......... .......... 60%  106M 0s\n",
            " 34550K .......... .......... .......... .......... .......... 60%  118M 0s\n",
            " 34600K .......... .......... .......... .......... .......... 60%  184M 0s\n",
            " 34650K .......... .......... .......... .......... .......... 60%  170M 0s\n",
            " 34700K .......... .......... .......... .......... .......... 60%  187M 0s\n",
            " 34750K .......... .......... .......... .......... .......... 60%  134M 0s\n",
            " 34800K .......... .......... .......... .......... .......... 61%  143M 0s\n",
            " 34850K .......... .......... .......... .......... .......... 61%  112M 0s\n",
            " 34900K .......... .......... .......... .......... .......... 61%  215M 0s\n",
            " 34950K .......... .......... .......... .......... .......... 61% 94.1M 0s\n",
            " 35000K .......... .......... .......... .......... .......... 61% 94.7M 0s\n",
            " 35050K .......... .......... .......... .......... .......... 61%  102M 0s\n",
            " 35100K .......... .......... .......... .......... .......... 61% 93.0M 0s\n",
            " 35150K .......... .......... .......... .......... .......... 61% 62.9M 0s\n",
            " 35200K .......... .......... .......... .......... .......... 61% 89.5M 0s\n",
            " 35250K .......... .......... .......... .......... .......... 61%  112M 0s\n",
            " 35300K .......... .......... .......... .......... .......... 61%  102M 0s\n",
            " 35350K .......... .......... .......... .......... .......... 61% 83.4M 0s\n",
            " 35400K .......... .......... .......... .......... .......... 62% 90.0M 0s\n",
            " 35450K .......... .......... .......... .......... .......... 62% 94.6M 0s\n",
            " 35500K .......... .......... .......... .......... .......... 62%  114M 0s\n",
            " 35550K .......... .......... .......... .......... .......... 62% 14.8M 0s\n",
            " 35600K .......... .......... .......... .......... .......... 62%  190M 0s\n",
            " 35650K .......... .......... .......... .......... .......... 62%  356M 0s\n",
            " 35700K .......... .......... .......... .......... .......... 62%  291M 0s\n",
            " 35750K .......... .......... .......... .......... .......... 62%  335M 0s\n",
            " 35800K .......... .......... .......... .......... .......... 62% 35.5M 0s\n",
            " 35850K .......... .......... .......... .......... .......... 62%  206M 0s\n",
            " 35900K .......... .......... .......... .......... .......... 62%  219M 0s\n",
            " 35950K .......... .......... .......... .......... .......... 63%  300M 0s\n",
            " 36000K .......... .......... .......... .......... .......... 63%  347M 0s\n",
            " 36050K .......... .......... .......... .......... .......... 63%  317M 0s\n",
            " 36100K .......... .......... .......... .......... .......... 63%  128M 0s\n",
            " 36150K .......... .......... .......... .......... .......... 63%  163M 0s\n",
            " 36200K .......... .......... .......... .......... .......... 63%  300M 0s\n",
            " 36250K .......... .......... .......... .......... .......... 63%  364M 0s\n",
            " 36300K .......... .......... .......... .......... .......... 63%  191M 0s\n",
            " 36350K .......... .......... .......... .......... .......... 63%  131M 0s\n",
            " 36400K .......... .......... .......... .......... .......... 63%  249M 0s\n",
            " 36450K .......... .......... .......... .......... .......... 63%  138M 0s\n",
            " 36500K .......... .......... .......... .......... .......... 64%  153M 0s\n",
            " 36550K .......... .......... .......... .......... .......... 64%  171M 0s\n",
            " 36600K .......... .......... .......... .......... .......... 64%  169M 0s\n",
            " 36650K .......... .......... .......... .......... .......... 64%  169M 0s\n",
            " 36700K .......... .......... .......... .......... .......... 64%  121M 0s\n",
            " 36750K .......... .......... .......... .......... .......... 64%  132M 0s\n",
            " 36800K .......... .......... .......... .......... .......... 64%  227M 0s\n",
            " 36850K .......... .......... .......... .......... .......... 64% 71.6M 0s\n",
            " 36900K .......... .......... .......... .......... .......... 64%  119M 0s\n",
            " 36950K .......... .......... .......... .......... .......... 64%  191M 0s\n",
            " 37000K .......... .......... .......... .......... .......... 64%  131M 0s\n",
            " 37050K .......... .......... .......... .......... .......... 64%  259M 0s\n",
            " 37100K .......... .......... .......... .......... .......... 65%  227M 0s\n",
            " 37150K .......... .......... .......... .......... .......... 65% 99.3M 0s\n",
            " 37200K .......... .......... .......... .......... .......... 65%  226M 0s\n",
            " 37250K .......... .......... .......... .......... .......... 65%  243M 0s\n",
            " 37300K .......... .......... .......... .......... .......... 65%  192M 0s\n",
            " 37350K .......... .......... .......... .......... .......... 65%  186M 0s\n",
            " 37400K .......... .......... .......... .......... .......... 65% 45.6M 0s\n",
            " 37450K .......... .......... .......... .......... .......... 65%  252M 0s\n",
            " 37500K .......... .......... .......... .......... .......... 65%  259M 0s\n",
            " 37550K .......... .......... .......... .......... .......... 65%  219M 0s\n",
            " 37600K .......... .......... .......... .......... .......... 65%  298M 0s\n",
            " 37650K .......... .......... .......... .......... .......... 66%  357M 0s\n",
            " 37700K .......... .......... .......... .......... .......... 66% 47.3M 0s\n",
            " 37750K .......... .......... .......... .......... .......... 66% 33.9M 0s\n",
            " 37800K .......... .......... .......... .......... .......... 66%  206M 0s\n",
            " 37850K .......... .......... .......... .......... .......... 66%  354M 0s\n",
            " 37900K .......... .......... .......... .......... .......... 66%  330M 0s\n",
            " 37950K .......... .......... .......... .......... .......... 66%  261M 0s\n",
            " 38000K .......... .......... .......... .......... .......... 66%  258M 0s\n",
            " 38050K .......... .......... .......... .......... .......... 66%  377M 0s\n",
            " 38100K .......... .......... .......... .......... .......... 66%  105M 0s\n",
            " 38150K .......... .......... .......... .......... .......... 66%  233M 0s\n",
            " 38200K .......... .......... .......... .......... .......... 66%  249M 0s\n",
            " 38250K .......... .......... .......... .......... .......... 67% 85.6M 0s\n",
            " 38300K .......... .......... .......... .......... .......... 67%  318M 0s\n",
            " 38350K .......... .......... .......... .......... .......... 67% 49.9M 0s\n",
            " 38400K .......... .......... .......... .......... .......... 67%  241M 0s\n",
            " 38450K .......... .......... .......... .......... .......... 67% 53.9M 0s\n",
            " 38500K .......... .......... .......... .......... .......... 67%  221M 0s\n",
            " 38550K .......... .......... .......... .......... .......... 67%  224M 0s\n",
            " 38600K .......... .......... .......... .......... .......... 67%  263M 0s\n",
            " 38650K .......... .......... .......... .......... .......... 67% 39.0M 0s\n",
            " 38700K .......... .......... .......... .......... .......... 67%  125M 0s\n",
            " 38750K .......... .......... .......... .......... .......... 67%  139M 0s\n",
            " 38800K .......... .......... .......... .......... .......... 68%  214M 0s\n",
            " 38850K .......... .......... .......... .......... .......... 68%  266M 0s\n",
            " 38900K .......... .......... .......... .......... .......... 68%  346M 0s\n",
            " 38950K .......... .......... .......... .......... .......... 68%  310M 0s\n",
            " 39000K .......... .......... .......... .......... .......... 68%  314M 0s\n",
            " 39050K .......... .......... .......... .......... .......... 68% 92.8M 0s\n",
            " 39100K .......... .......... .......... .......... .......... 68%  245M 0s\n",
            " 39150K .......... .......... .......... .......... .......... 68% 16.8M 0s\n",
            " 39200K .......... .......... .......... .......... .......... 68%  251M 0s\n",
            " 39250K .......... .......... .......... .......... .......... 68%  227M 0s\n",
            " 39300K .......... .......... .......... .......... .......... 68%  230M 0s\n",
            " 39350K .......... .......... .......... .......... .......... 69%  207M 0s\n",
            " 39400K .......... .......... .......... .......... .......... 69%  241M 0s\n",
            " 39450K .......... .......... .......... .......... .......... 69%  280M 0s\n",
            " 39500K .......... .......... .......... .......... .......... 69%  262M 0s\n",
            " 39550K .......... .......... .......... .......... .......... 69%  238M 0s\n",
            " 39600K .......... .......... .......... .......... .......... 69%  195M 0s\n",
            " 39650K .......... .......... .......... .......... .......... 69%  234M 0s\n",
            " 39700K .......... .......... .......... .......... .......... 69%  260M 0s\n",
            " 39750K .......... .......... .......... .......... .......... 69%  208M 0s\n",
            " 39800K .......... .......... .......... .......... .......... 69%  223M 0s\n",
            " 39850K .......... .......... .......... .......... .......... 69%  242M 0s\n",
            " 39900K .......... .......... .......... .......... .......... 69%  269M 0s\n",
            " 39950K .......... .......... .......... .......... .......... 70% 32.4M 0s\n",
            " 40000K .......... .......... .......... .......... .......... 70%  201M 0s\n",
            " 40050K .......... .......... .......... .......... .......... 70%  187M 0s\n",
            " 40100K .......... .......... .......... .......... .......... 70%  184M 0s\n",
            " 40150K .......... .......... .......... .......... .......... 70%  204M 0s\n",
            " 40200K .......... .......... .......... .......... .......... 70%  225M 0s\n",
            " 40250K .......... .......... .......... .......... .......... 70%  193M 0s\n",
            " 40300K .......... .......... .......... .......... .......... 70%  213M 0s\n",
            " 40350K .......... .......... .......... .......... .......... 70%  204M 0s\n",
            " 40400K .......... .......... .......... .......... .......... 70%  253M 0s\n",
            " 40450K .......... .......... .......... .......... .......... 70%  249M 0s\n",
            " 40500K .......... .......... .......... .......... .......... 71% 12.7M 0s\n",
            " 40550K .......... .......... .......... .......... .......... 71%  191M 0s\n",
            " 40600K .......... .......... .......... .......... .......... 71%  186M 0s\n",
            " 40650K .......... .......... .......... .......... .......... 71%  199M 0s\n",
            " 40700K .......... .......... .......... .......... .......... 71%  204M 0s\n",
            " 40750K .......... .......... .......... .......... .......... 71%  183M 0s\n",
            " 40800K .......... .......... .......... .......... .......... 71%  247M 0s\n",
            " 40850K .......... .......... .......... .......... .......... 71%  235M 0s\n",
            " 40900K .......... .......... .......... .......... .......... 71%  227M 0s\n",
            " 40950K .......... .......... .......... .......... .......... 71%  208M 0s\n",
            " 41000K .......... .......... .......... .......... .......... 71%  244M 0s\n",
            " 41050K .......... .......... .......... .......... .......... 71%  229M 0s\n",
            " 41100K .......... .......... .......... .......... .......... 72%  203M 0s\n",
            " 41150K .......... .......... .......... .......... .......... 72%  165M 0s\n",
            " 41200K .......... .......... .......... .......... .......... 72%  194M 0s\n",
            " 41250K .......... .......... .......... .......... .......... 72%  208M 0s\n",
            " 41300K .......... .......... .......... .......... .......... 72%  224M 0s\n",
            " 41350K .......... .......... .......... .......... .......... 72%  226M 0s\n",
            " 41400K .......... .......... .......... .......... .......... 72%  223M 0s\n",
            " 41450K .......... .......... .......... .......... .......... 72%  285M 0s\n",
            " 41500K .......... .......... .......... .......... .......... 72%  325M 0s\n",
            " 41550K .......... .......... .......... .......... .......... 72%  277M 0s\n",
            " 41600K .......... .......... .......... .......... .......... 72%  346M 0s\n",
            " 41650K .......... .......... .......... .......... .......... 73%  345M 0s\n",
            " 41700K .......... .......... .......... .......... .......... 73%  332M 0s\n",
            " 41750K .......... .......... .......... .......... .......... 73%  330M 0s\n",
            " 41800K .......... .......... .......... .......... .......... 73%  357M 0s\n",
            " 41850K .......... .......... .......... .......... .......... 73%  324M 0s\n",
            " 41900K .......... .......... .......... .......... .......... 73%  357M 0s\n",
            " 41950K .......... .......... .......... .......... .......... 73%  166M 0s\n",
            " 42000K .......... .......... .......... .......... .......... 73%  193M 0s\n",
            " 42050K .......... .......... .......... .......... .......... 73% 44.0M 0s\n",
            " 42100K .......... .......... .......... .......... .......... 73%  210M 0s\n",
            " 42150K .......... .......... .......... .......... .......... 73% 88.8M 0s\n",
            " 42200K .......... .......... .......... .......... .......... 73%  354M 0s\n",
            " 42250K .......... .......... .......... .......... .......... 74% 52.9M 0s\n",
            " 42300K .......... .......... .......... .......... .......... 74%  172M 0s\n",
            " 42350K .......... .......... .......... .......... .......... 74%  141M 0s\n",
            " 42400K .......... .......... .......... .......... .......... 74%  200M 0s\n",
            " 42450K .......... .......... .......... .......... .......... 74%  238M 0s\n",
            " 42500K .......... .......... .......... .......... .......... 74% 20.0M 0s\n",
            " 42550K .......... .......... .......... .......... .......... 74%  283M 0s\n",
            " 42600K .......... .......... .......... .......... .......... 74%  359M 0s\n",
            " 42650K .......... .......... .......... .......... .......... 74%  326M 0s\n",
            " 42700K .......... .......... .......... .......... .......... 74%  302M 0s\n",
            " 42750K .......... .......... .......... .......... .......... 74%  241M 0s\n",
            " 42800K .......... .......... .......... .......... .......... 75%  353M 0s\n",
            " 42850K .......... .......... .......... .......... .......... 75%  330M 0s\n",
            " 42900K .......... .......... .......... .......... .......... 75%  362M 0s\n",
            " 42950K .......... .......... .......... .......... .......... 75% 27.4M 0s\n",
            " 43000K .......... .......... .......... .......... .......... 75%  348M 0s\n",
            " 43050K .......... .......... .......... .......... .......... 75%  326M 0s\n",
            " 43100K .......... .......... .......... .......... .......... 75%  357M 0s\n",
            " 43150K .......... .......... .......... .......... .......... 75%  311M 0s\n",
            " 43200K .......... .......... .......... .......... .......... 75% 15.1M 0s\n",
            " 43250K .......... .......... .......... .......... .......... 75%  313M 0s\n",
            " 43300K .......... .......... .......... .......... .......... 75%  289M 0s\n",
            " 43350K .......... .......... .......... .......... .......... 76%  293M 0s\n",
            " 43400K .......... .......... .......... .......... .......... 76%  281M 0s\n",
            " 43450K .......... .......... .......... .......... .......... 76%  293M 0s\n",
            " 43500K .......... .......... .......... .......... .......... 76%  320M 0s\n",
            " 43550K .......... .......... .......... .......... .......... 76%  254M 0s\n",
            " 43600K .......... .......... .......... .......... .......... 76%  367M 0s\n",
            " 43650K .......... .......... .......... .......... .......... 76%  317M 0s\n",
            " 43700K .......... .......... .......... .......... .......... 76%  334M 0s\n",
            " 43750K .......... .......... .......... .......... .......... 76%  343M 0s\n",
            " 43800K .......... .......... .......... .......... .......... 76%  390M 0s\n",
            " 43850K .......... .......... .......... .......... .......... 76%  360M 0s\n",
            " 43900K .......... .......... .......... .......... .......... 76% 23.4M 0s\n",
            " 43950K .......... .......... .......... .......... .......... 77%  238M 0s\n",
            " 44000K .......... .......... .......... .......... .......... 77%  314M 0s\n",
            " 44050K .......... .......... .......... .......... .......... 77%  316M 0s\n",
            " 44100K .......... .......... .......... .......... .......... 77%  339M 0s\n",
            " 44150K .......... .......... .......... .......... .......... 77%  298M 0s\n",
            " 44200K .......... .......... .......... .......... .......... 77%  271M 0s\n",
            " 44250K .......... .......... .......... .......... .......... 77%  360M 0s\n",
            " 44300K .......... .......... .......... .......... .......... 77%  320M 0s\n",
            " 44350K .......... .......... .......... .......... .......... 77%  278M 0s\n",
            " 44400K .......... .......... .......... .......... .......... 77%  316M 0s\n",
            " 44450K .......... .......... .......... .......... .......... 77%  359M 0s\n",
            " 44500K .......... .......... .......... .......... .......... 78%  276M 0s\n",
            " 44550K .......... .......... .......... .......... .......... 78%  301M 0s\n",
            " 44600K .......... .......... .......... .......... .......... 78%  302M 0s\n",
            " 44650K .......... .......... .......... .......... .......... 78%  194M 0s\n",
            " 44700K .......... .......... .......... .......... .......... 78% 45.4M 0s\n",
            " 44750K .......... .......... .......... .......... .......... 78%  291M 0s\n",
            " 44800K .......... .......... .......... .......... .......... 78%  253M 0s\n",
            " 44850K .......... .......... .......... .......... .......... 78% 76.3M 0s\n",
            " 44900K .......... .......... .......... .......... .......... 78%  310M 0s\n",
            " 44950K .......... .......... .......... .......... .......... 78%  137M 0s\n",
            " 45000K .......... .......... .......... .......... .......... 78% 54.5M 0s\n",
            " 45050K .......... .......... .......... .......... .......... 78%  321M 0s\n",
            " 45100K .......... .......... .......... .......... .......... 79%  325M 0s\n",
            " 45150K .......... .......... .......... .......... .......... 79%  251M 0s\n",
            " 45200K .......... .......... .......... .......... .......... 79%  202M 0s\n",
            " 45250K .......... .......... .......... .......... .......... 79%  172M 0s\n",
            " 45300K .......... .......... .......... .......... .......... 79% 85.3M 0s\n",
            " 45350K .......... .......... .......... .......... .......... 79%  201M 0s\n",
            " 45400K .......... .......... .......... .......... .......... 79%  189M 0s\n",
            " 45450K .......... .......... .......... .......... .......... 79%  166M 0s\n",
            " 45500K .......... .......... .......... .......... .......... 79%  146M 0s\n",
            " 45550K .......... .......... .......... .......... .......... 79% 52.4M 0s\n",
            " 45600K .......... .......... .......... .......... .......... 79%  270M 0s\n",
            " 45650K .......... .......... .......... .......... .......... 80%  175M 0s\n",
            " 45700K .......... .......... .......... .......... .......... 80%  159M 0s\n",
            " 45750K .......... .......... .......... .......... .......... 80%  187M 0s\n",
            " 45800K .......... .......... .......... .......... .......... 80%  123M 0s\n",
            " 45850K .......... .......... .......... .......... .......... 80%  159M 0s\n",
            " 45900K .......... .......... .......... .......... .......... 80%  142M 0s\n",
            " 45950K .......... .......... .......... .......... .......... 80%  137M 0s\n",
            " 46000K .......... .......... .......... .......... .......... 80% 93.9M 0s\n",
            " 46050K .......... .......... .......... .......... .......... 80% 72.6M 0s\n",
            " 46100K .......... .......... .......... .......... .......... 80%  131M 0s\n",
            " 46150K .......... .......... .......... .......... .......... 80% 78.3M 0s\n",
            " 46200K .......... .......... .......... .......... .......... 81%  280M 0s\n",
            " 46250K .......... .......... .......... .......... .......... 81%  156M 0s\n",
            " 46300K .......... .......... .......... .......... .......... 81%  329M 0s\n",
            " 46350K .......... .......... .......... .......... .......... 81% 36.9M 0s\n",
            " 46400K .......... .......... .......... .......... .......... 81%  305M 0s\n",
            " 46450K .......... .......... .......... .......... .......... 81%  297M 0s\n",
            " 46500K .......... .......... .......... .......... .......... 81%  321M 0s\n",
            " 46550K .......... .......... .......... .......... .......... 81%  293M 0s\n",
            " 46600K .......... .......... .......... .......... .......... 81%  210M 0s\n",
            " 46650K .......... .......... .......... .......... .......... 81% 56.5M 0s\n",
            " 46700K .......... .......... .......... .......... .......... 81%  296M 0s\n",
            " 46750K .......... .......... .......... .......... .......... 81%  274M 0s\n",
            " 46800K .......... .......... .......... .......... .......... 82%  213M 0s\n",
            " 46850K .......... .......... .......... .......... .......... 82% 9.80M 0s\n",
            " 46900K .......... .......... .......... .......... .......... 82%  318M 0s\n",
            " 46950K .......... .......... .......... .......... .......... 82%  276M 0s\n",
            " 47000K .......... .......... .......... .......... .......... 82%  334M 0s\n",
            " 47050K .......... .......... .......... .......... .......... 82%  347M 0s\n",
            " 47100K .......... .......... .......... .......... .......... 82%  360M 0s\n",
            " 47150K .......... .......... .......... .......... .......... 82%  253M 0s\n",
            " 47200K .......... .......... .......... .......... .......... 82%  325M 0s\n",
            " 47250K .......... .......... .......... .......... .......... 82%  338M 0s\n",
            " 47300K .......... .......... .......... .......... .......... 82%  328M 0s\n",
            " 47350K .......... .......... .......... .......... .......... 83%  285M 0s\n",
            " 47400K .......... .......... .......... .......... .......... 83%  356M 0s\n",
            " 47450K .......... .......... .......... .......... .......... 83%  343M 0s\n",
            " 47500K .......... .......... .......... .......... .......... 83%  309M 0s\n",
            " 47550K .......... .......... .......... .......... .......... 83%  295M 0s\n",
            " 47600K .......... .......... .......... .......... .......... 83%  318M 0s\n",
            " 47650K .......... .......... .......... .......... .......... 83%  356M 0s\n",
            " 47700K .......... .......... .......... .......... .......... 83%  367M 0s\n",
            " 47750K .......... .......... .......... .......... .......... 83%  286M 0s\n",
            " 47800K .......... .......... .......... .......... .......... 83%  287M 0s\n",
            " 47850K .......... .......... .......... .......... .......... 83%  349M 0s\n",
            " 47900K .......... .......... .......... .......... .......... 83%  178M 0s\n",
            " 47950K .......... .......... .......... .......... .......... 84% 93.2M 0s\n",
            " 48000K .......... .......... .......... .......... .......... 84%  116M 0s\n",
            " 48050K .......... .......... .......... .......... .......... 84% 88.6M 0s\n",
            " 48100K .......... .......... .......... .......... .......... 84%  269M 0s\n",
            " 48150K .......... .......... .......... .......... .......... 84%  139M 0s\n",
            " 48200K .......... .......... .......... .......... .......... 84%  117M 0s\n",
            " 48250K .......... .......... .......... .......... .......... 84%  202M 0s\n",
            " 48300K .......... .......... .......... .......... .......... 84%  143M 0s\n",
            " 48350K .......... .......... .......... .......... .......... 84%  152M 0s\n",
            " 48400K .......... .......... .......... .......... .......... 84%  120M 0s\n",
            " 48450K .......... .......... .......... .......... .......... 84%  137M 0s\n",
            " 48500K .......... .......... .......... .......... .......... 85%  122M 0s\n",
            " 48550K .......... .......... .......... .......... .......... 85%  161M 0s\n",
            " 48600K .......... .......... .......... .......... .......... 85%  150M 0s\n",
            " 48650K .......... .......... .......... .......... .......... 85% 90.1M 0s\n",
            " 48700K .......... .......... .......... .......... .......... 85% 93.3M 0s\n",
            " 48750K .......... .......... .......... .......... .......... 85% 16.1M 0s\n",
            " 48800K .......... .......... .......... .......... .......... 85%  326M 0s\n",
            " 48850K .......... .......... .......... .......... .......... 85%  335M 0s\n",
            " 48900K .......... .......... .......... .......... .......... 85%  353M 0s\n",
            " 48950K .......... .......... .......... .......... .......... 85%  322M 0s\n",
            " 49000K .......... .......... .......... .......... .......... 85% 96.3M 0s\n",
            " 49050K .......... .......... .......... .......... .......... 85% 89.6M 0s\n",
            " 49100K .......... .......... .......... .......... .......... 86%  122M 0s\n",
            " 49150K .......... .......... .......... .......... .......... 86% 68.9M 0s\n",
            " 49200K .......... .......... .......... .......... .......... 86% 89.6M 0s\n",
            " 49250K .......... .......... .......... .......... .......... 86% 19.7M 0s\n",
            " 49300K .......... .......... .......... .......... .......... 86%  335M 0s\n",
            " 49350K .......... .......... .......... .......... .......... 86%  245M 0s\n",
            " 49400K .......... .......... .......... .......... .......... 86%  157M 0s\n",
            " 49450K .......... .......... .......... .......... .......... 86% 96.0M 0s\n",
            " 49500K .......... .......... .......... .......... .......... 86%  110M 0s\n",
            " 49550K .......... .......... .......... .......... .......... 86% 51.7M 0s\n",
            " 49600K .......... .......... .......... .......... .......... 86%  111M 0s\n",
            " 49650K .......... .......... .......... .......... .......... 87%  156M 0s\n",
            " 49700K .......... .......... .......... .......... .......... 87%  212M 0s\n",
            " 49750K .......... .......... .......... .......... .......... 87%  130M 0s\n",
            " 49800K .......... .......... .......... .......... .......... 87%  164M 0s\n",
            " 49850K .......... .......... .......... .......... .......... 87% 55.7M 0s\n",
            " 49900K .......... .......... .......... .......... .......... 87% 23.6M 0s\n",
            " 49950K .......... .......... .......... .......... .......... 87%  267M 0s\n",
            " 50000K .......... .......... .......... .......... .......... 87%  345M 0s\n",
            " 50050K .......... .......... .......... .......... .......... 87%  330M 0s\n",
            " 50100K .......... .......... .......... .......... .......... 87%  365M 0s\n",
            " 50150K .......... .......... .......... .......... .......... 87%  312M 0s\n",
            " 50200K .......... .......... .......... .......... .......... 88%  331M 0s\n",
            " 50250K .......... .......... .......... .......... .......... 88%  344M 0s\n",
            " 50300K .......... .......... .......... .......... .......... 88%  392M 0s\n",
            " 50350K .......... .......... .......... .......... .......... 88%  254M 0s\n",
            " 50400K .......... .......... .......... .......... .......... 88%  327M 0s\n",
            " 50450K .......... .......... .......... .......... .......... 88%  113M 0s\n",
            " 50500K .......... .......... .......... .......... .......... 88%  142M 0s\n",
            " 50550K .......... .......... .......... .......... .......... 88%  163M 0s\n",
            " 50600K .......... .......... .......... .......... .......... 88% 77.7M 0s\n",
            " 50650K .......... .......... .......... .......... .......... 88% 91.8M 0s\n",
            " 50700K .......... .......... .......... .......... .......... 88% 80.8M 0s\n",
            " 50750K .......... .......... .......... .......... .......... 88% 85.5M 0s\n",
            " 50800K .......... .......... .......... .......... .......... 89% 89.4M 0s\n",
            " 50850K .......... .......... .......... .......... .......... 89% 75.6M 0s\n",
            " 50900K .......... .......... .......... .......... .......... 89% 75.8M 0s\n",
            " 50950K .......... .......... .......... .......... .......... 89%  106M 0s\n",
            " 51000K .......... .......... .......... .......... .......... 89% 82.2M 0s\n",
            " 51050K .......... .......... .......... .......... .......... 89% 95.8M 0s\n",
            " 51100K .......... .......... .......... .......... .......... 89%  104M 0s\n",
            " 51150K .......... .......... .......... .......... .......... 89%  146M 0s\n",
            " 51200K .......... .......... .......... .......... .......... 89%  156M 0s\n",
            " 51250K .......... .......... .......... .......... .......... 89% 81.7M 0s\n",
            " 51300K .......... .......... .......... .......... .......... 89%  195M 0s\n",
            " 51350K .......... .......... .......... .......... .......... 90%  153M 0s\n",
            " 51400K .......... .......... .......... .......... .......... 90%  190M 0s\n",
            " 51450K .......... .......... .......... .......... .......... 90%  162M 0s\n",
            " 51500K .......... .......... .......... .......... .......... 90% 61.8M 0s\n",
            " 51550K .......... .......... .......... .......... .......... 90%  157M 0s\n",
            " 51600K .......... .......... .......... .......... .......... 90%  149M 0s\n",
            " 51650K .......... .......... .......... .......... .......... 90% 11.3M 0s\n",
            " 51700K .......... .......... .......... .......... .......... 90%  246M 0s\n",
            " 51750K .......... .......... .......... .......... .......... 90%  263M 0s\n",
            " 51800K .......... .......... .......... .......... .......... 90%  281M 0s\n",
            " 51850K .......... .......... .......... .......... .......... 90%  322M 0s\n",
            " 51900K .......... .......... .......... .......... .......... 90%  306M 0s\n",
            " 51950K .......... .......... .......... .......... .......... 91%  266M 0s\n",
            " 52000K .......... .......... .......... .......... .......... 91%  361M 0s\n",
            " 52050K .......... .......... .......... .......... .......... 91%  371M 0s\n",
            " 52100K .......... .......... .......... .......... .......... 91%  348M 0s\n",
            " 52150K .......... .......... .......... .......... .......... 91%  310M 0s\n",
            " 52200K .......... .......... .......... .......... .......... 91%  357M 0s\n",
            " 52250K .......... .......... .......... .......... .......... 91%  343M 0s\n",
            " 52300K .......... .......... .......... .......... .......... 91% 63.2M 0s\n",
            " 52350K .......... .......... .......... .......... .......... 91%  204M 0s\n",
            " 52400K .......... .......... .......... .......... .......... 91%  342M 0s\n",
            " 52450K .......... .......... .......... .......... .......... 91%  344M 0s\n",
            " 52500K .......... .......... .......... .......... .......... 92%  360M 0s\n",
            " 52550K .......... .......... .......... .......... .......... 92%  306M 0s\n",
            " 52600K .......... .......... .......... .......... .......... 92% 12.6M 0s\n",
            " 52650K .......... .......... .......... .......... .......... 92%  249M 0s\n",
            " 52700K .......... .......... .......... .......... .......... 92%  275M 0s\n",
            " 52750K .......... .......... .......... .......... .......... 92%  250M 0s\n",
            " 52800K .......... .......... .......... .......... .......... 92%  336M 0s\n",
            " 52850K .......... .......... .......... .......... .......... 92%  328M 0s\n",
            " 52900K .......... .......... .......... .......... .......... 92%  363M 0s\n",
            " 52950K .......... .......... .......... .......... .......... 92%  287M 0s\n",
            " 53000K .......... .......... .......... .......... .......... 92%  366M 0s\n",
            " 53050K .......... .......... .......... .......... .......... 92%  344M 0s\n",
            " 53100K .......... .......... .......... .......... .......... 93%  368M 0s\n",
            " 53150K .......... .......... .......... .......... .......... 93%  316M 0s\n",
            " 53200K .......... .......... .......... .......... .......... 93%  380M 0s\n",
            " 53250K .......... .......... .......... .......... .......... 93%  381M 0s\n",
            " 53300K .......... .......... .......... .......... .......... 93% 18.0M 0s\n",
            " 53350K .......... .......... .......... .......... .......... 93%  225M 0s\n",
            " 53400K .......... .......... .......... .......... .......... 93%  292M 0s\n",
            " 53450K .......... .......... .......... .......... .......... 93%  307M 0s\n",
            " 53500K .......... .......... .......... .......... .......... 93%  348M 0s\n",
            " 53550K .......... .......... .......... .......... .......... 93%  277M 0s\n",
            " 53600K .......... .......... .......... .......... .......... 93%  376M 0s\n",
            " 53650K .......... .......... .......... .......... .......... 94%  377M 0s\n",
            " 53700K .......... .......... .......... .......... .......... 94%  383M 0s\n",
            " 53750K .......... .......... .......... .......... .......... 94%  345M 0s\n",
            " 53800K .......... .......... .......... .......... .......... 94%  360M 0s\n",
            " 53850K .......... .......... .......... .......... .......... 94% 41.2M 0s\n",
            " 53900K .......... .......... .......... .......... .......... 94%  260M 0s\n",
            " 53950K .......... .......... .......... .......... .......... 94%  262M 0s\n",
            " 54000K .......... .......... .......... .......... .......... 94%  327M 0s\n",
            " 54050K .......... .......... .......... .......... .......... 94%  325M 0s\n",
            " 54100K .......... .......... .......... .......... .......... 94%  335M 0s\n",
            " 54150K .......... .......... .......... .......... .......... 94%  288M 0s\n",
            " 54200K .......... .......... .......... .......... .......... 95%  315M 0s\n",
            " 54250K .......... .......... .......... .......... .......... 95%  378M 0s\n",
            " 54300K .......... .......... .......... .......... .......... 95%  333M 0s\n",
            " 54350K .......... .......... .......... .......... .......... 95%  124M 0s\n",
            " 54400K .......... .......... .......... .......... .......... 95%  169M 0s\n",
            " 54450K .......... .......... .......... .......... .......... 95%  176M 0s\n",
            " 54500K .......... .......... .......... .......... .......... 95%  164M 0s\n",
            " 54550K .......... .......... .......... .......... .......... 95%  102M 0s\n",
            " 54600K .......... .......... .......... .......... .......... 95% 87.9M 0s\n",
            " 54650K .......... .......... .......... .......... .......... 95%  168M 0s\n",
            " 54700K .......... .......... .......... .......... .......... 95%  181M 0s\n",
            " 54750K .......... .......... .......... .......... .......... 95%  144M 0s\n",
            " 54800K .......... .......... .......... .......... .......... 96%  136M 0s\n",
            " 54850K .......... .......... .......... .......... .......... 96%  140M 0s\n",
            " 54900K .......... .......... .......... .......... .......... 96%  138M 0s\n",
            " 54950K .......... .......... .......... .......... .......... 96%  172M 0s\n",
            " 55000K .......... .......... .......... .......... .......... 96%  164M 0s\n",
            " 55050K .......... .......... .......... .......... .......... 96%  122M 0s\n",
            " 55100K .......... .......... .......... .......... .......... 96%  154M 0s\n",
            " 55150K .......... .......... .......... .......... .......... 96%  132M 0s\n",
            " 55200K .......... .......... .......... .......... .......... 96%  163M 0s\n",
            " 55250K .......... .......... .......... .......... .......... 96%  190M 0s\n",
            " 55300K .......... .......... .......... .......... .......... 96%  136M 0s\n",
            " 55350K .......... .......... .......... .......... .......... 97%  121M 0s\n",
            " 55400K .......... .......... .......... .......... .......... 97%  174M 0s\n",
            " 55450K .......... .......... .......... .......... .......... 97%  202M 0s\n",
            " 55500K .......... .......... .......... .......... .......... 97%  140M 0s\n",
            " 55550K .......... .......... .......... .......... .......... 97%  122M 0s\n",
            " 55600K .......... .......... .......... .......... .......... 97% 31.4M 0s\n",
            " 55650K .......... .......... .......... .......... .......... 97%  283M 0s\n",
            " 55700K .......... .......... .......... .......... .......... 97%  328M 0s\n",
            " 55750K .......... .......... .......... .......... .......... 97%  299M 0s\n",
            " 55800K .......... .......... .......... .......... .......... 97%  319M 0s\n",
            " 55850K .......... .......... .......... .......... .......... 97%  297M 0s\n",
            " 55900K .......... .......... .......... .......... .......... 97%  143M 0s\n",
            " 55950K .......... .......... .......... .......... .......... 98%  132M 0s\n",
            " 56000K .......... .......... .......... .......... .......... 98%  147M 0s\n",
            " 56050K .......... .......... .......... .......... .......... 98% 57.5M 0s\n",
            " 56100K .......... .......... .......... .......... .......... 98%  151M 0s\n",
            " 56150K .......... .......... .......... .......... .......... 98%  162M 0s\n",
            " 56200K .......... .......... .......... .......... .......... 98%  195M 0s\n",
            " 56250K .......... .......... .......... .......... .......... 98%  162M 0s\n",
            " 56300K .......... .......... .......... .......... .......... 98% 88.9M 0s\n",
            " 56350K .......... .......... .......... .......... .......... 98%  142M 0s\n",
            " 56400K .......... .......... .......... .......... .......... 98%  136M 0s\n",
            " 56450K .......... .......... .......... .......... .......... 98% 40.2M 0s\n",
            " 56500K .......... .......... .......... .......... .......... 99%  175M 0s\n",
            " 56550K .......... .......... .......... .......... .......... 99%  174M 0s\n",
            " 56600K .......... .......... .......... .......... .......... 99%  131M 0s\n",
            " 56650K .......... .......... .......... .......... .......... 99%  195M 0s\n",
            " 56700K .......... .......... .......... .......... .......... 99%  144M 0s\n",
            " 56750K .......... .......... .......... .......... .......... 99%  127M 0s\n",
            " 56800K .......... .......... .......... .......... .......... 99%  209M 0s\n",
            " 56850K .......... .......... .......... .......... .......... 99%  143M 0s\n",
            " 56900K .......... .......... .......... .......... .......... 99%  174M 0s\n",
            " 56950K .......... .......... .......... .......... .......... 99%  179M 0s\n",
            " 57000K .......... .......... .......... .......... .......... 99%  137M 0s\n",
            " 57050K .......... .......... .......... .......... ........  100%  213M=0.5s\n",
            "\n",
            "2022-12-13 13:02:52 (112 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh.1’ saved [58468498/58468498]\n",
            "\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which conda\n",
        "!conda --version\n",
        "!which python \n",
        "#미니 콘다가 설치된 후에는 파이썬 버젼이 살짝 바뀜\n",
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0eOTJBC1QmR",
        "outputId": "900916ec-e789-4329-9ade-c23ac135011b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/conda\n",
            "conda 4.5.4\n",
            "/usr/local/bin/python\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "conda install --channel defaults conda python=3.6 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThK436gh067J",
        "outputId": "74bcbfa2-bd7f-4643-8104-41230e4f97c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    sqlite-3.38.2              |       hc218d9a_0         1.5 MB\n",
            "    tk-8.6.11                  |       h1ccaba5_0         3.2 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         4.7 MB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates: 2018.03.07-0          --> 2022.10.11-h06a4308_0   \n",
            "    certifi:         2018.4.16-py36_0      --> 2021.5.30-py36h06a4308_0\n",
            "    cffi:            1.11.5-py36h9745a5d_0 --> 1.14.6-py36h400218f_0   \n",
            "    conda:           4.5.4-py36_0          --> 4.10.3-py36h06a4308_0   \n",
            "    cryptography:    2.2.2-py36h14c3975_0  --> 35.0.0-py36hd23ed53_0   \n",
            "    libffi:          3.2.1-hd88cf55_4      --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:       7.2.0-hdf63c60_3      --> 9.1.0-hdf63c60_0        \n",
            "    libstdcxx-ng:    7.2.0-hdf63c60_3      --> 9.1.0-hdf63c60_0        \n",
            "    ncurses:         6.1-hf484d3e_0        --> 6.3-h7f8727e_2          \n",
            "    openssl:         1.0.2o-h20670df_0     --> 1.1.1s-h7f8727e_0       \n",
            "    python:          3.6.5-hc3d631a_2      --> 3.6.13-h12debd9_1       \n",
            "    readline:        7.0-ha6073c6_4        --> 8.1.2-h7f8727e_1        \n",
            "    sqlite:          3.23.1-he433501_0     --> 3.38.2-hc218d9a_0       \n",
            "    tk:              8.6.7-hc745277_3      --> 8.6.11-h1ccaba5_0       \n",
            "    xz:              5.2.4-h14c3975_4      --> 5.2.5-h7f8727e_1        \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  libgcc-ng                                9.1.0-hdf63c60_0 --> 11.2.0-h1234567_1\n",
            "  libstdcxx-ng                             9.1.0-hdf63c60_0 --> 11.2.0-h1234567_1\n",
            "  ncurses                                    6.3-h7f8727e_2 --> 6.3-h5eee18b_3\n",
            "  readline                                 8.1.2-h7f8727e_1 --> 8.2-h5eee18b_0\n",
            "  xz                                       5.2.5-h7f8727e_1 --> 5.2.8-h5eee18b_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsqlite-3.38.2        |  1.5 MB |            |   0% \rsqlite-3.38.2        |  1.5 MB | ########   |  81% \rsqlite-3.38.2        |  1.5 MB | ########## | 100% \n",
            "\rtk-8.6.11            |  3.2 MB |            |   0% \rtk-8.6.11            |  3.2 MB | #          |  10% \rtk-8.6.11            |  3.2 MB | ####1      |  41% \rtk-8.6.11            |  3.2 MB | #######5   |  75% \rtk-8.6.11            |  3.2 MB | #########2 |  93% \rtk-8.6.11            |  3.2 MB | ########## | 100% \n",
            "/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/x509.py:18: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
            "  utils.DeprecatedIn35,\n",
            "\n",
            "The environment is inconsistent, please check the package plan carefully\n",
            "The following packages are causing the inconsistency:\n",
            "\n",
            "  - defaults/linux-64::python==3.6.13=h12debd9_1\n",
            "  - defaults/linux-64::yaml==0.1.7=had09818_2\n",
            "  - defaults/linux-64::brotlipy==0.7.0=py36h27cfd23_1003\n",
            "  - defaults/linux-64::pycosat==0.6.3=py36h0a5515d_0\n",
            "  - defaults/linux-64::ruamel_yaml==0.15.37=py36h14c3975_2\n",
            "  - defaults/linux-64::tk==8.6.11=h1ccaba5_0\n",
            "  - defaults/linux-64::chardet==3.0.4=py36h0f667ec_1\n",
            "  - defaults/linux-64::conda==4.10.3=py36h06a4308_0\n",
            "  - defaults/linux-64::six==1.11.0=py36h372c433_1\n",
            "  - defaults/linux-64::conda-package-handling==1.7.3=py36h27cfd23_1\n",
            "  - defaults/linux-64::requests==2.18.4=py36he2e5f8d_1\n",
            "  - defaults/linux-64::cffi==1.14.6=py36h400218f_0\n",
            "  - defaults/linux-64::sqlite==3.38.2=hc218d9a_0\n",
            "  - defaults/linux-64::pip==10.0.1=py36_0\n",
            "  - defaults/linux-64::pycparser==2.18=py36hf9f622e_1\n",
            "  - defaults/linux-64::cryptography==35.0.0=py36hd23ed53_0\n",
            "  - defaults/linux-64::pyopenssl==18.0.0=py36_0\n",
            "  - defaults/linux-64::wheel==0.31.1=py36_0\n",
            "  - defaults/noarch::tqdm==4.63.0=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::idna==2.6=py36h82fb2a8_1\n",
            "  - defaults/linux-64::urllib3==1.22=py36hbe7ace6_0\n",
            "  - defaults/noarch::charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::setuptools==39.2.0=py36_0\n",
            "  - defaults/linux-64::pysocks==1.6.8=py36_0\n",
            "  - defaults/noarch::colorama==0.4.4=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::asn1crypto==0.24.0=py36_0\n",
            "  - defaults/linux-64::zlib==1.2.11=ha838bed_2\n",
            "  - defaults/linux-64::certifi==2021.5.30=py36h06a4308_0\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.10.3\n",
            "  latest version: 22.11.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version\n",
        "!python --version\n",
        "import sys\n",
        "sys.path\n",
        "import sys\n",
        "_ = (sys.path.append(\"/usr/local/lib/python3.6/site-packages\"))\n",
        "sys.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYynodme0-Jh",
        "outputId": "6845e9ad-c619-40d3-f9b1-9993c2389b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 4.10.3\n",
            "Python 3.6.13 :: Anaconda, Inc.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python38.zip',\n",
              " '/usr/lib/python3.8',\n",
              " '/usr/lib/python3.8/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.8/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.8/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/usr/local/lib/python3.6/site-packages',\n",
              " '/usr/local/lib/python3.6/site-packages']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/IoBT-VISTEC/MIN2Net/main/environment.yml\n",
        "!conda env create -f environment.yml\n",
        "!conda activate min2net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqigmR9iuSKH",
        "outputId": "b578a781-08c7-4048-f899-5e020f6a5d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-13 13:03:42--  https://raw.githubusercontent.com/IoBT-VISTEC/MIN2Net/main/environment.yml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 265 [text/plain]\n",
            "Saving to: ‘environment.yml.1’\n",
            "\n",
            "environment.yml.1   100%[===================>]     265  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-13 13:03:42 (13.0 MB/s) - ‘environment.yml.1’ saved [265/265]\n",
            "\n",
            "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
            "\n",
            "CondaValueError: prefix already exists: /usr/local/envs/min2net\n",
            "\n",
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install min2net\n",
        "! wget https://github.com/IoBT-VISTEC/MIN2Net/releases/download/v1.0.1/min2net-1.0.1-py3-none-any.whl\n",
        "! pip install min2net-1.0.1-py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJZ7j5iGfqZt",
        "outputId": "e3a129c4-4f46-4db1-c333-1652b8d37bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: min2net in /usr/local/lib/python3.6/site-packages (1.0.1)\n",
            "Requirement already satisfied: tensorflow-addons==0.9.1 in /usr/local/lib/python3.6/site-packages (from min2net) (0.9.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.6/site-packages (from min2net) (0.24.2)\n",
            "Collecting setuptools>=42 (from min2net)\n",
            "/usr/local/lib/python3.6/site-packages/cryptography/hazmat/backends/openssl/x509.py:18: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
            "  utils.DeprecatedIn35,\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/3a/88b210db68e56854d0bcf4b38e165e03be377e13907746f825790f3df5bf/setuptools-59.6.0-py3-none-any.whl (952kB)\n",
            "\u001b[K    100% |████████████████████████████████| 962kB 15.8MB/s \n",
            "\u001b[?25hCollecting wheel>=0.37.0 (from min2net)\n",
            "  Downloading https://files.pythonhosted.org/packages/27/d6/003e593296a85fd6ed616ed962795b2f87709c3eee2bca4f6d0fe55c6d00/wheel-0.37.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wget>=3.2 in /usr/local/lib/python3.6/site-packages (from min2net) (3.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/site-packages (from tensorflow-addons==0.9.1->min2net) (2.13.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net) (1.5.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net) (1.19.5)\n",
            "\u001b[31mtqdm 4.63.0 requires importlib-resources; python_version < \"3.7\", which is not installed.\u001b[0m\n",
            "\u001b[31mconda 4.10.3 requires ruamel_yaml_conda>=0.11.14, which is not installed.\u001b[0m\n",
            "Installing collected packages: setuptools, wheel\n",
            "  Found existing installation: setuptools 40.6.2\n",
            "    Uninstalling setuptools-40.6.2:\n",
            "      Successfully uninstalled setuptools-40.6.2\n",
            "  Found existing installation: wheel 0.31.1\n",
            "    Uninstalling wheel-0.31.1:\n",
            "      Successfully uninstalled wheel-0.31.1\n",
            "Successfully installed setuptools-59.6.0 wheel-0.37.1\n",
            "--2022-12-13 13:03:45--  https://github.com/IoBT-VISTEC/MIN2Net/releases/download/v1.0.1/min2net-1.0.1-py3-none-any.whl\n",
            "Resolving github.com (github.com)... 20.201.28.151\n",
            "Connecting to github.com (github.com)|20.201.28.151|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/367768855/01697e89-2959-4692-b687-cbbe1f9f9f25?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221213T130346Z&X-Amz-Expires=300&X-Amz-Signature=f847b8a3ba1225beffa017f1a4f20089e707fb72314ad5e1c130c82c3340dc0c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=367768855&response-content-disposition=attachment%3B%20filename%3Dmin2net-1.0.1-py3-none-any.whl&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-13 13:03:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/367768855/01697e89-2959-4692-b687-cbbe1f9f9f25?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221213T130346Z&X-Amz-Expires=300&X-Amz-Signature=f847b8a3ba1225beffa017f1a4f20089e707fb72314ad5e1c130c82c3340dc0c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=367768855&response-content-disposition=attachment%3B%20filename%3Dmin2net-1.0.1-py3-none-any.whl&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58196 (57K) [application/octet-stream]\n",
            "Saving to: ‘min2net-1.0.1-py3-none-any.whl.1’\n",
            "\n",
            "min2net-1.0.1-py3-n 100%[===================>]  56.83K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-12-13 13:03:46 (2.16 MB/s) - ‘min2net-1.0.1-py3-none-any.whl.1’ saved [58196/58196]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: min2net==1.0.1 from file:///content/min2net-1.0.1-py3-none-any.whl in /usr/local/lib/python3.6/site-packages (1.0.1)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (59.6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (0.24.2)\n",
            "Requirement already satisfied: wget>=3.2 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (3.2)\n",
            "Requirement already satisfied: tensorflow-addons==0.9.1 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (0.9.1)\n",
            "Requirement already satisfied: wheel>=0.37.0 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (0.37.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net==1.0.1) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net==1.0.1) (1.5.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net==1.0.1) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net==1.0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/site-packages (from tensorflow-addons==0.9.1->min2net==1.0.1) (2.13.3)\n",
            "\u001b[31mtqdm 4.63.0 requires importlib-resources; python_version < \"3.7\", which is not installed.\u001b[0m\n",
            "\u001b[31mconda 4.10.3 requires ruamel_yaml_conda>=0.11.14, which is not installed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!cd drive/MyDrive/Term\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, filtfilt\n",
        "import wget\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "from scipy.interpolate import CubicSpline \n",
        "from scipy import ndimage\n",
        "import argparse\n",
        "PATH = os.getcwd()\n",
        "\n",
        "print(PATH)\n",
        "\n",
        "folder_name = str(PATH)+'/datasets'\n",
        "print(folder_name)"
      ],
      "metadata": {
        "id": "R1qzHWR1nke6",
        "outputId": "53523264-4fe7-4449-ee8f-5bb7ded35f4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!cd drive/MyDrive/Term"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD2SleoIlx9A",
        "outputId": "e8ec16d8-b7d6-472c-bb00-6eaba3710dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, filtfilt\n",
        "import wget\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "from scipy.interpolate import CubicSpline \n",
        "from scipy import ndimage\n",
        "import argparse\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "# !cd drive/MyDrive/Term\n",
        "PATH= '/content/drive/MyDrive/Term'\n",
        "# PATH = os.getcwd()\n",
        "print(PATH)\n",
        "\n",
        "folder_name = str(PATH)+'/datasets'\n",
        "print(folder_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8TT2JKBl9ze",
        "outputId": "56b036e6-6af7-4125-a3e4-465d1f969cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Term\n",
            "/content/drive/MyDrive/Term/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, filtfilt\n",
        "import wget\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "from scipy.interpolate import CubicSpline \n",
        "from scipy import ndimage\n",
        "import argparse\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "# !cd drive/MyDrive/Term\n",
        "PATH= '/content/drive/MyDrive/Term'\n",
        "# PATH = os.getcwd()\n",
        "print(PATH)\n",
        "\n",
        "folder_name = str(PATH)+'/datasets'\n",
        "print(folder_name)\n",
        "# lib path\n",
        "# PATH = os.path.dirname(os.path.realpath(__file__))\n",
        "\n",
        "# def load_raw(dataset):\n",
        "  \n",
        "#     PATH= '/content/drive/MyDrive/Term'\n",
        "#     folder_name = str(PATH)+'/datasets'\n",
        "#     # folder_name = 'datasets'\n",
        "#     if dataset == 'OpenBMI':\n",
        "#         try:\n",
        "#             num_subjects = 54\n",
        "#             sessions = [1, 2]\n",
        "#             save_path = folder_name + '/' + dataset + '/raw'\n",
        "#             if save_path is not None:\n",
        "#                 if not os.path.exists(save_path):\n",
        "#                     os.makedirs(save_path)\n",
        "#             for session in sessions:\n",
        "#                 for person in range(1, num_subjects+1):\n",
        "#                     file_name = '/sess{:02d}_subj{:02d}_EEG_MI.mat'.format(session,person)\n",
        "#                     if os.path.exists(save_path+file_name):\n",
        "#                         os.remove(save_path+file_name) # if exist, remove file\n",
        "#                     print('\\n===Download is being processed on session: {} subject: {}==='.format(session, person))\n",
        "#                     url = 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100542/session{}/s{}{}'.format(session, person, file_name)\n",
        "#                     print('save to: '+save_path+file_name)\n",
        "#                     wget.download(url,  save_path+file_name)\n",
        "#             print('\\nDone!')\n",
        "#         except:\n",
        "#             raise Exception('Path Error: file does not exist, please direccly download at http://gigadb.org/dataset/100542')\n",
        "#     elif dataset == 'BCIC2a':\n",
        "#         try:\n",
        "#             num_subjects = 9\n",
        "#             sessions = ['T', 'E']\n",
        "#             save_path = folder_name + '/' + dataset + '/raw'\n",
        "#             if save_path is not None:\n",
        "#                 if not os.path.exists(save_path):\n",
        "#                     os.makedirs(save_path)\n",
        "\n",
        "#             for session in sessions:\n",
        "#                 for person in range(1, num_subjects+1):\n",
        "#                     file_name = '/A{:02d}{}.mat'.format(person, session)\n",
        "#                     if os.path.exists(save_path+file_name):\n",
        "#                         os.remove(save_path+file_name) # if exist, remove file\n",
        "#                     print('\\n===Download is being processed on session: {} subject: {}==='.format(session, person))\n",
        "#                     url = 'https://lampx.tugraz.at/~bci/database/001-2014'+file_name\n",
        "#                     print('save to: '+save_path+file_name)\n",
        "#                     wget.download(url, save_path+file_name)\n",
        "#             print('\\nDone!')\n",
        "#         except:\n",
        "#             raise Exception('Path Error: file does not exist, please direccly download at http://bnci-horizon-2020.eu/database/data-sets')\n",
        "#     elif dataset == 'SMR_BCI':\n",
        "#         try:\n",
        "#             num_subjects = 14\n",
        "#             sessions = ['T', 'E']\n",
        "#             save_path = folder_name + '/' + dataset + '/raw'\n",
        "#             print(save_path)\n",
        "#             if save_path is not None:\n",
        "#                 if not os.path.exists(save_path):\n",
        "#                     os.makedirs(save_path)\n",
        "#             for session in sessions:\n",
        "#                 for person in range(1, num_subjects+1):\n",
        "#                     file_name = '/S{:02d}{}.mat'.format(person, session)\n",
        "#                     if os.path.exists(save_path+file_name):\n",
        "#                         os.remove(save_path+file_name) # if exist, remove file\n",
        "#                     print('\\n===Download is being processed on session: {} subject: {}==='.format(session, person))\n",
        "#                     # url = 'https://lampx.tugraz.at/~bci/database/002-2014'+file_name\n",
        "#                     url='https://drive.google.com/uc?id=1AJV8otG_SWXOou3LbJTJsRaSls2AlTZH'\n",
        "#                     print('save to: '+save_path+file_name)\n",
        "#                     print(save_path)\n",
        "#                     wget.download(url,  save_path+file_name) # 이거 느낌표 안먹힐텐데..\n",
        "#                     #혹시 데이터 몇개야?\n",
        "#             print('\\nDone!')\n",
        "#         except:\n",
        "#             raise Exception('Path Error: file does not exist, please direccly download at http://bnci-horizon-2020.eu/database/data-sets')\n"
      ],
      "metadata": {
        "id": "l8gVNcAc1r2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5796a9bb-0d08-4c8e-df83-0d9f1bff2db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Term\n",
            "/content/drive/MyDrive/Term/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, dataset, train_type=None, data_type=None, num_class=2, subject=None, data_format=None, dataset_path='/datasets', **kwargs):\n",
        "\n",
        "        self.dataset = dataset #Dataset name: 'OpenBMI', 'SMR_BCI', 'BCIC2a'\n",
        "        self.train_type = train_type # 'subject_dependent', 'subject_independent'\n",
        "        self.data_type = data_type # 'fbcsp', 'spectral_spatial', 'time_domain'\n",
        "        self.dataset_path = dataset_path\n",
        "        self.subject = subject # id, start at 1\n",
        "        self.data_format = data_format # 'channels_first', 'channels_last'\n",
        "        self.fold = None # fold, start at 1\n",
        "        self.prefix_name = 'S'\n",
        "        self.num_class = num_class\n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "\n",
        "\n",
        "        self.path = self.dataset_path+'/'+self.dataset+'/'+self.data_type+'/'+str(self.num_class)+'_class/'+self.train_type\n",
        "    \n",
        "    def _change_data_format(self, X):\n",
        "        if self.data_format == 'NCTD':\n",
        "            # (#n_trial, #channels, #time, #depth)\n",
        "            X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
        "        elif self.data_format == 'NDCT':\n",
        "            # (#n_trial, #depth, #channels, #time)\n",
        "            X = X.reshape(X.shape[0], 1, X.shape[1], X.shape[2])\n",
        "        elif self.data_format == 'NTCD':\n",
        "            # (#n_trial, #time, #channels, #depth)\n",
        "            X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
        "            X = np.swapaxes(X, 1, 3)\n",
        "        elif self.data_format == 'NSHWD':\n",
        "            # (#n_trial, #Freqs, #height, #width, #depth)\n",
        "            X = zero_padding(X)\n",
        "            X = X.reshape(X.shape[0], X.shape[1], X.shape[2], X.shape[3], 1)\n",
        "        elif self.data_format == None:\n",
        "            pass\n",
        "        else:\n",
        "            raise Exception('Value Error: data_format requires None, \\'NCTD\\', \\'NDCT\\', \\'NTCD\\' or \\'NSHWD\\', found data_format={}'.format(self.data_format))\n",
        "        print('change data_format to \\'{}\\', new dimention is {}'.format(self.data_format, X.shape))\n",
        "        return X\n",
        "\n",
        "    def load_train_set(self, fold, **kwargs):\n",
        "        self.fold = fold\n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "    \n",
        "        # load \n",
        "        X, y =  np.array([]),  np.array([])\n",
        "        try:\n",
        "            self.file_x = self.path+'/X_train_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            self.file_y = self.path+'/y_train_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            X = self._change_data_format(np.load(self.file_x))\n",
        "            y = np.load(self.file_y)\n",
        "        except:\n",
        "            raise Exception('Path Error: file does not exist, please check this path {}, and {}'.format(self.file_x, self.file_y))\n",
        "        return X, y\n",
        "\n",
        "    def load_val_set(self, fold, **kwargs):\n",
        "        self.fold = fold\n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "\n",
        "        # load \n",
        "        X, y =  np.array([]),  np.array([])\n",
        "        try:\n",
        "            self.file_x = self.path+'/X_val_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            self.file_y = self.path+'/y_val_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            X = self._change_data_format(np.load(self.file_x))\n",
        "            y = np.load(self.file_y)\n",
        "        except:\n",
        "            raise Exception('Path Error: file does not exist, please check this path {}, and {}'.format(self.file_x, self.file_y))\n",
        "        return X, y\n",
        "    \n",
        "    def load_test_set(self, fold, **kwargs):\n",
        "        self.fold = fold\n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "\n",
        "        # load \n",
        "        X, y =  np.array([]),  np.array([])\n",
        "        try:\n",
        "            self.file_x = self.path+'/X_test_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            self.file_y = self.path+'/y_test_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            X = self._change_data_format(np.load(self.file_x))\n",
        "            y = np.load(self.file_y)\n",
        "        except:\n",
        "            raise Exception('Path Error: file does not exist, please check this path {}, and {}'.format(self.file_x, self.file_y))\n",
        "        return X, y\n",
        "\n",
        "def compute_class_weight(y_train):\n",
        "    \"\"\"compute class balancing\n",
        "    Args:\n",
        "        y_train (list, ndarray): [description]\n",
        "    Returns:\n",
        "        (dict): class weight balancing\n",
        "    \"\"\"\n",
        "    return dict(zip(np.unique(y_train), \n",
        "                    class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                      classes=np.unique(y_train),\n",
        "                                                      y=y_train))) \n",
        "        \n",
        "def str2bool(v):\n",
        "    if isinstance(v, bool):\n",
        "       return v\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, save_path=None):\n",
        "        self.save_path = save_path\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.logs = []\n",
        "        if self.save_path:\n",
        "            write_log(filepath=self.save_path, data=['time_log'], mode='w')\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.start_time = time.time()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        time_diff = time.time()-self.start_time\n",
        "        self.logs.append(time_diff)\n",
        "        if self.save_path:\n",
        "            write_log(filepath=self.save_path, data=[time_diff], mode='a')\n",
        "\n",
        "def write_log(filepath='test.log', data=[], mode='w'):\n",
        "    '''\n",
        "    filepath: path to save\n",
        "    data: list of data\n",
        "    mode: a = update data to file, w = write a new file\n",
        "    '''\n",
        "    try:\n",
        "        with open(filepath, mode) as csvFile:\n",
        "            writer = csv.writer(csvFile)\n",
        "            writer.writerow(data)\n",
        "    except IOError:\n",
        "        raise Exception('I/O error')\n",
        "\n",
        "def zero_padding(data, pad_size=4):\n",
        "    if len(data.shape) != 4:\n",
        "        raise Exception('Dimension is not match!, must have 4 dims')\n",
        "    new_shape = int(data.shape[2]+(2*pad_size))\n",
        "    data_pad = np.zeros((data.shape[0], data.shape[1], new_shape, new_shape))\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            data_pad[i,j,:,:] = np.pad(data[i,j,:,:], [pad_size, pad_size], mode='constant')\n",
        "    print(data_pad.shape)\n",
        "    return data_pad \n",
        "\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def resampling(data, new_smp_freq, data_len):\n",
        "    if len(data.shape) != 3:\n",
        "        raise Exception('Dimesion error', \"--> please use three-dimensional input\")\n",
        "    new_smp_point = int(data_len*new_smp_freq)\n",
        "    data_resampled = np.zeros((data.shape[0], data.shape[1], new_smp_point))\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            data_resampled[i,j,:] = signal.resample(data[i,j,:], new_smp_point)\n",
        "    return data_resampled\n",
        "\n",
        "def psd_welch(data, smp_freq):\n",
        "    if len(data.shape) != 3:\n",
        "        raise Exception(\"Dimension Error, must have 3 dimension\")\n",
        "    n_samples,n_chs,n_points = data.shape\n",
        "    data_psd = np.zeros((n_samples,n_chs,89))\n",
        "    for i in range(n_samples):\n",
        "        for j in range(n_chs):\n",
        "            freq, power_den = signal.welch(data[i,j], smp_freq, nperseg=n_points)\n",
        "            index = np.where((freq>=8) & (freq<=30))[0].tolist()\n",
        "            # print(\"the length of---\", len(index))\n",
        "            data_psd[i,j] = power_den[index]\n",
        "    return data_psd\n",
        "    "
      ],
      "metadata": {
        "id": "a-1aXK5vwbC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess dada"
      ],
      "metadata": {
        "id": "OpUnRxfNWc9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import min2net\n",
        "# import min2net.preprocessing as prep\n",
        "\n",
        "# load_raw('SMR_BCI')\n",
        "# 이건 인터넷에있는 거 다운로드해서 matlab(.mat)로 저장하는거\n",
        "#.... 클래스 안에 있는거 코드만 끌어오면 이름 바꿔야 되나본데? 이해했니???설마 나한테 이거 맡겨놓고 씻으러가다거나 그런건가\n",
        "\n",
        "# min2net.utils.load_raw('OpenBMI')\n"
      ],
      "metadata": {
        "id": "VHtg7Tu5WdVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from min2net.utils import PATH\n",
        "\n",
        "CONSTANT = {\n",
        "    'BCIC2a': {\n",
        "        'raw_path': 'datasets/BCIC2a/raw', # raw data path 'raw_path': 'datasets/BCIC2a'\n",
        "        'n_subjs': 9,\n",
        "        'n_trials': 144,\n",
        "        'n_trials_per_class': 72,\n",
        "        'n_chs': 20,\n",
        "        'orig_smp_freq': 250,                  # Original sampling frequency (Hz)\n",
        "        'trial_len': 7,                        # 7s\n",
        "        'MI': {\n",
        "            'start': 2,                        # start at time = 2 s\n",
        "            'stop': 6,                         # stop at time = 6 s\n",
        "            'len': 4,                          # 4s\n",
        "        },\n",
        "        'orig_chs': ['FC3', 'FC1', 'FCz', 'FC2', 'FC4',\n",
        "                    'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6',\n",
        "                    'CP3', 'CP1', 'CPz', 'CP2', 'CP4',\n",
        "                    'P1', 'Pz', 'P2'],\n",
        "        'sel_chs': ['FC3', 'FC1', 'FCz', 'FC2', 'FC4', \n",
        "                    'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6',\n",
        "                    'CP3', 'CP1', 'CPz', 'CP2', 'CP4',\n",
        "                    'P1', 'Pz', 'P2'] \n",
        "    },\n",
        "    'SMR_BCI': {\n",
        "        'raw_path': '/content/drive/MyDrive/Term/datasets/SMR_BCI/raw', # raw data path\n",
        "        'n_subjs': 15,\n",
        "        'n_trials_tr': 50,\n",
        "        'n_trials_te': 30, \n",
        "        'n_chs': 63,\n",
        "        'orig_smp_freq': 512,                   # Original sampling frequency  (Hz)\n",
        "        'trial_len': 6,                         # 7s\n",
        "        'MI': {\n",
        "            'start': 0,                         # start at time = 4 s\n",
        "            'stop': 6,                          # stop at time = 8 s\n",
        "            'len': 6,                           # 4s\n",
        "        },\n",
        "        # 'orig_chs': ['FCC3',                   'FCCz',                 'FCC4',\n",
        "        #             'C5h', 'C3', 'C3h',       'C1h', 'Cz', 'C2h',       'C4h', 'C4', 'C6h',\n",
        "        #                    'CCP3',                   'CCPz',                 'CCP4'],\n",
        "        'orig_chs': ['Fp1', 'Fp2', 'F7', 'FCC3', 'FCCz', 'FCC4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'T7', \n",
        "                    'C3','Cz','C4', 'T8', 'TP9', 'C5h', 'CP1', 'CP2', 'CP6', 'TP10', 'P7', 'CCP3', \n",
        "                    'CCPz', 'CCP4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10', 'FC3', 'FC4', 'C5', 'C1h',\n",
        "                    'C2h', 'C6h', 'C3h','CPz', 'C4h', 'P1', 'P2', 'POz', 'FT9', 'FTT9h', 'TTP7h', \n",
        "                    'TP7', 'TPP9h', 'FT10','FTT10h','TPP8h', 'TP8', 'TPP10h', 'F9', 'F10', \n",
        "                    'AF7', 'AF3', 'AF4', 'AF8', 'PO3','PO4','M'],\n",
        "        'sel_chs': ['Fp1', 'Fp2', 'F7', 'FCC3', 'FCCz', 'FCC4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'T7', \n",
        "                    'C3','Cz','C4', 'T8', 'TP9', 'C5h', 'CP1', 'CP2', 'CP6', 'TP10', 'P7', 'CCP3', \n",
        "                    'CCPz', 'CCP4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10', 'FC3', 'FC4', 'C5', 'C1h',\n",
        "                    'C2h', 'C6h', 'C3h','CPz', 'C4h', 'P1', 'P2', 'POz', 'FT9', 'FTT9h', 'TTP7h', \n",
        "                    'TP7', 'TPP9h', 'FT10','FTT10h','TPP8h', 'TP8', 'TPP10h', 'F9', 'F10', \n",
        "                    'AF7', 'AF3', 'AF4', 'AF8', 'PO3','PO4','M']\n",
        "        # 'sel_chs': [       'FCC3',                   'FCCz',                 'FCC4', \n",
        "        #             'C5h', 'C3', 'C3h',       'C1h', 'Cz', 'C2h',       'C4h','C4', 'C6h', \n",
        "        #                    'CCP3',                   'CCPz',                 'CCP4']  \n",
        "    },\n",
        "    'OpenBMI': {\n",
        "        'raw_path': 'datasets/OpenBMI/raw', # raw data path\n",
        "        'n_subjs': 54,\n",
        "        'n_trials_2_class': 100,\n",
        "        'n_trials_3_class': 150, \n",
        "        'n_chs': 62,\n",
        "        'orig_smp_freq': 1000,                  # Original sampling frequency  (Hz)\n",
        "        'trial_len': 8,                         # 8s (cut-off)\n",
        "        'MI': {\n",
        "            'start': 0,                         # start at time = 0 s\n",
        "            'stop': 4,                          # stop at time = 0 s\n",
        "            'len': 4,                           # 4s\n",
        "        },\n",
        "        'orig_chs': ['Fp1', 'Fp2', 'F7', 'FCC3', 'FCCz', 'FCC4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'T7', \n",
        "                    'C3','Cz','C4', 'T8', 'TP9', 'CP5', 'CP1', 'CP2', 'CP6', 'TP10', 'P7', 'P3', \n",
        "                    'Pz', 'P4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10', 'FC3', 'FC4', 'C5', 'C1',\n",
        "                    'C2', 'C6', 'CP3','CPz', 'CP4', 'P1', 'P2', 'POz', 'FT9', 'FTT9h', 'TTP7h', \n",
        "                    'TP7', 'TPP9h', 'FT10','FTT10h','TPP8h', 'TP8', 'TPP10h', 'F9', 'F10', \n",
        "                    'AF7', 'AF3', 'AF4', 'AF8', 'PO3','PO4'],\n",
        "        'sel_chs': ['FC5', 'FC3', 'FC1', 'FC2', 'FC4','FC6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', \n",
        "                    'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6']  \n",
        "    }\n",
        "\n",
        "}\n",
        "CONSTANT = CONSTANT['SMR_BCI']\n",
        "\n"
      ],
      "metadata": {
        "id": "T3z808Zsoj__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "# from min2net.utils import resampling\n",
        "# from min2net.preprocessing.config import CONSTANT\n",
        "# load variable form config file\n",
        "orig_chs = CONSTANT['orig_chs']\n",
        "orig_smp_freq = CONSTANT['orig_smp_freq']\n",
        "trial_len = CONSTANT['trial_len'] \n",
        "n_chs = CONSTANT['n_chs'] # 15\n",
        "window_len = CONSTANT['trial_len']*CONSTANT['orig_smp_freq'] # 8*512\n",
        "\n",
        "def read_raw(PATH, subject , training, id_chosen_chs):\n",
        "    if training:\n",
        "        mat = sio.loadmat(PATH+'/P'+str(subject).zfill(2)+'T.mat')['Data']\n",
        "        n_trials = CONSTANT['n_trials_tr'] # 100\n",
        "        label = np.zeros(n_trials)\n",
        "        data = np.zeros((n_trials, n_chs, window_len))\n",
        "    else:\n",
        "        mat = sio.loadmat(PATH+'/P'+str(subject).zfill(2)+'E.mat')['Data']\n",
        "        n_trials = CONSTANT['n_trials_te'] # 60\n",
        "        label = np.zeros(n_trials)\n",
        "        data = np.zeros((n_trials, n_chs, window_len))\n",
        "    NO_valid_trial = 0\n",
        "    for ii in range(0,mat.size):\n",
        "        mat_1 = mat[0,ii]\n",
        "        mat_2 = [mat_1[0,0]]\n",
        "        mat_info = mat_2[0]\n",
        "        _X = mat_info[3]\n",
        "        _trial = mat_info[2]\n",
        "        _y = mat_info[4]\n",
        "        _fs = mat_info[0]\n",
        "        _classes = mat_info[1]\n",
        "        # _X = mat_info[0]\n",
        "        # _trial = mat_info[1]\n",
        "        # _y = mat_info[2]\n",
        "        # _fs = mat_info[3]\n",
        "        # _classes = mat_info[4]\n",
        "        for trial in range(0, _trial.size):\n",
        "            # class 1 (right hand) and class 2 (feet) \n",
        "            _data = np.transpose(_X[_trial[0][trial]:int(_trial[0][trial]+window_len),id_chosen_chs])\n",
        "            _label = int(_y[0][trial])\n",
        "            data[NO_valid_trial,:,:] =  _data\n",
        "            label[NO_valid_trial] = _label\n",
        "            NO_valid_trial +=1\n",
        "    return data, label-1\n",
        "\n",
        "def chanel_selection(sel_chs): \n",
        "    chs_id = []\n",
        "    for name_ch in sel_chs:\n",
        "        ch_id = np.where(np.array(orig_chs) == name_ch)[0][0]\n",
        "        chs_id.append(ch_id)\n",
        "        print('chosen_channel:', name_ch, '---', 'Index_is:', ch_id)\n",
        "    return chs_id\n",
        "\n",
        "def load_crop_data(PATH, subject, start, stop, new_smp_freq, id_chosen_chs):\n",
        "    start_time = int(start*new_smp_freq) # 4*\n",
        "    stop_time = int(stop*new_smp_freq) # 8*\n",
        "    X_train, y_tr = read_raw(PATH=PATH, subject=subject, training=True, id_chosen_chs=id_chosen_chs)\n",
        "    X_test, y_te = read_raw(PATH=PATH, subject=subject, training=False, id_chosen_chs=id_chosen_chs)\n",
        "    if new_smp_freq < orig_smp_freq:\n",
        "        X_train = resampling(X_train, new_smp_freq, trial_len)\n",
        "        X_test = resampling(X_test, new_smp_freq, trial_len)\n",
        "    X_train = X_train[:,:,start_time:stop_time]\n",
        "    X_test = X_test[:,:,start_time:stop_time]\n",
        "    return X_train, y_tr, X_test, y_te  "
      ],
      "metadata": {
        "id": "MYvJqFFnooXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split \n",
        "import os\n",
        "# from min2net.utils import butter_bandpass_filter\n",
        "# from min2net.preprocessing.SMR_BCI import raw\n",
        "# from min2net.preprocessing.config import CONSTANT\n",
        "raw_path = CONSTANT['raw_path']\n",
        "n_subjs = CONSTANT['n_subjs']\n",
        "n_trials_tr = CONSTANT['n_trials_tr'] \n",
        "n_trials_te = CONSTANT['n_trials_te']\n",
        "n_chs = CONSTANT['n_chs']\n",
        "orig_smp_freq = CONSTANT['orig_smp_freq']\n",
        "MI_len = CONSTANT['MI']['len']\n",
        "\n",
        "def subject_dependent_setting(k_folds, pick_smp_freq, bands, order, save_path, num_class=2, sel_chs=None):\n",
        "    sel_chs = CONSTANT['sel_chs'] if sel_chs == None else sel_chs\n",
        "    n_folds = k_folds\n",
        "    save_path = save_path + '/SMR_BCI/time_domain/{}_class/subject_dependent'.format(num_class)\n",
        "\n",
        "    X_train_all, y_train_all = np.zeros((n_subjs, n_trials_tr, n_chs, int(MI_len*pick_smp_freq))), np.zeros((n_subjs, n_trials_tr))\n",
        "    X_test_all, y_test_all = np.zeros((n_subjs, n_trials_te, n_chs, int(MI_len*pick_smp_freq))), np.zeros((n_subjs, n_trials_te))\n",
        "\n",
        "    id_chosen_chs = chanel_selection(sel_chs)\n",
        "    for s in range(n_subjs):\n",
        "        X_train, y_train, X_test, y_test = __load_SMR_BCI(raw_path, s+1, pick_smp_freq, id_chosen_chs)\n",
        "        X_train_all[s], y_train_all[s] = X_train, y_train\n",
        "        X_test_all[s], y_test_all[s] = X_test, y_test\n",
        "\n",
        "    for directory in [save_path]:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "    # Carry out subject-dependent setting with 5-fold cross validation\n",
        "    for person, (X_tr, y_tr, X_te, y_te) in enumerate(zip(X_train_all, y_train_all, X_test_all, y_test_all)):\n",
        "        if len(X_tr.shape) != 3:\n",
        "            raise Exception('Dimension Error, must have 3 dimension')\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
        "        for fold, (train_index, val_index) in enumerate(skf.split(X_tr , y_tr)):\n",
        "            print('FOLD:', fold+1, 'TRAIN:', len(train_index), 'VALIDATION:', len(val_index))\n",
        "            X_tr_cv, X_val_cv = X_tr[train_index], X_tr[val_index]\n",
        "            y_tr_cv, y_val_cv = y_tr[train_index], y_tr[val_index]\n",
        "\n",
        "            print('Band-pass filtering from {} to {} Hz.'.format(bands[0],  bands[1]))\n",
        "            X_tr_fil = butter_bandpass_filter(X_tr_cv,  bands[0],  bands[1], pick_smp_freq, order)\n",
        "            X_val_fil = butter_bandpass_filter(X_val_cv,  bands[0],  bands[1], pick_smp_freq, order)\n",
        "            X_te_fil = butter_bandpass_filter(X_te,  bands[0],  bands[1], pick_smp_freq, order)\n",
        "            print('Check dimension of training data {}, val data {} and testing data {}'.format(X_tr_fil.shape, X_val_fil.shape, X_te_fil.shape))\n",
        "            SAVE_NAME = 'S{:03d}_fold{:03d}'.format(person+1, fold+1)\n",
        "            __save_data_with_valset(save_path, SAVE_NAME, X_tr_fil, y_tr_cv, X_val_fil, y_val_cv, X_te_fil, y_te)\n",
        "            print('The preprocessing of subject {} from fold {} is DONE!!!'.format(person+1, fold+1))\n",
        "\n",
        "def subject_independent_setting(k_folds, pick_smp_freq, bands, order, save_path, num_class=2, sel_chs=None):\n",
        "    sel_chs = CONSTANT['sel_chs'] if sel_chs == None else sel_chs\n",
        "    n_folds = k_folds\n",
        "    save_path = save_path + '/SMR_BCI/time_domain/{}_class/subject_independent'.format(num_class)\n",
        "\n",
        "    X_train_all, y_train_all = np.zeros((n_subjs, n_trials_tr, n_chs, int(MI_len*pick_smp_freq))), np.zeros((n_subjs, n_trials_tr))\n",
        "    X_test_all, y_test_all = np.zeros((n_subjs, n_trials_te, n_chs, int(MI_len*pick_smp_freq))), np.zeros((n_subjs, n_trials_te))\n",
        "\n",
        "    id_chosen_chs = chanel_selection(sel_chs)\n",
        "    for s in range(n_subjs):\n",
        "        X_train, y_train, X_test, y_test = __load_SMR_BCI(raw_path, s+1, pick_smp_freq, id_chosen_chs)\n",
        "        X_train_all[s], y_train_all[s] = X_train, y_train\n",
        "        X_test_all[s], y_test_all[s] = X_test, y_test\n",
        "\n",
        "    for directory in [save_path]:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "    # Carry out subject-independent setting with 5-fold cross validation\n",
        "    for person, (X_val, y_val, X_te, y_te) in enumerate(zip(X_train_all, y_train_all, X_test_all, y_test_all)):\n",
        "        train_subj = [i for i in range(n_subjs)]\n",
        "        train_subj = np.delete(train_subj, person) # remove test subject\n",
        "\n",
        "         # Generating fake data to used for k-fold cross-validation only\n",
        "        fake_tr = np.zeros((len(train_subj), 2))\n",
        "        fake_tr_la = np.zeros((len(train_subj)))\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
        "        for fold, (train_ind, val_ind) in enumerate(skf.split(fake_tr , fake_tr_la)):\n",
        "            print('FOLD:', fold+1, 'TRAIN:', len(train_ind), 'VALIDATION:', len(val_ind))\n",
        "            train_index, val_index = train_subj[train_ind], train_subj[val_ind]\n",
        "            X_train_cat = np.concatenate((X_train_all[train_index].reshape(-1,n_chs,int(MI_len*pick_smp_freq)), X_test_all[train_index].reshape(-1,n_chs,int(MI_len*pick_smp_freq))), axis=0)\n",
        "            X_val_cat = np.concatenate((X_train_all[val_index].reshape(-1,n_chs,int(MI_len*pick_smp_freq)), X_test_all[val_index].reshape(-1,n_chs,int(MI_len*pick_smp_freq))), axis=0)\n",
        "            y_train_cat = np.concatenate((y_train_all[train_index].reshape(-1), y_test_all[train_index].reshape(-1)), axis=0)\n",
        "            y_val_cat = np.concatenate((y_train_all[val_index].reshape(-1), y_test_all[val_index].reshape(-1)), axis=0)\n",
        "\n",
        "            # Performing bandpass-filtering\n",
        "            print('Band-pass filtering from {} to {} Hz.'.format(bands[0],  bands[1]))\n",
        "            X_train_fil =  butter_bandpass_filter(X_train_cat, bands[0],  bands[1], pick_smp_freq, order)\n",
        "            X_val_fil = butter_bandpass_filter(X_val_cat, bands[0],  bands[1], pick_smp_freq, order)\n",
        "            X_test_fil = butter_bandpass_filter(X_te, bands[0],  bands[1], pick_smp_freq, order)\n",
        "\n",
        "            print('Verify the final dimesion of training data {}, val data {} and testing data {}'.format(X_train_fil.shape, X_val_fil.shape,X_test_fil.shape))\n",
        "            SAVE_NAME = 'S{:03d}_fold{:03d}'.format(person+1, fold+1)\n",
        "            __save_data_with_valset(save_path, SAVE_NAME, X_train_fil, y_train_cat, X_val_fil, y_val_cat, X_test_fil, y_te)\n",
        "            print('The preprocessing of subject {} from fold {} is DONE!!!'.format(person+1, fold+1))\n",
        "                      \n",
        "def __load_SMR_BCI(PATH, subject, new_smp_freq, id_chosen_chs):\n",
        "    start = CONSTANT['MI']['start'] # 4\n",
        "    stop = CONSTANT['MI']['stop'] # 8\n",
        "    X_train, y_tr, X_test, y_te  = load_crop_data(PATH=PATH, subject=subject, start=start, stop=stop, new_smp_freq=new_smp_freq, id_chosen_chs=id_chosen_chs)\n",
        "    return X_train, y_tr, X_test, y_te\n",
        "\n",
        "def __save_data_with_valset(save_path, NAME, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    np.save(save_path+'/X_train_'+NAME+'.npy', X_train)\n",
        "    np.save(save_path+'/X_val_'+NAME+'.npy', X_val)\n",
        "    np.save(save_path+'/X_test_'+NAME+'.npy', X_test)\n",
        "    np.save(save_path+'/y_train_'+NAME+'.npy', y_train)\n",
        "    np.save(save_path+'/y_val_'+NAME+'.npy', y_val)\n",
        "    np.save(save_path+'/y_test_'+NAME+'.npy', y_test)\n",
        "    print('save DONE')\n"
      ],
      "metadata": {
        "id": "NS384SKZoj1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prep.SMR_BCI.time_domain.\n",
        "subject_dependent_setting(k_folds=5,\n",
        "                                                 pick_smp_freq=100, \n",
        "                                                 bands=[0.1, 30], \n",
        "                                                 order=3, \n",
        "                                                 save_path='datasets')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__9yZ0H7Dylq",
        "outputId": "d967e0dc-8364-4420-ac47-167ab03a09e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chosen_channel: Fp1 --- Index_is: 0\n",
            "chosen_channel: Fp2 --- Index_is: 1\n",
            "chosen_channel: F7 --- Index_is: 2\n",
            "chosen_channel: FCC3 --- Index_is: 3\n",
            "chosen_channel: FCCz --- Index_is: 4\n",
            "chosen_channel: FCC4 --- Index_is: 5\n",
            "chosen_channel: F8 --- Index_is: 6\n",
            "chosen_channel: FC5 --- Index_is: 7\n",
            "chosen_channel: FC1 --- Index_is: 8\n",
            "chosen_channel: FC2 --- Index_is: 9\n",
            "chosen_channel: FC6 --- Index_is: 10\n",
            "chosen_channel: T7 --- Index_is: 11\n",
            "chosen_channel: C3 --- Index_is: 12\n",
            "chosen_channel: Cz --- Index_is: 13\n",
            "chosen_channel: C4 --- Index_is: 14\n",
            "chosen_channel: T8 --- Index_is: 15\n",
            "chosen_channel: TP9 --- Index_is: 16\n",
            "chosen_channel: C5h --- Index_is: 17\n",
            "chosen_channel: CP1 --- Index_is: 18\n",
            "chosen_channel: CP2 --- Index_is: 19\n",
            "chosen_channel: CP6 --- Index_is: 20\n",
            "chosen_channel: TP10 --- Index_is: 21\n",
            "chosen_channel: P7 --- Index_is: 22\n",
            "chosen_channel: CCP3 --- Index_is: 23\n",
            "chosen_channel: CCPz --- Index_is: 24\n",
            "chosen_channel: CCP4 --- Index_is: 25\n",
            "chosen_channel: P8 --- Index_is: 26\n",
            "chosen_channel: PO9 --- Index_is: 27\n",
            "chosen_channel: O1 --- Index_is: 28\n",
            "chosen_channel: Oz --- Index_is: 29\n",
            "chosen_channel: O2 --- Index_is: 30\n",
            "chosen_channel: PO10 --- Index_is: 31\n",
            "chosen_channel: FC3 --- Index_is: 32\n",
            "chosen_channel: FC4 --- Index_is: 33\n",
            "chosen_channel: C5 --- Index_is: 34\n",
            "chosen_channel: C1h --- Index_is: 35\n",
            "chosen_channel: C2h --- Index_is: 36\n",
            "chosen_channel: C6h --- Index_is: 37\n",
            "chosen_channel: C3h --- Index_is: 38\n",
            "chosen_channel: CPz --- Index_is: 39\n",
            "chosen_channel: C4h --- Index_is: 40\n",
            "chosen_channel: P1 --- Index_is: 41\n",
            "chosen_channel: P2 --- Index_is: 42\n",
            "chosen_channel: POz --- Index_is: 43\n",
            "chosen_channel: FT9 --- Index_is: 44\n",
            "chosen_channel: FTT9h --- Index_is: 45\n",
            "chosen_channel: TTP7h --- Index_is: 46\n",
            "chosen_channel: TP7 --- Index_is: 47\n",
            "chosen_channel: TPP9h --- Index_is: 48\n",
            "chosen_channel: FT10 --- Index_is: 49\n",
            "chosen_channel: FTT10h --- Index_is: 50\n",
            "chosen_channel: TPP8h --- Index_is: 51\n",
            "chosen_channel: TP8 --- Index_is: 52\n",
            "chosen_channel: TPP10h --- Index_is: 53\n",
            "chosen_channel: F9 --- Index_is: 54\n",
            "chosen_channel: F10 --- Index_is: 55\n",
            "chosen_channel: AF7 --- Index_is: 56\n",
            "chosen_channel: AF3 --- Index_is: 57\n",
            "chosen_channel: AF4 --- Index_is: 58\n",
            "chosen_channel: AF8 --- Index_is: 59\n",
            "chosen_channel: PO3 --- Index_is: 60\n",
            "chosen_channel: PO4 --- Index_is: 61\n",
            "chosen_channel: M --- Index_is: 62\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 5 is DONE!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Create DataLoader"
      ],
      "metadata": {
        "id": "3IhZkgNJW_cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=10, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n"
      ],
      "metadata": {
        "id": "uZhGpGOaW_9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "axilFwgjt2F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIN2NET"
      ],
      "metadata": {
        "id": "buhJeFIGbd33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=200,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(1,2):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)"
      ],
      "metadata": {
        "id": "bl-5wVomt1ig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c6470ff-6c16-4783-a2a1-5ccef8d5d53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 1\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_10 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_11 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_5 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_10 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_11 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.8044 - decoder_loss: 25.1448 - encoder_loss: 4.2128 - classifier_loss: 0.7719 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5250\n",
            "Epoch 1: val_loss improved from inf to 63.38364, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 13s 13s/step - loss: 6.8044 - decoder_loss: 25.1448 - encoder_loss: 4.2128 - classifier_loss: 0.7719 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5250 - val_loss: 63.3836 - val_decoder_loss: 29.3490 - val_encoder_loss: 60.3897 - val_classifier_loss: 0.5902 - val_decoder_accuracy: 0.0175 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.6313 - decoder_loss: 25.1386 - encoder_loss: 1.0524 - classifier_loss: 0.6503 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6500\n",
            "Epoch 2: val_loss improved from 63.38364 to 8.73835, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 3.6313 - decoder_loss: 25.1386 - encoder_loss: 1.0524 - classifier_loss: 0.6503 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6500 - val_loss: 8.7383 - val_decoder_loss: 29.3206 - val_encoder_loss: 5.7510 - val_classifier_loss: 0.5524 - val_decoder_accuracy: 0.0185 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 13.7852 - decoder_loss: 25.1008 - encoder_loss: 11.2198 - classifier_loss: 0.5541 - decoder_accuracy: 0.0210 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7500\n",
            "Epoch 3: val_loss improved from 8.73835 to 4.32618, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 13.7852 - decoder_loss: 25.1008 - encoder_loss: 11.2198 - classifier_loss: 0.5541 - decoder_accuracy: 0.0210 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7500 - val_loss: 4.3262 - val_decoder_loss: 29.3225 - val_encoder_loss: 1.3368 - val_classifier_loss: 0.5709 - val_decoder_accuracy: 0.0177 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.2007 - decoder_loss: 25.0732 - encoder_loss: 1.6385 - classifier_loss: 0.5490 - decoder_accuracy: 0.0196 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7250\n",
            "Epoch 4: val_loss did not improve from 4.32618\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.2007 - decoder_loss: 25.0732 - encoder_loss: 1.6385 - classifier_loss: 0.5490 - decoder_accuracy: 0.0196 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7250 - val_loss: 8.3630 - val_decoder_loss: 29.2609 - val_encoder_loss: 5.3901 - val_classifier_loss: 0.4682 - val_decoder_accuracy: 0.0185 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.5919 - decoder_loss: 24.7926 - encoder_loss: 1.0745 - classifier_loss: 0.3821 - decoder_accuracy: 0.0253 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9000\n",
            "Epoch 5: val_loss did not improve from 4.32618\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.5919 - decoder_loss: 24.7926 - encoder_loss: 1.0745 - classifier_loss: 0.3821 - decoder_accuracy: 0.0253 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9000 - val_loss: 7.5307 - val_decoder_loss: 29.9638 - val_encoder_loss: 4.4751 - val_classifier_loss: 0.5913 - val_decoder_accuracy: 0.0247 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.6289 - decoder_loss: 25.4692 - encoder_loss: 2.0453 - classifier_loss: 0.3666 - decoder_accuracy: 0.0225 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 6: val_loss did not improve from 4.32618\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.6289 - decoder_loss: 25.4692 - encoder_loss: 2.0453 - classifier_loss: 0.3666 - decoder_accuracy: 0.0225 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 28.4483 - val_decoder_loss: 29.5885 - val_encoder_loss: 25.4127 - val_classifier_loss: 0.7667 - val_decoder_accuracy: 0.0133 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.1547 - decoder_loss: 25.1379 - encoder_loss: 4.5994 - classifier_loss: 0.4157 - decoder_accuracy: 0.0183 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 7: val_loss did not improve from 4.32618\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.1547 - decoder_loss: 25.1379 - encoder_loss: 4.5994 - classifier_loss: 0.4157 - decoder_accuracy: 0.0183 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 12.5290 - val_decoder_loss: 29.4319 - val_encoder_loss: 9.5177 - val_classifier_loss: 0.6812 - val_decoder_accuracy: 0.0278 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.3295 - decoder_loss: 24.7247 - encoder_loss: 3.8007 - classifier_loss: 0.5640 - decoder_accuracy: 0.0448 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000\n",
            "Epoch 8: val_loss improved from 4.32618 to 2.98691, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 6.3295 - decoder_loss: 24.7247 - encoder_loss: 3.8007 - classifier_loss: 0.5640 - decoder_accuracy: 0.0448 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000 - val_loss: 2.9869 - val_decoder_loss: 29.3628 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.5063 - val_decoder_accuracy: 0.0278 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.4250 - decoder_loss: 24.6603 - encoder_loss: 0.9275 - classifier_loss: 0.3147 - decoder_accuracy: 0.0337 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 9: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.4250 - decoder_loss: 24.6603 - encoder_loss: 0.9275 - classifier_loss: 0.3147 - decoder_accuracy: 0.0337 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 3.0041 - val_decoder_loss: 29.5472 - val_encoder_loss: 0.0229 - val_classifier_loss: 0.2646 - val_decoder_accuracy: 0.0218 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 11.0763 - decoder_loss: 24.3739 - encoder_loss: 8.6205 - classifier_loss: 0.1839 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 10: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 11.0763 - decoder_loss: 24.3739 - encoder_loss: 8.6205 - classifier_loss: 0.1839 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 3.7794 - val_decoder_loss: 29.7847 - val_encoder_loss: 0.7709 - val_classifier_loss: 0.3007 - val_decoder_accuracy: 0.0220 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5177 - decoder_loss: 24.7234 - encoder_loss: 0.0371 - classifier_loss: 0.0827 - decoder_accuracy: 0.0334 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 11: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5177 - decoder_loss: 24.7234 - encoder_loss: 0.0371 - classifier_loss: 0.0827 - decoder_accuracy: 0.0334 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 4.6514 - val_decoder_loss: 29.6035 - val_encoder_loss: 1.6538 - val_classifier_loss: 0.3727 - val_decoder_accuracy: 0.0267 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4690 - decoder_loss: 24.5476 - encoder_loss: 0.0079 - classifier_loss: 0.0635 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 12: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4690 - decoder_loss: 24.5476 - encoder_loss: 0.0079 - classifier_loss: 0.0635 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 4.0666 - val_decoder_loss: 29.5402 - val_encoder_loss: 1.0782 - val_classifier_loss: 0.3432 - val_decoder_accuracy: 0.0307 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4406 - decoder_loss: 24.3229 - encoder_loss: 0.0036 - classifier_loss: 0.0475 - decoder_accuracy: 0.0395 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.4406 - decoder_loss: 24.3229 - encoder_loss: 0.0036 - classifier_loss: 0.0475 - decoder_accuracy: 0.0395 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.4324 - val_decoder_loss: 29.2303 - val_encoder_loss: 0.4747 - val_classifier_loss: 0.3471 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4287 - decoder_loss: 24.2565 - encoder_loss: 1.1504e-04 - classifier_loss: 0.0296 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4287 - decoder_loss: 24.2565 - encoder_loss: 1.1504e-04 - classifier_loss: 0.0296 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.4090 - val_decoder_loss: 29.4899 - val_encoder_loss: 0.4275 - val_classifier_loss: 0.3255 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4199 - decoder_loss: 24.1685 - encoder_loss: 3.4141e-04 - classifier_loss: 0.0270 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.4199 - decoder_loss: 24.1685 - encoder_loss: 3.4141e-04 - classifier_loss: 0.0270 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.3207 - val_decoder_loss: 29.2091 - val_encoder_loss: 0.3672 - val_classifier_loss: 0.3259 - val_decoder_accuracy: 0.0248 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4117 - decoder_loss: 24.0922 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0244 - decoder_accuracy: 0.0520 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.4117 - decoder_loss: 24.0922 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0244 - decoder_accuracy: 0.0520 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.3306 - val_decoder_loss: 29.1546 - val_encoder_loss: 0.3826 - val_classifier_loss: 0.3258 - val_decoder_accuracy: 0.0278 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4015 - decoder_loss: 23.9927 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0224 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4015 - decoder_loss: 23.9927 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0224 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.3307 - val_decoder_loss: 29.0209 - val_encoder_loss: 0.3962 - val_classifier_loss: 0.3241 - val_decoder_accuracy: 0.0273 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3925 - decoder_loss: 23.9045 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0206 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.3925 - decoder_loss: 23.9045 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0206 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.3221 - val_decoder_loss: 28.8264 - val_encoder_loss: 0.4070 - val_classifier_loss: 0.3244 - val_decoder_accuracy: 0.0325 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3819 - decoder_loss: 23.7884 - encoder_loss: 0.0012 - classifier_loss: 0.0191 - decoder_accuracy: 0.0663 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.3819 - decoder_loss: 23.7884 - encoder_loss: 0.0012 - classifier_loss: 0.0191 - decoder_accuracy: 0.0663 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2229 - val_decoder_loss: 28.7433 - val_encoder_loss: 0.3170 - val_classifier_loss: 0.3156 - val_decoder_accuracy: 0.0323 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0025\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3709 - decoder_loss: 23.6889 - encoder_loss: 1.7588e-04 - classifier_loss: 0.0184 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.3709 - decoder_loss: 23.6889 - encoder_loss: 1.7588e-04 - classifier_loss: 0.0184 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2675 - val_decoder_loss: 28.6517 - val_encoder_loss: 0.3708 - val_classifier_loss: 0.3153 - val_decoder_accuracy: 0.0325 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0025\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3652 - decoder_loss: 23.6343 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0671 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.3652 - decoder_loss: 23.6343 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0671 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2548 - val_decoder_loss: 28.5660 - val_encoder_loss: 0.3667 - val_classifier_loss: 0.3143 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0025\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3596 - decoder_loss: 23.5791 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3596 - decoder_loss: 23.5791 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2450 - val_decoder_loss: 28.4839 - val_encoder_loss: 0.3653 - val_classifier_loss: 0.3136 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0025\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3541 - decoder_loss: 23.5240 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3541 - decoder_loss: 23.5240 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2577 - val_decoder_loss: 28.4049 - val_encoder_loss: 0.3859 - val_classifier_loss: 0.3131 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0025\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3486 - decoder_loss: 23.4697 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.3486 - decoder_loss: 23.4697 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2650 - val_decoder_loss: 28.3682 - val_encoder_loss: 0.3970 - val_classifier_loss: 0.3122 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0012\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3458 - decoder_loss: 23.4426 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.3458 - decoder_loss: 23.4426 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2589 - val_decoder_loss: 28.3320 - val_encoder_loss: 0.3945 - val_classifier_loss: 0.3120 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0012\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3431 - decoder_loss: 23.4155 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0694 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3431 - decoder_loss: 23.4155 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0694 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2518 - val_decoder_loss: 28.2985 - val_encoder_loss: 0.3907 - val_classifier_loss: 0.3119 - val_decoder_accuracy: 0.0388 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0012\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3404 - decoder_loss: 23.3888 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3404 - decoder_loss: 23.3888 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2447 - val_decoder_loss: 28.2662 - val_encoder_loss: 0.3869 - val_classifier_loss: 0.3118 - val_decoder_accuracy: 0.0408 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0012\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3377 - decoder_loss: 23.3623 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3377 - decoder_loss: 23.3623 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2378 - val_decoder_loss: 28.2352 - val_encoder_loss: 0.3831 - val_classifier_loss: 0.3119 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0012\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3351 - decoder_loss: 23.3359 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.3351 - decoder_loss: 23.3359 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2394 - val_decoder_loss: 28.2205 - val_encoder_loss: 0.3862 - val_classifier_loss: 0.3117 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3338 - decoder_loss: 23.3227 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.3338 - decoder_loss: 23.3227 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2366 - val_decoder_loss: 28.2058 - val_encoder_loss: 0.3849 - val_classifier_loss: 0.3118 - val_decoder_accuracy: 0.0430 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3324 - decoder_loss: 23.3095 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.3324 - decoder_loss: 23.3095 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2334 - val_decoder_loss: 28.1915 - val_encoder_loss: 0.3831 - val_classifier_loss: 0.3118 - val_decoder_accuracy: 0.0435 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3311 - decoder_loss: 23.2962 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3311 - decoder_loss: 23.2962 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2302 - val_decoder_loss: 28.1775 - val_encoder_loss: 0.3813 - val_classifier_loss: 0.3120 - val_decoder_accuracy: 0.0438 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3297 - decoder_loss: 23.2829 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0691 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3297 - decoder_loss: 23.2829 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0691 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2271 - val_decoder_loss: 28.1638 - val_encoder_loss: 0.3795 - val_classifier_loss: 0.3121 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3284 - decoder_loss: 23.2696 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 34: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3284 - decoder_loss: 23.2696 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2274 - val_decoder_loss: 28.1571 - val_encoder_loss: 0.3805 - val_classifier_loss: 0.3121 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3277 - decoder_loss: 23.2630 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3277 - decoder_loss: 23.2630 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2267 - val_decoder_loss: 28.1505 - val_encoder_loss: 0.3805 - val_classifier_loss: 0.3122 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3271 - decoder_loss: 23.2563 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3271 - decoder_loss: 23.2563 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2259 - val_decoder_loss: 28.1439 - val_encoder_loss: 0.3802 - val_classifier_loss: 0.3123 - val_decoder_accuracy: 0.0435 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3264 - decoder_loss: 23.2496 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3264 - decoder_loss: 23.2496 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2250 - val_decoder_loss: 28.1375 - val_encoder_loss: 0.3800 - val_classifier_loss: 0.3124 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3257 - decoder_loss: 23.2429 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3257 - decoder_loss: 23.2429 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2242 - val_decoder_loss: 28.1311 - val_encoder_loss: 0.3798 - val_classifier_loss: 0.3126 - val_decoder_accuracy: 0.0438 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3250 - decoder_loss: 23.2362 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3250 - decoder_loss: 23.2362 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2242 - val_decoder_loss: 28.1280 - val_encoder_loss: 0.3802 - val_classifier_loss: 0.3126 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3247 - decoder_loss: 23.2328 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3247 - decoder_loss: 23.2328 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2238 - val_decoder_loss: 28.1248 - val_encoder_loss: 0.3801 - val_classifier_loss: 0.3127 - val_decoder_accuracy: 0.0438 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3244 - decoder_loss: 23.2295 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.3244 - decoder_loss: 23.2295 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2234 - val_decoder_loss: 28.1217 - val_encoder_loss: 0.3800 - val_classifier_loss: 0.3127 - val_decoder_accuracy: 0.0442 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3240 - decoder_loss: 23.2261 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3240 - decoder_loss: 23.2261 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2230 - val_decoder_loss: 28.1186 - val_encoder_loss: 0.3799 - val_classifier_loss: 0.3128 - val_decoder_accuracy: 0.0443 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3237 - decoder_loss: 23.2226 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3237 - decoder_loss: 23.2226 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2226 - val_decoder_loss: 28.1155 - val_encoder_loss: 0.3797 - val_classifier_loss: 0.3129 - val_decoder_accuracy: 0.0443 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3233 - decoder_loss: 23.2192 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3233 - decoder_loss: 23.2192 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2224 - val_decoder_loss: 28.1135 - val_encoder_loss: 0.3798 - val_classifier_loss: 0.3130 - val_decoder_accuracy: 0.0447 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3231 - decoder_loss: 23.2170 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3231 - decoder_loss: 23.2170 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2222 - val_decoder_loss: 28.1115 - val_encoder_loss: 0.3797 - val_classifier_loss: 0.3130 - val_decoder_accuracy: 0.0447 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3229 - decoder_loss: 23.2148 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3229 - decoder_loss: 23.2148 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2219 - val_decoder_loss: 28.1096 - val_encoder_loss: 0.3796 - val_classifier_loss: 0.3131 - val_decoder_accuracy: 0.0447 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3227 - decoder_loss: 23.2126 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3227 - decoder_loss: 23.2126 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2216 - val_decoder_loss: 28.1076 - val_encoder_loss: 0.3795 - val_classifier_loss: 0.3131 - val_decoder_accuracy: 0.0447 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3224 - decoder_loss: 23.2103 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3224 - decoder_loss: 23.2103 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2213 - val_decoder_loss: 28.1056 - val_encoder_loss: 0.3795 - val_classifier_loss: 0.3132 - val_decoder_accuracy: 0.0447 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3222 - decoder_loss: 23.2081 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 49: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3222 - decoder_loss: 23.2081 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2211 - val_decoder_loss: 28.1037 - val_encoder_loss: 0.3794 - val_classifier_loss: 0.3132 - val_decoder_accuracy: 0.0447 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3220 - decoder_loss: 23.2059 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3220 - decoder_loss: 23.2059 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2208 - val_decoder_loss: 28.1017 - val_encoder_loss: 0.3793 - val_classifier_loss: 0.3133 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3218 - decoder_loss: 23.2036 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.3218 - decoder_loss: 23.2036 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2205 - val_decoder_loss: 28.0998 - val_encoder_loss: 0.3792 - val_classifier_loss: 0.3134 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3215 - decoder_loss: 23.2013 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3215 - decoder_loss: 23.2013 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2202 - val_decoder_loss: 28.0978 - val_encoder_loss: 0.3791 - val_classifier_loss: 0.3134 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3213 - decoder_loss: 23.1991 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3213 - decoder_loss: 23.1991 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2200 - val_decoder_loss: 28.0959 - val_encoder_loss: 0.3790 - val_classifier_loss: 0.3135 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3211 - decoder_loss: 23.1968 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3211 - decoder_loss: 23.1968 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2197 - val_decoder_loss: 28.0939 - val_encoder_loss: 0.3789 - val_classifier_loss: 0.3136 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3209 - decoder_loss: 23.1945 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3209 - decoder_loss: 23.1945 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2194 - val_decoder_loss: 28.0920 - val_encoder_loss: 0.3788 - val_classifier_loss: 0.3136 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3206 - decoder_loss: 23.1923 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3206 - decoder_loss: 23.1923 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2191 - val_decoder_loss: 28.0901 - val_encoder_loss: 0.3788 - val_classifier_loss: 0.3137 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3204 - decoder_loss: 23.1900 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3204 - decoder_loss: 23.1900 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2189 - val_decoder_loss: 28.0882 - val_encoder_loss: 0.3787 - val_classifier_loss: 0.3138 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3202 - decoder_loss: 23.1877 - encoder_loss: 5.4189e-05 - classifier_loss: 0.0140 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 58: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3202 - decoder_loss: 23.1877 - encoder_loss: 5.4189e-05 - classifier_loss: 0.0140 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2217 - val_decoder_loss: 28.0865 - val_encoder_loss: 0.3817 - val_classifier_loss: 0.3142 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3200 - decoder_loss: 23.1858 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 59: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.3200 - decoder_loss: 23.1858 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2215 - val_decoder_loss: 28.0846 - val_encoder_loss: 0.3816 - val_classifier_loss: 0.3143 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3198 - decoder_loss: 23.1836 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 60: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3198 - decoder_loss: 23.1836 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2214 - val_decoder_loss: 28.0827 - val_encoder_loss: 0.3817 - val_classifier_loss: 0.3144 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3195 - decoder_loss: 23.1813 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 61: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3195 - decoder_loss: 23.1813 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2213 - val_decoder_loss: 28.0809 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3145 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3193 - decoder_loss: 23.1790 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 62: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3193 - decoder_loss: 23.1790 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2212 - val_decoder_loss: 28.0790 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3146 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3191 - decoder_loss: 23.1768 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 63: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3191 - decoder_loss: 23.1768 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2211 - val_decoder_loss: 28.0771 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3147 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3188 - decoder_loss: 23.1745 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3188 - decoder_loss: 23.1745 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2209 - val_decoder_loss: 28.0753 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3148 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3186 - decoder_loss: 23.1722 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 65: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3186 - decoder_loss: 23.1722 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2208 - val_decoder_loss: 28.0735 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3149 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3184 - decoder_loss: 23.1699 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 66: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3184 - decoder_loss: 23.1699 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2206 - val_decoder_loss: 28.0716 - val_encoder_loss: 0.3820 - val_classifier_loss: 0.3150 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3181 - decoder_loss: 23.1676 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 67: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3181 - decoder_loss: 23.1676 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2204 - val_decoder_loss: 28.0698 - val_encoder_loss: 0.3820 - val_classifier_loss: 0.3151 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3179 - decoder_loss: 23.1653 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 68: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3179 - decoder_loss: 23.1653 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2203 - val_decoder_loss: 28.0679 - val_encoder_loss: 0.3820 - val_classifier_loss: 0.3152 - val_decoder_accuracy: 0.0447 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3177 - decoder_loss: 23.1630 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 69: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3177 - decoder_loss: 23.1630 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2201 - val_decoder_loss: 28.0661 - val_encoder_loss: 0.3820 - val_classifier_loss: 0.3153 - val_decoder_accuracy: 0.0445 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3174 - decoder_loss: 23.1606 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 70: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3174 - decoder_loss: 23.1606 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2199 - val_decoder_loss: 28.0643 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3154 - val_decoder_accuracy: 0.0447 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3172 - decoder_loss: 23.1583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 71: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3172 - decoder_loss: 23.1583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2197 - val_decoder_loss: 28.0625 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3155 - val_decoder_accuracy: 0.0443 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3170 - decoder_loss: 23.1560 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 72: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3170 - decoder_loss: 23.1560 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2195 - val_decoder_loss: 28.0607 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3156 - val_decoder_accuracy: 0.0442 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3167 - decoder_loss: 23.1537 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 73: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3167 - decoder_loss: 23.1537 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2193 - val_decoder_loss: 28.0589 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3157 - val_decoder_accuracy: 0.0442 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3165 - decoder_loss: 23.1514 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 74: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3165 - decoder_loss: 23.1514 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2191 - val_decoder_loss: 28.0571 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3158 - val_decoder_accuracy: 0.0442 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3163 - decoder_loss: 23.1491 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 75: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3163 - decoder_loss: 23.1491 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2189 - val_decoder_loss: 28.0553 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3159 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3160 - decoder_loss: 23.1467 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 76: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.3160 - decoder_loss: 23.1467 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2187 - val_decoder_loss: 28.0535 - val_encoder_loss: 0.3817 - val_classifier_loss: 0.3160 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3158 - decoder_loss: 23.1444 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 77: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3158 - decoder_loss: 23.1444 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2185 - val_decoder_loss: 28.0517 - val_encoder_loss: 0.3817 - val_classifier_loss: 0.3161 - val_decoder_accuracy: 0.0442 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3156 - decoder_loss: 23.1421 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 78: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3156 - decoder_loss: 23.1421 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2182 - val_decoder_loss: 28.0499 - val_encoder_loss: 0.3816 - val_classifier_loss: 0.3162 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3154 - decoder_loss: 23.1398 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 79: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3154 - decoder_loss: 23.1398 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2180 - val_decoder_loss: 28.0482 - val_encoder_loss: 0.3816 - val_classifier_loss: 0.3163 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3151 - decoder_loss: 23.1375 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 80: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3151 - decoder_loss: 23.1375 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2178 - val_decoder_loss: 28.0464 - val_encoder_loss: 0.3815 - val_classifier_loss: 0.3164 - val_decoder_accuracy: 0.0438 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3149 - decoder_loss: 23.1352 - encoder_loss: 2.1031e-05 - classifier_loss: 0.0137 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 81: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3149 - decoder_loss: 23.1352 - encoder_loss: 2.1031e-05 - classifier_loss: 0.0137 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2214 - val_decoder_loss: 28.0449 - val_encoder_loss: 0.3852 - val_classifier_loss: 0.3169 - val_decoder_accuracy: 0.0442 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3148 - decoder_loss: 23.1334 - encoder_loss: 9.2296e-05 - classifier_loss: 0.0136 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 82: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3148 - decoder_loss: 23.1334 - encoder_loss: 9.2296e-05 - classifier_loss: 0.0136 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2186 - val_decoder_loss: 28.0434 - val_encoder_loss: 0.3826 - val_classifier_loss: 0.3169 - val_decoder_accuracy: 0.0442 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3145 - decoder_loss: 23.1316 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 83: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3145 - decoder_loss: 23.1316 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2182 - val_decoder_loss: 28.0417 - val_encoder_loss: 0.3823 - val_classifier_loss: 0.3170 - val_decoder_accuracy: 0.0442 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3143 - decoder_loss: 23.1293 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 84: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3143 - decoder_loss: 23.1293 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2180 - val_decoder_loss: 28.0400 - val_encoder_loss: 0.3823 - val_classifier_loss: 0.3171 - val_decoder_accuracy: 0.0443 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3141 - decoder_loss: 23.1271 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 85: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3141 - decoder_loss: 23.1271 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2178 - val_decoder_loss: 28.0383 - val_encoder_loss: 0.3822 - val_classifier_loss: 0.3173 - val_decoder_accuracy: 0.0443 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3138 - decoder_loss: 23.1248 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 86: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3138 - decoder_loss: 23.1248 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2176 - val_decoder_loss: 28.0366 - val_encoder_loss: 0.3822 - val_classifier_loss: 0.3174 - val_decoder_accuracy: 0.0443 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3136 - decoder_loss: 23.1226 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 87: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3136 - decoder_loss: 23.1226 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2174 - val_decoder_loss: 28.0349 - val_encoder_loss: 0.3821 - val_classifier_loss: 0.3175 - val_decoder_accuracy: 0.0445 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3134 - decoder_loss: 23.1203 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3134 - decoder_loss: 23.1203 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2172 - val_decoder_loss: 28.0332 - val_encoder_loss: 0.3821 - val_classifier_loss: 0.3176 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3132 - decoder_loss: 23.1180 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3132 - decoder_loss: 23.1180 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2170 - val_decoder_loss: 28.0316 - val_encoder_loss: 0.3820 - val_classifier_loss: 0.3177 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3129 - decoder_loss: 23.1158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3129 - decoder_loss: 23.1158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2168 - val_decoder_loss: 28.0299 - val_encoder_loss: 0.3820 - val_classifier_loss: 0.3179 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3127 - decoder_loss: 23.1135 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3127 - decoder_loss: 23.1135 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2166 - val_decoder_loss: 28.0283 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3180 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3125 - decoder_loss: 23.1112 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3125 - decoder_loss: 23.1112 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2164 - val_decoder_loss: 28.0266 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3181 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3122 - decoder_loss: 23.1089 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 93: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3122 - decoder_loss: 23.1089 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2162 - val_decoder_loss: 28.0250 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3182 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3120 - decoder_loss: 23.1067 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 94: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3120 - decoder_loss: 23.1067 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2160 - val_decoder_loss: 28.0233 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3184 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3118 - decoder_loss: 23.1045 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3118 - decoder_loss: 23.1045 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0135 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2158 - val_decoder_loss: 28.0217 - val_encoder_loss: 0.3817 - val_classifier_loss: 0.3185 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3116 - decoder_loss: 23.1022 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 96: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3116 - decoder_loss: 23.1022 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2155 - val_decoder_loss: 28.0201 - val_encoder_loss: 0.3817 - val_classifier_loss: 0.3186 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3113 - decoder_loss: 23.1000 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 97: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3113 - decoder_loss: 23.1000 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2153 - val_decoder_loss: 28.0184 - val_encoder_loss: 0.3816 - val_classifier_loss: 0.3188 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3111 - decoder_loss: 23.0978 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 98: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3111 - decoder_loss: 23.0978 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2151 - val_decoder_loss: 28.0168 - val_encoder_loss: 0.3816 - val_classifier_loss: 0.3189 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3109 - decoder_loss: 23.0956 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 99: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3109 - decoder_loss: 23.0956 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2149 - val_decoder_loss: 28.0152 - val_encoder_loss: 0.3815 - val_classifier_loss: 0.3190 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3107 - decoder_loss: 23.0934 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3107 - decoder_loss: 23.0934 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2147 - val_decoder_loss: 28.0136 - val_encoder_loss: 0.3815 - val_classifier_loss: 0.3191 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3105 - decoder_loss: 23.0912 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3105 - decoder_loss: 23.0912 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2145 - val_decoder_loss: 28.0120 - val_encoder_loss: 0.3814 - val_classifier_loss: 0.3193 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3102 - decoder_loss: 23.0889 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3102 - decoder_loss: 23.0889 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2143 - val_decoder_loss: 28.0104 - val_encoder_loss: 0.3813 - val_classifier_loss: 0.3194 - val_decoder_accuracy: 0.0455 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3100 - decoder_loss: 23.0867 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3100 - decoder_loss: 23.0867 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0134 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2141 - val_decoder_loss: 28.0088 - val_encoder_loss: 0.3813 - val_classifier_loss: 0.3195 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3098 - decoder_loss: 23.0845 - encoder_loss: 3.0317e-05 - classifier_loss: 0.0133 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3098 - decoder_loss: 23.0845 - encoder_loss: 3.0317e-05 - classifier_loss: 0.0133 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2183 - val_decoder_loss: 28.0075 - val_encoder_loss: 0.3856 - val_classifier_loss: 0.3201 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3098 - decoder_loss: 23.0829 - encoder_loss: 2.0652e-04 - classifier_loss: 0.0133 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3098 - decoder_loss: 23.0829 - encoder_loss: 2.0652e-04 - classifier_loss: 0.0133 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2152 - val_decoder_loss: 28.0061 - val_encoder_loss: 0.3826 - val_classifier_loss: 0.3201 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3094 - decoder_loss: 23.0811 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0133 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3094 - decoder_loss: 23.0811 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0133 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2148 - val_decoder_loss: 28.0046 - val_encoder_loss: 0.3823 - val_classifier_loss: 0.3203 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3092 - decoder_loss: 23.0790 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0133 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3092 - decoder_loss: 23.0790 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0133 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2146 - val_decoder_loss: 28.0031 - val_encoder_loss: 0.3823 - val_classifier_loss: 0.3204 - val_decoder_accuracy: 0.0455 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3090 - decoder_loss: 23.0768 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0133 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3090 - decoder_loss: 23.0768 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0133 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2145 - val_decoder_loss: 28.0016 - val_encoder_loss: 0.3823 - val_classifier_loss: 0.3206 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3088 - decoder_loss: 23.0746 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 109: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3088 - decoder_loss: 23.0746 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2143 - val_decoder_loss: 28.0001 - val_encoder_loss: 0.3822 - val_classifier_loss: 0.3207 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3086 - decoder_loss: 23.0725 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3086 - decoder_loss: 23.0725 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2141 - val_decoder_loss: 27.9987 - val_encoder_loss: 0.3822 - val_classifier_loss: 0.3209 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3084 - decoder_loss: 23.0703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3084 - decoder_loss: 23.0703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2140 - val_decoder_loss: 27.9972 - val_encoder_loss: 0.3822 - val_classifier_loss: 0.3210 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3081 - decoder_loss: 23.0681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3081 - decoder_loss: 23.0681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2138 - val_decoder_loss: 27.9957 - val_encoder_loss: 0.3821 - val_classifier_loss: 0.3212 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3079 - decoder_loss: 23.0660 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3079 - decoder_loss: 23.0660 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2137 - val_decoder_loss: 27.9942 - val_encoder_loss: 0.3821 - val_classifier_loss: 0.3214 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3077 - decoder_loss: 23.0638 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3077 - decoder_loss: 23.0638 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2135 - val_decoder_loss: 27.9928 - val_encoder_loss: 0.3821 - val_classifier_loss: 0.3215 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3075 - decoder_loss: 23.0616 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3075 - decoder_loss: 23.0616 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2133 - val_decoder_loss: 27.9913 - val_encoder_loss: 0.3820 - val_classifier_loss: 0.3217 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3073 - decoder_loss: 23.0595 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3073 - decoder_loss: 23.0595 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0132 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2132 - val_decoder_loss: 27.9899 - val_encoder_loss: 0.3820 - val_classifier_loss: 0.3218 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3070 - decoder_loss: 23.0573 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3070 - decoder_loss: 23.0573 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2130 - val_decoder_loss: 27.9885 - val_encoder_loss: 0.3820 - val_classifier_loss: 0.3220 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3068 - decoder_loss: 23.0551 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3068 - decoder_loss: 23.0551 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2128 - val_decoder_loss: 27.9870 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3221 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3066 - decoder_loss: 23.0529 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3066 - decoder_loss: 23.0529 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2127 - val_decoder_loss: 27.9856 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3223 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3064 - decoder_loss: 23.0508 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3064 - decoder_loss: 23.0508 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2125 - val_decoder_loss: 27.9842 - val_encoder_loss: 0.3819 - val_classifier_loss: 0.3224 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3062 - decoder_loss: 23.0486 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 121: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3062 - decoder_loss: 23.0486 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2124 - val_decoder_loss: 27.9828 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3226 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3059 - decoder_loss: 23.0464 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3059 - decoder_loss: 23.0464 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2122 - val_decoder_loss: 27.9814 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3227 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3057 - decoder_loss: 23.0442 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3057 - decoder_loss: 23.0442 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0131 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2121 - val_decoder_loss: 27.9800 - val_encoder_loss: 0.3818 - val_classifier_loss: 0.3229 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3055 - decoder_loss: 23.0421 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3055 - decoder_loss: 23.0421 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2119 - val_decoder_loss: 27.9786 - val_encoder_loss: 0.3817 - val_classifier_loss: 0.3231 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3053 - decoder_loss: 23.0399 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.3053 - decoder_loss: 23.0399 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2118 - val_decoder_loss: 27.9772 - val_encoder_loss: 0.3817 - val_classifier_loss: 0.3232 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3051 - decoder_loss: 23.0377 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3051 - decoder_loss: 23.0377 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2116 - val_decoder_loss: 27.9759 - val_encoder_loss: 0.3817 - val_classifier_loss: 0.3234 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3049 - decoder_loss: 23.0356 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3049 - decoder_loss: 23.0356 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2114 - val_decoder_loss: 27.9745 - val_encoder_loss: 0.3816 - val_classifier_loss: 0.3235 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3046 - decoder_loss: 23.0334 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3046 - decoder_loss: 23.0334 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0130 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2113 - val_decoder_loss: 27.9732 - val_encoder_loss: 0.3816 - val_classifier_loss: 0.3237 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3045 - decoder_loss: 23.0312 - encoder_loss: 1.2737e-04 - classifier_loss: 0.0130 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.3045 - decoder_loss: 23.0312 - encoder_loss: 1.2737e-04 - classifier_loss: 0.0130 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2129 - val_decoder_loss: 27.9723 - val_encoder_loss: 0.3832 - val_classifier_loss: 0.3242 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3043 - decoder_loss: 23.0301 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.3043 - decoder_loss: 23.0301 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2123 - val_decoder_loss: 27.9710 - val_encoder_loss: 0.3828 - val_classifier_loss: 0.3244 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3041 - decoder_loss: 23.0281 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3041 - decoder_loss: 23.0281 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2122 - val_decoder_loss: 27.9697 - val_encoder_loss: 0.3828 - val_classifier_loss: 0.3246 - val_decoder_accuracy: 0.0468 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3039 - decoder_loss: 23.0260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3039 - decoder_loss: 23.0260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2121 - val_decoder_loss: 27.9684 - val_encoder_loss: 0.3828 - val_classifier_loss: 0.3248 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3037 - decoder_loss: 23.0239 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3037 - decoder_loss: 23.0239 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2120 - val_decoder_loss: 27.9672 - val_encoder_loss: 0.3828 - val_classifier_loss: 0.3249 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3035 - decoder_loss: 23.0219 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.3035 - decoder_loss: 23.0219 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2119 - val_decoder_loss: 27.9659 - val_encoder_loss: 0.3828 - val_classifier_loss: 0.3251 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3033 - decoder_loss: 23.0198 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3033 - decoder_loss: 23.0198 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2118 - val_decoder_loss: 27.9647 - val_encoder_loss: 0.3828 - val_classifier_loss: 0.3253 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3031 - decoder_loss: 23.0177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.3031 - decoder_loss: 23.0177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0129 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2118 - val_decoder_loss: 27.9634 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3255 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3029 - decoder_loss: 23.0157 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3029 - decoder_loss: 23.0157 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2117 - val_decoder_loss: 27.9622 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3257 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3026 - decoder_loss: 23.0136 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3026 - decoder_loss: 23.0136 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2116 - val_decoder_loss: 27.9610 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3259 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3024 - decoder_loss: 23.0115 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3024 - decoder_loss: 23.0115 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2115 - val_decoder_loss: 27.9598 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3260 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3022 - decoder_loss: 23.0095 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.3022 - decoder_loss: 23.0095 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2114 - val_decoder_loss: 27.9585 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3262 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3020 - decoder_loss: 23.0074 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 141: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.3020 - decoder_loss: 23.0074 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2113 - val_decoder_loss: 27.9573 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3264 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3018 - decoder_loss: 23.0054 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.3018 - decoder_loss: 23.0054 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2112 - val_decoder_loss: 27.9561 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3266 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3016 - decoder_loss: 23.0034 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3016 - decoder_loss: 23.0034 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2111 - val_decoder_loss: 27.9550 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3268 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3014 - decoder_loss: 23.0013 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3014 - decoder_loss: 23.0013 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2110 - val_decoder_loss: 27.9538 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3270 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3012 - decoder_loss: 22.9993 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3012 - decoder_loss: 22.9993 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2109 - val_decoder_loss: 27.9526 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3271 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3010 - decoder_loss: 22.9973 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3010 - decoder_loss: 22.9973 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2108 - val_decoder_loss: 27.9514 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3273 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3008 - decoder_loss: 22.9952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3008 - decoder_loss: 22.9952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2107 - val_decoder_loss: 27.9502 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3275 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3006 - decoder_loss: 22.9932 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.3006 - decoder_loss: 22.9932 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2106 - val_decoder_loss: 27.9491 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3277 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3004 - decoder_loss: 22.9912 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3004 - decoder_loss: 22.9912 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2105 - val_decoder_loss: 27.9479 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3279 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3002 - decoder_loss: 22.9892 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.3002 - decoder_loss: 22.9892 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2104 - val_decoder_loss: 27.9468 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3281 - val_decoder_accuracy: 0.0470 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3000 - decoder_loss: 22.9871 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.3000 - decoder_loss: 22.9871 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0127 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2103 - val_decoder_loss: 27.9456 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3283 - val_decoder_accuracy: 0.0467 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2998 - decoder_loss: 22.9851 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0126 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2998 - decoder_loss: 22.9851 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0126 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2102 - val_decoder_loss: 27.9445 - val_encoder_loss: 0.3829 - val_classifier_loss: 0.3284 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2996 - decoder_loss: 22.9831 - encoder_loss: 9.8279e-06 - classifier_loss: 0.0126 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2996 - decoder_loss: 22.9831 - encoder_loss: 9.8279e-06 - classifier_loss: 0.0126 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2065 - val_decoder_loss: 27.9435 - val_encoder_loss: 0.3793 - val_classifier_loss: 0.3284 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2996 - decoder_loss: 22.9816 - encoder_loss: 1.5794e-04 - classifier_loss: 0.0126 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2996 - decoder_loss: 22.9816 - encoder_loss: 1.5794e-04 - classifier_loss: 0.0126 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2115 - val_decoder_loss: 27.9427 - val_encoder_loss: 0.3843 - val_classifier_loss: 0.3292 - val_decoder_accuracy: 0.0468 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2993 - decoder_loss: 22.9802 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0126 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2993 - decoder_loss: 22.9802 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0126 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2112 - val_decoder_loss: 27.9416 - val_encoder_loss: 0.3841 - val_classifier_loss: 0.3294 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2991 - decoder_loss: 22.9783 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0126 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2991 - decoder_loss: 22.9783 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0126 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2112 - val_decoder_loss: 27.9406 - val_encoder_loss: 0.3842 - val_classifier_loss: 0.3296 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2989 - decoder_loss: 22.9763 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0126 - decoder_accuracy: 0.0674 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2989 - decoder_loss: 22.9763 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0126 - decoder_accuracy: 0.0674 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2112 - val_decoder_loss: 27.9395 - val_encoder_loss: 0.3842 - val_classifier_loss: 0.3298 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2987 - decoder_loss: 22.9744 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2987 - decoder_loss: 22.9744 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2112 - val_decoder_loss: 27.9385 - val_encoder_loss: 0.3843 - val_classifier_loss: 0.3300 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2985 - decoder_loss: 22.9724 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2985 - decoder_loss: 22.9724 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2112 - val_decoder_loss: 27.9374 - val_encoder_loss: 0.3844 - val_classifier_loss: 0.3302 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2983 - decoder_loss: 22.9705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2983 - decoder_loss: 22.9705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2112 - val_decoder_loss: 27.9364 - val_encoder_loss: 0.3845 - val_classifier_loss: 0.3305 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2981 - decoder_loss: 22.9685 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2981 - decoder_loss: 22.9685 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2112 - val_decoder_loss: 27.9353 - val_encoder_loss: 0.3846 - val_classifier_loss: 0.3307 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2979 - decoder_loss: 22.9666 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 162: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2979 - decoder_loss: 22.9666 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2111 - val_decoder_loss: 27.9343 - val_encoder_loss: 0.3846 - val_classifier_loss: 0.3309 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2977 - decoder_loss: 22.9646 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 163: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2977 - decoder_loss: 22.9646 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2111 - val_decoder_loss: 27.9333 - val_encoder_loss: 0.3847 - val_classifier_loss: 0.3311 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2975 - decoder_loss: 22.9627 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2975 - decoder_loss: 22.9627 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2111 - val_decoder_loss: 27.9322 - val_encoder_loss: 0.3847 - val_classifier_loss: 0.3313 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2973 - decoder_loss: 22.9607 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2973 - decoder_loss: 22.9607 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2111 - val_decoder_loss: 27.9312 - val_encoder_loss: 0.3848 - val_classifier_loss: 0.3315 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2971 - decoder_loss: 22.9588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 166: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2971 - decoder_loss: 22.9588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2110 - val_decoder_loss: 27.9302 - val_encoder_loss: 0.3848 - val_classifier_loss: 0.3317 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2969 - decoder_loss: 22.9569 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2969 - decoder_loss: 22.9569 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2110 - val_decoder_loss: 27.9292 - val_encoder_loss: 0.3849 - val_classifier_loss: 0.3319 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2967 - decoder_loss: 22.9549 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2967 - decoder_loss: 22.9549 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2110 - val_decoder_loss: 27.9282 - val_encoder_loss: 0.3849 - val_classifier_loss: 0.3321 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2965 - decoder_loss: 22.9530 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2965 - decoder_loss: 22.9530 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2109 - val_decoder_loss: 27.9273 - val_encoder_loss: 0.3850 - val_classifier_loss: 0.3323 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2963 - decoder_loss: 22.9511 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2963 - decoder_loss: 22.9511 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2109 - val_decoder_loss: 27.9263 - val_encoder_loss: 0.3850 - val_classifier_loss: 0.3325 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2962 - decoder_loss: 22.9492 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2962 - decoder_loss: 22.9492 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2108 - val_decoder_loss: 27.9253 - val_encoder_loss: 0.3850 - val_classifier_loss: 0.3328 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2960 - decoder_loss: 22.9472 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2960 - decoder_loss: 22.9472 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2108 - val_decoder_loss: 27.9243 - val_encoder_loss: 0.3851 - val_classifier_loss: 0.3330 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2958 - decoder_loss: 22.9453 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2958 - decoder_loss: 22.9453 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0124 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2108 - val_decoder_loss: 27.9234 - val_encoder_loss: 0.3851 - val_classifier_loss: 0.3332 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2956 - decoder_loss: 22.9434 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2956 - decoder_loss: 22.9434 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2107 - val_decoder_loss: 27.9224 - val_encoder_loss: 0.3851 - val_classifier_loss: 0.3334 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2954 - decoder_loss: 22.9415 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2954 - decoder_loss: 22.9415 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2107 - val_decoder_loss: 27.9215 - val_encoder_loss: 0.3852 - val_classifier_loss: 0.3336 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2952 - decoder_loss: 22.9396 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2952 - decoder_loss: 22.9396 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2106 - val_decoder_loss: 27.9206 - val_encoder_loss: 0.3852 - val_classifier_loss: 0.3338 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2950 - decoder_loss: 22.9377 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2950 - decoder_loss: 22.9377 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2106 - val_decoder_loss: 27.9196 - val_encoder_loss: 0.3852 - val_classifier_loss: 0.3340 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2948 - decoder_loss: 22.9358 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2948 - decoder_loss: 22.9358 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2106 - val_decoder_loss: 27.9187 - val_encoder_loss: 0.3853 - val_classifier_loss: 0.3342 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2947 - decoder_loss: 22.9339 - encoder_loss: 4.9009e-05 - classifier_loss: 0.0123 - decoder_accuracy: 0.0674 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2947 - decoder_loss: 22.9339 - encoder_loss: 4.9009e-05 - classifier_loss: 0.0123 - decoder_accuracy: 0.0674 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2065 - val_decoder_loss: 27.9179 - val_encoder_loss: 0.3813 - val_classifier_loss: 0.3342 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2958 - decoder_loss: 22.9325 - encoder_loss: 0.0013 - classifier_loss: 0.0123 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.2958 - decoder_loss: 22.9325 - encoder_loss: 0.0013 - classifier_loss: 0.0123 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1922 - val_decoder_loss: 27.9175 - val_encoder_loss: 0.3670 - val_classifier_loss: 0.3338 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2943 - decoder_loss: 22.9309 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2943 - decoder_loss: 22.9309 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1908 - val_decoder_loss: 27.9166 - val_encoder_loss: 0.3657 - val_classifier_loss: 0.3339 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2942 - decoder_loss: 22.9291 - encoder_loss: 4.8547e-05 - classifier_loss: 0.0122 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2942 - decoder_loss: 22.9291 - encoder_loss: 4.8547e-05 - classifier_loss: 0.0122 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1958 - val_decoder_loss: 27.9160 - val_encoder_loss: 0.3707 - val_classifier_loss: 0.3347 - val_decoder_accuracy: 0.0467 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2940 - decoder_loss: 22.9279 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2940 - decoder_loss: 22.9279 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1948 - val_decoder_loss: 27.9151 - val_encoder_loss: 0.3698 - val_classifier_loss: 0.3349 - val_decoder_accuracy: 0.0467 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2938 - decoder_loss: 22.9261 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2938 - decoder_loss: 22.9261 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1942 - val_decoder_loss: 27.9143 - val_encoder_loss: 0.3692 - val_classifier_loss: 0.3351 - val_decoder_accuracy: 0.0468 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2936 - decoder_loss: 22.9242 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2936 - decoder_loss: 22.9242 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1936 - val_decoder_loss: 27.9135 - val_encoder_loss: 0.3688 - val_classifier_loss: 0.3353 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2935 - decoder_loss: 22.9224 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2935 - decoder_loss: 22.9224 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1932 - val_decoder_loss: 27.9126 - val_encoder_loss: 0.3683 - val_classifier_loss: 0.3355 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2933 - decoder_loss: 22.9206 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2933 - decoder_loss: 22.9206 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1927 - val_decoder_loss: 27.9118 - val_encoder_loss: 0.3680 - val_classifier_loss: 0.3357 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2931 - decoder_loss: 22.9188 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2931 - decoder_loss: 22.9188 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1923 - val_decoder_loss: 27.9110 - val_encoder_loss: 0.3676 - val_classifier_loss: 0.3360 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2929 - decoder_loss: 22.9170 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2929 - decoder_loss: 22.9170 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1920 - val_decoder_loss: 27.9102 - val_encoder_loss: 0.3673 - val_classifier_loss: 0.3362 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2927 - decoder_loss: 22.9152 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.2927 - decoder_loss: 22.9152 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1916 - val_decoder_loss: 27.9094 - val_encoder_loss: 0.3671 - val_classifier_loss: 0.3364 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2925 - decoder_loss: 22.9134 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2925 - decoder_loss: 22.9134 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1913 - val_decoder_loss: 27.9086 - val_encoder_loss: 0.3668 - val_classifier_loss: 0.3366 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2924 - decoder_loss: 22.9115 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2924 - decoder_loss: 22.9115 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1911 - val_decoder_loss: 27.9077 - val_encoder_loss: 0.3666 - val_classifier_loss: 0.3368 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2922 - decoder_loss: 22.9097 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2922 - decoder_loss: 22.9097 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1908 - val_decoder_loss: 27.9070 - val_encoder_loss: 0.3664 - val_classifier_loss: 0.3371 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2920 - decoder_loss: 22.9079 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2920 - decoder_loss: 22.9079 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1906 - val_decoder_loss: 27.9062 - val_encoder_loss: 0.3663 - val_classifier_loss: 0.3373 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2918 - decoder_loss: 22.9061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2918 - decoder_loss: 22.9061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1904 - val_decoder_loss: 27.9054 - val_encoder_loss: 0.3661 - val_classifier_loss: 0.3375 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2916 - decoder_loss: 22.9043 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2916 - decoder_loss: 22.9043 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1903 - val_decoder_loss: 27.9046 - val_encoder_loss: 0.3660 - val_classifier_loss: 0.3377 - val_decoder_accuracy: 0.0470 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2914 - decoder_loss: 22.9024 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2914 - decoder_loss: 22.9024 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1901 - val_decoder_loss: 27.9038 - val_encoder_loss: 0.3659 - val_classifier_loss: 0.3380 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2913 - decoder_loss: 22.9006 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2913 - decoder_loss: 22.9006 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0681 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1900 - val_decoder_loss: 27.9030 - val_encoder_loss: 0.3658 - val_classifier_loss: 0.3382 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2911 - decoder_loss: 22.8988 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2911 - decoder_loss: 22.8988 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1898 - val_decoder_loss: 27.9023 - val_encoder_loss: 0.3658 - val_classifier_loss: 0.3384 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2909 - decoder_loss: 22.8970 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2909 - decoder_loss: 22.8970 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1897 - val_decoder_loss: 27.9015 - val_encoder_loss: 0.3657 - val_classifier_loss: 0.3386 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2907 - decoder_loss: 22.8952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2907 - decoder_loss: 22.8952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1896 - val_decoder_loss: 27.9008 - val_encoder_loss: 0.3657 - val_classifier_loss: 0.3389 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2905 - decoder_loss: 22.8934 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0685 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2905 - decoder_loss: 22.8934 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0685 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1895 - val_decoder_loss: 27.9000 - val_encoder_loss: 0.3656 - val_classifier_loss: 0.3391 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2904 - decoder_loss: 22.8916 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 203: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2904 - decoder_loss: 22.8916 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1895 - val_decoder_loss: 27.8993 - val_encoder_loss: 0.3656 - val_classifier_loss: 0.3393 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2902 - decoder_loss: 22.8898 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 204: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2902 - decoder_loss: 22.8898 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1894 - val_decoder_loss: 27.8985 - val_encoder_loss: 0.3656 - val_classifier_loss: 0.3396 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2900 - decoder_loss: 22.8880 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 205: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2900 - decoder_loss: 22.8880 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0120 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1893 - val_decoder_loss: 27.8978 - val_encoder_loss: 0.3656 - val_classifier_loss: 0.3398 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2898 - decoder_loss: 22.8862 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0119 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 206: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2898 - decoder_loss: 22.8862 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0119 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1893 - val_decoder_loss: 27.8971 - val_encoder_loss: 0.3656 - val_classifier_loss: 0.3400 - val_decoder_accuracy: 0.0468 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2896 - decoder_loss: 22.8844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0119 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 207: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2896 - decoder_loss: 22.8844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0119 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1892 - val_decoder_loss: 27.8964 - val_encoder_loss: 0.3656 - val_classifier_loss: 0.3403 - val_decoder_accuracy: 0.0468 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2895 - decoder_loss: 22.8826 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0119 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 208: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2895 - decoder_loss: 22.8826 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0119 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.1892 - val_decoder_loss: 27.8956 - val_encoder_loss: 0.3656 - val_classifier_loss: 0.3405 - val_decoder_accuracy: 0.0468 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 208: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_12 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_13 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_6 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_12 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_13 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 343ms/step\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 5.9640 - decoder_loss: 26.4712 - encoder_loss: 3.2477 - classifier_loss: 0.6917 - decoder_accuracy: 0.0257 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7333\n",
            "F1-score is computed based on binary\n",
            "(loss: 5.964024066925049, accuracy: 0.7333333492279053)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.73      0.73        15\n",
            "         1.0       0.73      0.73      0.73        15\n",
            "\n",
            "    accuracy                           0.73        30\n",
            "   macro avg       0.73      0.73      0.73        30\n",
            "weighted avg       0.73      0.73      0.73        30\n",
            "\n",
            "Accuracy: 0.7333333492279053\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7333333492279053\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fold2"
      ],
      "metadata": {
        "id": "ciHvOA0swdBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=10, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=200,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(2,3):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZPkBNE4LweMV",
        "outputId": "c12e7621-6c6f-40be-f43a-9fc1f87dc49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 2\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_18 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_19 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_9 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_18 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_19 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5454 - decoder_loss: 26.5397 - encoder_loss: 2.8249 - classifier_loss: 0.6658 - decoder_accuracy: 0.0174 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750\n",
            "Epoch 1: val_loss improved from inf to 666.17865, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 5.5454 - decoder_loss: 26.5397 - encoder_loss: 2.8249 - classifier_loss: 0.6658 - decoder_accuracy: 0.0174 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750 - val_loss: 666.1786 - val_decoder_loss: 23.7731 - val_encoder_loss: 663.5687 - val_classifier_loss: 2.3261 - val_decoder_accuracy: 0.0160 - val_encoder_accuracy: 0.3000 - val_classifier_accuracy: 0.2000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.6128 - decoder_loss: 26.5351 - encoder_loss: 0.8932 - classifier_loss: 0.6612 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6500\n",
            "Epoch 2: val_loss improved from 666.17865 to 38.35162, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 3.6128 - decoder_loss: 26.5351 - encoder_loss: 0.8932 - classifier_loss: 0.6612 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6500 - val_loss: 38.3516 - val_decoder_loss: 23.7402 - val_encoder_loss: 35.9087 - val_classifier_loss: 0.6895 - val_decoder_accuracy: 0.0187 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 12.1732 - decoder_loss: 26.5225 - encoder_loss: 9.4729 - classifier_loss: 0.4801 - decoder_accuracy: 0.0192 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 3: val_loss improved from 38.35162 to 10.24164, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 12.1732 - decoder_loss: 26.5225 - encoder_loss: 9.4729 - classifier_loss: 0.4801 - decoder_accuracy: 0.0192 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 10.2416 - val_decoder_loss: 23.7274 - val_encoder_loss: 7.7877 - val_classifier_loss: 0.8124 - val_decoder_accuracy: 0.0163 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.3411 - decoder_loss: 26.5332 - encoder_loss: 1.6311 - classifier_loss: 0.5669 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.7500\n",
            "Epoch 4: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 4.3411 - decoder_loss: 26.5332 - encoder_loss: 1.6311 - classifier_loss: 0.5669 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.7500 - val_loss: 13.7692 - val_decoder_loss: 23.6738 - val_encoder_loss: 11.3417 - val_classifier_loss: 0.6008 - val_decoder_accuracy: 0.0160 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.4963 - decoder_loss: 26.4164 - encoder_loss: 1.8224 - classifier_loss: 0.3227 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 5: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.4963 - decoder_loss: 26.4164 - encoder_loss: 1.8224 - classifier_loss: 0.3227 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 56.8705 - val_decoder_loss: 23.6940 - val_encoder_loss: 54.4540 - val_classifier_loss: 0.4714 - val_decoder_accuracy: 0.0123 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 10.5918 - decoder_loss: 26.2406 - encoder_loss: 7.9364 - classifier_loss: 0.3131 - decoder_accuracy: 0.0120 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 6: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 10.5918 - decoder_loss: 26.2406 - encoder_loss: 7.9364 - classifier_loss: 0.3131 - decoder_accuracy: 0.0120 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 35.9842 - val_decoder_loss: 23.7835 - val_encoder_loss: 33.4297 - val_classifier_loss: 1.7613 - val_decoder_accuracy: 0.0185 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.2762 - decoder_loss: 26.1321 - encoder_loss: 3.6139 - classifier_loss: 0.4906 - decoder_accuracy: 0.0211 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 7: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.2762 - decoder_loss: 26.1321 - encoder_loss: 3.6139 - classifier_loss: 0.4906 - decoder_accuracy: 0.0211 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 134.3846 - val_decoder_loss: 23.6728 - val_encoder_loss: 131.8754 - val_classifier_loss: 1.4193 - val_decoder_accuracy: 0.0285 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 23.0711 - decoder_loss: 26.3580 - encoder_loss: 20.3807 - classifier_loss: 0.5458 - decoder_accuracy: 0.0288 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 8: val_loss did not improve from 10.24164\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 23.0711 - decoder_loss: 26.3580 - encoder_loss: 20.3807 - classifier_loss: 0.5458 - decoder_accuracy: 0.0288 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 27.7517 - val_decoder_loss: 24.1066 - val_encoder_loss: 25.2776 - val_classifier_loss: 0.6337 - val_decoder_accuracy: 0.0207 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.5974 - decoder_loss: 26.8608 - encoder_loss: 4.8592 - classifier_loss: 0.5212 - decoder_accuracy: 0.0211 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750\n",
            "Epoch 9: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 7.5974 - decoder_loss: 26.8608 - encoder_loss: 4.8592 - classifier_loss: 0.5212 - decoder_accuracy: 0.0211 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750 - val_loss: 24.1010 - val_decoder_loss: 23.6987 - val_encoder_loss: 21.6717 - val_classifier_loss: 0.5949 - val_decoder_accuracy: 0.0207 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 12.7411 - decoder_loss: 26.4614 - encoder_loss: 10.0367 - classifier_loss: 0.5827 - decoder_accuracy: 0.0230 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750\n",
            "Epoch 10: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 12.7411 - decoder_loss: 26.4614 - encoder_loss: 10.0367 - classifier_loss: 0.5827 - decoder_accuracy: 0.0230 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750 - val_loss: 19.4547 - val_decoder_loss: 23.5113 - val_encoder_loss: 17.0478 - val_classifier_loss: 0.5575 - val_decoder_accuracy: 0.0208 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3385 - decoder_loss: 26.2663 - encoder_loss: 0.6713 - classifier_loss: 0.4061 - decoder_accuracy: 0.0243 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 11: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.3385 - decoder_loss: 26.2663 - encoder_loss: 0.6713 - classifier_loss: 0.4061 - decoder_accuracy: 0.0243 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 21.7922 - val_decoder_loss: 23.4728 - val_encoder_loss: 19.3943 - val_classifier_loss: 0.5060 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8715 - decoder_loss: 26.1495 - encoder_loss: 0.2237 - classifier_loss: 0.3285 - decoder_accuracy: 0.0296 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750\n",
            "Epoch 12: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.8715 - decoder_loss: 26.1495 - encoder_loss: 0.2237 - classifier_loss: 0.3285 - decoder_accuracy: 0.0296 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750 - val_loss: 20.6908 - val_decoder_loss: 23.4286 - val_encoder_loss: 18.2962 - val_classifier_loss: 0.5179 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7307 - decoder_loss: 26.0187 - encoder_loss: 0.1007 - classifier_loss: 0.2808 - decoder_accuracy: 0.0344 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750\n",
            "Epoch 13: val_loss did not improve from 10.24164\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.7307 - decoder_loss: 26.0187 - encoder_loss: 0.1007 - classifier_loss: 0.2808 - decoder_accuracy: 0.0344 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750 - val_loss: 18.7190 - val_decoder_loss: 23.4302 - val_encoder_loss: 16.3254 - val_classifier_loss: 0.5062 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6878 - decoder_loss: 25.9128 - encoder_loss: 0.0722 - classifier_loss: 0.2440 - decoder_accuracy: 0.0358 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 14: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.6878 - decoder_loss: 25.9128 - encoder_loss: 0.0722 - classifier_loss: 0.2440 - decoder_accuracy: 0.0358 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 17.3683 - val_decoder_loss: 23.4111 - val_encoder_loss: 14.9766 - val_classifier_loss: 0.5065 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0025\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6955 - decoder_loss: 25.8633 - encoder_loss: 0.0859 - classifier_loss: 0.2321 - decoder_accuracy: 0.0379 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 15: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.6955 - decoder_loss: 25.8633 - encoder_loss: 0.0859 - classifier_loss: 0.2321 - decoder_accuracy: 0.0379 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 16.4102 - val_decoder_loss: 23.3702 - val_encoder_loss: 14.0257 - val_classifier_loss: 0.4753 - val_decoder_accuracy: 0.0332 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0025\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6448 - decoder_loss: 25.7698 - encoder_loss: 0.0469 - classifier_loss: 0.2094 - decoder_accuracy: 0.0388 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250\n",
            "Epoch 16: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.6448 - decoder_loss: 25.7698 - encoder_loss: 0.0469 - classifier_loss: 0.2094 - decoder_accuracy: 0.0388 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250 - val_loss: 16.0947 - val_decoder_loss: 23.3367 - val_encoder_loss: 13.7147 - val_classifier_loss: 0.4640 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0025\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6403 - decoder_loss: 25.7086 - encoder_loss: 0.0505 - classifier_loss: 0.1891 - decoder_accuracy: 0.0397 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 17: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.6403 - decoder_loss: 25.7086 - encoder_loss: 0.0505 - classifier_loss: 0.1891 - decoder_accuracy: 0.0397 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 15.5329 - val_decoder_loss: 23.3064 - val_encoder_loss: 13.1557 - val_classifier_loss: 0.4661 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0025\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6184 - decoder_loss: 25.6422 - encoder_loss: 0.0365 - classifier_loss: 0.1766 - decoder_accuracy: 0.0399 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 18: val_loss did not improve from 10.24164\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.6184 - decoder_loss: 25.6422 - encoder_loss: 0.0365 - classifier_loss: 0.1766 - decoder_accuracy: 0.0399 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 14.8777 - val_decoder_loss: 23.2765 - val_encoder_loss: 12.5058 - val_classifier_loss: 0.4427 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0025\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6057 - decoder_loss: 25.5819 - encoder_loss: 0.0317 - classifier_loss: 0.1583 - decoder_accuracy: 0.0400 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 19: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.6057 - decoder_loss: 25.5819 - encoder_loss: 0.0317 - classifier_loss: 0.1583 - decoder_accuracy: 0.0400 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 14.2301 - val_decoder_loss: 23.2694 - val_encoder_loss: 11.8599 - val_classifier_loss: 0.4321 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0012\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6055 - decoder_loss: 25.5630 - encoder_loss: 0.0342 - classifier_loss: 0.1497 - decoder_accuracy: 0.0409 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.6055 - decoder_loss: 25.5630 - encoder_loss: 0.0342 - classifier_loss: 0.1497 - decoder_accuracy: 0.0409 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.4113 - val_decoder_loss: 23.2650 - val_encoder_loss: 11.0420 - val_classifier_loss: 0.4278 - val_decoder_accuracy: 0.0328 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0012\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5964 - decoder_loss: 25.5518 - encoder_loss: 0.0271 - classifier_loss: 0.1416 - decoder_accuracy: 0.0410 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5964 - decoder_loss: 25.5518 - encoder_loss: 0.0271 - classifier_loss: 0.1416 - decoder_accuracy: 0.0410 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 12.8949 - val_decoder_loss: 23.2547 - val_encoder_loss: 10.5277 - val_classifier_loss: 0.4169 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0012\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5858 - decoder_loss: 25.5291 - encoder_loss: 0.0197 - classifier_loss: 0.1322 - decoder_accuracy: 0.0413 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5858 - decoder_loss: 25.5291 - encoder_loss: 0.0197 - classifier_loss: 0.1322 - decoder_accuracy: 0.0413 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 12.7384 - val_decoder_loss: 23.2430 - val_encoder_loss: 10.3724 - val_classifier_loss: 0.4172 - val_decoder_accuracy: 0.0328 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0012\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5897 - decoder_loss: 25.5082 - encoder_loss: 0.0263 - classifier_loss: 0.1257 - decoder_accuracy: 0.0411 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 10.24164\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5897 - decoder_loss: 25.5082 - encoder_loss: 0.0263 - classifier_loss: 0.1257 - decoder_accuracy: 0.0411 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 12.0479 - val_decoder_loss: 23.2337 - val_encoder_loss: 9.6833 - val_classifier_loss: 0.4120 - val_decoder_accuracy: 0.0325 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0012\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5838 - decoder_loss: 25.4925 - encoder_loss: 0.0227 - classifier_loss: 0.1185 - decoder_accuracy: 0.0408 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5838 - decoder_loss: 25.4925 - encoder_loss: 0.0227 - classifier_loss: 0.1185 - decoder_accuracy: 0.0408 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 11.9152 - val_decoder_loss: 23.2276 - val_encoder_loss: 9.5510 - val_classifier_loss: 0.4141 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5750 - decoder_loss: 25.4824 - encoder_loss: 0.0152 - classifier_loss: 0.1154 - decoder_accuracy: 0.0407 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5750 - decoder_loss: 25.4824 - encoder_loss: 0.0152 - classifier_loss: 0.1154 - decoder_accuracy: 0.0407 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 11.6738 - val_decoder_loss: 23.2199 - val_encoder_loss: 9.3104 - val_classifier_loss: 0.4136 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5726 - decoder_loss: 25.4708 - encoder_loss: 0.0142 - classifier_loss: 0.1126 - decoder_accuracy: 0.0409 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5726 - decoder_loss: 25.4708 - encoder_loss: 0.0142 - classifier_loss: 0.1126 - decoder_accuracy: 0.0409 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 11.4299 - val_decoder_loss: 23.2147 - val_encoder_loss: 9.0674 - val_classifier_loss: 0.4101 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5718 - decoder_loss: 25.4645 - encoder_loss: 0.0144 - classifier_loss: 0.1093 - decoder_accuracy: 0.0417 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5718 - decoder_loss: 25.4645 - encoder_loss: 0.0144 - classifier_loss: 0.1093 - decoder_accuracy: 0.0417 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 11.1441 - val_decoder_loss: 23.2066 - val_encoder_loss: 8.7825 - val_classifier_loss: 0.4098 - val_decoder_accuracy: 0.0323 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5757 - decoder_loss: 25.4520 - encoder_loss: 0.0198 - classifier_loss: 0.1067 - decoder_accuracy: 0.0409 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 10.24164\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5757 - decoder_loss: 25.4520 - encoder_loss: 0.0198 - classifier_loss: 0.1067 - decoder_accuracy: 0.0409 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 10.8194 - val_decoder_loss: 23.2010 - val_encoder_loss: 8.4590 - val_classifier_loss: 0.4030 - val_decoder_accuracy: 0.0328 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 6.2500e-04\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5700 - decoder_loss: 25.4481 - encoder_loss: 0.0148 - classifier_loss: 0.1036 - decoder_accuracy: 0.0410 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5700 - decoder_loss: 25.4481 - encoder_loss: 0.0148 - classifier_loss: 0.1036 - decoder_accuracy: 0.0410 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 10.6649 - val_decoder_loss: 23.1978 - val_encoder_loss: 8.3050 - val_classifier_loss: 0.4014 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5733 - decoder_loss: 25.4436 - encoder_loss: 0.0187 - classifier_loss: 0.1026 - decoder_accuracy: 0.0410 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5733 - decoder_loss: 25.4436 - encoder_loss: 0.0187 - classifier_loss: 0.1026 - decoder_accuracy: 0.0410 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 10.4954 - val_decoder_loss: 23.1948 - val_encoder_loss: 8.1358 - val_classifier_loss: 0.4005 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5725 - decoder_loss: 25.4424 - encoder_loss: 0.0182 - classifier_loss: 0.1014 - decoder_accuracy: 0.0408 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 10.24164\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5725 - decoder_loss: 25.4424 - encoder_loss: 0.0182 - classifier_loss: 0.1014 - decoder_accuracy: 0.0408 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 10.3372 - val_decoder_loss: 23.1912 - val_encoder_loss: 7.9782 - val_classifier_loss: 0.3981 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5689 - decoder_loss: 25.4396 - encoder_loss: 0.0150 - classifier_loss: 0.0999 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 32: val_loss improved from 10.24164 to 10.17292, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.5689 - decoder_loss: 25.4396 - encoder_loss: 0.0150 - classifier_loss: 0.0999 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 10.1729 - val_decoder_loss: 23.1869 - val_encoder_loss: 7.8145 - val_classifier_loss: 0.3972 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5669 - decoder_loss: 25.4351 - encoder_loss: 0.0135 - classifier_loss: 0.0987 - decoder_accuracy: 0.0400 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 33: val_loss improved from 10.17292 to 10.11010, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.5669 - decoder_loss: 25.4351 - encoder_loss: 0.0135 - classifier_loss: 0.0987 - decoder_accuracy: 0.0400 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 10.1101 - val_decoder_loss: 23.1823 - val_encoder_loss: 7.7522 - val_classifier_loss: 0.3969 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5646 - decoder_loss: 25.4300 - encoder_loss: 0.0119 - classifier_loss: 0.0973 - decoder_accuracy: 0.0398 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 34: val_loss improved from 10.11010 to 10.00427, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.5646 - decoder_loss: 25.4300 - encoder_loss: 0.0119 - classifier_loss: 0.0973 - decoder_accuracy: 0.0398 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 10.0043 - val_decoder_loss: 23.1776 - val_encoder_loss: 7.6468 - val_classifier_loss: 0.3972 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5628 - decoder_loss: 25.4250 - encoder_loss: 0.0107 - classifier_loss: 0.0962 - decoder_accuracy: 0.0399 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss improved from 10.00427 to 9.91489, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.5628 - decoder_loss: 25.4250 - encoder_loss: 0.0107 - classifier_loss: 0.0962 - decoder_accuracy: 0.0399 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.9149 - val_decoder_loss: 23.1740 - val_encoder_loss: 7.5578 - val_classifier_loss: 0.3971 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5668 - decoder_loss: 25.4207 - encoder_loss: 0.0152 - classifier_loss: 0.0949 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 36: val_loss improved from 9.91489 to 9.87765, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.5668 - decoder_loss: 25.4207 - encoder_loss: 0.0152 - classifier_loss: 0.0949 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.8776 - val_decoder_loss: 23.1704 - val_encoder_loss: 7.5210 - val_classifier_loss: 0.3962 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5613 - decoder_loss: 25.4168 - encoder_loss: 0.0103 - classifier_loss: 0.0937 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 37: val_loss improved from 9.87765 to 9.81598, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.5613 - decoder_loss: 25.4168 - encoder_loss: 0.0103 - classifier_loss: 0.0937 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.8160 - val_decoder_loss: 23.1648 - val_encoder_loss: 7.4599 - val_classifier_loss: 0.3963 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5649 - decoder_loss: 25.4104 - encoder_loss: 0.0146 - classifier_loss: 0.0924 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 38: val_loss improved from 9.81598 to 9.74814, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.5649 - decoder_loss: 25.4104 - encoder_loss: 0.0146 - classifier_loss: 0.0924 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.7481 - val_decoder_loss: 23.1605 - val_encoder_loss: 7.3924 - val_classifier_loss: 0.3970 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5604 - decoder_loss: 25.4045 - encoder_loss: 0.0108 - classifier_loss: 0.0912 - decoder_accuracy: 0.0400 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 39: val_loss improved from 9.74814 to 9.65683, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.5604 - decoder_loss: 25.4045 - encoder_loss: 0.0108 - classifier_loss: 0.0912 - decoder_accuracy: 0.0400 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.6568 - val_decoder_loss: 23.1559 - val_encoder_loss: 7.3015 - val_classifier_loss: 0.3972 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5595 - decoder_loss: 25.3987 - encoder_loss: 0.0107 - classifier_loss: 0.0899 - decoder_accuracy: 0.0401 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 40: val_loss improved from 9.65683 to 9.53728, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.5595 - decoder_loss: 25.3987 - encoder_loss: 0.0107 - classifier_loss: 0.0899 - decoder_accuracy: 0.0401 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.5373 - val_decoder_loss: 23.1520 - val_encoder_loss: 7.1826 - val_classifier_loss: 0.3953 - val_decoder_accuracy: 0.0328 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5664 - decoder_loss: 25.3941 - encoder_loss: 0.0182 - classifier_loss: 0.0885 - decoder_accuracy: 0.0399 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 41: val_loss improved from 9.53728 to 9.38844, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.5664 - decoder_loss: 25.3941 - encoder_loss: 0.0182 - classifier_loss: 0.0885 - decoder_accuracy: 0.0399 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.3884 - val_decoder_loss: 23.1481 - val_encoder_loss: 7.0341 - val_classifier_loss: 0.3953 - val_decoder_accuracy: 0.0327 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5551 - decoder_loss: 25.3903 - encoder_loss: 0.0074 - classifier_loss: 0.0871 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 42: val_loss improved from 9.38844 to 9.28656, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.5551 - decoder_loss: 25.3903 - encoder_loss: 0.0074 - classifier_loss: 0.0871 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.2866 - val_decoder_loss: 23.1438 - val_encoder_loss: 6.9327 - val_classifier_loss: 0.3949 - val_decoder_accuracy: 0.0323 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5611 - decoder_loss: 25.3863 - encoder_loss: 0.0139 - classifier_loss: 0.0860 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 43: val_loss improved from 9.28656 to 9.19131, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.5611 - decoder_loss: 25.3863 - encoder_loss: 0.0139 - classifier_loss: 0.0860 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.1913 - val_decoder_loss: 23.1386 - val_encoder_loss: 6.8380 - val_classifier_loss: 0.3944 - val_decoder_accuracy: 0.0332 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5537 - decoder_loss: 25.3814 - encoder_loss: 0.0070 - classifier_loss: 0.0848 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 44: val_loss improved from 9.19131 to 9.01103, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.5537 - decoder_loss: 25.3814 - encoder_loss: 0.0070 - classifier_loss: 0.0848 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 9.0110 - val_decoder_loss: 23.1339 - val_encoder_loss: 6.6580 - val_classifier_loss: 0.3964 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5542 - decoder_loss: 25.3769 - encoder_loss: 0.0081 - classifier_loss: 0.0840 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 45: val_loss improved from 9.01103 to 8.97704, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 2.5542 - decoder_loss: 25.3769 - encoder_loss: 0.0081 - classifier_loss: 0.0840 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.9770 - val_decoder_loss: 23.1295 - val_encoder_loss: 6.6247 - val_classifier_loss: 0.3942 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5532 - decoder_loss: 25.3714 - encoder_loss: 0.0078 - classifier_loss: 0.0827 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 46: val_loss improved from 8.97704 to 8.89543, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 2.5532 - decoder_loss: 25.3714 - encoder_loss: 0.0078 - classifier_loss: 0.0827 - decoder_accuracy: 0.0403 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.8954 - val_decoder_loss: 23.1247 - val_encoder_loss: 6.5435 - val_classifier_loss: 0.3949 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5517 - decoder_loss: 25.3656 - encoder_loss: 0.0069 - classifier_loss: 0.0817 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 47: val_loss improved from 8.89543 to 8.86129, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.5517 - decoder_loss: 25.3656 - encoder_loss: 0.0069 - classifier_loss: 0.0817 - decoder_accuracy: 0.0404 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.8613 - val_decoder_loss: 23.1210 - val_encoder_loss: 6.5099 - val_classifier_loss: 0.3932 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5494 - decoder_loss: 25.3603 - encoder_loss: 0.0053 - classifier_loss: 0.0808 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 48: val_loss improved from 8.86129 to 8.77184, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.5494 - decoder_loss: 25.3603 - encoder_loss: 0.0053 - classifier_loss: 0.0808 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.7718 - val_decoder_loss: 23.1180 - val_encoder_loss: 6.4208 - val_classifier_loss: 0.3924 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5567 - decoder_loss: 25.3556 - encoder_loss: 0.0132 - classifier_loss: 0.0799 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 49: val_loss improved from 8.77184 to 8.66184, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.5567 - decoder_loss: 25.3556 - encoder_loss: 0.0132 - classifier_loss: 0.0799 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.6618 - val_decoder_loss: 23.1140 - val_encoder_loss: 6.3111 - val_classifier_loss: 0.3933 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5478 - decoder_loss: 25.3502 - encoder_loss: 0.0049 - classifier_loss: 0.0789 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 50: val_loss improved from 8.66184 to 8.62922, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.5478 - decoder_loss: 25.3502 - encoder_loss: 0.0049 - classifier_loss: 0.0789 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.6292 - val_decoder_loss: 23.1094 - val_encoder_loss: 6.2792 - val_classifier_loss: 0.3910 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5473 - decoder_loss: 25.3436 - encoder_loss: 0.0051 - classifier_loss: 0.0779 - decoder_accuracy: 0.0410 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 51: val_loss improved from 8.62922 to 8.55224, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.5473 - decoder_loss: 25.3436 - encoder_loss: 0.0051 - classifier_loss: 0.0779 - decoder_accuracy: 0.0410 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.5522 - val_decoder_loss: 23.1052 - val_encoder_loss: 6.2026 - val_classifier_loss: 0.3916 - val_decoder_accuracy: 0.0325 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5449 - decoder_loss: 25.3371 - encoder_loss: 0.0034 - classifier_loss: 0.0771 - decoder_accuracy: 0.0411 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 52: val_loss improved from 8.55224 to 8.45325, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.5449 - decoder_loss: 25.3371 - encoder_loss: 0.0034 - classifier_loss: 0.0771 - decoder_accuracy: 0.0411 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.4532 - val_decoder_loss: 23.1015 - val_encoder_loss: 6.1040 - val_classifier_loss: 0.3907 - val_decoder_accuracy: 0.0323 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5453 - decoder_loss: 25.3310 - encoder_loss: 0.0045 - classifier_loss: 0.0765 - decoder_accuracy: 0.0415 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 53: val_loss improved from 8.45325 to 8.40348, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.5453 - decoder_loss: 25.3310 - encoder_loss: 0.0045 - classifier_loss: 0.0765 - decoder_accuracy: 0.0415 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.4035 - val_decoder_loss: 23.0972 - val_encoder_loss: 6.0546 - val_classifier_loss: 0.3912 - val_decoder_accuracy: 0.0325 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5440 - decoder_loss: 25.3249 - encoder_loss: 0.0039 - classifier_loss: 0.0756 - decoder_accuracy: 0.0415 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 54: val_loss improved from 8.40348 to 8.31659, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.5440 - decoder_loss: 25.3249 - encoder_loss: 0.0039 - classifier_loss: 0.0756 - decoder_accuracy: 0.0415 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.3166 - val_decoder_loss: 23.0931 - val_encoder_loss: 5.9681 - val_classifier_loss: 0.3914 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5482 - decoder_loss: 25.3190 - encoder_loss: 0.0088 - classifier_loss: 0.0749 - decoder_accuracy: 0.0422 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 55: val_loss improved from 8.31659 to 8.26633, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.5482 - decoder_loss: 25.3190 - encoder_loss: 0.0088 - classifier_loss: 0.0749 - decoder_accuracy: 0.0422 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.2663 - val_decoder_loss: 23.0893 - val_encoder_loss: 5.9184 - val_classifier_loss: 0.3903 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5425 - decoder_loss: 25.3125 - encoder_loss: 0.0038 - classifier_loss: 0.0742 - decoder_accuracy: 0.0424 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 56: val_loss improved from 8.26633 to 8.22471, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.5425 - decoder_loss: 25.3125 - encoder_loss: 0.0038 - classifier_loss: 0.0742 - decoder_accuracy: 0.0424 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.2247 - val_decoder_loss: 23.0858 - val_encoder_loss: 5.8771 - val_classifier_loss: 0.3905 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5428 - decoder_loss: 25.3072 - encoder_loss: 0.0048 - classifier_loss: 0.0734 - decoder_accuracy: 0.0422 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 57: val_loss improved from 8.22471 to 8.20665, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.5428 - decoder_loss: 25.3072 - encoder_loss: 0.0048 - classifier_loss: 0.0734 - decoder_accuracy: 0.0422 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.2066 - val_decoder_loss: 23.0816 - val_encoder_loss: 5.8595 - val_classifier_loss: 0.3896 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5450 - decoder_loss: 25.3006 - encoder_loss: 0.0077 - classifier_loss: 0.0724 - decoder_accuracy: 0.0421 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 58: val_loss improved from 8.20665 to 8.16886, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.5450 - decoder_loss: 25.3006 - encoder_loss: 0.0077 - classifier_loss: 0.0724 - decoder_accuracy: 0.0421 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.1689 - val_decoder_loss: 23.0793 - val_encoder_loss: 5.8220 - val_classifier_loss: 0.3890 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5386 - decoder_loss: 25.2968 - encoder_loss: 0.0018 - classifier_loss: 0.0712 - decoder_accuracy: 0.0423 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 59: val_loss improved from 8.16886 to 8.14018, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.5386 - decoder_loss: 25.2968 - encoder_loss: 0.0018 - classifier_loss: 0.0712 - decoder_accuracy: 0.0423 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.1402 - val_decoder_loss: 23.0755 - val_encoder_loss: 5.7938 - val_classifier_loss: 0.3883 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5367 - decoder_loss: 25.2902 - encoder_loss: 6.2435e-04 - classifier_loss: 0.0705 - decoder_accuracy: 0.0429 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 60: val_loss improved from 8.14018 to 8.10965, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.5367 - decoder_loss: 25.2902 - encoder_loss: 6.2435e-04 - classifier_loss: 0.0705 - decoder_accuracy: 0.0429 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.1096 - val_decoder_loss: 23.0710 - val_encoder_loss: 5.7637 - val_classifier_loss: 0.3881 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5365 - decoder_loss: 25.2826 - encoder_loss: 0.0013 - classifier_loss: 0.0700 - decoder_accuracy: 0.0430 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 61: val_loss improved from 8.10965 to 8.04445, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.5365 - decoder_loss: 25.2826 - encoder_loss: 0.0013 - classifier_loss: 0.0700 - decoder_accuracy: 0.0430 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0444 - val_decoder_loss: 23.0671 - val_encoder_loss: 5.6989 - val_classifier_loss: 0.3885 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5390 - decoder_loss: 25.2756 - encoder_loss: 0.0045 - classifier_loss: 0.0695 - decoder_accuracy: 0.0430 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 62: val_loss improved from 8.04445 to 8.03685, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.5390 - decoder_loss: 25.2756 - encoder_loss: 0.0045 - classifier_loss: 0.0695 - decoder_accuracy: 0.0430 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0369 - val_decoder_loss: 23.0649 - val_encoder_loss: 5.6915 - val_classifier_loss: 0.3883 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5365 - decoder_loss: 25.2695 - encoder_loss: 0.0026 - classifier_loss: 0.0691 - decoder_accuracy: 0.0429 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 63: val_loss improved from 8.03685 to 7.97867, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.5365 - decoder_loss: 25.2695 - encoder_loss: 0.0026 - classifier_loss: 0.0691 - decoder_accuracy: 0.0429 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9787 - val_decoder_loss: 23.0607 - val_encoder_loss: 5.6336 - val_classifier_loss: 0.3900 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5343 - decoder_loss: 25.2615 - encoder_loss: 0.0013 - classifier_loss: 0.0683 - decoder_accuracy: 0.0431 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 7.97867\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5343 - decoder_loss: 25.2615 - encoder_loss: 0.0013 - classifier_loss: 0.0683 - decoder_accuracy: 0.0431 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9802 - val_decoder_loss: 23.0567 - val_encoder_loss: 5.6356 - val_classifier_loss: 0.3896 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5334 - decoder_loss: 25.2536 - encoder_loss: 0.0013 - classifier_loss: 0.0677 - decoder_accuracy: 0.0431 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 65: val_loss improved from 7.97867 to 7.96068, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.5334 - decoder_loss: 25.2536 - encoder_loss: 0.0013 - classifier_loss: 0.0677 - decoder_accuracy: 0.0431 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9607 - val_decoder_loss: 23.0525 - val_encoder_loss: 5.6164 - val_classifier_loss: 0.3899 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5326 - decoder_loss: 25.2458 - encoder_loss: 0.0013 - classifier_loss: 0.0672 - decoder_accuracy: 0.0435 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 66: val_loss improved from 7.96068 to 7.95269, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.5326 - decoder_loss: 25.2458 - encoder_loss: 0.0013 - classifier_loss: 0.0672 - decoder_accuracy: 0.0435 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9527 - val_decoder_loss: 23.0486 - val_encoder_loss: 5.6089 - val_classifier_loss: 0.3896 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5329 - decoder_loss: 25.2380 - encoder_loss: 0.0024 - classifier_loss: 0.0666 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 67: val_loss improved from 7.95269 to 7.94612, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.5329 - decoder_loss: 25.2380 - encoder_loss: 0.0024 - classifier_loss: 0.0666 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9461 - val_decoder_loss: 23.0444 - val_encoder_loss: 5.6027 - val_classifier_loss: 0.3894 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5298 - decoder_loss: 25.2300 - encoder_loss: 2.4141e-04 - classifier_loss: 0.0659 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 68: val_loss improved from 7.94612 to 7.94281, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.5298 - decoder_loss: 25.2300 - encoder_loss: 2.4141e-04 - classifier_loss: 0.0659 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9428 - val_decoder_loss: 23.0404 - val_encoder_loss: 5.5998 - val_classifier_loss: 0.3896 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5300 - decoder_loss: 25.2223 - encoder_loss: 0.0012 - classifier_loss: 0.0655 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 69: val_loss improved from 7.94281 to 7.93413, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.5300 - decoder_loss: 25.2223 - encoder_loss: 0.0012 - classifier_loss: 0.0655 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9341 - val_decoder_loss: 23.0371 - val_encoder_loss: 5.5915 - val_classifier_loss: 0.3893 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5294 - decoder_loss: 25.2154 - encoder_loss: 0.0013 - classifier_loss: 0.0650 - decoder_accuracy: 0.0438 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 70: val_loss improved from 7.93413 to 7.92803, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.5294 - decoder_loss: 25.2154 - encoder_loss: 0.0013 - classifier_loss: 0.0650 - decoder_accuracy: 0.0438 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9280 - val_decoder_loss: 23.0341 - val_encoder_loss: 5.5857 - val_classifier_loss: 0.3890 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5274 - decoder_loss: 25.2090 - encoder_loss: 3.9633e-05 - classifier_loss: 0.0646 - decoder_accuracy: 0.0440 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 71: val_loss improved from 7.92803 to 7.92312, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.5274 - decoder_loss: 25.2090 - encoder_loss: 3.9633e-05 - classifier_loss: 0.0646 - decoder_accuracy: 0.0440 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9231 - val_decoder_loss: 23.0306 - val_encoder_loss: 5.5812 - val_classifier_loss: 0.3888 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5266 - decoder_loss: 25.2021 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0643 - decoder_accuracy: 0.0439 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 72: val_loss improved from 7.92312 to 7.91900, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.5266 - decoder_loss: 25.2021 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0643 - decoder_accuracy: 0.0439 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9190 - val_decoder_loss: 23.0268 - val_encoder_loss: 5.5775 - val_classifier_loss: 0.3886 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5283 - decoder_loss: 25.1947 - encoder_loss: 0.0024 - classifier_loss: 0.0638 - decoder_accuracy: 0.0443 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 73: val_loss improved from 7.91900 to 7.90156, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.5283 - decoder_loss: 25.1947 - encoder_loss: 0.0024 - classifier_loss: 0.0638 - decoder_accuracy: 0.0443 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9016 - val_decoder_loss: 23.0229 - val_encoder_loss: 5.5604 - val_classifier_loss: 0.3886 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5268 - decoder_loss: 25.1877 - encoder_loss: 0.0017 - classifier_loss: 0.0635 - decoder_accuracy: 0.0446 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 74: val_loss improved from 7.90156 to 7.89433, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.5268 - decoder_loss: 25.1877 - encoder_loss: 0.0017 - classifier_loss: 0.0635 - decoder_accuracy: 0.0446 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8943 - val_decoder_loss: 23.0188 - val_encoder_loss: 5.5536 - val_classifier_loss: 0.3882 - val_decoder_accuracy: 0.0305 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5250 - decoder_loss: 25.1803 - encoder_loss: 6.8422e-04 - classifier_loss: 0.0630 - decoder_accuracy: 0.0445 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 75: val_loss improved from 7.89433 to 7.85877, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.5250 - decoder_loss: 25.1803 - encoder_loss: 6.8422e-04 - classifier_loss: 0.0630 - decoder_accuracy: 0.0445 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8588 - val_decoder_loss: 23.0149 - val_encoder_loss: 5.5185 - val_classifier_loss: 0.3879 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5248 - decoder_loss: 25.1728 - encoder_loss: 0.0012 - classifier_loss: 0.0626 - decoder_accuracy: 0.0444 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 76: val_loss improved from 7.85877 to 7.84210, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.5248 - decoder_loss: 25.1728 - encoder_loss: 0.0012 - classifier_loss: 0.0626 - decoder_accuracy: 0.0444 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8421 - val_decoder_loss: 23.0107 - val_encoder_loss: 5.5022 - val_classifier_loss: 0.3878 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5231 - decoder_loss: 25.1655 - encoder_loss: 3.7072e-04 - classifier_loss: 0.0623 - decoder_accuracy: 0.0444 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 77: val_loss improved from 7.84210 to 7.83852, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.5231 - decoder_loss: 25.1655 - encoder_loss: 3.7072e-04 - classifier_loss: 0.0623 - decoder_accuracy: 0.0444 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8385 - val_decoder_loss: 23.0067 - val_encoder_loss: 5.4992 - val_classifier_loss: 0.3869 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5220 - decoder_loss: 25.1585 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0618 - decoder_accuracy: 0.0448 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 78: val_loss improved from 7.83852 to 7.83197, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.5220 - decoder_loss: 25.1585 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0618 - decoder_accuracy: 0.0448 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8320 - val_decoder_loss: 23.0026 - val_encoder_loss: 5.4930 - val_classifier_loss: 0.3866 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5213 - decoder_loss: 25.1513 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0614 - decoder_accuracy: 0.0450 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 79: val_loss improved from 7.83197 to 7.82756, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.5213 - decoder_loss: 25.1513 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0614 - decoder_accuracy: 0.0450 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8276 - val_decoder_loss: 22.9985 - val_encoder_loss: 5.4891 - val_classifier_loss: 0.3863 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5217 - decoder_loss: 25.1441 - encoder_loss: 0.0012 - classifier_loss: 0.0611 - decoder_accuracy: 0.0452 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 80: val_loss improved from 7.82756 to 7.82613, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.5217 - decoder_loss: 25.1441 - encoder_loss: 0.0012 - classifier_loss: 0.0611 - decoder_accuracy: 0.0452 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8261 - val_decoder_loss: 22.9941 - val_encoder_loss: 5.4881 - val_classifier_loss: 0.3859 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5215 - decoder_loss: 25.1369 - encoder_loss: 0.0017 - classifier_loss: 0.0607 - decoder_accuracy: 0.0454 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 81: val_loss improved from 7.82613 to 7.81041, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.5215 - decoder_loss: 25.1369 - encoder_loss: 0.0017 - classifier_loss: 0.0607 - decoder_accuracy: 0.0454 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8104 - val_decoder_loss: 22.9899 - val_encoder_loss: 5.4729 - val_classifier_loss: 0.3853 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5194 - decoder_loss: 25.1299 - encoder_loss: 3.9868e-04 - classifier_loss: 0.0603 - decoder_accuracy: 0.0455 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 82: val_loss improved from 7.81041 to 7.79365, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.5194 - decoder_loss: 25.1299 - encoder_loss: 3.9868e-04 - classifier_loss: 0.0603 - decoder_accuracy: 0.0455 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7937 - val_decoder_loss: 22.9858 - val_encoder_loss: 5.4566 - val_classifier_loss: 0.3849 - val_decoder_accuracy: 0.0305 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5183 - decoder_loss: 25.1228 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0599 - decoder_accuracy: 0.0455 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 83: val_loss improved from 7.79365 to 7.79201, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.5183 - decoder_loss: 25.1228 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0599 - decoder_accuracy: 0.0455 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7920 - val_decoder_loss: 22.9814 - val_encoder_loss: 5.4554 - val_classifier_loss: 0.3847 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5175 - decoder_loss: 25.1158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0596 - decoder_accuracy: 0.0457 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 84: val_loss improved from 7.79201 to 7.78959, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 2.5175 - decoder_loss: 25.1158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0596 - decoder_accuracy: 0.0457 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7896 - val_decoder_loss: 22.9770 - val_encoder_loss: 5.4535 - val_classifier_loss: 0.3844 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5168 - decoder_loss: 25.1087 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0593 - decoder_accuracy: 0.0461 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 85: val_loss improved from 7.78959 to 7.78763, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.5168 - decoder_loss: 25.1087 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0593 - decoder_accuracy: 0.0461 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7876 - val_decoder_loss: 22.9725 - val_encoder_loss: 5.4520 - val_classifier_loss: 0.3840 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5161 - decoder_loss: 25.1017 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0590 - decoder_accuracy: 0.0463 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 86: val_loss improved from 7.78763 to 7.78621, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.5161 - decoder_loss: 25.1017 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0590 - decoder_accuracy: 0.0463 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7862 - val_decoder_loss: 22.9680 - val_encoder_loss: 5.4510 - val_classifier_loss: 0.3837 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5153 - decoder_loss: 25.0946 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0586 - decoder_accuracy: 0.0463 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 87: val_loss improved from 7.78621 to 7.75932, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.5153 - decoder_loss: 25.0946 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0586 - decoder_accuracy: 0.0463 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7593 - val_decoder_loss: 22.9634 - val_encoder_loss: 5.4246 - val_classifier_loss: 0.3834 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5146 - decoder_loss: 25.0876 - encoder_loss: 5.8726e-06 - classifier_loss: 0.0583 - decoder_accuracy: 0.0469 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 7.75932\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5146 - decoder_loss: 25.0876 - encoder_loss: 5.8726e-06 - classifier_loss: 0.0583 - decoder_accuracy: 0.0469 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7856 - val_decoder_loss: 22.9594 - val_encoder_loss: 5.4515 - val_classifier_loss: 0.3821 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5139 - decoder_loss: 25.0810 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0580 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 7.75932\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5139 - decoder_loss: 25.0810 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0580 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7838 - val_decoder_loss: 22.9547 - val_encoder_loss: 5.4501 - val_classifier_loss: 0.3818 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5132 - decoder_loss: 25.0740 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0577 - decoder_accuracy: 0.0472 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 7.75932\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5132 - decoder_loss: 25.0740 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0577 - decoder_accuracy: 0.0472 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7839 - val_decoder_loss: 22.9500 - val_encoder_loss: 5.4507 - val_classifier_loss: 0.3814 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5124 - decoder_loss: 25.0671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0574 - decoder_accuracy: 0.0474 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 7.75932\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5124 - decoder_loss: 25.0671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0574 - decoder_accuracy: 0.0474 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7844 - val_decoder_loss: 22.9453 - val_encoder_loss: 5.4518 - val_classifier_loss: 0.3811 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5130 - decoder_loss: 25.0602 - encoder_loss: 0.0013 - classifier_loss: 0.0571 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 7.75932\n",
            "\n",
            "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.5130 - decoder_loss: 25.0602 - encoder_loss: 0.0013 - classifier_loss: 0.0571 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7669 - val_decoder_loss: 22.9406 - val_encoder_loss: 5.4348 - val_classifier_loss: 0.3807 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 3.1250e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5126 - decoder_loss: 25.0534 - encoder_loss: 0.0016 - classifier_loss: 0.0567 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 93: val_loss improved from 7.75932 to 7.74879, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.5126 - decoder_loss: 25.0534 - encoder_loss: 0.0016 - classifier_loss: 0.0567 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7488 - val_decoder_loss: 22.9387 - val_encoder_loss: 5.4169 - val_classifier_loss: 0.3805 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5111 - decoder_loss: 25.0504 - encoder_loss: 4.0030e-04 - classifier_loss: 0.0565 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 94: val_loss improved from 7.74879 to 7.73979, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.5111 - decoder_loss: 25.0504 - encoder_loss: 4.0030e-04 - classifier_loss: 0.0565 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7398 - val_decoder_loss: 22.9366 - val_encoder_loss: 5.4081 - val_classifier_loss: 0.3803 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5104 - decoder_loss: 25.0474 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0564 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 7.73979\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5104 - decoder_loss: 25.0474 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0564 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7400 - val_decoder_loss: 22.9341 - val_encoder_loss: 5.4086 - val_classifier_loss: 0.3802 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5100 - decoder_loss: 25.0440 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0562 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 96: val_loss improved from 7.73979 to 7.73917, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.5100 - decoder_loss: 25.0440 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0562 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7392 - val_decoder_loss: 22.9316 - val_encoder_loss: 5.4080 - val_classifier_loss: 0.3801 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5097 - decoder_loss: 25.0405 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0561 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 97: val_loss improved from 7.73917 to 7.73852, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.5097 - decoder_loss: 25.0405 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0561 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7385 - val_decoder_loss: 22.9292 - val_encoder_loss: 5.4076 - val_classifier_loss: 0.3799 - val_decoder_accuracy: 0.0305 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5093 - decoder_loss: 25.0371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0559 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 98: val_loss improved from 7.73852 to 7.73811, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.5093 - decoder_loss: 25.0371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0559 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7381 - val_decoder_loss: 22.9267 - val_encoder_loss: 5.4075 - val_classifier_loss: 0.3797 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5089 - decoder_loss: 25.0337 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0558 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 99: val_loss improved from 7.73811 to 7.73794, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.5089 - decoder_loss: 25.0337 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0558 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7379 - val_decoder_loss: 22.9241 - val_encoder_loss: 5.4076 - val_classifier_loss: 0.3796 - val_decoder_accuracy: 0.0305 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5086 - decoder_loss: 25.0302 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0556 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5086 - decoder_loss: 25.0302 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0556 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7380 - val_decoder_loss: 22.9216 - val_encoder_loss: 5.4079 - val_classifier_loss: 0.3794 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5082 - decoder_loss: 25.0268 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0555 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5082 - decoder_loss: 25.0268 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0555 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7382 - val_decoder_loss: 22.9190 - val_encoder_loss: 5.4084 - val_classifier_loss: 0.3793 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5079 - decoder_loss: 25.0233 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0554 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5079 - decoder_loss: 25.0233 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0554 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7386 - val_decoder_loss: 22.9164 - val_encoder_loss: 5.4091 - val_classifier_loss: 0.3791 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5075 - decoder_loss: 25.0198 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0552 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5075 - decoder_loss: 25.0198 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0552 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7392 - val_decoder_loss: 22.9137 - val_encoder_loss: 5.4100 - val_classifier_loss: 0.3790 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5071 - decoder_loss: 25.0163 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0551 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 7.73794\n",
            "\n",
            "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5071 - decoder_loss: 25.0163 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0551 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7400 - val_decoder_loss: 22.9111 - val_encoder_loss: 5.4110 - val_classifier_loss: 0.3788 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.5625e-04\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5068 - decoder_loss: 25.0129 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0550 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5068 - decoder_loss: 25.0129 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0550 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7406 - val_decoder_loss: 22.9094 - val_encoder_loss: 5.4118 - val_classifier_loss: 0.3787 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5065 - decoder_loss: 25.0106 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0549 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5065 - decoder_loss: 25.0106 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0549 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7412 - val_decoder_loss: 22.9077 - val_encoder_loss: 5.4126 - val_classifier_loss: 0.3786 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5063 - decoder_loss: 25.0084 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0548 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5063 - decoder_loss: 25.0084 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0548 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7419 - val_decoder_loss: 22.9059 - val_encoder_loss: 5.4135 - val_classifier_loss: 0.3785 - val_decoder_accuracy: 0.0297 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5061 - decoder_loss: 25.0061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0547 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5061 - decoder_loss: 25.0061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0547 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7427 - val_decoder_loss: 22.9042 - val_encoder_loss: 5.4145 - val_classifier_loss: 0.3784 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5059 - decoder_loss: 25.0039 - encoder_loss: 5.9037e-05 - classifier_loss: 0.0546 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 109: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5059 - decoder_loss: 25.0039 - encoder_loss: 5.9037e-05 - classifier_loss: 0.0546 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7404 - val_decoder_loss: 22.9026 - val_encoder_loss: 5.4124 - val_classifier_loss: 0.3780 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5057 - decoder_loss: 25.0020 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0545 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5057 - decoder_loss: 25.0020 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0545 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7413 - val_decoder_loss: 22.9008 - val_encoder_loss: 5.4135 - val_classifier_loss: 0.3779 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5054 - decoder_loss: 24.9998 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0544 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5054 - decoder_loss: 24.9998 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0544 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7421 - val_decoder_loss: 22.8991 - val_encoder_loss: 5.4144 - val_classifier_loss: 0.3778 - val_decoder_accuracy: 0.0297 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5052 - decoder_loss: 24.9976 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0543 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5052 - decoder_loss: 24.9976 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0543 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7430 - val_decoder_loss: 22.8973 - val_encoder_loss: 5.4155 - val_classifier_loss: 0.3777 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5050 - decoder_loss: 24.9953 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0543 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5050 - decoder_loss: 24.9953 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0543 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7439 - val_decoder_loss: 22.8955 - val_encoder_loss: 5.4165 - val_classifier_loss: 0.3776 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5047 - decoder_loss: 24.9931 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0542 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5047 - decoder_loss: 24.9931 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0542 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7448 - val_decoder_loss: 22.8937 - val_encoder_loss: 5.4177 - val_classifier_loss: 0.3774 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5045 - decoder_loss: 24.9908 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0541 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5045 - decoder_loss: 24.9908 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0541 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7458 - val_decoder_loss: 22.8919 - val_encoder_loss: 5.4189 - val_classifier_loss: 0.3773 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5043 - decoder_loss: 24.9886 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0540 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5043 - decoder_loss: 24.9886 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0540 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7469 - val_decoder_loss: 22.8901 - val_encoder_loss: 5.4201 - val_classifier_loss: 0.3772 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5040 - decoder_loss: 24.9863 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0539 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5040 - decoder_loss: 24.9863 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0539 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7479 - val_decoder_loss: 22.8883 - val_encoder_loss: 5.4214 - val_classifier_loss: 0.3771 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5038 - decoder_loss: 24.9840 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0538 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5038 - decoder_loss: 24.9840 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0538 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7491 - val_decoder_loss: 22.8865 - val_encoder_loss: 5.4227 - val_classifier_loss: 0.3770 - val_decoder_accuracy: 0.0293 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5036 - decoder_loss: 24.9817 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0538 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5036 - decoder_loss: 24.9817 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0538 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7502 - val_decoder_loss: 22.8847 - val_encoder_loss: 5.4241 - val_classifier_loss: 0.3769 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5033 - decoder_loss: 24.9795 - encoder_loss: 3.5667e-05 - classifier_loss: 0.0537 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5033 - decoder_loss: 24.9795 - encoder_loss: 3.5667e-05 - classifier_loss: 0.0537 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7482 - val_decoder_loss: 22.8830 - val_encoder_loss: 5.4222 - val_classifier_loss: 0.3765 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5031 - decoder_loss: 24.9776 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0536 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 121: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5031 - decoder_loss: 24.9776 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0536 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7494 - val_decoder_loss: 22.8811 - val_encoder_loss: 5.4237 - val_classifier_loss: 0.3764 - val_decoder_accuracy: 0.0293 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5029 - decoder_loss: 24.9753 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0535 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5029 - decoder_loss: 24.9753 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0535 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7505 - val_decoder_loss: 22.8793 - val_encoder_loss: 5.4250 - val_classifier_loss: 0.3763 - val_decoder_accuracy: 0.0292 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5026 - decoder_loss: 24.9731 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0534 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5026 - decoder_loss: 24.9731 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0534 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7517 - val_decoder_loss: 22.8774 - val_encoder_loss: 5.4263 - val_classifier_loss: 0.3761 - val_decoder_accuracy: 0.0293 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5024 - decoder_loss: 24.9708 - encoder_loss: 1.6112e-05 - classifier_loss: 0.0533 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5024 - decoder_loss: 24.9708 - encoder_loss: 1.6112e-05 - classifier_loss: 0.0533 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7782 - val_decoder_loss: 22.8757 - val_encoder_loss: 5.4531 - val_classifier_loss: 0.3760 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5022 - decoder_loss: 24.9687 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0533 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5022 - decoder_loss: 24.9687 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0533 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7794 - val_decoder_loss: 22.8738 - val_encoder_loss: 5.4544 - val_classifier_loss: 0.3759 - val_decoder_accuracy: 0.0292 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5020 - decoder_loss: 24.9664 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0532 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5020 - decoder_loss: 24.9664 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0532 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7805 - val_decoder_loss: 22.8719 - val_encoder_loss: 5.4557 - val_classifier_loss: 0.3758 - val_decoder_accuracy: 0.0290 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5017 - decoder_loss: 24.9641 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0531 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5017 - decoder_loss: 24.9641 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0531 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7816 - val_decoder_loss: 22.8700 - val_encoder_loss: 5.4571 - val_classifier_loss: 0.3757 - val_decoder_accuracy: 0.0290 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5015 - decoder_loss: 24.9618 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0530 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5015 - decoder_loss: 24.9618 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0530 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7828 - val_decoder_loss: 22.8681 - val_encoder_loss: 5.4584 - val_classifier_loss: 0.3756 - val_decoder_accuracy: 0.0287 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5012 - decoder_loss: 24.9595 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0529 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5012 - decoder_loss: 24.9595 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0529 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7585 - val_decoder_loss: 22.8662 - val_encoder_loss: 5.4344 - val_classifier_loss: 0.3755 - val_decoder_accuracy: 0.0283 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5010 - decoder_loss: 24.9572 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0529 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5010 - decoder_loss: 24.9572 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0529 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7589 - val_decoder_loss: 22.8642 - val_encoder_loss: 5.4349 - val_classifier_loss: 0.3754 - val_decoder_accuracy: 0.0283 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5008 - decoder_loss: 24.9549 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0528 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5008 - decoder_loss: 24.9549 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0528 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7592 - val_decoder_loss: 22.8623 - val_encoder_loss: 5.4354 - val_classifier_loss: 0.3753 - val_decoder_accuracy: 0.0283 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5005 - decoder_loss: 24.9526 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0527 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5005 - decoder_loss: 24.9526 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0527 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7595 - val_decoder_loss: 22.8604 - val_encoder_loss: 5.4360 - val_classifier_loss: 0.3752 - val_decoder_accuracy: 0.0287 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5003 - decoder_loss: 24.9502 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0526 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5003 - decoder_loss: 24.9502 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0526 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7599 - val_decoder_loss: 22.8584 - val_encoder_loss: 5.4365 - val_classifier_loss: 0.3751 - val_decoder_accuracy: 0.0288 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5001 - decoder_loss: 24.9479 - encoder_loss: 4.9737e-05 - classifier_loss: 0.0525 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5001 - decoder_loss: 24.9479 - encoder_loss: 4.9737e-05 - classifier_loss: 0.0525 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7559 - val_decoder_loss: 22.8570 - val_encoder_loss: 5.4327 - val_classifier_loss: 0.3746 - val_decoder_accuracy: 0.0290 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4999 - decoder_loss: 24.9463 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0524 - decoder_accuracy: 0.0499 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4999 - decoder_loss: 24.9463 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0524 - decoder_accuracy: 0.0499 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7573 - val_decoder_loss: 22.8550 - val_encoder_loss: 5.4343 - val_classifier_loss: 0.3745 - val_decoder_accuracy: 0.0290 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4996 - decoder_loss: 24.9440 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0523 - decoder_accuracy: 0.0500 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4996 - decoder_loss: 24.9440 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0523 - decoder_accuracy: 0.0500 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7576 - val_decoder_loss: 22.8531 - val_encoder_loss: 5.4348 - val_classifier_loss: 0.3744 - val_decoder_accuracy: 0.0292 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4994 - decoder_loss: 24.9417 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0523 - decoder_accuracy: 0.0501 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4994 - decoder_loss: 24.9417 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0523 - decoder_accuracy: 0.0501 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7578 - val_decoder_loss: 22.8511 - val_encoder_loss: 5.4353 - val_classifier_loss: 0.3743 - val_decoder_accuracy: 0.0292 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4992 - decoder_loss: 24.9394 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0522 - decoder_accuracy: 0.0502 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4992 - decoder_loss: 24.9394 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0522 - decoder_accuracy: 0.0502 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7581 - val_decoder_loss: 22.8491 - val_encoder_loss: 5.4357 - val_classifier_loss: 0.3742 - val_decoder_accuracy: 0.0292 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4989 - decoder_loss: 24.9371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0521 - decoder_accuracy: 0.0502 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4989 - decoder_loss: 24.9371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0521 - decoder_accuracy: 0.0502 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7583 - val_decoder_loss: 22.8471 - val_encoder_loss: 5.4362 - val_classifier_loss: 0.3740 - val_decoder_accuracy: 0.0292 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4987 - decoder_loss: 24.9348 - encoder_loss: 4.1510e-06 - classifier_loss: 0.0520 - decoder_accuracy: 0.0503 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4987 - decoder_loss: 24.9348 - encoder_loss: 4.1510e-06 - classifier_loss: 0.0520 - decoder_accuracy: 0.0503 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7570 - val_decoder_loss: 22.8453 - val_encoder_loss: 5.4350 - val_classifier_loss: 0.3739 - val_decoder_accuracy: 0.0293 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4985 - decoder_loss: 24.9326 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0520 - decoder_accuracy: 0.0505 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 141: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4985 - decoder_loss: 24.9326 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0520 - decoder_accuracy: 0.0505 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7573 - val_decoder_loss: 22.8433 - val_encoder_loss: 5.4355 - val_classifier_loss: 0.3738 - val_decoder_accuracy: 0.0293 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4982 - decoder_loss: 24.9303 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0519 - decoder_accuracy: 0.0506 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4982 - decoder_loss: 24.9303 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0519 - decoder_accuracy: 0.0506 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7575 - val_decoder_loss: 22.8413 - val_encoder_loss: 5.4360 - val_classifier_loss: 0.3737 - val_decoder_accuracy: 0.0292 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4980 - decoder_loss: 24.9279 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0518 - decoder_accuracy: 0.0507 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4980 - decoder_loss: 24.9279 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0518 - decoder_accuracy: 0.0507 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7577 - val_decoder_loss: 22.8392 - val_encoder_loss: 5.4364 - val_classifier_loss: 0.3736 - val_decoder_accuracy: 0.0293 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4977 - decoder_loss: 24.9256 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0517 - decoder_accuracy: 0.0509 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4977 - decoder_loss: 24.9256 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0517 - decoder_accuracy: 0.0509 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7580 - val_decoder_loss: 22.8372 - val_encoder_loss: 5.4369 - val_classifier_loss: 0.3735 - val_decoder_accuracy: 0.0290 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4975 - decoder_loss: 24.9232 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0517 - decoder_accuracy: 0.0511 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4975 - decoder_loss: 24.9232 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0517 - decoder_accuracy: 0.0511 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7582 - val_decoder_loss: 22.8352 - val_encoder_loss: 5.4374 - val_classifier_loss: 0.3734 - val_decoder_accuracy: 0.0292 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4972 - decoder_loss: 24.9209 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0516 - decoder_accuracy: 0.0511 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 7.73794\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4972 - decoder_loss: 24.9209 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0516 - decoder_accuracy: 0.0511 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7585 - val_decoder_loss: 22.8331 - val_encoder_loss: 5.4379 - val_classifier_loss: 0.3733 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4970 - decoder_loss: 24.9185 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0515 - decoder_accuracy: 0.0513 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 147: val_loss improved from 7.73794 to 7.73379, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.4970 - decoder_loss: 24.9185 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0515 - decoder_accuracy: 0.0513 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7338 - val_decoder_loss: 22.8310 - val_encoder_loss: 5.4134 - val_classifier_loss: 0.3732 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4968 - decoder_loss: 24.9161 - encoder_loss: 5.6166e-06 - classifier_loss: 0.0514 - decoder_accuracy: 0.0514 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4968 - decoder_loss: 24.9161 - encoder_loss: 5.6166e-06 - classifier_loss: 0.0514 - decoder_accuracy: 0.0514 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7636 - val_decoder_loss: 22.8292 - val_encoder_loss: 5.4434 - val_classifier_loss: 0.3731 - val_decoder_accuracy: 0.0297 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4965 - decoder_loss: 24.9140 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0513 - decoder_accuracy: 0.0514 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4965 - decoder_loss: 24.9140 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0513 - decoder_accuracy: 0.0514 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7641 - val_decoder_loss: 22.8272 - val_encoder_loss: 5.4441 - val_classifier_loss: 0.3731 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4963 - decoder_loss: 24.9117 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0512 - decoder_accuracy: 0.0514 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4963 - decoder_loss: 24.9117 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0512 - decoder_accuracy: 0.0514 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7396 - val_decoder_loss: 22.8251 - val_encoder_loss: 5.4198 - val_classifier_loss: 0.3730 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4961 - decoder_loss: 24.9093 - encoder_loss: 5.5358e-05 - classifier_loss: 0.0512 - decoder_accuracy: 0.0515 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4961 - decoder_loss: 24.9093 - encoder_loss: 5.5358e-05 - classifier_loss: 0.0512 - decoder_accuracy: 0.0515 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7353 - val_decoder_loss: 22.8236 - val_encoder_loss: 5.4157 - val_classifier_loss: 0.3724 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4959 - decoder_loss: 24.9077 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0510 - decoder_accuracy: 0.0516 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4959 - decoder_loss: 24.9077 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0510 - decoder_accuracy: 0.0516 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7368 - val_decoder_loss: 22.8215 - val_encoder_loss: 5.4174 - val_classifier_loss: 0.3724 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4956 - decoder_loss: 24.9054 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0510 - decoder_accuracy: 0.0518 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4956 - decoder_loss: 24.9054 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0510 - decoder_accuracy: 0.0518 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7370 - val_decoder_loss: 22.8194 - val_encoder_loss: 5.4179 - val_classifier_loss: 0.3723 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4954 - decoder_loss: 24.9031 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0509 - decoder_accuracy: 0.0518 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4954 - decoder_loss: 24.9031 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0509 - decoder_accuracy: 0.0518 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7372 - val_decoder_loss: 22.8173 - val_encoder_loss: 5.4183 - val_classifier_loss: 0.3721 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4952 - decoder_loss: 24.9007 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0508 - decoder_accuracy: 0.0518 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4952 - decoder_loss: 24.9007 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0508 - decoder_accuracy: 0.0518 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7373 - val_decoder_loss: 22.8152 - val_encoder_loss: 5.4186 - val_classifier_loss: 0.3720 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4949 - decoder_loss: 24.8983 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0507 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4949 - decoder_loss: 24.8983 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0507 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7375 - val_decoder_loss: 22.8130 - val_encoder_loss: 5.4190 - val_classifier_loss: 0.3719 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4947 - decoder_loss: 24.8959 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0507 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4947 - decoder_loss: 24.8959 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0507 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7376 - val_decoder_loss: 22.8109 - val_encoder_loss: 5.4194 - val_classifier_loss: 0.3718 - val_decoder_accuracy: 0.0297 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4944 - decoder_loss: 24.8936 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0506 - decoder_accuracy: 0.0516 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4944 - decoder_loss: 24.8936 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0506 - decoder_accuracy: 0.0516 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7378 - val_decoder_loss: 22.8088 - val_encoder_loss: 5.4197 - val_classifier_loss: 0.3717 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4942 - decoder_loss: 24.8912 - encoder_loss: 4.1962e-06 - classifier_loss: 0.0505 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4942 - decoder_loss: 24.8912 - encoder_loss: 4.1962e-06 - classifier_loss: 0.0505 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7365 - val_decoder_loss: 22.8068 - val_encoder_loss: 5.4187 - val_classifier_loss: 0.3716 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4939 - decoder_loss: 24.8890 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0504 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4939 - decoder_loss: 24.8890 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0504 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7367 - val_decoder_loss: 22.8046 - val_encoder_loss: 5.4191 - val_classifier_loss: 0.3715 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4937 - decoder_loss: 24.8866 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0504 - decoder_accuracy: 0.0518 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 7.73379\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4937 - decoder_loss: 24.8866 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0504 - decoder_accuracy: 0.0518 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7368 - val_decoder_loss: 22.8024 - val_encoder_loss: 5.4194 - val_classifier_loss: 0.3714 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4947 - decoder_loss: 24.8841 - encoder_loss: 0.0013 - classifier_loss: 0.0503 - decoder_accuracy: 0.0520 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 162: val_loss improved from 7.73379 to 7.73282, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.4947 - decoder_loss: 24.8841 - encoder_loss: 0.0013 - classifier_loss: 0.0503 - decoder_accuracy: 0.0520 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7328 - val_decoder_loss: 22.8000 - val_encoder_loss: 5.4157 - val_classifier_loss: 0.3715 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4941 - decoder_loss: 24.8817 - encoder_loss: 8.7574e-04 - classifier_loss: 0.0502 - decoder_accuracy: 0.0521 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 163: val_loss improved from 7.73282 to 7.72893, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.4941 - decoder_loss: 24.8817 - encoder_loss: 8.7574e-04 - classifier_loss: 0.0502 - decoder_accuracy: 0.0521 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7289 - val_decoder_loss: 22.7976 - val_encoder_loss: 5.4120 - val_classifier_loss: 0.3715 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4934 - decoder_loss: 24.8792 - encoder_loss: 4.1815e-04 - classifier_loss: 0.0502 - decoder_accuracy: 0.0522 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 164: val_loss improved from 7.72893 to 7.72488, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.4934 - decoder_loss: 24.8792 - encoder_loss: 4.1815e-04 - classifier_loss: 0.0502 - decoder_accuracy: 0.0522 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7249 - val_decoder_loss: 22.7952 - val_encoder_loss: 5.4082 - val_classifier_loss: 0.3715 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4927 - decoder_loss: 24.8767 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0501 - decoder_accuracy: 0.0522 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 165: val_loss improved from 7.72488 to 7.72462, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.4927 - decoder_loss: 24.8767 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0501 - decoder_accuracy: 0.0522 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7246 - val_decoder_loss: 22.7930 - val_encoder_loss: 5.4082 - val_classifier_loss: 0.3714 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4925 - decoder_loss: 24.8742 - encoder_loss: 6.2631e-05 - classifier_loss: 0.0500 - decoder_accuracy: 0.0524 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 166: val_loss improved from 7.72462 to 7.71930, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.4925 - decoder_loss: 24.8742 - encoder_loss: 6.2631e-05 - classifier_loss: 0.0500 - decoder_accuracy: 0.0524 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7193 - val_decoder_loss: 22.7913 - val_encoder_loss: 5.4031 - val_classifier_loss: 0.3709 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4924 - decoder_loss: 24.8726 - encoder_loss: 1.2736e-04 - classifier_loss: 0.0499 - decoder_accuracy: 0.0525 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4924 - decoder_loss: 24.8726 - encoder_loss: 1.2736e-04 - classifier_loss: 0.0499 - decoder_accuracy: 0.0525 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7255 - val_decoder_loss: 22.7894 - val_encoder_loss: 5.4095 - val_classifier_loss: 0.3709 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4920 - decoder_loss: 24.8705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0498 - decoder_accuracy: 0.0525 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4920 - decoder_loss: 24.8705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0498 - decoder_accuracy: 0.0525 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7252 - val_decoder_loss: 22.7871 - val_encoder_loss: 5.4094 - val_classifier_loss: 0.3708 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4918 - decoder_loss: 24.8681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0497 - decoder_accuracy: 0.0526 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4918 - decoder_loss: 24.8681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0497 - decoder_accuracy: 0.0526 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7250 - val_decoder_loss: 22.7849 - val_encoder_loss: 5.4095 - val_classifier_loss: 0.3707 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4915 - decoder_loss: 24.8657 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0496 - decoder_accuracy: 0.0528 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4915 - decoder_loss: 24.8657 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0496 - decoder_accuracy: 0.0528 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7250 - val_decoder_loss: 22.7826 - val_encoder_loss: 5.4097 - val_classifier_loss: 0.3706 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4913 - decoder_loss: 24.8633 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0496 - decoder_accuracy: 0.0527 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4913 - decoder_loss: 24.8633 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0496 - decoder_accuracy: 0.0527 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7251 - val_decoder_loss: 22.7804 - val_encoder_loss: 5.4100 - val_classifier_loss: 0.3705 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4910 - decoder_loss: 24.8608 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0495 - decoder_accuracy: 0.0527 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4910 - decoder_loss: 24.8608 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0495 - decoder_accuracy: 0.0527 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7253 - val_decoder_loss: 22.7781 - val_encoder_loss: 5.4104 - val_classifier_loss: 0.3704 - val_decoder_accuracy: 0.0305 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4908 - decoder_loss: 24.8583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0494 - decoder_accuracy: 0.0529 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4908 - decoder_loss: 24.8583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0494 - decoder_accuracy: 0.0529 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7255 - val_decoder_loss: 22.7758 - val_encoder_loss: 5.4109 - val_classifier_loss: 0.3703 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4905 - decoder_loss: 24.8559 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0493 - decoder_accuracy: 0.0530 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4905 - decoder_loss: 24.8559 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0493 - decoder_accuracy: 0.0530 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7257 - val_decoder_loss: 22.7735 - val_encoder_loss: 5.4113 - val_classifier_loss: 0.3702 - val_decoder_accuracy: 0.0307 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4903 - decoder_loss: 24.8534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0493 - decoder_accuracy: 0.0528 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4903 - decoder_loss: 24.8534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0493 - decoder_accuracy: 0.0528 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7259 - val_decoder_loss: 22.7712 - val_encoder_loss: 5.4118 - val_classifier_loss: 0.3701 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4900 - decoder_loss: 24.8509 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0492 - decoder_accuracy: 0.0528 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4900 - decoder_loss: 24.8509 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0492 - decoder_accuracy: 0.0528 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7262 - val_decoder_loss: 22.7689 - val_encoder_loss: 5.4123 - val_classifier_loss: 0.3700 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4897 - decoder_loss: 24.8484 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0491 - decoder_accuracy: 0.0531 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4897 - decoder_loss: 24.8484 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0491 - decoder_accuracy: 0.0531 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7265 - val_decoder_loss: 22.7666 - val_encoder_loss: 5.4128 - val_classifier_loss: 0.3700 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4895 - decoder_loss: 24.8458 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0490 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4895 - decoder_loss: 24.8458 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0490 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7268 - val_decoder_loss: 22.7642 - val_encoder_loss: 5.4133 - val_classifier_loss: 0.3699 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4892 - decoder_loss: 24.8433 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0490 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4892 - decoder_loss: 24.8433 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0490 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7271 - val_decoder_loss: 22.7619 - val_encoder_loss: 5.4139 - val_classifier_loss: 0.3698 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4890 - decoder_loss: 24.8408 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0489 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4890 - decoder_loss: 24.8408 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0489 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7274 - val_decoder_loss: 22.7596 - val_encoder_loss: 5.4145 - val_classifier_loss: 0.3697 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4887 - decoder_loss: 24.8382 - encoder_loss: 1.4747e-05 - classifier_loss: 0.0488 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4887 - decoder_loss: 24.8382 - encoder_loss: 1.4747e-05 - classifier_loss: 0.0488 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7271 - val_decoder_loss: 22.7574 - val_encoder_loss: 5.4144 - val_classifier_loss: 0.3692 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4886 - decoder_loss: 24.8362 - encoder_loss: 1.0705e-04 - classifier_loss: 0.0487 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4886 - decoder_loss: 24.8362 - encoder_loss: 1.0705e-04 - classifier_loss: 0.0487 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7339 - val_decoder_loss: 22.7554 - val_encoder_loss: 5.4215 - val_classifier_loss: 0.3691 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4883 - decoder_loss: 24.8340 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0486 - decoder_accuracy: 0.0530 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.4883 - decoder_loss: 24.8340 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0486 - decoder_accuracy: 0.0530 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7345 - val_decoder_loss: 22.7530 - val_encoder_loss: 5.4223 - val_classifier_loss: 0.3690 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4880 - decoder_loss: 24.8315 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0485 - decoder_accuracy: 0.0533 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4880 - decoder_loss: 24.8315 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0485 - decoder_accuracy: 0.0533 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7352 - val_decoder_loss: 22.7506 - val_encoder_loss: 5.4232 - val_classifier_loss: 0.3689 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4878 - decoder_loss: 24.8290 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0485 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4878 - decoder_loss: 24.8290 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0485 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7359 - val_decoder_loss: 22.7483 - val_encoder_loss: 5.4242 - val_classifier_loss: 0.3688 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4875 - decoder_loss: 24.8265 - encoder_loss: 3.9362e-05 - classifier_loss: 0.0484 - decoder_accuracy: 0.0534 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4875 - decoder_loss: 24.8265 - encoder_loss: 3.9362e-05 - classifier_loss: 0.0484 - decoder_accuracy: 0.0534 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7312 - val_decoder_loss: 22.7463 - val_encoder_loss: 5.4197 - val_classifier_loss: 0.3686 - val_decoder_accuracy: 0.0307 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4873 - decoder_loss: 24.8244 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0483 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4873 - decoder_loss: 24.8244 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0483 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7327 - val_decoder_loss: 22.7439 - val_encoder_loss: 5.4214 - val_classifier_loss: 0.3686 - val_decoder_accuracy: 0.0307 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4870 - decoder_loss: 24.8218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0482 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4870 - decoder_loss: 24.8218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0482 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7332 - val_decoder_loss: 22.7416 - val_encoder_loss: 5.4222 - val_classifier_loss: 0.3685 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4867 - decoder_loss: 24.8193 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0482 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4867 - decoder_loss: 24.8193 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0482 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7336 - val_decoder_loss: 22.7392 - val_encoder_loss: 5.4228 - val_classifier_loss: 0.3684 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4865 - decoder_loss: 24.8168 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0481 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4865 - decoder_loss: 24.8168 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0481 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7340 - val_decoder_loss: 22.7368 - val_encoder_loss: 5.4235 - val_classifier_loss: 0.3683 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4862 - decoder_loss: 24.8142 - encoder_loss: 4.5325e-06 - classifier_loss: 0.0480 - decoder_accuracy: 0.0533 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4862 - decoder_loss: 24.8142 - encoder_loss: 4.5325e-06 - classifier_loss: 0.0480 - decoder_accuracy: 0.0533 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7390 - val_decoder_loss: 22.7347 - val_encoder_loss: 5.4287 - val_classifier_loss: 0.3677 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4860 - decoder_loss: 24.8119 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0479 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4860 - decoder_loss: 24.8119 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0479 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7387 - val_decoder_loss: 22.7323 - val_encoder_loss: 5.4287 - val_classifier_loss: 0.3676 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4857 - decoder_loss: 24.8093 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0479 - decoder_accuracy: 0.0533 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4857 - decoder_loss: 24.8093 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0479 - decoder_accuracy: 0.0533 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7392 - val_decoder_loss: 22.7298 - val_encoder_loss: 5.4295 - val_classifier_loss: 0.3675 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4855 - decoder_loss: 24.8068 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0478 - decoder_accuracy: 0.0534 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4855 - decoder_loss: 24.8068 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0478 - decoder_accuracy: 0.0534 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7398 - val_decoder_loss: 22.7274 - val_encoder_loss: 5.4304 - val_classifier_loss: 0.3674 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4852 - decoder_loss: 24.8042 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0477 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4852 - decoder_loss: 24.8042 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0477 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7405 - val_decoder_loss: 22.7250 - val_encoder_loss: 5.4312 - val_classifier_loss: 0.3673 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4849 - decoder_loss: 24.8017 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0476 - decoder_accuracy: 0.0536 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4849 - decoder_loss: 24.8017 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0476 - decoder_accuracy: 0.0536 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7411 - val_decoder_loss: 22.7226 - val_encoder_loss: 5.4321 - val_classifier_loss: 0.3672 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4847 - decoder_loss: 24.7991 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0476 - decoder_accuracy: 0.0536 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4847 - decoder_loss: 24.7991 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0476 - decoder_accuracy: 0.0536 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7416 - val_decoder_loss: 22.7202 - val_encoder_loss: 5.4329 - val_classifier_loss: 0.3671 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4844 - decoder_loss: 24.7966 - encoder_loss: 3.4915e-05 - classifier_loss: 0.0475 - decoder_accuracy: 0.0536 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4844 - decoder_loss: 24.7966 - encoder_loss: 3.4915e-05 - classifier_loss: 0.0475 - decoder_accuracy: 0.0536 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7415 - val_decoder_loss: 22.7180 - val_encoder_loss: 5.4331 - val_classifier_loss: 0.3665 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4843 - decoder_loss: 24.7945 - encoder_loss: 1.0384e-04 - classifier_loss: 0.0474 - decoder_accuracy: 0.0537 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4843 - decoder_loss: 24.7945 - encoder_loss: 1.0384e-04 - classifier_loss: 0.0474 - decoder_accuracy: 0.0537 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7490 - val_decoder_loss: 22.7160 - val_encoder_loss: 5.4408 - val_classifier_loss: 0.3664 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4840 - decoder_loss: 24.7924 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0473 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4840 - decoder_loss: 24.7924 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0473 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7498 - val_decoder_loss: 22.7136 - val_encoder_loss: 5.4418 - val_classifier_loss: 0.3663 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4837 - decoder_loss: 24.7899 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0472 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4837 - decoder_loss: 24.7899 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0472 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7507 - val_decoder_loss: 22.7112 - val_encoder_loss: 5.4430 - val_classifier_loss: 0.3662 - val_decoder_accuracy: 0.0322 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4835 - decoder_loss: 24.7874 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0472 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4835 - decoder_loss: 24.7874 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0472 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7516 - val_decoder_loss: 22.7088 - val_encoder_loss: 5.4441 - val_classifier_loss: 0.3661 - val_decoder_accuracy: 0.0322 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4832 - decoder_loss: 24.7848 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0471 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 203: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4832 - decoder_loss: 24.7848 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0471 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7524 - val_decoder_loss: 22.7063 - val_encoder_loss: 5.4452 - val_classifier_loss: 0.3660 - val_decoder_accuracy: 0.0325 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4829 - decoder_loss: 24.7822 - encoder_loss: 1.7563e-05 - classifier_loss: 0.0470 - decoder_accuracy: 0.0540 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 204: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4829 - decoder_loss: 24.7822 - encoder_loss: 1.7563e-05 - classifier_loss: 0.0470 - decoder_accuracy: 0.0540 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7476 - val_decoder_loss: 22.7044 - val_encoder_loss: 5.4406 - val_classifier_loss: 0.3658 - val_decoder_accuracy: 0.0323 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4827 - decoder_loss: 24.7801 - encoder_loss: 3.5838e-06 - classifier_loss: 0.0469 - decoder_accuracy: 0.0542 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 205: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4827 - decoder_loss: 24.7801 - encoder_loss: 3.5838e-06 - classifier_loss: 0.0469 - decoder_accuracy: 0.0542 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7477 - val_decoder_loss: 22.7022 - val_encoder_loss: 5.4409 - val_classifier_loss: 0.3657 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4825 - decoder_loss: 24.7777 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0469 - decoder_accuracy: 0.0542 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 206: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4825 - decoder_loss: 24.7777 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0469 - decoder_accuracy: 0.0542 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7483 - val_decoder_loss: 22.6997 - val_encoder_loss: 5.4418 - val_classifier_loss: 0.3656 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4822 - decoder_loss: 24.7752 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0468 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 207: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4822 - decoder_loss: 24.7752 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0468 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7488 - val_decoder_loss: 22.6973 - val_encoder_loss: 5.4425 - val_classifier_loss: 0.3655 - val_decoder_accuracy: 0.0320 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4819 - decoder_loss: 24.7726 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0467 - decoder_accuracy: 0.0546 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 208: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4819 - decoder_loss: 24.7726 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0467 - decoder_accuracy: 0.0546 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7492 - val_decoder_loss: 22.6949 - val_encoder_loss: 5.4431 - val_classifier_loss: 0.3654 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4817 - decoder_loss: 24.7700 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0467 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 209: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4817 - decoder_loss: 24.7700 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0467 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7496 - val_decoder_loss: 22.6924 - val_encoder_loss: 5.4438 - val_classifier_loss: 0.3653 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4814 - decoder_loss: 24.7674 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0466 - decoder_accuracy: 0.0546 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 210: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4814 - decoder_loss: 24.7674 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0466 - decoder_accuracy: 0.0546 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7500 - val_decoder_loss: 22.6900 - val_encoder_loss: 5.4445 - val_classifier_loss: 0.3653 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4811 - decoder_loss: 24.7648 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0465 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 211: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4811 - decoder_loss: 24.7648 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0465 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7505 - val_decoder_loss: 22.6875 - val_encoder_loss: 5.4452 - val_classifier_loss: 0.3652 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4809 - decoder_loss: 24.7621 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0465 - decoder_accuracy: 0.0549 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 212: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4809 - decoder_loss: 24.7621 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0465 - decoder_accuracy: 0.0549 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7509 - val_decoder_loss: 22.6850 - val_encoder_loss: 5.4459 - val_classifier_loss: 0.3651 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4806 - decoder_loss: 24.7595 - encoder_loss: 2.9684e-05 - classifier_loss: 0.0464 - decoder_accuracy: 0.0548 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 213: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4806 - decoder_loss: 24.7595 - encoder_loss: 2.9684e-05 - classifier_loss: 0.0464 - decoder_accuracy: 0.0548 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7583 - val_decoder_loss: 22.6829 - val_encoder_loss: 5.4535 - val_classifier_loss: 0.3650 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4804 - decoder_loss: 24.7573 - encoder_loss: 6.2340e-06 - classifier_loss: 0.0463 - decoder_accuracy: 0.0549 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 214: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4804 - decoder_loss: 24.7573 - encoder_loss: 6.2340e-06 - classifier_loss: 0.0463 - decoder_accuracy: 0.0549 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7830 - val_decoder_loss: 22.6807 - val_encoder_loss: 5.4785 - val_classifier_loss: 0.3645 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4801 - decoder_loss: 24.7552 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0462 - decoder_accuracy: 0.0550 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 215: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4801 - decoder_loss: 24.7552 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0462 - decoder_accuracy: 0.0550 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7837 - val_decoder_loss: 22.6783 - val_encoder_loss: 5.4794 - val_classifier_loss: 0.3644 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4799 - decoder_loss: 24.7525 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0461 - decoder_accuracy: 0.0551 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 216: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4799 - decoder_loss: 24.7525 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0461 - decoder_accuracy: 0.0551 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7841 - val_decoder_loss: 22.6758 - val_encoder_loss: 5.4801 - val_classifier_loss: 0.3643 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4796 - decoder_loss: 24.7499 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0461 - decoder_accuracy: 0.0552 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 217: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4796 - decoder_loss: 24.7499 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0461 - decoder_accuracy: 0.0552 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7844 - val_decoder_loss: 22.6733 - val_encoder_loss: 5.4806 - val_classifier_loss: 0.3642 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4793 - decoder_loss: 24.7472 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0460 - decoder_accuracy: 0.0553 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 218: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4793 - decoder_loss: 24.7472 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0460 - decoder_accuracy: 0.0553 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7847 - val_decoder_loss: 22.6708 - val_encoder_loss: 5.4812 - val_classifier_loss: 0.3641 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4791 - decoder_loss: 24.7446 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0460 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 219: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4791 - decoder_loss: 24.7446 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0460 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8096 - val_decoder_loss: 22.6684 - val_encoder_loss: 5.5064 - val_classifier_loss: 0.3640 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4788 - decoder_loss: 24.7419 - encoder_loss: 3.9151e-07 - classifier_loss: 0.0459 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 220: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4788 - decoder_loss: 24.7419 - encoder_loss: 3.9151e-07 - classifier_loss: 0.0459 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8039 - val_decoder_loss: 22.6664 - val_encoder_loss: 5.5009 - val_classifier_loss: 0.3638 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4785 - decoder_loss: 24.7396 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0458 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 221: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4785 - decoder_loss: 24.7396 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0458 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8042 - val_decoder_loss: 22.6639 - val_encoder_loss: 5.5014 - val_classifier_loss: 0.3637 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4783 - decoder_loss: 24.7369 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0457 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 222: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4783 - decoder_loss: 24.7369 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0457 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8035 - val_decoder_loss: 22.6614 - val_encoder_loss: 5.5009 - val_classifier_loss: 0.3637 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4780 - decoder_loss: 24.7342 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0457 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 223: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4780 - decoder_loss: 24.7342 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0457 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8026 - val_decoder_loss: 22.6589 - val_encoder_loss: 5.5004 - val_classifier_loss: 0.3636 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4777 - decoder_loss: 24.7315 - encoder_loss: 3.1356e-05 - classifier_loss: 0.0456 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 224: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4777 - decoder_loss: 24.7315 - encoder_loss: 3.1356e-05 - classifier_loss: 0.0456 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7992 - val_decoder_loss: 22.6566 - val_encoder_loss: 5.4972 - val_classifier_loss: 0.3635 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4775 - decoder_loss: 24.7290 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0456 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 225: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4775 - decoder_loss: 24.7290 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0456 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.7984 - val_decoder_loss: 22.6541 - val_encoder_loss: 5.4966 - val_classifier_loss: 0.3634 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4772 - decoder_loss: 24.7263 - encoder_loss: 1.6704e-05 - classifier_loss: 0.0455 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 226: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4772 - decoder_loss: 24.7263 - encoder_loss: 1.6704e-05 - classifier_loss: 0.0455 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8047 - val_decoder_loss: 22.6520 - val_encoder_loss: 5.5032 - val_classifier_loss: 0.3633 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4769 - decoder_loss: 24.7241 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0454 - decoder_accuracy: 0.0554 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 227: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4769 - decoder_loss: 24.7241 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0454 - decoder_accuracy: 0.0554 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8038 - val_decoder_loss: 22.6495 - val_encoder_loss: 5.5026 - val_classifier_loss: 0.3633 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4767 - decoder_loss: 24.7213 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0453 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 228: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4767 - decoder_loss: 24.7213 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0453 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8033 - val_decoder_loss: 22.6470 - val_encoder_loss: 5.5023 - val_classifier_loss: 0.3632 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4764 - decoder_loss: 24.7186 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0453 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 229: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4764 - decoder_loss: 24.7186 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0453 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8027 - val_decoder_loss: 22.6444 - val_encoder_loss: 5.5020 - val_classifier_loss: 0.3631 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4761 - decoder_loss: 24.7158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0452 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 230: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4761 - decoder_loss: 24.7158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0452 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8022 - val_decoder_loss: 22.6419 - val_encoder_loss: 5.5017 - val_classifier_loss: 0.3630 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4759 - decoder_loss: 24.7131 - encoder_loss: 6.4604e-05 - classifier_loss: 0.0452 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 231: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4759 - decoder_loss: 24.7131 - encoder_loss: 6.4604e-05 - classifier_loss: 0.0452 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8068 - val_decoder_loss: 22.6394 - val_encoder_loss: 5.5066 - val_classifier_loss: 0.3627 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4756 - decoder_loss: 24.7109 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0450 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 232: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4756 - decoder_loss: 24.7109 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0450 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8067 - val_decoder_loss: 22.6369 - val_encoder_loss: 5.5067 - val_classifier_loss: 0.3626 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4753 - decoder_loss: 24.7082 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0450 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 233: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4753 - decoder_loss: 24.7082 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0450 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8064 - val_decoder_loss: 22.6344 - val_encoder_loss: 5.5067 - val_classifier_loss: 0.3625 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4750 - decoder_loss: 24.7054 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0449 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 234: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4750 - decoder_loss: 24.7054 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0449 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8061 - val_decoder_loss: 22.6319 - val_encoder_loss: 5.5067 - val_classifier_loss: 0.3624 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4747 - decoder_loss: 24.7026 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0448 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 235: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4747 - decoder_loss: 24.7026 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0448 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8307 - val_decoder_loss: 22.6294 - val_encoder_loss: 5.5315 - val_classifier_loss: 0.3624 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4745 - decoder_loss: 24.6998 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0448 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 236: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4745 - decoder_loss: 24.6998 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0448 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8301 - val_decoder_loss: 22.6268 - val_encoder_loss: 5.5312 - val_classifier_loss: 0.3623 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4742 - decoder_loss: 24.6969 - encoder_loss: 4.8467e-05 - classifier_loss: 0.0447 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 237: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4742 - decoder_loss: 24.6969 - encoder_loss: 4.8467e-05 - classifier_loss: 0.0447 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8243 - val_decoder_loss: 22.6249 - val_encoder_loss: 5.5256 - val_classifier_loss: 0.3621 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4740 - decoder_loss: 24.6945 - encoder_loss: 5.8907e-05 - classifier_loss: 0.0446 - decoder_accuracy: 0.0560 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 238: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.4740 - decoder_loss: 24.6945 - encoder_loss: 5.8907e-05 - classifier_loss: 0.0446 - decoder_accuracy: 0.0560 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8216 - val_decoder_loss: 22.6225 - val_encoder_loss: 5.5232 - val_classifier_loss: 0.3621 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4737 - decoder_loss: 24.6920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0446 - decoder_accuracy: 0.0561 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 239: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4737 - decoder_loss: 24.6920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0446 - decoder_accuracy: 0.0561 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8208 - val_decoder_loss: 22.6200 - val_encoder_loss: 5.5226 - val_classifier_loss: 0.3620 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4734 - decoder_loss: 24.6892 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0445 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 240: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4734 - decoder_loss: 24.6892 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0445 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8198 - val_decoder_loss: 22.6175 - val_encoder_loss: 5.5218 - val_classifier_loss: 0.3619 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4731 - decoder_loss: 24.6863 - encoder_loss: 4.3969e-05 - classifier_loss: 0.0445 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 241: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4731 - decoder_loss: 24.6863 - encoder_loss: 4.3969e-05 - classifier_loss: 0.0445 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8264 - val_decoder_loss: 22.6154 - val_encoder_loss: 5.5286 - val_classifier_loss: 0.3619 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4728 - decoder_loss: 24.6841 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0444 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 242: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4728 - decoder_loss: 24.6841 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0444 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8253 - val_decoder_loss: 22.6130 - val_encoder_loss: 5.5279 - val_classifier_loss: 0.3618 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4726 - decoder_loss: 24.6813 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0443 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 243: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4726 - decoder_loss: 24.6813 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0443 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8247 - val_decoder_loss: 22.6105 - val_encoder_loss: 5.5275 - val_classifier_loss: 0.3618 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4723 - decoder_loss: 24.6785 - encoder_loss: 1.2900e-06 - classifier_loss: 0.0442 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 244: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4723 - decoder_loss: 24.6785 - encoder_loss: 1.2900e-06 - classifier_loss: 0.0442 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8299 - val_decoder_loss: 22.6081 - val_encoder_loss: 5.5329 - val_classifier_loss: 0.3614 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4721 - decoder_loss: 24.6764 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0441 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 245: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4721 - decoder_loss: 24.6764 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0441 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8297 - val_decoder_loss: 22.6057 - val_encoder_loss: 5.5330 - val_classifier_loss: 0.3613 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4718 - decoder_loss: 24.6736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0441 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 246: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4718 - decoder_loss: 24.6736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0441 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8294 - val_decoder_loss: 22.6032 - val_encoder_loss: 5.5330 - val_classifier_loss: 0.3613 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4715 - decoder_loss: 24.6708 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0440 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 247: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4715 - decoder_loss: 24.6708 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0440 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8290 - val_decoder_loss: 22.6007 - val_encoder_loss: 5.5328 - val_classifier_loss: 0.3612 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4712 - decoder_loss: 24.6680 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0439 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 248: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4712 - decoder_loss: 24.6680 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0439 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8286 - val_decoder_loss: 22.5983 - val_encoder_loss: 5.5326 - val_classifier_loss: 0.3611 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4709 - decoder_loss: 24.6652 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0439 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 249: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4709 - decoder_loss: 24.6652 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0439 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8281 - val_decoder_loss: 22.5958 - val_encoder_loss: 5.5324 - val_classifier_loss: 0.3610 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4706 - decoder_loss: 24.6623 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0438 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 250: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4706 - decoder_loss: 24.6623 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0438 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8275 - val_decoder_loss: 22.5933 - val_encoder_loss: 5.5321 - val_classifier_loss: 0.3609 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4703 - decoder_loss: 24.6594 - encoder_loss: 2.2577e-05 - classifier_loss: 0.0438 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 251: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4703 - decoder_loss: 24.6594 - encoder_loss: 2.2577e-05 - classifier_loss: 0.0438 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8240 - val_decoder_loss: 22.5911 - val_encoder_loss: 5.5288 - val_classifier_loss: 0.3608 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4712 - decoder_loss: 24.6568 - encoder_loss: 0.0012 - classifier_loss: 0.0437 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 252: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.4712 - decoder_loss: 24.6568 - encoder_loss: 0.0012 - classifier_loss: 0.0437 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8172 - val_decoder_loss: 22.5892 - val_encoder_loss: 5.5222 - val_classifier_loss: 0.3609 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4705 - decoder_loss: 24.6545 - encoder_loss: 6.7477e-04 - classifier_loss: 0.0437 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 253: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4705 - decoder_loss: 24.6545 - encoder_loss: 6.7477e-04 - classifier_loss: 0.0437 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8179 - val_decoder_loss: 22.5868 - val_encoder_loss: 5.5231 - val_classifier_loss: 0.3610 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4697 - decoder_loss: 24.6517 - encoder_loss: 1.4217e-04 - classifier_loss: 0.0436 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 254: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4697 - decoder_loss: 24.6517 - encoder_loss: 1.4217e-04 - classifier_loss: 0.0436 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8260 - val_decoder_loss: 22.5849 - val_encoder_loss: 5.5314 - val_classifier_loss: 0.3611 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4693 - decoder_loss: 24.6495 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0435 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 255: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.4693 - decoder_loss: 24.6495 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0435 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8265 - val_decoder_loss: 22.5824 - val_encoder_loss: 5.5322 - val_classifier_loss: 0.3611 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4691 - decoder_loss: 24.6466 - encoder_loss: 7.0994e-05 - classifier_loss: 0.0435 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 256: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4691 - decoder_loss: 24.6466 - encoder_loss: 7.0994e-05 - classifier_loss: 0.0435 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8316 - val_decoder_loss: 22.5800 - val_encoder_loss: 5.5375 - val_classifier_loss: 0.3608 - val_decoder_accuracy: 0.0307 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4688 - decoder_loss: 24.6445 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0434 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 257: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4688 - decoder_loss: 24.6445 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0434 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8324 - val_decoder_loss: 22.5776 - val_encoder_loss: 5.5386 - val_classifier_loss: 0.3607 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4685 - decoder_loss: 24.6416 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0433 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 258: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4685 - decoder_loss: 24.6416 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0433 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8330 - val_decoder_loss: 22.5751 - val_encoder_loss: 5.5394 - val_classifier_loss: 0.3607 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4682 - decoder_loss: 24.6387 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0433 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 259: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4682 - decoder_loss: 24.6387 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0433 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8335 - val_decoder_loss: 22.5727 - val_encoder_loss: 5.5401 - val_classifier_loss: 0.3606 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4679 - decoder_loss: 24.6358 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0432 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 260: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4679 - decoder_loss: 24.6358 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0432 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8339 - val_decoder_loss: 22.5702 - val_encoder_loss: 5.5408 - val_classifier_loss: 0.3605 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4676 - decoder_loss: 24.6329 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0431 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 261: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4676 - decoder_loss: 24.6329 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0431 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8342 - val_decoder_loss: 22.5677 - val_encoder_loss: 5.5414 - val_classifier_loss: 0.3605 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4673 - decoder_loss: 24.6300 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0431 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 262: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4673 - decoder_loss: 24.6300 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0431 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8345 - val_decoder_loss: 22.5652 - val_encoder_loss: 5.5420 - val_classifier_loss: 0.3604 - val_decoder_accuracy: 0.0307 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4670 - decoder_loss: 24.6270 - encoder_loss: 2.0579e-05 - classifier_loss: 0.0430 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 263: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4670 - decoder_loss: 24.6270 - encoder_loss: 2.0579e-05 - classifier_loss: 0.0430 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8395 - val_decoder_loss: 22.5630 - val_encoder_loss: 5.5472 - val_classifier_loss: 0.3597 - val_decoder_accuracy: 0.0307 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4667 - decoder_loss: 24.6243 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0429 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 264: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4667 - decoder_loss: 24.6243 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0429 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8393 - val_decoder_loss: 22.5605 - val_encoder_loss: 5.5473 - val_classifier_loss: 0.3597 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4664 - decoder_loss: 24.6213 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0429 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 265: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4664 - decoder_loss: 24.6213 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0429 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8403 - val_decoder_loss: 22.5581 - val_encoder_loss: 5.5485 - val_classifier_loss: 0.3596 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4661 - decoder_loss: 24.6183 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0428 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 266: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4661 - decoder_loss: 24.6183 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0428 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8413 - val_decoder_loss: 22.5556 - val_encoder_loss: 5.5498 - val_classifier_loss: 0.3595 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4659 - decoder_loss: 24.6153 - encoder_loss: 4.5360e-05 - classifier_loss: 0.0428 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 267: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4659 - decoder_loss: 24.6153 - encoder_loss: 4.5360e-05 - classifier_loss: 0.0428 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8352 - val_decoder_loss: 22.5537 - val_encoder_loss: 5.5439 - val_classifier_loss: 0.3593 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4655 - decoder_loss: 24.6128 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0427 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 268: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4655 - decoder_loss: 24.6128 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0427 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8369 - val_decoder_loss: 22.5512 - val_encoder_loss: 5.5459 - val_classifier_loss: 0.3593 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4653 - decoder_loss: 24.6098 - encoder_loss: 3.0116e-05 - classifier_loss: 0.0426 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 269: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4653 - decoder_loss: 24.6098 - encoder_loss: 3.0116e-05 - classifier_loss: 0.0426 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8472 - val_decoder_loss: 22.5492 - val_encoder_loss: 5.5563 - val_classifier_loss: 0.3592 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4650 - decoder_loss: 24.6074 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0425 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 270: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4650 - decoder_loss: 24.6074 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0425 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8479 - val_decoder_loss: 22.5468 - val_encoder_loss: 5.5573 - val_classifier_loss: 0.3592 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4647 - decoder_loss: 24.6045 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0425 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 271: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4647 - decoder_loss: 24.6045 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0425 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8489 - val_decoder_loss: 22.5444 - val_encoder_loss: 5.5586 - val_classifier_loss: 0.3591 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4645 - decoder_loss: 24.6015 - encoder_loss: 8.0169e-05 - classifier_loss: 0.0424 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 272: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4645 - decoder_loss: 24.6015 - encoder_loss: 8.0169e-05 - classifier_loss: 0.0424 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8530 - val_decoder_loss: 22.5421 - val_encoder_loss: 5.5629 - val_classifier_loss: 0.3587 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4642 - decoder_loss: 24.5992 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0423 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 273: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4642 - decoder_loss: 24.5992 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0423 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8545 - val_decoder_loss: 22.5396 - val_encoder_loss: 5.5647 - val_classifier_loss: 0.3586 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4638 - decoder_loss: 24.5962 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0423 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 274: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4638 - decoder_loss: 24.5962 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0423 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8557 - val_decoder_loss: 22.5372 - val_encoder_loss: 5.5661 - val_classifier_loss: 0.3586 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4635 - decoder_loss: 24.5932 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0422 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 275: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4635 - decoder_loss: 24.5932 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0422 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8568 - val_decoder_loss: 22.5348 - val_encoder_loss: 5.5674 - val_classifier_loss: 0.3585 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4632 - decoder_loss: 24.5902 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0421 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 276: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4632 - decoder_loss: 24.5902 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0421 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8578 - val_decoder_loss: 22.5324 - val_encoder_loss: 5.5687 - val_classifier_loss: 0.3584 - val_decoder_accuracy: 0.0310 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4629 - decoder_loss: 24.5872 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0421 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 277: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4629 - decoder_loss: 24.5872 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0421 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8587 - val_decoder_loss: 22.5299 - val_encoder_loss: 5.5699 - val_classifier_loss: 0.3583 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4626 - decoder_loss: 24.5841 - encoder_loss: 6.5251e-06 - classifier_loss: 0.0420 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 278: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4626 - decoder_loss: 24.5841 - encoder_loss: 6.5251e-06 - classifier_loss: 0.0420 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8706 - val_decoder_loss: 22.5276 - val_encoder_loss: 5.5820 - val_classifier_loss: 0.3583 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4624 - decoder_loss: 24.5816 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0420 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 279: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4624 - decoder_loss: 24.5816 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0420 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8714 - val_decoder_loss: 22.5252 - val_encoder_loss: 5.5830 - val_classifier_loss: 0.3582 - val_decoder_accuracy: 0.0312 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4620 - decoder_loss: 24.5786 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0419 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 280: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4620 - decoder_loss: 24.5786 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0419 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8728 - val_decoder_loss: 22.5228 - val_encoder_loss: 5.5847 - val_classifier_loss: 0.3581 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4617 - decoder_loss: 24.5755 - encoder_loss: 8.7336e-07 - classifier_loss: 0.0419 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 281: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4617 - decoder_loss: 24.5755 - encoder_loss: 8.7336e-07 - classifier_loss: 0.0419 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8839 - val_decoder_loss: 22.5209 - val_encoder_loss: 5.5960 - val_classifier_loss: 0.3581 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4615 - decoder_loss: 24.5731 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0418 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 282: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4615 - decoder_loss: 24.5731 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0418 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8854 - val_decoder_loss: 22.5185 - val_encoder_loss: 5.5978 - val_classifier_loss: 0.3580 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4612 - decoder_loss: 24.5700 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0417 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 283: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4612 - decoder_loss: 24.5700 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0417 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8871 - val_decoder_loss: 22.5161 - val_encoder_loss: 5.5997 - val_classifier_loss: 0.3579 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4609 - decoder_loss: 24.5669 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0417 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 284: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4609 - decoder_loss: 24.5669 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0417 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8888 - val_decoder_loss: 22.5137 - val_encoder_loss: 5.6016 - val_classifier_loss: 0.3579 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4605 - decoder_loss: 24.5638 - encoder_loss: 2.1684e-06 - classifier_loss: 0.0416 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 285: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4605 - decoder_loss: 24.5638 - encoder_loss: 2.1684e-06 - classifier_loss: 0.0416 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8934 - val_decoder_loss: 22.5115 - val_encoder_loss: 5.6065 - val_classifier_loss: 0.3575 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4603 - decoder_loss: 24.5615 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0415 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 286: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4603 - decoder_loss: 24.5615 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0415 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8954 - val_decoder_loss: 22.5091 - val_encoder_loss: 5.6087 - val_classifier_loss: 0.3574 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4600 - decoder_loss: 24.5584 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0415 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 287: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4600 - decoder_loss: 24.5584 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0415 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8970 - val_decoder_loss: 22.5067 - val_encoder_loss: 5.6106 - val_classifier_loss: 0.3574 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4597 - decoder_loss: 24.5553 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0414 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 288: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4597 - decoder_loss: 24.5553 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0414 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8984 - val_decoder_loss: 22.5043 - val_encoder_loss: 5.6122 - val_classifier_loss: 0.3573 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4593 - decoder_loss: 24.5521 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0414 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 289: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4593 - decoder_loss: 24.5521 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0414 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8997 - val_decoder_loss: 22.5020 - val_encoder_loss: 5.6138 - val_classifier_loss: 0.3572 - val_decoder_accuracy: 0.0322 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4590 - decoder_loss: 24.5490 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0413 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 290: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4590 - decoder_loss: 24.5490 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0413 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9009 - val_decoder_loss: 22.4996 - val_encoder_loss: 5.6153 - val_classifier_loss: 0.3571 - val_decoder_accuracy: 0.0323 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4587 - decoder_loss: 24.5458 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0413 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 291: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4587 - decoder_loss: 24.5458 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0413 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9021 - val_decoder_loss: 22.4972 - val_encoder_loss: 5.6167 - val_classifier_loss: 0.3571 - val_decoder_accuracy: 0.0328 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4584 - decoder_loss: 24.5426 - encoder_loss: 4.8045e-05 - classifier_loss: 0.0412 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 292: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.4584 - decoder_loss: 24.5426 - encoder_loss: 4.8045e-05 - classifier_loss: 0.0412 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8956 - val_decoder_loss: 22.4954 - val_encoder_loss: 5.6104 - val_classifier_loss: 0.3569 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4581 - decoder_loss: 24.5400 - encoder_loss: 3.6711e-05 - classifier_loss: 0.0411 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 293: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4581 - decoder_loss: 24.5400 - encoder_loss: 3.6711e-05 - classifier_loss: 0.0411 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9325 - val_decoder_loss: 22.4935 - val_encoder_loss: 5.6475 - val_classifier_loss: 0.3569 - val_decoder_accuracy: 0.0332 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4579 - decoder_loss: 24.5375 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0410 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 294: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4579 - decoder_loss: 24.5375 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0410 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9334 - val_decoder_loss: 22.4912 - val_encoder_loss: 5.6486 - val_classifier_loss: 0.3569 - val_decoder_accuracy: 0.0332 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4575 - decoder_loss: 24.5344 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0410 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 295: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4575 - decoder_loss: 24.5344 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0410 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9344 - val_decoder_loss: 22.4888 - val_encoder_loss: 5.6499 - val_classifier_loss: 0.3568 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4573 - decoder_loss: 24.5312 - encoder_loss: 5.8726e-05 - classifier_loss: 0.0409 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 296: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4573 - decoder_loss: 24.5312 - encoder_loss: 5.8726e-05 - classifier_loss: 0.0409 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9332 - val_decoder_loss: 22.4867 - val_encoder_loss: 5.6489 - val_classifier_loss: 0.3567 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4569 - decoder_loss: 24.5284 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0409 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 297: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4569 - decoder_loss: 24.5284 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0409 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9341 - val_decoder_loss: 22.4843 - val_encoder_loss: 5.6500 - val_classifier_loss: 0.3567 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4566 - decoder_loss: 24.5252 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0408 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 298: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4566 - decoder_loss: 24.5252 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0408 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9348 - val_decoder_loss: 22.4820 - val_encoder_loss: 5.6510 - val_classifier_loss: 0.3566 - val_decoder_accuracy: 0.0330 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4563 - decoder_loss: 24.5220 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0408 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 299: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4563 - decoder_loss: 24.5220 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0408 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9355 - val_decoder_loss: 22.4796 - val_encoder_loss: 5.6518 - val_classifier_loss: 0.3566 - val_decoder_accuracy: 0.0332 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4560 - decoder_loss: 24.5188 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0408 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 300: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4560 - decoder_loss: 24.5188 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0408 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9361 - val_decoder_loss: 22.4772 - val_encoder_loss: 5.6527 - val_classifier_loss: 0.3565 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4557 - decoder_loss: 24.5155 - encoder_loss: 8.6097e-05 - classifier_loss: 0.0407 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 301: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4557 - decoder_loss: 24.5155 - encoder_loss: 8.6097e-05 - classifier_loss: 0.0407 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9413 - val_decoder_loss: 22.4750 - val_encoder_loss: 5.6582 - val_classifier_loss: 0.3562 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4554 - decoder_loss: 24.5131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0406 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 302: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4554 - decoder_loss: 24.5131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0406 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9426 - val_decoder_loss: 22.4726 - val_encoder_loss: 5.6597 - val_classifier_loss: 0.3561 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4550 - decoder_loss: 24.5098 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0405 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 303: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4550 - decoder_loss: 24.5098 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0405 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9435 - val_decoder_loss: 22.4703 - val_encoder_loss: 5.6609 - val_classifier_loss: 0.3560 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4547 - decoder_loss: 24.5066 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0405 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 304: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4547 - decoder_loss: 24.5066 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0405 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9443 - val_decoder_loss: 22.4679 - val_encoder_loss: 5.6619 - val_classifier_loss: 0.3560 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4544 - decoder_loss: 24.5034 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0404 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 305: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4544 - decoder_loss: 24.5034 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0404 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9451 - val_decoder_loss: 22.4656 - val_encoder_loss: 5.6629 - val_classifier_loss: 0.3559 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4541 - decoder_loss: 24.5001 - encoder_loss: 9.0659e-05 - classifier_loss: 0.0404 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 306: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4541 - decoder_loss: 24.5001 - encoder_loss: 9.0659e-05 - classifier_loss: 0.0404 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9522 - val_decoder_loss: 22.4639 - val_encoder_loss: 5.6702 - val_classifier_loss: 0.3558 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4539 - decoder_loss: 24.4979 - encoder_loss: 1.0481e-04 - classifier_loss: 0.0403 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 307: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4539 - decoder_loss: 24.4979 - encoder_loss: 1.0481e-04 - classifier_loss: 0.0403 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9458 - val_decoder_loss: 22.4623 - val_encoder_loss: 5.6640 - val_classifier_loss: 0.3557 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4536 - decoder_loss: 24.4952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0403 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 308: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4536 - decoder_loss: 24.4952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0403 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9480 - val_decoder_loss: 22.4599 - val_encoder_loss: 5.6665 - val_classifier_loss: 0.3557 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4532 - decoder_loss: 24.4920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0402 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 309: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4532 - decoder_loss: 24.4920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0402 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9488 - val_decoder_loss: 22.4576 - val_encoder_loss: 5.6675 - val_classifier_loss: 0.3556 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4529 - decoder_loss: 24.4888 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0402 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 310: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4529 - decoder_loss: 24.4888 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0402 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9494 - val_decoder_loss: 22.4553 - val_encoder_loss: 5.6683 - val_classifier_loss: 0.3556 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4526 - decoder_loss: 24.4856 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0401 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 311: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4526 - decoder_loss: 24.4856 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0401 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9500 - val_decoder_loss: 22.4530 - val_encoder_loss: 5.6691 - val_classifier_loss: 0.3555 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4522 - decoder_loss: 24.4823 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0401 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 312: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4522 - decoder_loss: 24.4823 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0401 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9506 - val_decoder_loss: 22.4507 - val_encoder_loss: 5.6700 - val_classifier_loss: 0.3555 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4519 - decoder_loss: 24.4790 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0400 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 313: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4519 - decoder_loss: 24.4790 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0400 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9513 - val_decoder_loss: 22.4483 - val_encoder_loss: 5.6709 - val_classifier_loss: 0.3554 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4516 - decoder_loss: 24.4757 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0400 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 314: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.4516 - decoder_loss: 24.4757 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0400 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9519 - val_decoder_loss: 22.4460 - val_encoder_loss: 5.6718 - val_classifier_loss: 0.3554 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4513 - decoder_loss: 24.4724 - encoder_loss: 7.0758e-05 - classifier_loss: 0.0399 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 315: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4513 - decoder_loss: 24.4724 - encoder_loss: 7.0758e-05 - classifier_loss: 0.0399 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9690 - val_decoder_loss: 22.4438 - val_encoder_loss: 5.6892 - val_classifier_loss: 0.3549 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4510 - decoder_loss: 24.4705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0398 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 316: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4510 - decoder_loss: 24.4705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0398 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9698 - val_decoder_loss: 22.4415 - val_encoder_loss: 5.6901 - val_classifier_loss: 0.3549 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4507 - decoder_loss: 24.4672 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0397 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 317: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4507 - decoder_loss: 24.4672 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0397 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9712 - val_decoder_loss: 22.4392 - val_encoder_loss: 5.6918 - val_classifier_loss: 0.3548 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4504 - decoder_loss: 24.4640 - encoder_loss: 1.7081e-05 - classifier_loss: 0.0397 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 318: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4504 - decoder_loss: 24.4640 - encoder_loss: 1.7081e-05 - classifier_loss: 0.0397 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9709 - val_decoder_loss: 22.4372 - val_encoder_loss: 5.6917 - val_classifier_loss: 0.3547 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4501 - decoder_loss: 24.4611 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0396 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 319: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4501 - decoder_loss: 24.4611 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0396 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9724 - val_decoder_loss: 22.4349 - val_encoder_loss: 5.6934 - val_classifier_loss: 0.3546 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4498 - decoder_loss: 24.4578 - encoder_loss: 4.9887e-05 - classifier_loss: 0.0396 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 320: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4498 - decoder_loss: 24.4578 - encoder_loss: 4.9887e-05 - classifier_loss: 0.0396 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9584 - val_decoder_loss: 22.4329 - val_encoder_loss: 5.6797 - val_classifier_loss: 0.3545 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4494 - decoder_loss: 24.4548 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0396 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 321: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4494 - decoder_loss: 24.4548 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0396 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9597 - val_decoder_loss: 22.4306 - val_encoder_loss: 5.6812 - val_classifier_loss: 0.3545 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4491 - decoder_loss: 24.4515 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0395 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 322: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4491 - decoder_loss: 24.4515 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0395 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9600 - val_decoder_loss: 22.4283 - val_encoder_loss: 5.6817 - val_classifier_loss: 0.3544 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4488 - decoder_loss: 24.4482 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0395 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 323: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4488 - decoder_loss: 24.4482 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0395 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9602 - val_decoder_loss: 22.4260 - val_encoder_loss: 5.6821 - val_classifier_loss: 0.3544 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4485 - decoder_loss: 24.4448 - encoder_loss: 5.5514e-05 - classifier_loss: 0.0394 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 324: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4485 - decoder_loss: 24.4448 - encoder_loss: 5.5514e-05 - classifier_loss: 0.0394 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9690 - val_decoder_loss: 22.4242 - val_encoder_loss: 5.6911 - val_classifier_loss: 0.3544 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4482 - decoder_loss: 24.4422 - encoder_loss: 7.8904e-06 - classifier_loss: 0.0393 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 325: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4482 - decoder_loss: 24.4422 - encoder_loss: 7.8904e-06 - classifier_loss: 0.0393 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9741 - val_decoder_loss: 22.4222 - val_encoder_loss: 5.6965 - val_classifier_loss: 0.3540 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4479 - decoder_loss: 24.4397 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0392 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 326: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4479 - decoder_loss: 24.4397 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0392 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9757 - val_decoder_loss: 22.4200 - val_encoder_loss: 5.6983 - val_classifier_loss: 0.3539 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4476 - decoder_loss: 24.4364 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0392 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 327: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4476 - decoder_loss: 24.4364 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0392 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9769 - val_decoder_loss: 22.4177 - val_encoder_loss: 5.6997 - val_classifier_loss: 0.3539 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4472 - decoder_loss: 24.4331 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0391 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 328: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4472 - decoder_loss: 24.4331 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0391 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9779 - val_decoder_loss: 22.4155 - val_encoder_loss: 5.7010 - val_classifier_loss: 0.3538 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4469 - decoder_loss: 24.4298 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0391 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 329: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4469 - decoder_loss: 24.4298 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0391 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9789 - val_decoder_loss: 22.4133 - val_encoder_loss: 5.7022 - val_classifier_loss: 0.3537 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4465 - decoder_loss: 24.4264 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0391 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 330: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4465 - decoder_loss: 24.4264 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0391 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9798 - val_decoder_loss: 22.4111 - val_encoder_loss: 5.7034 - val_classifier_loss: 0.3537 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4462 - decoder_loss: 24.4230 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0390 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 331: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4462 - decoder_loss: 24.4230 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0390 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9807 - val_decoder_loss: 22.4089 - val_encoder_loss: 5.7045 - val_classifier_loss: 0.3536 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4459 - decoder_loss: 24.4196 - encoder_loss: 2.1302e-05 - classifier_loss: 0.0390 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 332: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4459 - decoder_loss: 24.4196 - encoder_loss: 2.1302e-05 - classifier_loss: 0.0390 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9798 - val_decoder_loss: 22.4069 - val_encoder_loss: 5.7037 - val_classifier_loss: 0.3535 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4456 - decoder_loss: 24.4166 - encoder_loss: 8.7668e-05 - classifier_loss: 0.0389 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 333: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4456 - decoder_loss: 24.4166 - encoder_loss: 8.7668e-05 - classifier_loss: 0.0389 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9729 - val_decoder_loss: 22.4054 - val_encoder_loss: 5.6971 - val_classifier_loss: 0.3534 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4453 - decoder_loss: 24.4138 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0389 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 334: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4453 - decoder_loss: 24.4138 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0389 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9749 - val_decoder_loss: 22.4032 - val_encoder_loss: 5.6993 - val_classifier_loss: 0.3534 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4449 - decoder_loss: 24.4104 - encoder_loss: 4.8738e-06 - classifier_loss: 0.0388 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 335: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4449 - decoder_loss: 24.4104 - encoder_loss: 4.8738e-06 - classifier_loss: 0.0388 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9876 - val_decoder_loss: 22.4013 - val_encoder_loss: 5.7122 - val_classifier_loss: 0.3531 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4446 - decoder_loss: 24.4076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0387 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 336: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4446 - decoder_loss: 24.4076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0387 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9885 - val_decoder_loss: 22.3991 - val_encoder_loss: 5.7133 - val_classifier_loss: 0.3530 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4443 - decoder_loss: 24.4043 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0387 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 337: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4443 - decoder_loss: 24.4043 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0387 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9895 - val_decoder_loss: 22.3970 - val_encoder_loss: 5.7146 - val_classifier_loss: 0.3529 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4440 - decoder_loss: 24.4009 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0387 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 338: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4440 - decoder_loss: 24.4009 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0387 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9906 - val_decoder_loss: 22.3948 - val_encoder_loss: 5.7158 - val_classifier_loss: 0.3528 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4437 - decoder_loss: 24.3976 - encoder_loss: 1.0437e-04 - classifier_loss: 0.0386 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 339: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4437 - decoder_loss: 24.3976 - encoder_loss: 1.0437e-04 - classifier_loss: 0.0386 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0037 - val_decoder_loss: 22.3930 - val_encoder_loss: 5.7291 - val_classifier_loss: 0.3526 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4434 - decoder_loss: 24.3952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0386 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 340: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4434 - decoder_loss: 24.3952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0386 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0042 - val_decoder_loss: 22.3910 - val_encoder_loss: 5.7299 - val_classifier_loss: 0.3525 - val_decoder_accuracy: 0.0353 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4430 - decoder_loss: 24.3918 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0385 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 341: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4430 - decoder_loss: 24.3918 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0385 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0057 - val_decoder_loss: 22.3888 - val_encoder_loss: 5.7316 - val_classifier_loss: 0.3524 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4427 - decoder_loss: 24.3885 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0385 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 342: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4427 - decoder_loss: 24.3885 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0385 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0072 - val_decoder_loss: 22.3867 - val_encoder_loss: 5.7333 - val_classifier_loss: 0.3523 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4424 - decoder_loss: 24.3851 - encoder_loss: 6.4498e-05 - classifier_loss: 0.0384 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 343: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4424 - decoder_loss: 24.3851 - encoder_loss: 6.4498e-05 - classifier_loss: 0.0384 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0222 - val_decoder_loss: 22.3853 - val_encoder_loss: 5.7485 - val_classifier_loss: 0.3520 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4435 - decoder_loss: 24.3834 - encoder_loss: 0.0013 - classifier_loss: 0.0383 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 344: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4435 - decoder_loss: 24.3834 - encoder_loss: 0.0013 - classifier_loss: 0.0383 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0145 - val_decoder_loss: 22.3832 - val_encoder_loss: 5.7411 - val_classifier_loss: 0.3513 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4420 - decoder_loss: 24.3801 - encoder_loss: 2.1515e-04 - classifier_loss: 0.0382 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 345: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4420 - decoder_loss: 24.3801 - encoder_loss: 2.1515e-04 - classifier_loss: 0.0382 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0030 - val_decoder_loss: 22.3813 - val_encoder_loss: 5.7299 - val_classifier_loss: 0.3505 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4415 - decoder_loss: 24.3773 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0381 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 346: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4415 - decoder_loss: 24.3773 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0381 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0028 - val_decoder_loss: 22.3791 - val_encoder_loss: 5.7299 - val_classifier_loss: 0.3503 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4412 - decoder_loss: 24.3740 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0381 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 347: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4412 - decoder_loss: 24.3740 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0381 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0031 - val_decoder_loss: 22.3770 - val_encoder_loss: 5.7304 - val_classifier_loss: 0.3501 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4409 - decoder_loss: 24.3707 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0381 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 348: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4409 - decoder_loss: 24.3707 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0381 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0034 - val_decoder_loss: 22.3750 - val_encoder_loss: 5.7309 - val_classifier_loss: 0.3500 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4405 - decoder_loss: 24.3673 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0380 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 349: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4405 - decoder_loss: 24.3673 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0380 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0038 - val_decoder_loss: 22.3729 - val_encoder_loss: 5.7315 - val_classifier_loss: 0.3499 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4402 - decoder_loss: 24.3640 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0380 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 350: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4402 - decoder_loss: 24.3640 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0380 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0041 - val_decoder_loss: 22.3708 - val_encoder_loss: 5.7321 - val_classifier_loss: 0.3497 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4399 - decoder_loss: 24.3606 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0379 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 351: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4399 - decoder_loss: 24.3606 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0379 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0045 - val_decoder_loss: 22.3687 - val_encoder_loss: 5.7326 - val_classifier_loss: 0.3496 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4395 - decoder_loss: 24.3572 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0379 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 352: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4395 - decoder_loss: 24.3572 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0379 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0049 - val_decoder_loss: 22.3666 - val_encoder_loss: 5.7333 - val_classifier_loss: 0.3495 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4393 - decoder_loss: 24.3538 - encoder_loss: 9.9262e-05 - classifier_loss: 0.0378 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 353: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4393 - decoder_loss: 24.3538 - encoder_loss: 9.9262e-05 - classifier_loss: 0.0378 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9903 - val_decoder_loss: 22.3660 - val_encoder_loss: 5.7188 - val_classifier_loss: 0.3493 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4390 - decoder_loss: 24.3521 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0378 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 354: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4390 - decoder_loss: 24.3521 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0378 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9927 - val_decoder_loss: 22.3640 - val_encoder_loss: 5.7213 - val_classifier_loss: 0.3493 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4386 - decoder_loss: 24.3488 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0377 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 355: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4386 - decoder_loss: 24.3488 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0377 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9926 - val_decoder_loss: 22.3619 - val_encoder_loss: 5.7215 - val_classifier_loss: 0.3493 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4383 - decoder_loss: 24.3454 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0377 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 356: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4383 - decoder_loss: 24.3454 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0377 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9924 - val_decoder_loss: 22.3599 - val_encoder_loss: 5.7215 - val_classifier_loss: 0.3492 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4380 - decoder_loss: 24.3421 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0376 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 357: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4380 - decoder_loss: 24.3421 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0376 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9922 - val_decoder_loss: 22.3579 - val_encoder_loss: 5.7215 - val_classifier_loss: 0.3491 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4376 - decoder_loss: 24.3387 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0376 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 358: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4376 - decoder_loss: 24.3387 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0376 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9921 - val_decoder_loss: 22.3558 - val_encoder_loss: 5.7216 - val_classifier_loss: 0.3490 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4373 - decoder_loss: 24.3354 - encoder_loss: 5.4234e-05 - classifier_loss: 0.0376 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 359: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4373 - decoder_loss: 24.3354 - encoder_loss: 5.4234e-05 - classifier_loss: 0.0376 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9902 - val_decoder_loss: 22.3540 - val_encoder_loss: 5.7199 - val_classifier_loss: 0.3490 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4370 - decoder_loss: 24.3324 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0375 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 360: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4370 - decoder_loss: 24.3324 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0375 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9903 - val_decoder_loss: 22.3520 - val_encoder_loss: 5.7202 - val_classifier_loss: 0.3489 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4367 - decoder_loss: 24.3291 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0375 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 361: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4367 - decoder_loss: 24.3291 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0375 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9903 - val_decoder_loss: 22.3499 - val_encoder_loss: 5.7204 - val_classifier_loss: 0.3488 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4364 - decoder_loss: 24.3257 - encoder_loss: 5.8646e-05 - classifier_loss: 0.0375 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 362: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4364 - decoder_loss: 24.3257 - encoder_loss: 5.8646e-05 - classifier_loss: 0.0375 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0202 - val_decoder_loss: 22.3487 - val_encoder_loss: 5.7506 - val_classifier_loss: 0.3482 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4362 - decoder_loss: 24.3250 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0374 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 363: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4362 - decoder_loss: 24.3250 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0374 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0177 - val_decoder_loss: 22.3468 - val_encoder_loss: 5.7482 - val_classifier_loss: 0.3481 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4359 - decoder_loss: 24.3218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0373 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 364: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4359 - decoder_loss: 24.3218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0373 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0190 - val_decoder_loss: 22.3449 - val_encoder_loss: 5.7497 - val_classifier_loss: 0.3480 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4356 - decoder_loss: 24.3185 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0373 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 365: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4356 - decoder_loss: 24.3185 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0373 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0205 - val_decoder_loss: 22.3429 - val_encoder_loss: 5.7514 - val_classifier_loss: 0.3479 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4353 - decoder_loss: 24.3153 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0373 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 366: val_loss did not improve from 7.71930\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4353 - decoder_loss: 24.3153 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0373 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0220 - val_decoder_loss: 22.3409 - val_encoder_loss: 5.7531 - val_classifier_loss: 0.3479 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 366: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_20 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_21 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_10 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_20 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_21 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 10.3225 - decoder_loss: 25.5625 - encoder_loss: 7.7029 - classifier_loss: 0.6335 - decoder_accuracy: 0.0350 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000\n",
            "F1-score is computed based on binary\n",
            "(loss: 10.322539329528809, accuracy: 0.699999988079071)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.73      0.71        15\n",
            "         1.0       0.71      0.67      0.69        15\n",
            "\n",
            "    accuracy                           0.70        30\n",
            "   macro avg       0.70      0.70      0.70        30\n",
            "weighted avg       0.70      0.70      0.70        30\n",
            "\n",
            "Accuracy: 0.699999988079071\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.699999988079071\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fold3"
      ],
      "metadata": {
        "id": "dGkjzHq8w0L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=10, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=200,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(3,4):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vcRgq-HKwcdX",
        "outputId": "b7a6f308-c065-41c6-9536-463dab97d1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 3\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_22 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_23 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_11 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_22 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_23 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.2092 - decoder_loss: 27.4664 - encoder_loss: 3.3959 - classifier_loss: 0.6669 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6500\n",
            "Epoch 1: val_loss improved from inf to 83.45241, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.2092 - decoder_loss: 27.4664 - encoder_loss: 3.3959 - classifier_loss: 0.6669 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6500 - val_loss: 83.4524 - val_decoder_loss: 20.0633 - val_encoder_loss: 81.3368 - val_classifier_loss: 1.0931 - val_decoder_accuracy: 0.0147 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.8173 - decoder_loss: 27.4597 - encoder_loss: 1.0037 - classifier_loss: 0.6755 - decoder_accuracy: 0.0151 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6000\n",
            "Epoch 2: val_loss improved from 83.45241 to 10.20811, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 3.8173 - decoder_loss: 27.4597 - encoder_loss: 1.0037 - classifier_loss: 0.6755 - decoder_accuracy: 0.0151 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6000 - val_loss: 10.2081 - val_decoder_loss: 20.0475 - val_encoder_loss: 8.1425 - val_classifier_loss: 0.6085 - val_decoder_accuracy: 0.0132 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 12.3077 - decoder_loss: 27.4680 - encoder_loss: 9.5096 - classifier_loss: 0.5131 - decoder_accuracy: 0.0162 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000\n",
            "Epoch 3: val_loss improved from 10.20811 to 5.89887, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 12.3077 - decoder_loss: 27.4680 - encoder_loss: 9.5096 - classifier_loss: 0.5131 - decoder_accuracy: 0.0162 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000 - val_loss: 5.8989 - val_decoder_loss: 20.0343 - val_encoder_loss: 3.8361 - val_classifier_loss: 0.5930 - val_decoder_accuracy: 0.0167 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5288 - decoder_loss: 27.4413 - encoder_loss: 2.7169 - classifier_loss: 0.6773 - decoder_accuracy: 0.0185 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6250\n",
            "Epoch 4: val_loss did not improve from 5.89887\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.5288 - decoder_loss: 27.4413 - encoder_loss: 2.7169 - classifier_loss: 0.6773 - decoder_accuracy: 0.0185 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6250 - val_loss: 8.7537 - val_decoder_loss: 19.9888 - val_encoder_loss: 6.6741 - val_classifier_loss: 0.8080 - val_decoder_accuracy: 0.0165 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7261 - decoder_loss: 27.3864 - encoder_loss: 0.9348 - classifier_loss: 0.5267 - decoder_accuracy: 0.0195 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.7750\n",
            "Epoch 5: val_loss did not improve from 5.89887\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.7261 - decoder_loss: 27.3864 - encoder_loss: 0.9348 - classifier_loss: 0.5267 - decoder_accuracy: 0.0195 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.7750 - val_loss: 12.7941 - val_decoder_loss: 19.8363 - val_encoder_loss: 10.7242 - val_classifier_loss: 0.8625 - val_decoder_accuracy: 0.0113 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.7442 - decoder_loss: 27.1254 - encoder_loss: 3.9867 - classifier_loss: 0.4491 - decoder_accuracy: 0.0161 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750\n",
            "Epoch 6: val_loss improved from 5.89887 to 3.81789, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 6.7442 - decoder_loss: 27.1254 - encoder_loss: 3.9867 - classifier_loss: 0.4491 - decoder_accuracy: 0.0161 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750 - val_loss: 3.8179 - val_decoder_loss: 19.7607 - val_encoder_loss: 1.7711 - val_classifier_loss: 0.7075 - val_decoder_accuracy: 0.0180 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1362 - decoder_loss: 26.9674 - encoder_loss: 0.4043 - classifier_loss: 0.3511 - decoder_accuracy: 0.0169 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750\n",
            "Epoch 7: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.1362 - decoder_loss: 26.9674 - encoder_loss: 0.4043 - classifier_loss: 0.3511 - decoder_accuracy: 0.0169 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750 - val_loss: 6.0212 - val_decoder_loss: 20.0120 - val_encoder_loss: 3.9441 - val_classifier_loss: 0.7588 - val_decoder_accuracy: 0.0152 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2501 - decoder_loss: 27.0968 - encoder_loss: 0.5178 - classifier_loss: 0.2264 - decoder_accuracy: 0.0227 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250\n",
            "Epoch 8: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3.2501 - decoder_loss: 27.0968 - encoder_loss: 0.5178 - classifier_loss: 0.2264 - decoder_accuracy: 0.0227 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250 - val_loss: 5.2996 - val_decoder_loss: 19.5370 - val_encoder_loss: 3.2878 - val_classifier_loss: 0.5803 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1970 - decoder_loss: 26.7690 - encoder_loss: 0.4956 - classifier_loss: 0.2450 - decoder_accuracy: 0.0328 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 9: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3.1970 - decoder_loss: 26.7690 - encoder_loss: 0.4956 - classifier_loss: 0.2450 - decoder_accuracy: 0.0328 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 14.7865 - val_decoder_loss: 19.8268 - val_encoder_loss: 12.7237 - val_classifier_loss: 0.8011 - val_decoder_accuracy: 0.0187 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.6967 - decoder_loss: 26.9432 - encoder_loss: 0.9869 - classifier_loss: 0.1550 - decoder_accuracy: 0.0309 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 10: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3.6967 - decoder_loss: 26.9432 - encoder_loss: 0.9869 - classifier_loss: 0.1550 - decoder_accuracy: 0.0309 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 10.1882 - val_decoder_loss: 19.5901 - val_encoder_loss: 8.1091 - val_classifier_loss: 1.2016 - val_decoder_accuracy: 0.0245 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.7031 - decoder_loss: 27.4454 - encoder_loss: 3.9214 - classifier_loss: 0.3709 - decoder_accuracy: 0.0268 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 11: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 6.7031 - decoder_loss: 27.4454 - encoder_loss: 3.9214 - classifier_loss: 0.3709 - decoder_accuracy: 0.0268 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 14.7766 - val_decoder_loss: 20.2713 - val_encoder_loss: 12.6587 - val_classifier_loss: 0.9080 - val_decoder_accuracy: 0.0195 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7550 - decoder_loss: 27.4154 - encoder_loss: 0.0080 - classifier_loss: 0.0551 - decoder_accuracy: 0.0355 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 12: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.7550 - decoder_loss: 27.4154 - encoder_loss: 0.0080 - classifier_loss: 0.0551 - decoder_accuracy: 0.0355 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 12.0661 - val_decoder_loss: 19.8028 - val_encoder_loss: 10.0096 - val_classifier_loss: 0.7622 - val_decoder_accuracy: 0.0207 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6958 - decoder_loss: 26.9191 - encoder_loss: 5.4489e-04 - classifier_loss: 0.0338 - decoder_accuracy: 0.0350 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.6958 - decoder_loss: 26.9191 - encoder_loss: 5.4489e-04 - classifier_loss: 0.0338 - decoder_accuracy: 0.0350 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 12.5919 - val_decoder_loss: 19.6776 - val_encoder_loss: 10.5447 - val_classifier_loss: 0.7940 - val_decoder_accuracy: 0.0253 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6862 - decoder_loss: 26.7833 - encoder_loss: 0.0049 - classifier_loss: 0.0290 - decoder_accuracy: 0.0355 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.6862 - decoder_loss: 26.7833 - encoder_loss: 0.0049 - classifier_loss: 0.0290 - decoder_accuracy: 0.0355 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.1778 - val_decoder_loss: 19.6114 - val_encoder_loss: 11.1350 - val_classifier_loss: 0.8164 - val_decoder_accuracy: 0.0245 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6735 - decoder_loss: 26.7085 - encoder_loss: 5.0334e-04 - classifier_loss: 0.0212 - decoder_accuracy: 0.0386 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.6735 - decoder_loss: 26.7085 - encoder_loss: 5.0334e-04 - classifier_loss: 0.0212 - decoder_accuracy: 0.0386 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.4912 - val_decoder_loss: 19.5258 - val_encoder_loss: 11.4557 - val_classifier_loss: 0.8298 - val_decoder_accuracy: 0.0247 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6622 - decoder_loss: 26.6036 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0408 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.6622 - decoder_loss: 26.6036 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0408 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7558 - val_decoder_loss: 19.5091 - val_encoder_loss: 11.7207 - val_classifier_loss: 0.8416 - val_decoder_accuracy: 0.0235 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6535 - decoder_loss: 26.5026 - encoder_loss: 0.0016 - classifier_loss: 0.0166 - decoder_accuracy: 0.0429 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.6535 - decoder_loss: 26.5026 - encoder_loss: 0.0016 - classifier_loss: 0.0166 - decoder_accuracy: 0.0429 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8699 - val_decoder_loss: 19.4202 - val_encoder_loss: 11.8432 - val_classifier_loss: 0.8466 - val_decoder_accuracy: 0.0250 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6468 - decoder_loss: 26.4424 - encoder_loss: 0.0010 - classifier_loss: 0.0153 - decoder_accuracy: 0.0443 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.6468 - decoder_loss: 26.4424 - encoder_loss: 0.0010 - classifier_loss: 0.0153 - decoder_accuracy: 0.0443 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7954 - val_decoder_loss: 19.4308 - val_encoder_loss: 11.7677 - val_classifier_loss: 0.8463 - val_decoder_accuracy: 0.0255 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6405 - decoder_loss: 26.3774 - encoder_loss: 0.0013 - classifier_loss: 0.0139 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.6405 - decoder_loss: 26.3774 - encoder_loss: 0.0013 - classifier_loss: 0.0139 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8948 - val_decoder_loss: 19.3487 - val_encoder_loss: 11.8758 - val_classifier_loss: 0.8413 - val_decoder_accuracy: 0.0275 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6323 - decoder_loss: 26.3097 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.6323 - decoder_loss: 26.3097 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9747 - val_decoder_loss: 19.3575 - val_encoder_loss: 11.9545 - val_classifier_loss: 0.8440 - val_decoder_accuracy: 0.0273 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6240 - decoder_loss: 26.2280 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.6240 - decoder_loss: 26.2280 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0122 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0078 - val_decoder_loss: 19.2670 - val_encoder_loss: 11.9963 - val_classifier_loss: 0.8479 - val_decoder_accuracy: 0.0290 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6157 - decoder_loss: 26.1456 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0117 - decoder_accuracy: 0.0502 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.6157 - decoder_loss: 26.1456 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0117 - decoder_accuracy: 0.0502 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0220 - val_decoder_loss: 19.2722 - val_encoder_loss: 12.0097 - val_classifier_loss: 0.8514 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6108 - decoder_loss: 26.0865 - encoder_loss: 9.6841e-04 - classifier_loss: 0.0114 - decoder_accuracy: 0.0502 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.6108 - decoder_loss: 26.0865 - encoder_loss: 9.6841e-04 - classifier_loss: 0.0114 - decoder_accuracy: 0.0502 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0736 - val_decoder_loss: 19.2502 - val_encoder_loss: 12.0638 - val_classifier_loss: 0.8479 - val_decoder_accuracy: 0.0290 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6052 - decoder_loss: 26.0406 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0111 - decoder_accuracy: 0.0505 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.6052 - decoder_loss: 26.0406 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0111 - decoder_accuracy: 0.0505 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.1006 - val_decoder_loss: 19.2289 - val_encoder_loss: 12.0928 - val_classifier_loss: 0.8496 - val_decoder_accuracy: 0.0295 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6002 - decoder_loss: 25.9910 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0508 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.6002 - decoder_loss: 25.9910 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0508 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.1214 - val_decoder_loss: 19.2078 - val_encoder_loss: 12.1156 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5959 - decoder_loss: 25.9398 - encoder_loss: 8.5945e-04 - classifier_loss: 0.0106 - decoder_accuracy: 0.0515 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5959 - decoder_loss: 25.9398 - encoder_loss: 8.5945e-04 - classifier_loss: 0.0106 - decoder_accuracy: 0.0515 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0185 - val_decoder_loss: 19.1858 - val_encoder_loss: 12.0150 - val_classifier_loss: 0.8490 - val_decoder_accuracy: 0.0302 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5897 - decoder_loss: 25.8870 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5897 - decoder_loss: 25.8870 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0535 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0385 - val_decoder_loss: 19.1760 - val_encoder_loss: 12.0358 - val_classifier_loss: 0.8512 - val_decoder_accuracy: 0.0308 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5870 - decoder_loss: 25.8600 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0102 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5870 - decoder_loss: 25.8600 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0102 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0430 - val_decoder_loss: 19.1658 - val_encoder_loss: 12.0412 - val_classifier_loss: 0.8518 - val_decoder_accuracy: 0.0313 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5861 - decoder_loss: 25.8326 - encoder_loss: 0.0018 - classifier_loss: 0.0101 - decoder_accuracy: 0.0546 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5861 - decoder_loss: 25.8326 - encoder_loss: 0.0018 - classifier_loss: 0.0101 - decoder_accuracy: 0.0546 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0386 - val_decoder_loss: 19.1555 - val_encoder_loss: 12.0381 - val_classifier_loss: 0.8494 - val_decoder_accuracy: 0.0317 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5822 - decoder_loss: 25.8074 - encoder_loss: 4.1249e-04 - classifier_loss: 0.0100 - decoder_accuracy: 0.0550 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5822 - decoder_loss: 25.8074 - encoder_loss: 4.1249e-04 - classifier_loss: 0.0100 - decoder_accuracy: 0.0550 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0082 - val_decoder_loss: 19.1449 - val_encoder_loss: 12.0088 - val_classifier_loss: 0.8492 - val_decoder_accuracy: 0.0322 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5790 - decoder_loss: 25.7800 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0553 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5790 - decoder_loss: 25.7800 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0553 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0138 - val_decoder_loss: 19.1347 - val_encoder_loss: 12.0153 - val_classifier_loss: 0.8499 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5762 - decoder_loss: 25.7522 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0553 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5762 - decoder_loss: 25.7522 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0553 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0122 - val_decoder_loss: 19.1297 - val_encoder_loss: 12.0142 - val_classifier_loss: 0.8503 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5748 - decoder_loss: 25.7382 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5748 - decoder_loss: 25.7382 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0099 - val_decoder_loss: 19.1247 - val_encoder_loss: 12.0124 - val_classifier_loss: 0.8504 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5734 - decoder_loss: 25.7241 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 34: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5734 - decoder_loss: 25.7241 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0074 - val_decoder_loss: 19.1197 - val_encoder_loss: 12.0104 - val_classifier_loss: 0.8505 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5720 - decoder_loss: 25.7099 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5720 - decoder_loss: 25.7099 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0047 - val_decoder_loss: 19.1148 - val_encoder_loss: 12.0082 - val_classifier_loss: 0.8505 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5705 - decoder_loss: 25.6957 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5705 - decoder_loss: 25.6957 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0020 - val_decoder_loss: 19.1100 - val_encoder_loss: 12.0059 - val_classifier_loss: 0.8506 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5691 - decoder_loss: 25.6815 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5691 - decoder_loss: 25.6815 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0004 - val_decoder_loss: 19.1076 - val_encoder_loss: 12.0046 - val_classifier_loss: 0.8507 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5684 - decoder_loss: 25.6744 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0560 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5684 - decoder_loss: 25.6744 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0560 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9989 - val_decoder_loss: 19.1052 - val_encoder_loss: 12.0033 - val_classifier_loss: 0.8507 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5677 - decoder_loss: 25.6673 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0561 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5677 - decoder_loss: 25.6673 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0561 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9973 - val_decoder_loss: 19.1029 - val_encoder_loss: 12.0020 - val_classifier_loss: 0.8507 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5670 - decoder_loss: 25.6601 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5670 - decoder_loss: 25.6601 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9957 - val_decoder_loss: 19.1005 - val_encoder_loss: 12.0006 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5662 - decoder_loss: 25.6530 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5662 - decoder_loss: 25.6530 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9940 - val_decoder_loss: 19.0982 - val_encoder_loss: 11.9991 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5655 - decoder_loss: 25.6458 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5655 - decoder_loss: 25.6458 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9929 - val_decoder_loss: 19.0967 - val_encoder_loss: 11.9982 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5651 - decoder_loss: 25.6412 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5651 - decoder_loss: 25.6412 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9918 - val_decoder_loss: 19.0952 - val_encoder_loss: 11.9972 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0353 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5646 - decoder_loss: 25.6366 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5646 - decoder_loss: 25.6366 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9907 - val_decoder_loss: 19.0937 - val_encoder_loss: 11.9962 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5641 - decoder_loss: 25.6320 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5641 - decoder_loss: 25.6320 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9895 - val_decoder_loss: 19.0923 - val_encoder_loss: 11.9952 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5637 - decoder_loss: 25.6273 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0566 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5637 - decoder_loss: 25.6273 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0566 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9883 - val_decoder_loss: 19.0908 - val_encoder_loss: 11.9942 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5632 - decoder_loss: 25.6227 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5632 - decoder_loss: 25.6227 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9871 - val_decoder_loss: 19.0894 - val_encoder_loss: 11.9931 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5627 - decoder_loss: 25.6181 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5627 - decoder_loss: 25.6181 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9859 - val_decoder_loss: 19.0879 - val_encoder_loss: 11.9920 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5623 - decoder_loss: 25.6135 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 49: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5623 - decoder_loss: 25.6135 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9847 - val_decoder_loss: 19.0864 - val_encoder_loss: 11.9909 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5618 - decoder_loss: 25.6089 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5618 - decoder_loss: 25.6089 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9834 - val_decoder_loss: 19.0850 - val_encoder_loss: 11.9898 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5614 - decoder_loss: 25.6043 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5614 - decoder_loss: 25.6043 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9822 - val_decoder_loss: 19.0835 - val_encoder_loss: 11.9887 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5609 - decoder_loss: 25.5998 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5609 - decoder_loss: 25.5998 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9809 - val_decoder_loss: 19.0821 - val_encoder_loss: 11.9876 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5605 - decoder_loss: 25.5952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5605 - decoder_loss: 25.5952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9796 - val_decoder_loss: 19.0807 - val_encoder_loss: 11.9864 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5600 - decoder_loss: 25.5906 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5600 - decoder_loss: 25.5906 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9783 - val_decoder_loss: 19.0793 - val_encoder_loss: 11.9852 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5595 - decoder_loss: 25.5861 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5595 - decoder_loss: 25.5861 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9769 - val_decoder_loss: 19.0779 - val_encoder_loss: 11.9841 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5591 - decoder_loss: 25.5815 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5591 - decoder_loss: 25.5815 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9756 - val_decoder_loss: 19.0765 - val_encoder_loss: 11.9829 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5586 - decoder_loss: 25.5769 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5586 - decoder_loss: 25.5769 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9743 - val_decoder_loss: 19.0751 - val_encoder_loss: 11.9817 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5582 - decoder_loss: 25.5724 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 58: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5582 - decoder_loss: 25.5724 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9729 - val_decoder_loss: 19.0737 - val_encoder_loss: 11.9804 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5577 - decoder_loss: 25.5678 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 59: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5577 - decoder_loss: 25.5678 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9715 - val_decoder_loss: 19.0724 - val_encoder_loss: 11.9792 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0373 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5573 - decoder_loss: 25.5633 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 60: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5573 - decoder_loss: 25.5633 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9702 - val_decoder_loss: 19.0710 - val_encoder_loss: 11.9780 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5568 - decoder_loss: 25.5587 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 61: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5568 - decoder_loss: 25.5587 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9688 - val_decoder_loss: 19.0696 - val_encoder_loss: 11.9767 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5563 - decoder_loss: 25.5542 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 62: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5563 - decoder_loss: 25.5542 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9674 - val_decoder_loss: 19.0683 - val_encoder_loss: 11.9754 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5559 - decoder_loss: 25.5496 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 63: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5559 - decoder_loss: 25.5496 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9660 - val_decoder_loss: 19.0670 - val_encoder_loss: 11.9742 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5554 - decoder_loss: 25.5451 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5554 - decoder_loss: 25.5451 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9646 - val_decoder_loss: 19.0656 - val_encoder_loss: 11.9729 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5550 - decoder_loss: 25.5405 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 65: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5550 - decoder_loss: 25.5405 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9631 - val_decoder_loss: 19.0643 - val_encoder_loss: 11.9716 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5545 - decoder_loss: 25.5360 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 66: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5545 - decoder_loss: 25.5360 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9617 - val_decoder_loss: 19.0630 - val_encoder_loss: 11.9703 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5541 - decoder_loss: 25.5315 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 67: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5541 - decoder_loss: 25.5315 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9603 - val_decoder_loss: 19.0617 - val_encoder_loss: 11.9690 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5536 - decoder_loss: 25.5269 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 68: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5536 - decoder_loss: 25.5269 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9588 - val_decoder_loss: 19.0604 - val_encoder_loss: 11.9677 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5532 - decoder_loss: 25.5224 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 69: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5532 - decoder_loss: 25.5224 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9574 - val_decoder_loss: 19.0592 - val_encoder_loss: 11.9664 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0373 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5527 - decoder_loss: 25.5179 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 70: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5527 - decoder_loss: 25.5179 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9559 - val_decoder_loss: 19.0579 - val_encoder_loss: 11.9650 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5523 - decoder_loss: 25.5134 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 71: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5523 - decoder_loss: 25.5134 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9545 - val_decoder_loss: 19.0566 - val_encoder_loss: 11.9637 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0373 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5518 - decoder_loss: 25.5089 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 72: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5518 - decoder_loss: 25.5089 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9530 - val_decoder_loss: 19.0554 - val_encoder_loss: 11.9624 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5514 - decoder_loss: 25.5044 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 73: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5514 - decoder_loss: 25.5044 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9515 - val_decoder_loss: 19.0542 - val_encoder_loss: 11.9610 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0373 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5509 - decoder_loss: 25.4999 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 74: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5509 - decoder_loss: 25.4999 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9500 - val_decoder_loss: 19.0529 - val_encoder_loss: 11.9596 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5505 - decoder_loss: 25.4954 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 75: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5505 - decoder_loss: 25.4954 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9486 - val_decoder_loss: 19.0517 - val_encoder_loss: 11.9583 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5500 - decoder_loss: 25.4910 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 76: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5500 - decoder_loss: 25.4910 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9471 - val_decoder_loss: 19.0506 - val_encoder_loss: 11.9569 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5496 - decoder_loss: 25.4867 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 77: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5496 - decoder_loss: 25.4867 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9456 - val_decoder_loss: 19.0494 - val_encoder_loss: 11.9556 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5491 - decoder_loss: 25.4823 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 78: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5491 - decoder_loss: 25.4823 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9441 - val_decoder_loss: 19.0482 - val_encoder_loss: 11.9542 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5487 - decoder_loss: 25.4780 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 79: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5487 - decoder_loss: 25.4780 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9426 - val_decoder_loss: 19.0471 - val_encoder_loss: 11.9528 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5483 - decoder_loss: 25.4737 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 80: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5483 - decoder_loss: 25.4737 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9411 - val_decoder_loss: 19.0459 - val_encoder_loss: 11.9514 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5478 - decoder_loss: 25.4694 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 81: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5478 - decoder_loss: 25.4694 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9396 - val_decoder_loss: 19.0448 - val_encoder_loss: 11.9500 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5474 - decoder_loss: 25.4651 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 82: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5474 - decoder_loss: 25.4651 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9381 - val_decoder_loss: 19.0437 - val_encoder_loss: 11.9487 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5470 - decoder_loss: 25.4608 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 83: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5470 - decoder_loss: 25.4608 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9366 - val_decoder_loss: 19.0426 - val_encoder_loss: 11.9473 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5466 - decoder_loss: 25.4565 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 84: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5466 - decoder_loss: 25.4565 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9351 - val_decoder_loss: 19.0415 - val_encoder_loss: 11.9459 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5461 - decoder_loss: 25.4522 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 85: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5461 - decoder_loss: 25.4522 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9336 - val_decoder_loss: 19.0404 - val_encoder_loss: 11.9445 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5457 - decoder_loss: 25.4479 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 86: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5457 - decoder_loss: 25.4479 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9321 - val_decoder_loss: 19.0393 - val_encoder_loss: 11.9431 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5453 - decoder_loss: 25.4436 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 87: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5453 - decoder_loss: 25.4436 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9306 - val_decoder_loss: 19.0382 - val_encoder_loss: 11.9417 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5448 - decoder_loss: 25.4394 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5448 - decoder_loss: 25.4394 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9039 - val_decoder_loss: 19.0372 - val_encoder_loss: 11.9151 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5444 - decoder_loss: 25.4352 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5444 - decoder_loss: 25.4352 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9023 - val_decoder_loss: 19.0361 - val_encoder_loss: 11.9136 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5440 - decoder_loss: 25.4310 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5440 - decoder_loss: 25.4310 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9007 - val_decoder_loss: 19.0351 - val_encoder_loss: 11.9121 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0373 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5436 - decoder_loss: 25.4268 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5436 - decoder_loss: 25.4268 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8990 - val_decoder_loss: 19.0341 - val_encoder_loss: 11.9105 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5432 - decoder_loss: 25.4226 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5432 - decoder_loss: 25.4226 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8974 - val_decoder_loss: 19.0330 - val_encoder_loss: 11.9090 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5427 - decoder_loss: 25.4184 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 93: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5427 - decoder_loss: 25.4184 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8957 - val_decoder_loss: 19.0320 - val_encoder_loss: 11.9074 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5423 - decoder_loss: 25.4143 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 94: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5423 - decoder_loss: 25.4143 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8941 - val_decoder_loss: 19.0310 - val_encoder_loss: 11.9059 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5419 - decoder_loss: 25.4101 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5419 - decoder_loss: 25.4101 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8924 - val_decoder_loss: 19.0301 - val_encoder_loss: 11.9043 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5415 - decoder_loss: 25.4060 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 96: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5415 - decoder_loss: 25.4060 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8908 - val_decoder_loss: 19.0291 - val_encoder_loss: 11.9028 - val_classifier_loss: 0.8511 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5411 - decoder_loss: 25.4018 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 97: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5411 - decoder_loss: 25.4018 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8891 - val_decoder_loss: 19.0281 - val_encoder_loss: 11.9012 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5407 - decoder_loss: 25.3977 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 98: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5407 - decoder_loss: 25.3977 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8875 - val_decoder_loss: 19.0271 - val_encoder_loss: 11.8996 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5403 - decoder_loss: 25.3936 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 99: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5403 - decoder_loss: 25.3936 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8858 - val_decoder_loss: 19.0262 - val_encoder_loss: 11.8981 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0373 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5398 - decoder_loss: 25.3895 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5398 - decoder_loss: 25.3895 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8841 - val_decoder_loss: 19.0252 - val_encoder_loss: 11.8965 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0373 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5394 - decoder_loss: 25.3854 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5394 - decoder_loss: 25.3854 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8825 - val_decoder_loss: 19.0243 - val_encoder_loss: 11.8949 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5390 - decoder_loss: 25.3813 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5390 - decoder_loss: 25.3813 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8808 - val_decoder_loss: 19.0234 - val_encoder_loss: 11.8934 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5386 - decoder_loss: 25.3773 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5386 - decoder_loss: 25.3773 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0089 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8792 - val_decoder_loss: 19.0225 - val_encoder_loss: 11.8918 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5382 - decoder_loss: 25.3732 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5382 - decoder_loss: 25.3732 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8775 - val_decoder_loss: 19.0216 - val_encoder_loss: 11.8902 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5378 - decoder_loss: 25.3692 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5378 - decoder_loss: 25.3692 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8758 - val_decoder_loss: 19.0207 - val_encoder_loss: 11.8887 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5374 - decoder_loss: 25.3651 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5374 - decoder_loss: 25.3651 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8742 - val_decoder_loss: 19.0198 - val_encoder_loss: 11.8871 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5370 - decoder_loss: 25.3611 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5370 - decoder_loss: 25.3611 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8725 - val_decoder_loss: 19.0189 - val_encoder_loss: 11.8855 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0388 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5366 - decoder_loss: 25.3571 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5366 - decoder_loss: 25.3571 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8709 - val_decoder_loss: 19.0180 - val_encoder_loss: 11.8840 - val_classifier_loss: 0.8510 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5362 - decoder_loss: 25.3531 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 109: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5362 - decoder_loss: 25.3531 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8692 - val_decoder_loss: 19.0172 - val_encoder_loss: 11.8824 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5358 - decoder_loss: 25.3491 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5358 - decoder_loss: 25.3491 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8675 - val_decoder_loss: 19.0163 - val_encoder_loss: 11.8808 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0388 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5354 - decoder_loss: 25.3451 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5354 - decoder_loss: 25.3451 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8659 - val_decoder_loss: 19.0155 - val_encoder_loss: 11.8792 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5350 - decoder_loss: 25.3411 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5350 - decoder_loss: 25.3411 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8642 - val_decoder_loss: 19.0146 - val_encoder_loss: 11.8777 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0388 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5346 - decoder_loss: 25.3371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5346 - decoder_loss: 25.3371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0088 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8626 - val_decoder_loss: 19.0138 - val_encoder_loss: 11.8761 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5342 - decoder_loss: 25.3332 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5342 - decoder_loss: 25.3332 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8609 - val_decoder_loss: 19.0130 - val_encoder_loss: 11.8745 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0388 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5338 - decoder_loss: 25.3292 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5338 - decoder_loss: 25.3292 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8592 - val_decoder_loss: 19.0122 - val_encoder_loss: 11.8729 - val_classifier_loss: 0.8509 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5334 - decoder_loss: 25.3253 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.5334 - decoder_loss: 25.3253 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8576 - val_decoder_loss: 19.0114 - val_encoder_loss: 11.8714 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5330 - decoder_loss: 25.3214 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5330 - decoder_loss: 25.3214 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8559 - val_decoder_loss: 19.0106 - val_encoder_loss: 11.8698 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5326 - decoder_loss: 25.3175 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0596 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5326 - decoder_loss: 25.3175 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0596 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8543 - val_decoder_loss: 19.0098 - val_encoder_loss: 11.8682 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5322 - decoder_loss: 25.3135 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0596 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5322 - decoder_loss: 25.3135 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0596 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8526 - val_decoder_loss: 19.0090 - val_encoder_loss: 11.8667 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0392 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5318 - decoder_loss: 25.3097 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0596 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5318 - decoder_loss: 25.3097 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0596 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8510 - val_decoder_loss: 19.0082 - val_encoder_loss: 11.8651 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0393 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5314 - decoder_loss: 25.3058 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0598 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 121: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5314 - decoder_loss: 25.3058 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0598 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8493 - val_decoder_loss: 19.0075 - val_encoder_loss: 11.8635 - val_classifier_loss: 0.8508 - val_decoder_accuracy: 0.0395 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5311 - decoder_loss: 25.3019 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5311 - decoder_loss: 25.3019 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8477 - val_decoder_loss: 19.0067 - val_encoder_loss: 11.8619 - val_classifier_loss: 0.8507 - val_decoder_accuracy: 0.0395 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5307 - decoder_loss: 25.2980 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5307 - decoder_loss: 25.2980 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0087 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8460 - val_decoder_loss: 19.0060 - val_encoder_loss: 11.8604 - val_classifier_loss: 0.8507 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5303 - decoder_loss: 25.2942 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5303 - decoder_loss: 25.2942 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8444 - val_decoder_loss: 19.0053 - val_encoder_loss: 11.8588 - val_classifier_loss: 0.8507 - val_decoder_accuracy: 0.0392 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5299 - decoder_loss: 25.2903 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5299 - decoder_loss: 25.2903 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8428 - val_decoder_loss: 19.0045 - val_encoder_loss: 11.8572 - val_classifier_loss: 0.8507 - val_decoder_accuracy: 0.0395 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5295 - decoder_loss: 25.2865 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5295 - decoder_loss: 25.2865 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8411 - val_decoder_loss: 19.0038 - val_encoder_loss: 11.8557 - val_classifier_loss: 0.8507 - val_decoder_accuracy: 0.0395 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5291 - decoder_loss: 25.2827 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5291 - decoder_loss: 25.2827 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8395 - val_decoder_loss: 19.0031 - val_encoder_loss: 11.8541 - val_classifier_loss: 0.8507 - val_decoder_accuracy: 0.0393 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5287 - decoder_loss: 25.2789 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5287 - decoder_loss: 25.2789 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8379 - val_decoder_loss: 19.0024 - val_encoder_loss: 11.8526 - val_classifier_loss: 0.8506 - val_decoder_accuracy: 0.0393 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5284 - decoder_loss: 25.2751 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5284 - decoder_loss: 25.2751 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8362 - val_decoder_loss: 19.0017 - val_encoder_loss: 11.8510 - val_classifier_loss: 0.8506 - val_decoder_accuracy: 0.0395 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5280 - decoder_loss: 25.2713 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5280 - decoder_loss: 25.2713 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8346 - val_decoder_loss: 19.0010 - val_encoder_loss: 11.8494 - val_classifier_loss: 0.8506 - val_decoder_accuracy: 0.0397 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5276 - decoder_loss: 25.2675 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5276 - decoder_loss: 25.2675 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8330 - val_decoder_loss: 19.0004 - val_encoder_loss: 11.8479 - val_classifier_loss: 0.8506 - val_decoder_accuracy: 0.0398 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5272 - decoder_loss: 25.2637 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5272 - decoder_loss: 25.2637 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0086 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8314 - val_decoder_loss: 18.9997 - val_encoder_loss: 11.8463 - val_classifier_loss: 0.8505 - val_decoder_accuracy: 0.0400 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5269 - decoder_loss: 25.2600 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5269 - decoder_loss: 25.2600 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8297 - val_decoder_loss: 18.9990 - val_encoder_loss: 11.8448 - val_classifier_loss: 0.8505 - val_decoder_accuracy: 0.0397 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5265 - decoder_loss: 25.2562 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0603 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5265 - decoder_loss: 25.2562 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0603 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8281 - val_decoder_loss: 18.9984 - val_encoder_loss: 11.8432 - val_classifier_loss: 0.8505 - val_decoder_accuracy: 0.0397 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5261 - decoder_loss: 25.2525 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5261 - decoder_loss: 25.2525 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8265 - val_decoder_loss: 18.9977 - val_encoder_loss: 11.8417 - val_classifier_loss: 0.8505 - val_decoder_accuracy: 0.0398 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5257 - decoder_loss: 25.2488 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5257 - decoder_loss: 25.2488 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8249 - val_decoder_loss: 18.9971 - val_encoder_loss: 11.8402 - val_classifier_loss: 0.8505 - val_decoder_accuracy: 0.0397 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5254 - decoder_loss: 25.2450 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5254 - decoder_loss: 25.2450 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8233 - val_decoder_loss: 18.9965 - val_encoder_loss: 11.8386 - val_classifier_loss: 0.8504 - val_decoder_accuracy: 0.0398 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5250 - decoder_loss: 25.2413 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5250 - decoder_loss: 25.2413 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8217 - val_decoder_loss: 18.9959 - val_encoder_loss: 11.8371 - val_classifier_loss: 0.8504 - val_decoder_accuracy: 0.0400 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5246 - decoder_loss: 25.2376 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5246 - decoder_loss: 25.2376 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8201 - val_decoder_loss: 18.9953 - val_encoder_loss: 11.8355 - val_classifier_loss: 0.8504 - val_decoder_accuracy: 0.0398 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5242 - decoder_loss: 25.2339 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5242 - decoder_loss: 25.2339 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8185 - val_decoder_loss: 18.9947 - val_encoder_loss: 11.8340 - val_classifier_loss: 0.8504 - val_decoder_accuracy: 0.0402 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5239 - decoder_loss: 25.2303 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 141: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5239 - decoder_loss: 25.2303 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8169 - val_decoder_loss: 18.9941 - val_encoder_loss: 11.8325 - val_classifier_loss: 0.8503 - val_decoder_accuracy: 0.0403 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5235 - decoder_loss: 25.2266 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0606 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5235 - decoder_loss: 25.2266 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0085 - decoder_accuracy: 0.0606 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8153 - val_decoder_loss: 18.9935 - val_encoder_loss: 11.8310 - val_classifier_loss: 0.8503 - val_decoder_accuracy: 0.0405 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5231 - decoder_loss: 25.2229 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0606 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5231 - decoder_loss: 25.2229 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0606 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8137 - val_decoder_loss: 18.9929 - val_encoder_loss: 11.8294 - val_classifier_loss: 0.8503 - val_decoder_accuracy: 0.0410 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5228 - decoder_loss: 25.2193 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5228 - decoder_loss: 25.2193 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8122 - val_decoder_loss: 18.9923 - val_encoder_loss: 11.8279 - val_classifier_loss: 0.8502 - val_decoder_accuracy: 0.0410 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5224 - decoder_loss: 25.2156 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0606 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5224 - decoder_loss: 25.2156 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0606 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8106 - val_decoder_loss: 18.9918 - val_encoder_loss: 11.8264 - val_classifier_loss: 0.8502 - val_decoder_accuracy: 0.0412 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5220 - decoder_loss: 25.2120 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0608 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5220 - decoder_loss: 25.2120 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0608 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8090 - val_decoder_loss: 18.9912 - val_encoder_loss: 11.8249 - val_classifier_loss: 0.8502 - val_decoder_accuracy: 0.0413 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5217 - decoder_loss: 25.2084 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0608 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5217 - decoder_loss: 25.2084 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0608 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8074 - val_decoder_loss: 18.9906 - val_encoder_loss: 11.8234 - val_classifier_loss: 0.8502 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5213 - decoder_loss: 25.2048 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5213 - decoder_loss: 25.2048 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8059 - val_decoder_loss: 18.9901 - val_encoder_loss: 11.8219 - val_classifier_loss: 0.8501 - val_decoder_accuracy: 0.0420 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5210 - decoder_loss: 25.2012 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0612 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5210 - decoder_loss: 25.2012 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0612 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8047 - val_decoder_loss: 18.9896 - val_encoder_loss: 11.8207 - val_classifier_loss: 0.8501 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5206 - decoder_loss: 25.1976 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0612 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5206 - decoder_loss: 25.1976 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0612 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8045 - val_decoder_loss: 18.9890 - val_encoder_loss: 11.8206 - val_classifier_loss: 0.8501 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5202 - decoder_loss: 25.1940 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5202 - decoder_loss: 25.1940 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8044 - val_decoder_loss: 18.9885 - val_encoder_loss: 11.8205 - val_classifier_loss: 0.8500 - val_decoder_accuracy: 0.0420 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5199 - decoder_loss: 25.1904 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5199 - decoder_loss: 25.1904 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8043 - val_decoder_loss: 18.9880 - val_encoder_loss: 11.8205 - val_classifier_loss: 0.8500 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5195 - decoder_loss: 25.1869 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5195 - decoder_loss: 25.1869 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0084 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8041 - val_decoder_loss: 18.9875 - val_encoder_loss: 11.8204 - val_classifier_loss: 0.8500 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5192 - decoder_loss: 25.1834 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5192 - decoder_loss: 25.1834 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8040 - val_decoder_loss: 18.9870 - val_encoder_loss: 11.8203 - val_classifier_loss: 0.8500 - val_decoder_accuracy: 0.0420 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5188 - decoder_loss: 25.1799 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5188 - decoder_loss: 25.1799 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8039 - val_decoder_loss: 18.9866 - val_encoder_loss: 11.8203 - val_classifier_loss: 0.8499 - val_decoder_accuracy: 0.0415 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5185 - decoder_loss: 25.1764 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5185 - decoder_loss: 25.1764 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8287 - val_decoder_loss: 18.9861 - val_encoder_loss: 11.8451 - val_classifier_loss: 0.8499 - val_decoder_accuracy: 0.0420 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5181 - decoder_loss: 25.1730 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5181 - decoder_loss: 25.1730 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8285 - val_decoder_loss: 18.9856 - val_encoder_loss: 11.8450 - val_classifier_loss: 0.8499 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5178 - decoder_loss: 25.1695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0609 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5178 - decoder_loss: 25.1695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0609 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8283 - val_decoder_loss: 18.9852 - val_encoder_loss: 11.8448 - val_classifier_loss: 0.8498 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5174 - decoder_loss: 25.1661 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5174 - decoder_loss: 25.1661 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0610 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8282 - val_decoder_loss: 18.9847 - val_encoder_loss: 11.8447 - val_classifier_loss: 0.8498 - val_decoder_accuracy: 0.0425 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5171 - decoder_loss: 25.1626 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5171 - decoder_loss: 25.1626 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8280 - val_decoder_loss: 18.9843 - val_encoder_loss: 11.8446 - val_classifier_loss: 0.8498 - val_decoder_accuracy: 0.0423 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5167 - decoder_loss: 25.1592 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0612 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5167 - decoder_loss: 25.1592 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0612 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8526 - val_decoder_loss: 18.9838 - val_encoder_loss: 11.8692 - val_classifier_loss: 0.8497 - val_decoder_accuracy: 0.0425 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5164 - decoder_loss: 25.1558 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 162: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5164 - decoder_loss: 25.1558 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8512 - val_decoder_loss: 18.9834 - val_encoder_loss: 11.8679 - val_classifier_loss: 0.8497 - val_decoder_accuracy: 0.0423 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5161 - decoder_loss: 25.1524 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 163: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5161 - decoder_loss: 25.1524 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0083 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8500 - val_decoder_loss: 18.9830 - val_encoder_loss: 11.8667 - val_classifier_loss: 0.8497 - val_decoder_accuracy: 0.0423 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5157 - decoder_loss: 25.1490 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5157 - decoder_loss: 25.1490 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8487 - val_decoder_loss: 18.9825 - val_encoder_loss: 11.8654 - val_classifier_loss: 0.8496 - val_decoder_accuracy: 0.0423 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5154 - decoder_loss: 25.1456 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5154 - decoder_loss: 25.1456 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8474 - val_decoder_loss: 18.9821 - val_encoder_loss: 11.8642 - val_classifier_loss: 0.8496 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5150 - decoder_loss: 25.1423 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 166: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5150 - decoder_loss: 25.1423 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8461 - val_decoder_loss: 18.9817 - val_encoder_loss: 11.8630 - val_classifier_loss: 0.8496 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5147 - decoder_loss: 25.1389 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5147 - decoder_loss: 25.1389 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8187 - val_decoder_loss: 18.9813 - val_encoder_loss: 11.8356 - val_classifier_loss: 0.8495 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5144 - decoder_loss: 25.1355 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.5144 - decoder_loss: 25.1355 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8160 - val_decoder_loss: 18.9809 - val_encoder_loss: 11.8329 - val_classifier_loss: 0.8495 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5140 - decoder_loss: 25.1322 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5140 - decoder_loss: 25.1322 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8133 - val_decoder_loss: 18.9805 - val_encoder_loss: 11.8303 - val_classifier_loss: 0.8494 - val_decoder_accuracy: 0.0427 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5137 - decoder_loss: 25.1289 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5137 - decoder_loss: 25.1289 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8106 - val_decoder_loss: 18.9801 - val_encoder_loss: 11.8276 - val_classifier_loss: 0.8494 - val_decoder_accuracy: 0.0430 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5134 - decoder_loss: 25.1255 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0616 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5134 - decoder_loss: 25.1255 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0616 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8079 - val_decoder_loss: 18.9797 - val_encoder_loss: 11.8249 - val_classifier_loss: 0.8494 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5130 - decoder_loss: 25.1222 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5130 - decoder_loss: 25.1222 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8052 - val_decoder_loss: 18.9794 - val_encoder_loss: 11.8223 - val_classifier_loss: 0.8493 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5127 - decoder_loss: 25.1189 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5127 - decoder_loss: 25.1189 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8025 - val_decoder_loss: 18.9790 - val_encoder_loss: 11.8196 - val_classifier_loss: 0.8493 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5124 - decoder_loss: 25.1156 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5124 - decoder_loss: 25.1156 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0082 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7998 - val_decoder_loss: 18.9786 - val_encoder_loss: 11.8170 - val_classifier_loss: 0.8493 - val_decoder_accuracy: 0.0435 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5120 - decoder_loss: 25.1123 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0616 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5120 - decoder_loss: 25.1123 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0616 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7971 - val_decoder_loss: 18.9783 - val_encoder_loss: 11.8143 - val_classifier_loss: 0.8492 - val_decoder_accuracy: 0.0435 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5117 - decoder_loss: 25.1090 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5117 - decoder_loss: 25.1090 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7944 - val_decoder_loss: 18.9779 - val_encoder_loss: 11.8117 - val_classifier_loss: 0.8492 - val_decoder_accuracy: 0.0435 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5114 - decoder_loss: 25.1058 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5114 - decoder_loss: 25.1058 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7917 - val_decoder_loss: 18.9776 - val_encoder_loss: 11.8090 - val_classifier_loss: 0.8492 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5111 - decoder_loss: 25.1025 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5111 - decoder_loss: 25.1025 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7890 - val_decoder_loss: 18.9772 - val_encoder_loss: 11.8064 - val_classifier_loss: 0.8491 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5107 - decoder_loss: 25.0993 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5107 - decoder_loss: 25.0993 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7863 - val_decoder_loss: 18.9769 - val_encoder_loss: 11.8037 - val_classifier_loss: 0.8491 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5104 - decoder_loss: 25.0961 - encoder_loss: 2.0258e-05 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5104 - decoder_loss: 25.0961 - encoder_loss: 2.0258e-05 - classifier_loss: 0.0081 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7865 - val_decoder_loss: 18.9768 - val_encoder_loss: 11.8040 - val_classifier_loss: 0.8481 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5101 - decoder_loss: 25.0933 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0619 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5101 - decoder_loss: 25.0933 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0619 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7843 - val_decoder_loss: 18.9765 - val_encoder_loss: 11.8018 - val_classifier_loss: 0.8480 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5098 - decoder_loss: 25.0902 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0619 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5098 - decoder_loss: 25.0902 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0619 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7818 - val_decoder_loss: 18.9761 - val_encoder_loss: 11.7994 - val_classifier_loss: 0.8479 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5095 - decoder_loss: 25.0870 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5095 - decoder_loss: 25.0870 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0081 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7794 - val_decoder_loss: 18.9758 - val_encoder_loss: 11.7970 - val_classifier_loss: 0.8479 - val_decoder_accuracy: 0.0442 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5092 - decoder_loss: 25.0838 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0622 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5092 - decoder_loss: 25.0838 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0622 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7781 - val_decoder_loss: 18.9755 - val_encoder_loss: 11.7957 - val_classifier_loss: 0.8478 - val_decoder_accuracy: 0.0443 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5089 - decoder_loss: 25.0807 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0623 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5089 - decoder_loss: 25.0807 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0623 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7767 - val_decoder_loss: 18.9752 - val_encoder_loss: 11.7944 - val_classifier_loss: 0.8477 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5086 - decoder_loss: 25.0775 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0623 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5086 - decoder_loss: 25.0775 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0623 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7754 - val_decoder_loss: 18.9748 - val_encoder_loss: 11.7931 - val_classifier_loss: 0.8476 - val_decoder_accuracy: 0.0455 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5082 - decoder_loss: 25.0744 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0622 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5082 - decoder_loss: 25.0744 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0622 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7740 - val_decoder_loss: 18.9745 - val_encoder_loss: 11.7918 - val_classifier_loss: 0.8475 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5079 - decoder_loss: 25.0713 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5079 - decoder_loss: 25.0713 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7726 - val_decoder_loss: 18.9742 - val_encoder_loss: 11.7905 - val_classifier_loss: 0.8475 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5076 - decoder_loss: 25.0682 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5076 - decoder_loss: 25.0682 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7713 - val_decoder_loss: 18.9739 - val_encoder_loss: 11.7891 - val_classifier_loss: 0.8474 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5073 - decoder_loss: 25.0650 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5073 - decoder_loss: 25.0650 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7699 - val_decoder_loss: 18.9736 - val_encoder_loss: 11.7878 - val_classifier_loss: 0.8473 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5070 - decoder_loss: 25.0619 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5070 - decoder_loss: 25.0619 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7685 - val_decoder_loss: 18.9733 - val_encoder_loss: 11.7865 - val_classifier_loss: 0.8473 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5067 - decoder_loss: 25.0588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5067 - decoder_loss: 25.0588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7671 - val_decoder_loss: 18.9730 - val_encoder_loss: 11.7851 - val_classifier_loss: 0.8472 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5064 - decoder_loss: 25.0557 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5064 - decoder_loss: 25.0557 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0080 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7658 - val_decoder_loss: 18.9727 - val_encoder_loss: 11.7838 - val_classifier_loss: 0.8472 - val_decoder_accuracy: 0.0468 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5061 - decoder_loss: 25.0527 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5061 - decoder_loss: 25.0527 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7644 - val_decoder_loss: 18.9724 - val_encoder_loss: 11.7824 - val_classifier_loss: 0.8471 - val_decoder_accuracy: 0.0470 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5058 - decoder_loss: 25.0496 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5058 - decoder_loss: 25.0496 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7879 - val_decoder_loss: 18.9721 - val_encoder_loss: 11.8060 - val_classifier_loss: 0.8470 - val_decoder_accuracy: 0.0470 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5054 - decoder_loss: 25.0465 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5054 - decoder_loss: 25.0465 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7860 - val_decoder_loss: 18.9718 - val_encoder_loss: 11.8041 - val_classifier_loss: 0.8470 - val_decoder_accuracy: 0.0470 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5051 - decoder_loss: 25.0434 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5051 - decoder_loss: 25.0434 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7841 - val_decoder_loss: 18.9715 - val_encoder_loss: 11.8022 - val_classifier_loss: 0.8469 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5048 - decoder_loss: 25.0404 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5048 - decoder_loss: 25.0404 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7822 - val_decoder_loss: 18.9713 - val_encoder_loss: 11.8003 - val_classifier_loss: 0.8469 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5045 - decoder_loss: 25.0373 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5045 - decoder_loss: 25.0373 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7803 - val_decoder_loss: 18.9710 - val_encoder_loss: 11.7985 - val_classifier_loss: 0.8468 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5042 - decoder_loss: 25.0343 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5042 - decoder_loss: 25.0343 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7784 - val_decoder_loss: 18.9707 - val_encoder_loss: 11.7966 - val_classifier_loss: 0.8468 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5039 - decoder_loss: 25.0312 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5039 - decoder_loss: 25.0312 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7765 - val_decoder_loss: 18.9704 - val_encoder_loss: 11.7948 - val_classifier_loss: 0.8467 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5036 - decoder_loss: 25.0282 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5036 - decoder_loss: 25.0282 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7746 - val_decoder_loss: 18.9702 - val_encoder_loss: 11.7929 - val_classifier_loss: 0.8467 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5033 - decoder_loss: 25.0252 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 203: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5033 - decoder_loss: 25.0252 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7727 - val_decoder_loss: 18.9699 - val_encoder_loss: 11.7911 - val_classifier_loss: 0.8466 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5030 - decoder_loss: 25.0222 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 204: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5030 - decoder_loss: 25.0222 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7708 - val_decoder_loss: 18.9697 - val_encoder_loss: 11.7892 - val_classifier_loss: 0.8466 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5027 - decoder_loss: 25.0192 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 205: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5027 - decoder_loss: 25.0192 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0079 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7690 - val_decoder_loss: 18.9694 - val_encoder_loss: 11.7874 - val_classifier_loss: 0.8465 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5024 - decoder_loss: 25.0162 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0078 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 206: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5024 - decoder_loss: 25.0162 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0078 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7671 - val_decoder_loss: 18.9691 - val_encoder_loss: 11.7855 - val_classifier_loss: 0.8465 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 206: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_24 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_25 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_12 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_24 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_25 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_13 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 7.1740 - decoder_loss: 26.4136 - encoder_loss: 4.4725 - classifier_loss: 0.6024 - decoder_accuracy: 0.0134 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6333\n",
            "F1-score is computed based on binary\n",
            "(loss: 7.1740498542785645, accuracy: 0.6333333253860474)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.73      0.67        15\n",
            "         1.0       0.67      0.53      0.59        15\n",
            "\n",
            "    accuracy                           0.63        30\n",
            "   macro avg       0.64      0.63      0.63        30\n",
            "weighted avg       0.64      0.63      0.63        30\n",
            "\n",
            "Accuracy: 0.6333333253860474\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6333333253860474\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIN2Net model example"
      ],
      "metadata": {
        "id": "K-Kn7p1VVXsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=15, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=200,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(1,2):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "id": "lPyutATxGTua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f93b566-7051-49c5-c983-a2b79976ab71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 1\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_14 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_15 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_7 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_14 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_15 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 26.2897 - decoder_loss: 62.8253 - encoder_loss: 19.9228 - classifier_loss: 0.8441 - decoder_accuracy: 0.0153 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.5500\n",
            "Epoch 1: val_loss improved from inf to 114.08508, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 26.2897 - decoder_loss: 62.8253 - encoder_loss: 19.9228 - classifier_loss: 0.8441 - decoder_accuracy: 0.0153 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.5500 - val_loss: 114.0851 - val_decoder_loss: 43.9175 - val_encoder_loss: 109.4757 - val_classifier_loss: 2.1767 - val_decoder_accuracy: 0.0172 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.8892 - decoder_loss: 62.8212 - encoder_loss: 0.5273 - classifier_loss: 0.7979 - decoder_accuracy: 0.0153 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.3000\n",
            "Epoch 2: val_loss improved from 114.08508 to 4.67016, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 6.8892 - decoder_loss: 62.8212 - encoder_loss: 0.5273 - classifier_loss: 0.7979 - decoder_accuracy: 0.0153 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.3000 - val_loss: 4.6702 - val_decoder_loss: 43.9199 - val_encoder_loss: 0.1882 - val_classifier_loss: 0.8998 - val_decoder_accuracy: 0.0202 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.2000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 16.0045 - decoder_loss: 62.7292 - encoder_loss: 9.6416 - classifier_loss: 0.8995 - decoder_accuracy: 0.0212 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.1750\n",
            "Epoch 3: val_loss improved from 4.67016 to 4.45908, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 16.0045 - decoder_loss: 62.7292 - encoder_loss: 9.6416 - classifier_loss: 0.8995 - decoder_accuracy: 0.0212 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.1750 - val_loss: 4.4591 - val_decoder_loss: 43.8694 - val_encoder_loss: 0.0259 - val_classifier_loss: 0.4627 - val_decoder_accuracy: 0.0182 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.2901 - decoder_loss: 62.5224 - encoder_loss: 1.9882 - classifier_loss: 0.4967 - decoder_accuracy: 0.0235 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750\n",
            "Epoch 4: val_loss did not improve from 4.45908\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.2901 - decoder_loss: 62.5224 - encoder_loss: 1.9882 - classifier_loss: 0.4967 - decoder_accuracy: 0.0235 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750 - val_loss: 5.1451 - val_decoder_loss: 43.7901 - val_encoder_loss: 0.7166 - val_classifier_loss: 0.4946 - val_decoder_accuracy: 0.0208 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.2957 - decoder_loss: 62.3733 - encoder_loss: 1.0079 - classifier_loss: 0.5049 - decoder_accuracy: 0.0250 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 5: val_loss improved from 4.45908 to 4.40844, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 7.2957 - decoder_loss: 62.3733 - encoder_loss: 1.0079 - classifier_loss: 0.5049 - decoder_accuracy: 0.0250 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 4.4084 - val_decoder_loss: 43.7930 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.2914 - val_decoder_accuracy: 0.0213 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 10.4274 - decoder_loss: 63.1054 - encoder_loss: 4.0820 - classifier_loss: 0.3491 - decoder_accuracy: 0.0238 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 6: val_loss did not improve from 4.40844\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 10.4274 - decoder_loss: 63.1054 - encoder_loss: 4.0820 - classifier_loss: 0.3491 - decoder_accuracy: 0.0238 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 6.5705 - val_decoder_loss: 43.6881 - val_encoder_loss: 2.1571 - val_classifier_loss: 0.4460 - val_decoder_accuracy: 0.0225 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.6203 - decoder_loss: 62.3633 - encoder_loss: 0.3417 - classifier_loss: 0.4230 - decoder_accuracy: 0.0282 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 7: val_loss improved from 4.40844 to 4.39243, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 6.6203 - decoder_loss: 62.3633 - encoder_loss: 0.3417 - classifier_loss: 0.4230 - decoder_accuracy: 0.0282 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 4.3924 - val_decoder_loss: 43.6789 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.2454 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 9.0973 - decoder_loss: 61.9154 - encoder_loss: 2.8760 - classifier_loss: 0.2975 - decoder_accuracy: 0.0406 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 8: val_loss did not improve from 4.39243\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 9.0973 - decoder_loss: 61.9154 - encoder_loss: 2.8760 - classifier_loss: 0.2975 - decoder_accuracy: 0.0406 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.6045 - val_decoder_loss: 43.6662 - val_encoder_loss: 0.2077 - val_classifier_loss: 0.3014 - val_decoder_accuracy: 0.0277 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.8387 - decoder_loss: 61.4488 - encoder_loss: 0.6627 - classifier_loss: 0.3114 - decoder_accuracy: 0.0436 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250\n",
            "Epoch 9: val_loss improved from 4.39243 to 4.36333, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 6.8387 - decoder_loss: 61.4488 - encoder_loss: 0.6627 - classifier_loss: 0.3114 - decoder_accuracy: 0.0436 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250 - val_loss: 4.3633 - val_decoder_loss: 43.3595 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.2739 - val_decoder_accuracy: 0.0327 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.1499 - decoder_loss: 60.0089 - encoder_loss: 0.1189 - classifier_loss: 0.3014 - decoder_accuracy: 0.0522 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 10: val_loss did not improve from 4.36333\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.1499 - decoder_loss: 60.0089 - encoder_loss: 0.1189 - classifier_loss: 0.3014 - decoder_accuracy: 0.0522 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.3832 - val_decoder_loss: 43.4308 - val_encoder_loss: 0.0146 - val_classifier_loss: 0.2555 - val_decoder_accuracy: 0.0393 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.0095 - decoder_loss: 59.1885 - encoder_loss: 0.0611 - classifier_loss: 0.2948 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 11: val_loss did not improve from 4.36333\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.0095 - decoder_loss: 59.1885 - encoder_loss: 0.0611 - classifier_loss: 0.2948 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.3876 - val_decoder_loss: 43.4645 - val_encoder_loss: 0.0129 - val_classifier_loss: 0.2824 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.1244 - decoder_loss: 58.3554 - encoder_loss: 0.2594 - classifier_loss: 0.2950 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 12: val_loss did not improve from 4.36333\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.1244 - decoder_loss: 58.3554 - encoder_loss: 0.2594 - classifier_loss: 0.2950 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.5337 - val_decoder_loss: 45.0344 - val_encoder_loss: 0.0117 - val_classifier_loss: 0.1861 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.2011 - decoder_loss: 60.1704 - encoder_loss: 0.1618 - classifier_loss: 0.2218 - decoder_accuracy: 0.0393 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 13: val_loss did not improve from 4.36333\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6.2011 - decoder_loss: 60.1704 - encoder_loss: 0.1618 - classifier_loss: 0.2218 - decoder_accuracy: 0.0393 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 6.1833 - val_decoder_loss: 46.2756 - val_encoder_loss: 1.5370 - val_classifier_loss: 0.1874 - val_decoder_accuracy: 0.0410 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.5337 - decoder_loss: 64.8923 - encoder_loss: 0.0244 - classifier_loss: 0.2004 - decoder_accuracy: 0.0375 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 4.36333\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 6.5337 - decoder_loss: 64.8923 - encoder_loss: 0.0244 - classifier_loss: 0.2004 - decoder_accuracy: 0.0375 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 6.4689 - val_decoder_loss: 43.2528 - val_encoder_loss: 2.1168 - val_classifier_loss: 0.2677 - val_decoder_accuracy: 0.0420 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.0644 - decoder_loss: 59.9355 - encoder_loss: 1.0410 - classifier_loss: 0.2987 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.1250 - classifier_accuracy: 0.9750\n",
            "Epoch 15: val_loss improved from 4.36333 to 4.34922, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 7.0644 - decoder_loss: 59.9355 - encoder_loss: 1.0410 - classifier_loss: 0.2987 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.1250 - classifier_accuracy: 0.9750 - val_loss: 4.3492 - val_decoder_loss: 43.4118 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.0805 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.2114 - decoder_loss: 61.6817 - encoder_loss: 1.0311 - classifier_loss: 0.1215 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 16: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 7.2114 - decoder_loss: 61.6817 - encoder_loss: 1.0311 - classifier_loss: 0.1215 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.3690 - val_decoder_loss: 43.4903 - val_encoder_loss: 0.0132 - val_classifier_loss: 0.0682 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.1355 - decoder_loss: 60.4549 - encoder_loss: 0.0810 - classifier_loss: 0.0899 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 17: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.1355 - decoder_loss: 60.4549 - encoder_loss: 0.0810 - classifier_loss: 0.0899 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 4.4052 - val_decoder_loss: 43.5865 - val_encoder_loss: 0.0399 - val_classifier_loss: 0.0657 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.9813 - decoder_loss: 59.6866 - encoder_loss: 0.0055 - classifier_loss: 0.0712 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 18: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.9813 - decoder_loss: 59.6866 - encoder_loss: 0.0055 - classifier_loss: 0.0712 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 4.6521 - val_decoder_loss: 43.6808 - val_encoder_loss: 0.2770 - val_classifier_loss: 0.0703 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.8810 - decoder_loss: 58.7313 - encoder_loss: 0.0011 - classifier_loss: 0.0676 - decoder_accuracy: 0.0670 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.8810 - decoder_loss: 58.7313 - encoder_loss: 0.0011 - classifier_loss: 0.0676 - decoder_accuracy: 0.0670 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.6682 - val_decoder_loss: 43.5455 - val_encoder_loss: 0.3071 - val_classifier_loss: 0.0658 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.7976 - decoder_loss: 57.8814 - encoder_loss: 0.0033 - classifier_loss: 0.0617 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.7976 - decoder_loss: 57.8814 - encoder_loss: 0.0033 - classifier_loss: 0.0617 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.7098 - val_decoder_loss: 43.4271 - val_encoder_loss: 0.3605 - val_classifier_loss: 0.0659 - val_decoder_accuracy: 0.0523 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.7191 - decoder_loss: 57.1128 - encoder_loss: 0.0024 - classifier_loss: 0.0545 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.7191 - decoder_loss: 57.1128 - encoder_loss: 0.0024 - classifier_loss: 0.0545 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.8099 - val_decoder_loss: 43.4294 - val_encoder_loss: 0.4604 - val_classifier_loss: 0.0659 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.6779 - decoder_loss: 56.7225 - encoder_loss: 3.7103e-04 - classifier_loss: 0.0524 - decoder_accuracy: 0.0701 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.6779 - decoder_loss: 56.7225 - encoder_loss: 3.7103e-04 - classifier_loss: 0.0524 - decoder_accuracy: 0.0701 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.8319 - val_decoder_loss: 43.4312 - val_encoder_loss: 0.4825 - val_classifier_loss: 0.0637 - val_decoder_accuracy: 0.0510 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.6392 - decoder_loss: 56.3372 - encoder_loss: 5.3439e-04 - classifier_loss: 0.0494 - decoder_accuracy: 0.0709 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.6392 - decoder_loss: 56.3372 - encoder_loss: 5.3439e-04 - classifier_loss: 0.0494 - decoder_accuracy: 0.0709 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.8974 - val_decoder_loss: 43.3774 - val_encoder_loss: 0.5532 - val_classifier_loss: 0.0647 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.6016 - decoder_loss: 55.9581 - encoder_loss: 9.0686e-04 - classifier_loss: 0.0486 - decoder_accuracy: 0.0707 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.6016 - decoder_loss: 55.9581 - encoder_loss: 9.0686e-04 - classifier_loss: 0.0486 - decoder_accuracy: 0.0707 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.8913 - val_decoder_loss: 43.3206 - val_encoder_loss: 0.5530 - val_classifier_loss: 0.0623 - val_decoder_accuracy: 0.0563 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5686 - decoder_loss: 55.6304 - encoder_loss: 9.8030e-04 - classifier_loss: 0.0459 - decoder_accuracy: 0.0710 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.5686 - decoder_loss: 55.6304 - encoder_loss: 9.8030e-04 - classifier_loss: 0.0459 - decoder_accuracy: 0.0710 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9161 - val_decoder_loss: 43.2478 - val_encoder_loss: 0.5853 - val_classifier_loss: 0.0607 - val_decoder_accuracy: 0.0585 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5417 - decoder_loss: 55.3735 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0433 - decoder_accuracy: 0.0691 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.5417 - decoder_loss: 55.3735 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0433 - decoder_accuracy: 0.0691 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9310 - val_decoder_loss: 43.2443 - val_encoder_loss: 0.6006 - val_classifier_loss: 0.0598 - val_decoder_accuracy: 0.0575 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5288 - decoder_loss: 55.2384 - encoder_loss: 7.2274e-04 - classifier_loss: 0.0424 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.5288 - decoder_loss: 55.2384 - encoder_loss: 7.2274e-04 - classifier_loss: 0.0424 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9501 - val_decoder_loss: 43.2167 - val_encoder_loss: 0.6225 - val_classifier_loss: 0.0589 - val_decoder_accuracy: 0.0570 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5173 - decoder_loss: 55.1273 - encoder_loss: 4.1484e-04 - classifier_loss: 0.0411 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.5173 - decoder_loss: 55.1273 - encoder_loss: 4.1484e-04 - classifier_loss: 0.0411 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9546 - val_decoder_loss: 43.2018 - val_encoder_loss: 0.6287 - val_classifier_loss: 0.0579 - val_decoder_accuracy: 0.0563 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5038 - decoder_loss: 54.9985 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0398 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.5038 - decoder_loss: 54.9985 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0398 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9608 - val_decoder_loss: 43.1856 - val_encoder_loss: 0.6365 - val_classifier_loss: 0.0571 - val_decoder_accuracy: 0.0563 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4937 - decoder_loss: 54.8765 - encoder_loss: 0.0021 - classifier_loss: 0.0389 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.4937 - decoder_loss: 54.8765 - encoder_loss: 0.0021 - classifier_loss: 0.0389 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9883 - val_decoder_loss: 43.1735 - val_encoder_loss: 0.6653 - val_classifier_loss: 0.0570 - val_decoder_accuracy: 0.0540 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4818 - decoder_loss: 54.7722 - encoder_loss: 7.0948e-04 - classifier_loss: 0.0383 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4818 - decoder_loss: 54.7722 - encoder_loss: 7.0948e-04 - classifier_loss: 0.0383 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9902 - val_decoder_loss: 43.1646 - val_encoder_loss: 0.6681 - val_classifier_loss: 0.0564 - val_decoder_accuracy: 0.0523 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4770 - decoder_loss: 54.7190 - encoder_loss: 0.0013 - classifier_loss: 0.0378 - decoder_accuracy: 0.0651 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.4770 - decoder_loss: 54.7190 - encoder_loss: 0.0013 - classifier_loss: 0.0378 - decoder_accuracy: 0.0651 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0153 - val_decoder_loss: 43.1381 - val_encoder_loss: 0.6959 - val_classifier_loss: 0.0563 - val_decoder_accuracy: 0.0522 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4730 - decoder_loss: 54.6818 - encoder_loss: 0.0011 - classifier_loss: 0.0373 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.4730 - decoder_loss: 54.6818 - encoder_loss: 0.0011 - classifier_loss: 0.0373 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0232 - val_decoder_loss: 43.1226 - val_encoder_loss: 0.7054 - val_classifier_loss: 0.0557 - val_decoder_accuracy: 0.0505 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4662 - decoder_loss: 54.6256 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0368 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 34: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4662 - decoder_loss: 54.6256 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0368 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0286 - val_decoder_loss: 43.1129 - val_encoder_loss: 0.7118 - val_classifier_loss: 0.0553 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4608 - decoder_loss: 54.5712 - encoder_loss: 1.0621e-05 - classifier_loss: 0.0364 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.4608 - decoder_loss: 54.5712 - encoder_loss: 1.0621e-05 - classifier_loss: 0.0364 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0266 - val_decoder_loss: 43.1065 - val_encoder_loss: 0.7105 - val_classifier_loss: 0.0547 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4558 - decoder_loss: 54.5215 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0360 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.4558 - decoder_loss: 54.5215 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0360 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0295 - val_decoder_loss: 43.0999 - val_encoder_loss: 0.7141 - val_classifier_loss: 0.0545 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 3.1250e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4531 - decoder_loss: 54.4949 - encoder_loss: 2.5277e-05 - classifier_loss: 0.0358 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4531 - decoder_loss: 54.4949 - encoder_loss: 2.5277e-05 - classifier_loss: 0.0358 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0432 - val_decoder_loss: 43.0901 - val_encoder_loss: 0.7288 - val_classifier_loss: 0.0545 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 3.1250e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4520 - decoder_loss: 54.4735 - encoder_loss: 0.0011 - classifier_loss: 0.0357 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.4520 - decoder_loss: 54.4735 - encoder_loss: 0.0011 - classifier_loss: 0.0357 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0506 - val_decoder_loss: 43.0826 - val_encoder_loss: 0.7369 - val_classifier_loss: 0.0545 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 3.1250e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4483 - decoder_loss: 54.4475 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0355 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.4483 - decoder_loss: 54.4475 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0355 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0532 - val_decoder_loss: 43.0764 - val_encoder_loss: 0.7402 - val_classifier_loss: 0.0543 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 3.1250e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4456 - decoder_loss: 54.4209 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0353 - decoder_accuracy: 0.0649 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.4456 - decoder_loss: 54.4209 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0353 - decoder_accuracy: 0.0649 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0554 - val_decoder_loss: 43.0701 - val_encoder_loss: 0.7430 - val_classifier_loss: 0.0541 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 3.1250e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4429 - decoder_loss: 54.3943 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0351 - decoder_accuracy: 0.0650 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.4429 - decoder_loss: 54.3943 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0351 - decoder_accuracy: 0.0650 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0568 - val_decoder_loss: 43.0668 - val_encoder_loss: 0.7447 - val_classifier_loss: 0.0540 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.5625e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4416 - decoder_loss: 54.3809 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0350 - decoder_accuracy: 0.0652 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4416 - decoder_loss: 54.3809 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0350 - decoder_accuracy: 0.0652 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0578 - val_decoder_loss: 43.0636 - val_encoder_loss: 0.7460 - val_classifier_loss: 0.0539 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.5625e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4404 - decoder_loss: 54.3675 - encoder_loss: 1.5961e-04 - classifier_loss: 0.0350 - decoder_accuracy: 0.0652 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4404 - decoder_loss: 54.3675 - encoder_loss: 1.5961e-04 - classifier_loss: 0.0350 - decoder_accuracy: 0.0652 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0652 - val_decoder_loss: 43.0585 - val_encoder_loss: 0.7539 - val_classifier_loss: 0.0539 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.5625e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4392 - decoder_loss: 54.3569 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0349 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4392 - decoder_loss: 54.3569 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0349 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0667 - val_decoder_loss: 43.0552 - val_encoder_loss: 0.7558 - val_classifier_loss: 0.0538 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.5625e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4378 - decoder_loss: 54.3435 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0348 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4378 - decoder_loss: 54.3435 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0348 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0678 - val_decoder_loss: 43.0518 - val_encoder_loss: 0.7572 - val_classifier_loss: 0.0537 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.5625e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4365 - decoder_loss: 54.3300 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0347 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4365 - decoder_loss: 54.3300 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0347 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0686 - val_decoder_loss: 43.0497 - val_encoder_loss: 0.7583 - val_classifier_loss: 0.0536 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4356 - decoder_loss: 54.3214 - encoder_loss: 1.5951e-05 - classifier_loss: 0.0347 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.4356 - decoder_loss: 54.3214 - encoder_loss: 1.5951e-05 - classifier_loss: 0.0347 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0736 - val_decoder_loss: 43.0464 - val_encoder_loss: 0.7636 - val_classifier_loss: 0.0536 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4349 - decoder_loss: 54.3146 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0346 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.4349 - decoder_loss: 54.3146 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0346 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0747 - val_decoder_loss: 43.0441 - val_encoder_loss: 0.7649 - val_classifier_loss: 0.0536 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4354 - decoder_loss: 54.3059 - encoder_loss: 0.0013 - classifier_loss: 0.0346 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 49: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4354 - decoder_loss: 54.3059 - encoder_loss: 0.0013 - classifier_loss: 0.0346 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0763 - val_decoder_loss: 43.0418 - val_encoder_loss: 0.7667 - val_classifier_loss: 0.0535 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4342 - decoder_loss: 54.2972 - encoder_loss: 0.0011 - classifier_loss: 0.0345 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4342 - decoder_loss: 54.2972 - encoder_loss: 0.0011 - classifier_loss: 0.0345 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0768 - val_decoder_loss: 43.0403 - val_encoder_loss: 0.7674 - val_classifier_loss: 0.0535 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4330 - decoder_loss: 54.2891 - encoder_loss: 6.2234e-04 - classifier_loss: 0.0345 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.4330 - decoder_loss: 54.2891 - encoder_loss: 6.2234e-04 - classifier_loss: 0.0345 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0784 - val_decoder_loss: 43.0379 - val_encoder_loss: 0.7692 - val_classifier_loss: 0.0534 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4319 - decoder_loss: 54.2803 - encoder_loss: 4.1103e-04 - classifier_loss: 0.0344 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.4319 - decoder_loss: 54.2803 - encoder_loss: 4.1103e-04 - classifier_loss: 0.0344 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0846 - val_decoder_loss: 43.0344 - val_encoder_loss: 0.7759 - val_classifier_loss: 0.0534 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4308 - decoder_loss: 54.2734 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0343 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.4308 - decoder_loss: 54.2734 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0343 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0859 - val_decoder_loss: 43.0321 - val_encoder_loss: 0.7774 - val_classifier_loss: 0.0534 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4299 - decoder_loss: 54.2647 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0343 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4299 - decoder_loss: 54.2647 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0343 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0869 - val_decoder_loss: 43.0298 - val_encoder_loss: 0.7786 - val_classifier_loss: 0.0533 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4291 - decoder_loss: 54.2560 - encoder_loss: 3.2666e-05 - classifier_loss: 0.0342 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.4291 - decoder_loss: 54.2560 - encoder_loss: 3.2666e-05 - classifier_loss: 0.0342 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0865 - val_decoder_loss: 43.0283 - val_encoder_loss: 0.7784 - val_classifier_loss: 0.0532 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4286 - decoder_loss: 54.2480 - encoder_loss: 3.4180e-04 - classifier_loss: 0.0342 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.4286 - decoder_loss: 54.2480 - encoder_loss: 3.4180e-04 - classifier_loss: 0.0342 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0936 - val_decoder_loss: 43.0236 - val_encoder_loss: 0.7859 - val_classifier_loss: 0.0532 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4277 - decoder_loss: 54.2431 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0341 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.4277 - decoder_loss: 54.2431 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0341 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0949 - val_decoder_loss: 43.0212 - val_encoder_loss: 0.7875 - val_classifier_loss: 0.0532 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4269 - decoder_loss: 54.2345 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0340 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 58: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4269 - decoder_loss: 54.2345 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0340 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0959 - val_decoder_loss: 43.0189 - val_encoder_loss: 0.7887 - val_classifier_loss: 0.0531 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4260 - decoder_loss: 54.2259 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0340 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 59: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4260 - decoder_loss: 54.2259 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0340 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0968 - val_decoder_loss: 43.0165 - val_encoder_loss: 0.7899 - val_classifier_loss: 0.0530 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4252 - decoder_loss: 54.2172 - encoder_loss: 5.3366e-05 - classifier_loss: 0.0339 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 60: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.4252 - decoder_loss: 54.2172 - encoder_loss: 5.3366e-05 - classifier_loss: 0.0339 - decoder_accuracy: 0.0646 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0964 - val_decoder_loss: 43.0151 - val_encoder_loss: 0.7896 - val_classifier_loss: 0.0529 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4244 - decoder_loss: 54.2092 - encoder_loss: 5.3195e-05 - classifier_loss: 0.0338 - decoder_accuracy: 0.0647 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 61: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.4244 - decoder_loss: 54.2092 - encoder_loss: 5.3195e-05 - classifier_loss: 0.0338 - decoder_accuracy: 0.0647 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0986 - val_decoder_loss: 43.0115 - val_encoder_loss: 0.7922 - val_classifier_loss: 0.0528 - val_decoder_accuracy: 0.0488 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4236 - decoder_loss: 54.2024 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0337 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 62: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.4236 - decoder_loss: 54.2024 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0337 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0994 - val_decoder_loss: 43.0091 - val_encoder_loss: 0.7932 - val_classifier_loss: 0.0528 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4228 - decoder_loss: 54.1938 - encoder_loss: 3.5196e-05 - classifier_loss: 0.0337 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 63: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.4228 - decoder_loss: 54.1938 - encoder_loss: 3.5196e-05 - classifier_loss: 0.0337 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1052 - val_decoder_loss: 43.0055 - val_encoder_loss: 0.7994 - val_classifier_loss: 0.0528 - val_decoder_accuracy: 0.0488 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4221 - decoder_loss: 54.1873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0336 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 5.4221 - decoder_loss: 54.1873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0336 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1064 - val_decoder_loss: 43.0031 - val_encoder_loss: 0.8008 - val_classifier_loss: 0.0527 - val_decoder_accuracy: 0.0488 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4213 - decoder_loss: 54.1786 - encoder_loss: 3.8850e-05 - classifier_loss: 0.0336 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 65: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.4213 - decoder_loss: 54.1786 - encoder_loss: 3.8850e-05 - classifier_loss: 0.0336 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1060 - val_decoder_loss: 43.0017 - val_encoder_loss: 0.8006 - val_classifier_loss: 0.0526 - val_decoder_accuracy: 0.0488 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4204 - decoder_loss: 54.1708 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0335 - decoder_accuracy: 0.0647 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 66: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.4204 - decoder_loss: 54.1708 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0335 - decoder_accuracy: 0.0647 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1068 - val_decoder_loss: 42.9993 - val_encoder_loss: 0.8016 - val_classifier_loss: 0.0525 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4196 - decoder_loss: 54.1621 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0335 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 67: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4196 - decoder_loss: 54.1621 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0335 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1074 - val_decoder_loss: 42.9970 - val_encoder_loss: 0.8025 - val_classifier_loss: 0.0524 - val_decoder_accuracy: 0.0488 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4191 - decoder_loss: 54.1534 - encoder_loss: 4.6166e-04 - classifier_loss: 0.0334 - decoder_accuracy: 0.0647 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 68: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.4191 - decoder_loss: 54.1534 - encoder_loss: 4.6166e-04 - classifier_loss: 0.0334 - decoder_accuracy: 0.0647 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1150 - val_decoder_loss: 42.9920 - val_encoder_loss: 0.8105 - val_classifier_loss: 0.0524 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4182 - decoder_loss: 54.1489 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0333 - decoder_accuracy: 0.0647 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 69: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4182 - decoder_loss: 54.1489 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0333 - decoder_accuracy: 0.0647 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1163 - val_decoder_loss: 42.9896 - val_encoder_loss: 0.8121 - val_classifier_loss: 0.0523 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4174 - decoder_loss: 54.1404 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0332 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 70: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.4174 - decoder_loss: 54.1404 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0332 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1173 - val_decoder_loss: 42.9872 - val_encoder_loss: 0.8133 - val_classifier_loss: 0.0523 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4166 - decoder_loss: 54.1318 - encoder_loss: 8.9003e-05 - classifier_loss: 0.0332 - decoder_accuracy: 0.0650 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 71: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4166 - decoder_loss: 54.1318 - encoder_loss: 8.9003e-05 - classifier_loss: 0.0332 - decoder_accuracy: 0.0650 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1168 - val_decoder_loss: 42.9858 - val_encoder_loss: 0.8130 - val_classifier_loss: 0.0521 - val_decoder_accuracy: 0.0488 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4158 - decoder_loss: 54.1240 - encoder_loss: 7.3905e-05 - classifier_loss: 0.0331 - decoder_accuracy: 0.0650 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 72: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.4158 - decoder_loss: 54.1240 - encoder_loss: 7.3905e-05 - classifier_loss: 0.0331 - decoder_accuracy: 0.0650 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1176 - val_decoder_loss: 42.9821 - val_encoder_loss: 0.8142 - val_classifier_loss: 0.0521 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4151 - decoder_loss: 54.1176 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0330 - decoder_accuracy: 0.0651 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 73: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4151 - decoder_loss: 54.1176 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0330 - decoder_accuracy: 0.0651 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1182 - val_decoder_loss: 42.9797 - val_encoder_loss: 0.8150 - val_classifier_loss: 0.0520 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4142 - decoder_loss: 54.1090 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0330 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 74: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.4142 - decoder_loss: 54.1090 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0330 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1187 - val_decoder_loss: 42.9773 - val_encoder_loss: 0.8158 - val_classifier_loss: 0.0519 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4134 - decoder_loss: 54.1004 - encoder_loss: 1.0245e-04 - classifier_loss: 0.0329 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 75: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.4134 - decoder_loss: 54.1004 - encoder_loss: 1.0245e-04 - classifier_loss: 0.0329 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1250 - val_decoder_loss: 42.9736 - val_encoder_loss: 0.8224 - val_classifier_loss: 0.0519 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4127 - decoder_loss: 54.0941 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0329 - decoder_accuracy: 0.0650 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 76: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.4127 - decoder_loss: 54.0941 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0329 - decoder_accuracy: 0.0650 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1261 - val_decoder_loss: 42.9712 - val_encoder_loss: 0.8238 - val_classifier_loss: 0.0519 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4119 - decoder_loss: 54.0856 - encoder_loss: 9.0981e-05 - classifier_loss: 0.0328 - decoder_accuracy: 0.0652 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 77: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4119 - decoder_loss: 54.0856 - encoder_loss: 9.0981e-05 - classifier_loss: 0.0328 - decoder_accuracy: 0.0652 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1256 - val_decoder_loss: 42.9684 - val_encoder_loss: 0.8236 - val_classifier_loss: 0.0518 - val_decoder_accuracy: 0.0495 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4113 - decoder_loss: 54.0801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0327 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 78: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.4113 - decoder_loss: 54.0801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0327 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1262 - val_decoder_loss: 42.9660 - val_encoder_loss: 0.8244 - val_classifier_loss: 0.0517 - val_decoder_accuracy: 0.0498 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4104 - decoder_loss: 54.0716 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0327 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 79: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4104 - decoder_loss: 54.0716 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0327 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1267 - val_decoder_loss: 42.9637 - val_encoder_loss: 0.8252 - val_classifier_loss: 0.0516 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4096 - decoder_loss: 54.0631 - encoder_loss: 3.6782e-05 - classifier_loss: 0.0326 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 80: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4096 - decoder_loss: 54.0631 - encoder_loss: 3.6782e-05 - classifier_loss: 0.0326 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1289 - val_decoder_loss: 42.9600 - val_encoder_loss: 0.8278 - val_classifier_loss: 0.0515 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4089 - decoder_loss: 54.0567 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0325 - decoder_accuracy: 0.0652 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 81: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.4089 - decoder_loss: 54.0567 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0325 - decoder_accuracy: 0.0652 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1296 - val_decoder_loss: 42.9576 - val_encoder_loss: 0.8287 - val_classifier_loss: 0.0514 - val_decoder_accuracy: 0.0498 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4081 - decoder_loss: 54.0482 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0324 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 82: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5.4081 - decoder_loss: 54.0482 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0324 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1301 - val_decoder_loss: 42.9553 - val_encoder_loss: 0.8295 - val_classifier_loss: 0.0514 - val_decoder_accuracy: 0.0498 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4075 - decoder_loss: 54.0397 - encoder_loss: 3.2429e-04 - classifier_loss: 0.0324 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 83: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.4075 - decoder_loss: 54.0397 - encoder_loss: 3.2429e-04 - classifier_loss: 0.0324 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1353 - val_decoder_loss: 42.9511 - val_encoder_loss: 0.8350 - val_classifier_loss: 0.0513 - val_decoder_accuracy: 0.0495 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4069 - decoder_loss: 54.0369 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0323 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 84: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.4069 - decoder_loss: 54.0369 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0323 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1363 - val_decoder_loss: 42.9487 - val_encoder_loss: 0.8363 - val_classifier_loss: 0.0513 - val_decoder_accuracy: 0.0495 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4061 - decoder_loss: 54.0286 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0322 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 85: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4061 - decoder_loss: 54.0286 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0322 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1370 - val_decoder_loss: 42.9464 - val_encoder_loss: 0.8372 - val_classifier_loss: 0.0512 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4052 - decoder_loss: 54.0202 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0322 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 86: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.4052 - decoder_loss: 54.0202 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0322 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1376 - val_decoder_loss: 42.9441 - val_encoder_loss: 0.8381 - val_classifier_loss: 0.0511 - val_decoder_accuracy: 0.0495 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4044 - decoder_loss: 54.0118 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0321 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 87: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.4044 - decoder_loss: 54.0118 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0321 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1382 - val_decoder_loss: 42.9418 - val_encoder_loss: 0.8389 - val_classifier_loss: 0.0510 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4035 - decoder_loss: 54.0033 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0320 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.4035 - decoder_loss: 54.0033 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0320 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1387 - val_decoder_loss: 42.9395 - val_encoder_loss: 0.8396 - val_classifier_loss: 0.0509 - val_decoder_accuracy: 0.0495 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4030 - decoder_loss: 53.9947 - encoder_loss: 3.2468e-04 - classifier_loss: 0.0320 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.4030 - decoder_loss: 53.9947 - encoder_loss: 3.2468e-04 - classifier_loss: 0.0320 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1456 - val_decoder_loss: 42.9343 - val_encoder_loss: 0.8470 - val_classifier_loss: 0.0510 - val_decoder_accuracy: 0.0495 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4026 - decoder_loss: 53.9912 - encoder_loss: 2.3858e-04 - classifier_loss: 0.0319 - decoder_accuracy: 0.0655 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5.4026 - decoder_loss: 53.9912 - encoder_loss: 2.3858e-04 - classifier_loss: 0.0319 - decoder_accuracy: 0.0655 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1450 - val_decoder_loss: 42.9330 - val_encoder_loss: 0.8466 - val_classifier_loss: 0.0509 - val_decoder_accuracy: 0.0495 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4016 - decoder_loss: 53.9838 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0319 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.4016 - decoder_loss: 53.9838 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0319 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1458 - val_decoder_loss: 42.9308 - val_encoder_loss: 0.8476 - val_classifier_loss: 0.0508 - val_decoder_accuracy: 0.0495 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4007 - decoder_loss: 53.9755 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0318 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.4007 - decoder_loss: 53.9755 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0318 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1464 - val_decoder_loss: 42.9285 - val_encoder_loss: 0.8485 - val_classifier_loss: 0.0507 - val_decoder_accuracy: 0.0498 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3999 - decoder_loss: 53.9671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0317 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 93: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3999 - decoder_loss: 53.9671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0317 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1470 - val_decoder_loss: 42.9263 - val_encoder_loss: 0.8493 - val_classifier_loss: 0.0506 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3992 - decoder_loss: 53.9586 - encoder_loss: 1.7542e-04 - classifier_loss: 0.0317 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 94: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3992 - decoder_loss: 53.9586 - encoder_loss: 1.7542e-04 - classifier_loss: 0.0317 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1493 - val_decoder_loss: 42.9226 - val_encoder_loss: 0.8520 - val_classifier_loss: 0.0505 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3985 - decoder_loss: 53.9525 - encoder_loss: 6.3294e-05 - classifier_loss: 0.0316 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3985 - decoder_loss: 53.9525 - encoder_loss: 6.3294e-05 - classifier_loss: 0.0316 - decoder_accuracy: 0.0654 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1484 - val_decoder_loss: 42.9214 - val_encoder_loss: 0.8512 - val_classifier_loss: 0.0504 - val_decoder_accuracy: 0.0502 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3978 - decoder_loss: 53.9450 - encoder_loss: 1.2485e-04 - classifier_loss: 0.0315 - decoder_accuracy: 0.0655 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 96: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3978 - decoder_loss: 53.9450 - encoder_loss: 1.2485e-04 - classifier_loss: 0.0315 - decoder_accuracy: 0.0655 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1554 - val_decoder_loss: 42.9177 - val_encoder_loss: 0.8586 - val_classifier_loss: 0.0504 - val_decoder_accuracy: 0.0503 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3971 - decoder_loss: 53.9393 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0315 - decoder_accuracy: 0.0655 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 97: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3971 - decoder_loss: 53.9393 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0315 - decoder_accuracy: 0.0655 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1566 - val_decoder_loss: 42.9155 - val_encoder_loss: 0.8600 - val_classifier_loss: 0.0503 - val_decoder_accuracy: 0.0503 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3962 - decoder_loss: 53.9310 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0314 - decoder_accuracy: 0.0656 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 98: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3962 - decoder_loss: 53.9310 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0314 - decoder_accuracy: 0.0656 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1574 - val_decoder_loss: 42.9132 - val_encoder_loss: 0.8610 - val_classifier_loss: 0.0502 - val_decoder_accuracy: 0.0510 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3956 - decoder_loss: 53.9226 - encoder_loss: 2.2916e-04 - classifier_loss: 0.0313 - decoder_accuracy: 0.0657 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 99: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.3956 - decoder_loss: 53.9226 - encoder_loss: 2.2916e-04 - classifier_loss: 0.0313 - decoder_accuracy: 0.0657 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1582 - val_decoder_loss: 42.9095 - val_encoder_loss: 0.8622 - val_classifier_loss: 0.0502 - val_decoder_accuracy: 0.0510 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3948 - decoder_loss: 53.9168 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0312 - decoder_accuracy: 0.0657 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.3948 - decoder_loss: 53.9168 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0312 - decoder_accuracy: 0.0657 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1587 - val_decoder_loss: 42.9073 - val_encoder_loss: 0.8630 - val_classifier_loss: 0.0501 - val_decoder_accuracy: 0.0510 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3940 - decoder_loss: 53.9085 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0312 - decoder_accuracy: 0.0659 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.3940 - decoder_loss: 53.9085 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0312 - decoder_accuracy: 0.0659 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1592 - val_decoder_loss: 42.9051 - val_encoder_loss: 0.8637 - val_classifier_loss: 0.0500 - val_decoder_accuracy: 0.0510 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3932 - decoder_loss: 53.9001 - encoder_loss: 4.0968e-05 - classifier_loss: 0.0311 - decoder_accuracy: 0.0659 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3932 - decoder_loss: 53.9001 - encoder_loss: 4.0968e-05 - classifier_loss: 0.0311 - decoder_accuracy: 0.0659 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1581 - val_decoder_loss: 42.9040 - val_encoder_loss: 0.8627 - val_classifier_loss: 0.0499 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3933 - decoder_loss: 53.8927 - encoder_loss: 8.9711e-04 - classifier_loss: 0.0311 - decoder_accuracy: 0.0660 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.3933 - decoder_loss: 53.8927 - encoder_loss: 8.9711e-04 - classifier_loss: 0.0311 - decoder_accuracy: 0.0660 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1674 - val_decoder_loss: 42.8973 - val_encoder_loss: 0.8727 - val_classifier_loss: 0.0499 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3923 - decoder_loss: 53.8923 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0309 - decoder_accuracy: 0.0660 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3923 - decoder_loss: 53.8923 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0309 - decoder_accuracy: 0.0660 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1686 - val_decoder_loss: 42.8950 - val_encoder_loss: 0.8741 - val_classifier_loss: 0.0498 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3915 - decoder_loss: 53.8843 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0309 - decoder_accuracy: 0.0662 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3915 - decoder_loss: 53.8843 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0309 - decoder_accuracy: 0.0662 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1695 - val_decoder_loss: 42.8929 - val_encoder_loss: 0.8752 - val_classifier_loss: 0.0497 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3907 - decoder_loss: 53.8763 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0308 - decoder_accuracy: 0.0663 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3907 - decoder_loss: 53.8763 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0308 - decoder_accuracy: 0.0663 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1703 - val_decoder_loss: 42.8908 - val_encoder_loss: 0.8762 - val_classifier_loss: 0.0497 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3899 - decoder_loss: 53.8681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0307 - decoder_accuracy: 0.0663 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3899 - decoder_loss: 53.8681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0307 - decoder_accuracy: 0.0663 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1709 - val_decoder_loss: 42.8886 - val_encoder_loss: 0.8771 - val_classifier_loss: 0.0496 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3892 - decoder_loss: 53.8599 - encoder_loss: 1.0558e-04 - classifier_loss: 0.0307 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3892 - decoder_loss: 53.8599 - encoder_loss: 1.0558e-04 - classifier_loss: 0.0307 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1698 - val_decoder_loss: 42.8876 - val_encoder_loss: 0.8761 - val_classifier_loss: 0.0494 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3883 - decoder_loss: 53.8526 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0306 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 109: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3883 - decoder_loss: 53.8526 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0306 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1703 - val_decoder_loss: 42.8855 - val_encoder_loss: 0.8769 - val_classifier_loss: 0.0494 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3877 - decoder_loss: 53.8443 - encoder_loss: 1.9126e-04 - classifier_loss: 0.0305 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3877 - decoder_loss: 53.8443 - encoder_loss: 1.9126e-04 - classifier_loss: 0.0305 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1811 - val_decoder_loss: 42.8813 - val_encoder_loss: 0.8880 - val_classifier_loss: 0.0496 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3871 - decoder_loss: 53.8399 - encoder_loss: 1.3281e-05 - classifier_loss: 0.0306 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3871 - decoder_loss: 53.8399 - encoder_loss: 1.3281e-05 - classifier_loss: 0.0306 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1807 - val_decoder_loss: 42.8802 - val_encoder_loss: 0.8878 - val_classifier_loss: 0.0495 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3863 - decoder_loss: 53.8327 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0305 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3863 - decoder_loss: 53.8327 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0305 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1817 - val_decoder_loss: 42.8782 - val_encoder_loss: 0.8889 - val_classifier_loss: 0.0494 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3855 - decoder_loss: 53.8246 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0304 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3855 - decoder_loss: 53.8246 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0304 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1825 - val_decoder_loss: 42.8761 - val_encoder_loss: 0.8899 - val_classifier_loss: 0.0493 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3849 - decoder_loss: 53.8164 - encoder_loss: 2.3693e-04 - classifier_loss: 0.0304 - decoder_accuracy: 0.0665 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3849 - decoder_loss: 53.8164 - encoder_loss: 2.3693e-04 - classifier_loss: 0.0304 - decoder_accuracy: 0.0665 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1833 - val_decoder_loss: 42.8725 - val_encoder_loss: 0.8911 - val_classifier_loss: 0.0493 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3841 - decoder_loss: 53.8110 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0303 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3841 - decoder_loss: 53.8110 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0303 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1838 - val_decoder_loss: 42.8704 - val_encoder_loss: 0.8918 - val_classifier_loss: 0.0492 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3833 - decoder_loss: 53.8028 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0302 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3833 - decoder_loss: 53.8028 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0302 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1843 - val_decoder_loss: 42.8683 - val_encoder_loss: 0.8926 - val_classifier_loss: 0.0491 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3826 - decoder_loss: 53.7947 - encoder_loss: 9.5528e-05 - classifier_loss: 0.0302 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.3826 - decoder_loss: 53.7947 - encoder_loss: 9.5528e-05 - classifier_loss: 0.0302 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1869 - val_decoder_loss: 42.8648 - val_encoder_loss: 0.8955 - val_classifier_loss: 0.0490 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3819 - decoder_loss: 53.7890 - encoder_loss: 1.1022e-05 - classifier_loss: 0.0301 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3819 - decoder_loss: 53.7890 - encoder_loss: 1.1022e-05 - classifier_loss: 0.0301 - decoder_accuracy: 0.0667 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1858 - val_decoder_loss: 42.8638 - val_encoder_loss: 0.8945 - val_classifier_loss: 0.0489 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3813 - decoder_loss: 53.7819 - encoder_loss: 8.3903e-05 - classifier_loss: 0.0300 - decoder_accuracy: 0.0670 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.3813 - decoder_loss: 53.7819 - encoder_loss: 8.3903e-05 - classifier_loss: 0.0300 - decoder_accuracy: 0.0670 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1937 - val_decoder_loss: 42.8602 - val_encoder_loss: 0.9028 - val_classifier_loss: 0.0489 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3807 - decoder_loss: 53.7767 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0300 - decoder_accuracy: 0.0670 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3807 - decoder_loss: 53.7767 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0300 - decoder_accuracy: 0.0670 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1949 - val_decoder_loss: 42.8582 - val_encoder_loss: 0.9042 - val_classifier_loss: 0.0488 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3799 - decoder_loss: 53.7687 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0299 - decoder_accuracy: 0.0671 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 121: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.3799 - decoder_loss: 53.7687 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0299 - decoder_accuracy: 0.0671 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1958 - val_decoder_loss: 42.8562 - val_encoder_loss: 0.9053 - val_classifier_loss: 0.0487 - val_decoder_accuracy: 0.0520 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3793 - decoder_loss: 53.7607 - encoder_loss: 2.2147e-04 - classifier_loss: 0.0298 - decoder_accuracy: 0.0672 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3793 - decoder_loss: 53.7607 - encoder_loss: 2.2147e-04 - classifier_loss: 0.0298 - decoder_accuracy: 0.0672 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1966 - val_decoder_loss: 42.8525 - val_encoder_loss: 0.9065 - val_classifier_loss: 0.0487 - val_decoder_accuracy: 0.0520 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3785 - decoder_loss: 53.7554 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0298 - decoder_accuracy: 0.0671 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.3785 - decoder_loss: 53.7554 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0298 - decoder_accuracy: 0.0671 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1972 - val_decoder_loss: 42.8505 - val_encoder_loss: 0.9073 - val_classifier_loss: 0.0486 - val_decoder_accuracy: 0.0522 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3777 - decoder_loss: 53.7474 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0297 - decoder_accuracy: 0.0671 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.3777 - decoder_loss: 53.7474 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0297 - decoder_accuracy: 0.0671 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1977 - val_decoder_loss: 42.8485 - val_encoder_loss: 0.9080 - val_classifier_loss: 0.0485 - val_decoder_accuracy: 0.0520 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3769 - decoder_loss: 53.7394 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0296 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3769 - decoder_loss: 53.7394 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0296 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.1983 - val_decoder_loss: 42.8465 - val_encoder_loss: 0.9088 - val_classifier_loss: 0.0484 - val_decoder_accuracy: 0.0520 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3765 - decoder_loss: 53.7313 - encoder_loss: 4.2777e-04 - classifier_loss: 0.0296 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.3765 - decoder_loss: 53.7313 - encoder_loss: 4.2777e-04 - classifier_loss: 0.0296 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2046 - val_decoder_loss: 42.8425 - val_encoder_loss: 0.9155 - val_classifier_loss: 0.0484 - val_decoder_accuracy: 0.0520 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3760 - decoder_loss: 53.7301 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0295 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3760 - decoder_loss: 53.7301 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0295 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2058 - val_decoder_loss: 42.8404 - val_encoder_loss: 0.9169 - val_classifier_loss: 0.0483 - val_decoder_accuracy: 0.0522 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3752 - decoder_loss: 53.7223 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0295 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3752 - decoder_loss: 53.7223 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0295 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2066 - val_decoder_loss: 42.8385 - val_encoder_loss: 0.9179 - val_classifier_loss: 0.0483 - val_decoder_accuracy: 0.0522 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3744 - decoder_loss: 53.7144 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0294 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3744 - decoder_loss: 53.7144 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0294 - decoder_accuracy: 0.0673 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2073 - val_decoder_loss: 42.8365 - val_encoder_loss: 0.9188 - val_classifier_loss: 0.0482 - val_decoder_accuracy: 0.0523 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3737 - decoder_loss: 53.7065 - encoder_loss: 7.2369e-05 - classifier_loss: 0.0293 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3737 - decoder_loss: 53.7065 - encoder_loss: 7.2369e-05 - classifier_loss: 0.0293 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2114 - val_decoder_loss: 42.8339 - val_encoder_loss: 0.9232 - val_classifier_loss: 0.0483 - val_decoder_accuracy: 0.0525 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3732 - decoder_loss: 53.6997 - encoder_loss: 2.6525e-04 - classifier_loss: 0.0293 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3732 - decoder_loss: 53.6997 - encoder_loss: 2.6525e-04 - classifier_loss: 0.0293 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2103 - val_decoder_loss: 42.8331 - val_encoder_loss: 0.9221 - val_classifier_loss: 0.0482 - val_decoder_accuracy: 0.0525 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3726 - decoder_loss: 53.6927 - encoder_loss: 3.8643e-04 - classifier_loss: 0.0293 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3726 - decoder_loss: 53.6927 - encoder_loss: 3.8643e-04 - classifier_loss: 0.0293 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2131 - val_decoder_loss: 42.8297 - val_encoder_loss: 0.9253 - val_classifier_loss: 0.0481 - val_decoder_accuracy: 0.0525 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3717 - decoder_loss: 53.6875 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0291 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3717 - decoder_loss: 53.6875 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0291 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2139 - val_decoder_loss: 42.8277 - val_encoder_loss: 0.9263 - val_classifier_loss: 0.0480 - val_decoder_accuracy: 0.0525 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3709 - decoder_loss: 53.6796 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0291 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3709 - decoder_loss: 53.6796 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0291 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2145 - val_decoder_loss: 42.8258 - val_encoder_loss: 0.9272 - val_classifier_loss: 0.0479 - val_decoder_accuracy: 0.0525 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3702 - decoder_loss: 53.6717 - encoder_loss: 8.8310e-05 - classifier_loss: 0.0290 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3702 - decoder_loss: 53.6717 - encoder_loss: 8.8310e-05 - classifier_loss: 0.0290 - decoder_accuracy: 0.0676 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2231 - val_decoder_loss: 42.8224 - val_encoder_loss: 0.9360 - val_classifier_loss: 0.0480 - val_decoder_accuracy: 0.0527 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3697 - decoder_loss: 53.6668 - encoder_loss: 1.2538e-04 - classifier_loss: 0.0290 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3697 - decoder_loss: 53.6668 - encoder_loss: 1.2538e-04 - classifier_loss: 0.0290 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2225 - val_decoder_loss: 42.8217 - val_encoder_loss: 0.9356 - val_classifier_loss: 0.0478 - val_decoder_accuracy: 0.0527 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3690 - decoder_loss: 53.6600 - encoder_loss: 1.2712e-04 - classifier_loss: 0.0289 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3690 - decoder_loss: 53.6600 - encoder_loss: 1.2712e-04 - classifier_loss: 0.0289 - decoder_accuracy: 0.0677 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2236 - val_decoder_loss: 42.8181 - val_encoder_loss: 0.9370 - val_classifier_loss: 0.0478 - val_decoder_accuracy: 0.0527 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3684 - decoder_loss: 53.6552 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0289 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.3684 - decoder_loss: 53.6552 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0289 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2242 - val_decoder_loss: 42.8162 - val_encoder_loss: 0.9378 - val_classifier_loss: 0.0477 - val_decoder_accuracy: 0.0527 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3676 - decoder_loss: 53.6475 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0288 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.3676 - decoder_loss: 53.6475 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0288 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2248 - val_decoder_loss: 42.8143 - val_encoder_loss: 0.9386 - val_classifier_loss: 0.0476 - val_decoder_accuracy: 0.0527 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3668 - decoder_loss: 53.6397 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0287 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.3668 - decoder_loss: 53.6397 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0287 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2254 - val_decoder_loss: 42.8124 - val_encoder_loss: 0.9394 - val_classifier_loss: 0.0475 - val_decoder_accuracy: 0.0528 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3661 - decoder_loss: 53.6318 - encoder_loss: 8.9455e-05 - classifier_loss: 0.0287 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 141: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3661 - decoder_loss: 53.6318 - encoder_loss: 8.9455e-05 - classifier_loss: 0.0287 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2340 - val_decoder_loss: 42.8059 - val_encoder_loss: 0.9486 - val_classifier_loss: 0.0476 - val_decoder_accuracy: 0.0533 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3663 - decoder_loss: 53.6331 - encoder_loss: 1.0478e-04 - classifier_loss: 0.0286 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3663 - decoder_loss: 53.6331 - encoder_loss: 1.0478e-04 - classifier_loss: 0.0286 - decoder_accuracy: 0.0678 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2334 - val_decoder_loss: 42.8053 - val_encoder_loss: 0.9481 - val_classifier_loss: 0.0474 - val_decoder_accuracy: 0.0533 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3655 - decoder_loss: 53.6267 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0285 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.3655 - decoder_loss: 53.6267 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0285 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2343 - val_decoder_loss: 42.8034 - val_encoder_loss: 0.9493 - val_classifier_loss: 0.0473 - val_decoder_accuracy: 0.0537 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3648 - decoder_loss: 53.6192 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0284 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.3648 - decoder_loss: 53.6192 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0284 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2351 - val_decoder_loss: 42.8016 - val_encoder_loss: 0.9502 - val_classifier_loss: 0.0473 - val_decoder_accuracy: 0.0537 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3640 - decoder_loss: 53.6116 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0284 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3640 - decoder_loss: 53.6116 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0284 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2357 - val_decoder_loss: 42.7998 - val_encoder_loss: 0.9510 - val_classifier_loss: 0.0472 - val_decoder_accuracy: 0.0537 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3632 - decoder_loss: 53.6040 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0283 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3632 - decoder_loss: 53.6040 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0283 - decoder_accuracy: 0.0680 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2363 - val_decoder_loss: 42.7980 - val_encoder_loss: 0.9518 - val_classifier_loss: 0.0471 - val_decoder_accuracy: 0.0540 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3625 - decoder_loss: 53.5962 - encoder_loss: 5.7682e-05 - classifier_loss: 0.0282 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3625 - decoder_loss: 53.5962 - encoder_loss: 5.7682e-05 - classifier_loss: 0.0282 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2406 - val_decoder_loss: 42.7955 - val_encoder_loss: 0.9563 - val_classifier_loss: 0.0473 - val_decoder_accuracy: 0.0540 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3619 - decoder_loss: 53.5897 - encoder_loss: 1.5247e-04 - classifier_loss: 0.0282 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3619 - decoder_loss: 53.5897 - encoder_loss: 1.5247e-04 - classifier_loss: 0.0282 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2392 - val_decoder_loss: 42.7949 - val_encoder_loss: 0.9550 - val_classifier_loss: 0.0471 - val_decoder_accuracy: 0.0542 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3611 - decoder_loss: 53.5830 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0282 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3611 - decoder_loss: 53.5830 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0282 - decoder_accuracy: 0.0682 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2398 - val_decoder_loss: 42.7931 - val_encoder_loss: 0.9558 - val_classifier_loss: 0.0470 - val_decoder_accuracy: 0.0542 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3603 - decoder_loss: 53.5753 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0281 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3603 - decoder_loss: 53.5753 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0281 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2402 - val_decoder_loss: 42.7913 - val_encoder_loss: 0.9564 - val_classifier_loss: 0.0469 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3598 - decoder_loss: 53.5675 - encoder_loss: 2.2352e-04 - classifier_loss: 0.0281 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.3598 - decoder_loss: 53.5675 - encoder_loss: 2.2352e-04 - classifier_loss: 0.0281 - decoder_accuracy: 0.0684 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2492 - val_decoder_loss: 42.7862 - val_encoder_loss: 0.9659 - val_classifier_loss: 0.0470 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3594 - decoder_loss: 53.5660 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0280 - decoder_accuracy: 0.0685 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3594 - decoder_loss: 53.5660 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0280 - decoder_accuracy: 0.0685 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2505 - val_decoder_loss: 42.7844 - val_encoder_loss: 0.9673 - val_classifier_loss: 0.0470 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3586 - decoder_loss: 53.5585 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0280 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3586 - decoder_loss: 53.5585 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0280 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2514 - val_decoder_loss: 42.7827 - val_encoder_loss: 0.9684 - val_classifier_loss: 0.0469 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3579 - decoder_loss: 53.5509 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0279 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.3579 - decoder_loss: 53.5509 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0279 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2521 - val_decoder_loss: 42.7809 - val_encoder_loss: 0.9694 - val_classifier_loss: 0.0468 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3572 - decoder_loss: 53.5432 - encoder_loss: 5.2542e-05 - classifier_loss: 0.0278 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.3572 - decoder_loss: 53.5432 - encoder_loss: 5.2542e-05 - classifier_loss: 0.0278 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2507 - val_decoder_loss: 42.7805 - val_encoder_loss: 0.9680 - val_classifier_loss: 0.0467 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3564 - decoder_loss: 53.5366 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0278 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.3564 - decoder_loss: 53.5366 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0278 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2512 - val_decoder_loss: 42.7787 - val_encoder_loss: 0.9687 - val_classifier_loss: 0.0466 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3557 - decoder_loss: 53.5289 - encoder_loss: 7.6756e-05 - classifier_loss: 0.0277 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3557 - decoder_loss: 53.5289 - encoder_loss: 7.6756e-05 - classifier_loss: 0.0277 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2517 - val_decoder_loss: 42.7752 - val_encoder_loss: 0.9695 - val_classifier_loss: 0.0465 - val_decoder_accuracy: 0.0552 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3552 - decoder_loss: 53.5243 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0277 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3552 - decoder_loss: 53.5243 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0277 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2519 - val_decoder_loss: 42.7734 - val_encoder_loss: 0.9700 - val_classifier_loss: 0.0464 - val_decoder_accuracy: 0.0552 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3545 - decoder_loss: 53.5167 - encoder_loss: 3.2023e-05 - classifier_loss: 0.0276 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5.3545 - decoder_loss: 53.5167 - encoder_loss: 3.2023e-05 - classifier_loss: 0.0276 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2583 - val_decoder_loss: 42.7700 - val_encoder_loss: 0.9767 - val_classifier_loss: 0.0465 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3540 - decoder_loss: 53.5123 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0276 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3540 - decoder_loss: 53.5123 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0276 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2595 - val_decoder_loss: 42.7683 - val_encoder_loss: 0.9780 - val_classifier_loss: 0.0464 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3532 - decoder_loss: 53.5048 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0275 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3532 - decoder_loss: 53.5048 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0275 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2602 - val_decoder_loss: 42.7666 - val_encoder_loss: 0.9789 - val_classifier_loss: 0.0463 - val_decoder_accuracy: 0.0552 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3525 - decoder_loss: 53.4972 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0275 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 162: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.3525 - decoder_loss: 53.4972 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0275 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2608 - val_decoder_loss: 42.7649 - val_encoder_loss: 0.9797 - val_classifier_loss: 0.0462 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3518 - decoder_loss: 53.4895 - encoder_loss: 1.3618e-04 - classifier_loss: 0.0274 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 163: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3518 - decoder_loss: 53.4895 - encoder_loss: 1.3618e-04 - classifier_loss: 0.0274 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2637 - val_decoder_loss: 42.7600 - val_encoder_loss: 0.9831 - val_classifier_loss: 0.0461 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3519 - decoder_loss: 53.4881 - encoder_loss: 3.6322e-04 - classifier_loss: 0.0273 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3519 - decoder_loss: 53.4881 - encoder_loss: 3.6322e-04 - classifier_loss: 0.0273 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2622 - val_decoder_loss: 42.7596 - val_encoder_loss: 0.9816 - val_classifier_loss: 0.0460 - val_decoder_accuracy: 0.0552 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3509 - decoder_loss: 53.4818 - encoder_loss: 3.1521e-05 - classifier_loss: 0.0272 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.3509 - decoder_loss: 53.4818 - encoder_loss: 3.1521e-05 - classifier_loss: 0.0272 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2668 - val_decoder_loss: 42.7571 - val_encoder_loss: 0.9865 - val_classifier_loss: 0.0462 - val_decoder_accuracy: 0.0552 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3510 - decoder_loss: 53.4758 - encoder_loss: 6.6385e-04 - classifier_loss: 0.0272 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 166: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 5.3510 - decoder_loss: 53.4758 - encoder_loss: 6.6385e-04 - classifier_loss: 0.0272 - decoder_accuracy: 0.0687 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2684 - val_decoder_loss: 42.7557 - val_encoder_loss: 0.9882 - val_classifier_loss: 0.0461 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3497 - decoder_loss: 53.4703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0271 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.3497 - decoder_loss: 53.4703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0271 - decoder_accuracy: 0.0686 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2694 - val_decoder_loss: 42.7539 - val_encoder_loss: 0.9894 - val_classifier_loss: 0.0460 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3490 - decoder_loss: 53.4629 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0271 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3490 - decoder_loss: 53.4629 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0271 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2700 - val_decoder_loss: 42.7521 - val_encoder_loss: 0.9901 - val_classifier_loss: 0.0459 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3483 - decoder_loss: 53.4555 - encoder_loss: 2.3681e-05 - classifier_loss: 0.0270 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3483 - decoder_loss: 53.4555 - encoder_loss: 2.3681e-05 - classifier_loss: 0.0270 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2796 - val_decoder_loss: 42.7489 - val_encoder_loss: 1.0001 - val_classifier_loss: 0.0460 - val_decoder_accuracy: 0.0550 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3478 - decoder_loss: 53.4514 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0270 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3478 - decoder_loss: 53.4514 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0270 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2812 - val_decoder_loss: 42.7472 - val_encoder_loss: 1.0019 - val_classifier_loss: 0.0459 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3471 - decoder_loss: 53.4441 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0269 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5.3471 - decoder_loss: 53.4441 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0269 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2822 - val_decoder_loss: 42.7456 - val_encoder_loss: 1.0031 - val_classifier_loss: 0.0459 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3464 - decoder_loss: 53.4366 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0269 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.3464 - decoder_loss: 53.4366 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0269 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2831 - val_decoder_loss: 42.7440 - val_encoder_loss: 1.0042 - val_classifier_loss: 0.0458 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3456 - decoder_loss: 53.4291 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0268 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3456 - decoder_loss: 53.4291 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0268 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2839 - val_decoder_loss: 42.7424 - val_encoder_loss: 1.0051 - val_classifier_loss: 0.0457 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3451 - decoder_loss: 53.4216 - encoder_loss: 2.8476e-04 - classifier_loss: 0.0268 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3451 - decoder_loss: 53.4216 - encoder_loss: 2.8476e-04 - classifier_loss: 0.0268 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2847 - val_decoder_loss: 42.7391 - val_encoder_loss: 1.0062 - val_classifier_loss: 0.0456 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3444 - decoder_loss: 53.4174 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0267 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 5.3444 - decoder_loss: 53.4174 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0267 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2852 - val_decoder_loss: 42.7374 - val_encoder_loss: 1.0069 - val_classifier_loss: 0.0456 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3437 - decoder_loss: 53.4099 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0267 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3437 - decoder_loss: 53.4099 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0267 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2857 - val_decoder_loss: 42.7358 - val_encoder_loss: 1.0076 - val_classifier_loss: 0.0455 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3432 - decoder_loss: 53.4024 - encoder_loss: 2.6599e-04 - classifier_loss: 0.0266 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3432 - decoder_loss: 53.4024 - encoder_loss: 2.6599e-04 - classifier_loss: 0.0266 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2956 - val_decoder_loss: 42.7326 - val_encoder_loss: 1.0178 - val_classifier_loss: 0.0455 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3427 - decoder_loss: 53.3983 - encoder_loss: 2.1145e-04 - classifier_loss: 0.0266 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3427 - decoder_loss: 53.3983 - encoder_loss: 2.1145e-04 - classifier_loss: 0.0266 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2948 - val_decoder_loss: 42.7323 - val_encoder_loss: 1.0171 - val_classifier_loss: 0.0454 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3419 - decoder_loss: 53.3920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0265 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3419 - decoder_loss: 53.3920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0265 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2958 - val_decoder_loss: 42.7307 - val_encoder_loss: 1.0182 - val_classifier_loss: 0.0453 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3416 - decoder_loss: 53.3847 - encoder_loss: 4.7469e-04 - classifier_loss: 0.0265 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3416 - decoder_loss: 53.3847 - encoder_loss: 4.7469e-04 - classifier_loss: 0.0265 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.2992 - val_decoder_loss: 42.7259 - val_encoder_loss: 1.0221 - val_classifier_loss: 0.0452 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3410 - decoder_loss: 53.3837 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0263 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.3410 - decoder_loss: 53.3837 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0263 - decoder_accuracy: 0.0688 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3001 - val_decoder_loss: 42.7243 - val_encoder_loss: 1.0231 - val_classifier_loss: 0.0452 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3403 - decoder_loss: 53.3766 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0263 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3403 - decoder_loss: 53.3766 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0263 - decoder_accuracy: 0.0689 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3008 - val_decoder_loss: 42.7228 - val_encoder_loss: 1.0240 - val_classifier_loss: 0.0451 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3396 - decoder_loss: 53.3694 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0262 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3396 - decoder_loss: 53.3694 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0262 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3015 - val_decoder_loss: 42.7213 - val_encoder_loss: 1.0248 - val_classifier_loss: 0.0450 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3388 - decoder_loss: 53.3621 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0262 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3388 - decoder_loss: 53.3621 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0262 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3021 - val_decoder_loss: 42.7197 - val_encoder_loss: 1.0256 - val_classifier_loss: 0.0449 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3382 - decoder_loss: 53.3548 - encoder_loss: 1.0326e-04 - classifier_loss: 0.0261 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3382 - decoder_loss: 53.3548 - encoder_loss: 1.0326e-04 - classifier_loss: 0.0261 - decoder_accuracy: 0.0690 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3002 - val_decoder_loss: 42.7195 - val_encoder_loss: 1.0237 - val_classifier_loss: 0.0448 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3378 - decoder_loss: 53.3485 - encoder_loss: 3.4587e-04 - classifier_loss: 0.0260 - decoder_accuracy: 0.0691 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3378 - decoder_loss: 53.3485 - encoder_loss: 3.4587e-04 - classifier_loss: 0.0260 - decoder_accuracy: 0.0691 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3147 - val_decoder_loss: 42.7154 - val_encoder_loss: 1.0387 - val_classifier_loss: 0.0451 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3372 - decoder_loss: 53.3462 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0261 - decoder_accuracy: 0.0692 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3372 - decoder_loss: 53.3462 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0261 - decoder_accuracy: 0.0692 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3165 - val_decoder_loss: 42.7138 - val_encoder_loss: 1.0406 - val_classifier_loss: 0.0450 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3365 - decoder_loss: 53.3390 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0260 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3365 - decoder_loss: 53.3390 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0260 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3177 - val_decoder_loss: 42.7123 - val_encoder_loss: 1.0420 - val_classifier_loss: 0.0449 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3358 - decoder_loss: 53.3318 - encoder_loss: 1.6373e-05 - classifier_loss: 0.0260 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3358 - decoder_loss: 53.3318 - encoder_loss: 1.6373e-05 - classifier_loss: 0.0260 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3163 - val_decoder_loss: 42.7123 - val_encoder_loss: 1.0406 - val_classifier_loss: 0.0448 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3353 - decoder_loss: 53.3257 - encoder_loss: 1.7243e-04 - classifier_loss: 0.0259 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3353 - decoder_loss: 53.3257 - encoder_loss: 1.7243e-04 - classifier_loss: 0.0259 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3172 - val_decoder_loss: 42.7090 - val_encoder_loss: 1.0418 - val_classifier_loss: 0.0448 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3348 - decoder_loss: 53.3219 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0258 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3348 - decoder_loss: 53.3219 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0258 - decoder_accuracy: 0.0693 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3177 - val_decoder_loss: 42.7074 - val_encoder_loss: 1.0425 - val_classifier_loss: 0.0447 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3341 - decoder_loss: 53.3147 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0258 - decoder_accuracy: 0.0694 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3341 - decoder_loss: 53.3147 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0258 - decoder_accuracy: 0.0694 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3183 - val_decoder_loss: 42.7059 - val_encoder_loss: 1.0432 - val_classifier_loss: 0.0446 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3333 - decoder_loss: 53.3076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0257 - decoder_accuracy: 0.0696 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.3333 - decoder_loss: 53.3076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0257 - decoder_accuracy: 0.0696 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3188 - val_decoder_loss: 42.7043 - val_encoder_loss: 1.0439 - val_classifier_loss: 0.0445 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3326 - decoder_loss: 53.3003 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0257 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3326 - decoder_loss: 53.3003 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0257 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3192 - val_decoder_loss: 42.7028 - val_encoder_loss: 1.0445 - val_classifier_loss: 0.0444 - val_decoder_accuracy: 0.0548 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3328 - decoder_loss: 53.2930 - encoder_loss: 9.2316e-04 - classifier_loss: 0.0256 - decoder_accuracy: 0.0696 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 5.3328 - decoder_loss: 53.2930 - encoder_loss: 9.2316e-04 - classifier_loss: 0.0256 - decoder_accuracy: 0.0696 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3322 - val_decoder_loss: 42.6964 - val_encoder_loss: 1.0582 - val_classifier_loss: 0.0445 - val_decoder_accuracy: 0.0542 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3321 - decoder_loss: 53.2959 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0255 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3321 - decoder_loss: 53.2959 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0255 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3341 - val_decoder_loss: 42.6950 - val_encoder_loss: 1.0602 - val_classifier_loss: 0.0444 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3315 - decoder_loss: 53.2891 - encoder_loss: 4.3026e-05 - classifier_loss: 0.0255 - decoder_accuracy: 0.0696 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3315 - decoder_loss: 53.2891 - encoder_loss: 4.3026e-05 - classifier_loss: 0.0255 - decoder_accuracy: 0.0696 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3328 - val_decoder_loss: 42.6950 - val_encoder_loss: 1.0589 - val_classifier_loss: 0.0443 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3309 - decoder_loss: 53.2832 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0254 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3309 - decoder_loss: 53.2832 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0254 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3338 - val_decoder_loss: 42.6936 - val_encoder_loss: 1.0600 - val_classifier_loss: 0.0442 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3302 - decoder_loss: 53.2763 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0254 - decoder_accuracy: 0.0696 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3302 - decoder_loss: 53.2763 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0254 - decoder_accuracy: 0.0696 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3345 - val_decoder_loss: 42.6921 - val_encoder_loss: 1.0609 - val_classifier_loss: 0.0441 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3295 - decoder_loss: 53.2692 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0253 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.3295 - decoder_loss: 53.2692 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0253 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3352 - val_decoder_loss: 42.6907 - val_encoder_loss: 1.0617 - val_classifier_loss: 0.0440 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3287 - decoder_loss: 53.2621 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0252 - decoder_accuracy: 0.0697 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.3287 - decoder_loss: 53.2621 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0252 - decoder_accuracy: 0.0697 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3357 - val_decoder_loss: 42.6892 - val_encoder_loss: 1.0624 - val_classifier_loss: 0.0440 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3280 - decoder_loss: 53.2549 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0252 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3280 - decoder_loss: 53.2549 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0252 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3362 - val_decoder_loss: 42.6878 - val_encoder_loss: 1.0630 - val_classifier_loss: 0.0439 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3273 - decoder_loss: 53.2477 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0251 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 203: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 5.3273 - decoder_loss: 53.2477 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0251 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3366 - val_decoder_loss: 42.6863 - val_encoder_loss: 1.0636 - val_classifier_loss: 0.0438 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3268 - decoder_loss: 53.2404 - encoder_loss: 2.8106e-04 - classifier_loss: 0.0251 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 204: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3268 - decoder_loss: 53.2404 - encoder_loss: 2.8106e-04 - classifier_loss: 0.0251 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3489 - val_decoder_loss: 42.6824 - val_encoder_loss: 1.0763 - val_classifier_loss: 0.0441 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3266 - decoder_loss: 53.2382 - encoder_loss: 3.0303e-04 - classifier_loss: 0.0251 - decoder_accuracy: 0.0697 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 205: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.3266 - decoder_loss: 53.2382 - encoder_loss: 3.0303e-04 - classifier_loss: 0.0251 - decoder_accuracy: 0.0697 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3481 - val_decoder_loss: 42.6824 - val_encoder_loss: 1.0755 - val_classifier_loss: 0.0440 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3257 - decoder_loss: 53.2323 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0251 - decoder_accuracy: 0.0697 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 206: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3257 - decoder_loss: 53.2323 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0251 - decoder_accuracy: 0.0697 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3492 - val_decoder_loss: 42.6809 - val_encoder_loss: 1.0767 - val_classifier_loss: 0.0439 - val_decoder_accuracy: 0.0547 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3251 - decoder_loss: 53.2252 - encoder_loss: 1.0774e-04 - classifier_loss: 0.0250 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 207: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.3251 - decoder_loss: 53.2252 - encoder_loss: 1.0774e-04 - classifier_loss: 0.0250 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3500 - val_decoder_loss: 42.6779 - val_encoder_loss: 1.0778 - val_classifier_loss: 0.0439 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3247 - decoder_loss: 53.2217 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0250 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 208: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5.3247 - decoder_loss: 53.2217 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0250 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3506 - val_decoder_loss: 42.6766 - val_encoder_loss: 1.0786 - val_classifier_loss: 0.0438 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3240 - decoder_loss: 53.2147 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0249 - decoder_accuracy: 0.0699 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 209: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3240 - decoder_loss: 53.2147 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0249 - decoder_accuracy: 0.0699 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3512 - val_decoder_loss: 42.6752 - val_encoder_loss: 1.0793 - val_classifier_loss: 0.0437 - val_decoder_accuracy: 0.0545 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3232 - decoder_loss: 53.2076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0249 - decoder_accuracy: 0.0699 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 210: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3232 - decoder_loss: 53.2076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0249 - decoder_accuracy: 0.0699 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3517 - val_decoder_loss: 42.6739 - val_encoder_loss: 1.0800 - val_classifier_loss: 0.0436 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3225 - decoder_loss: 53.2005 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0248 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 211: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5.3225 - decoder_loss: 53.2005 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0248 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3522 - val_decoder_loss: 42.6726 - val_encoder_loss: 1.0806 - val_classifier_loss: 0.0436 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3220 - decoder_loss: 53.1933 - encoder_loss: 2.1383e-04 - classifier_loss: 0.0248 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 212: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3220 - decoder_loss: 53.1933 - encoder_loss: 2.1383e-04 - classifier_loss: 0.0248 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3526 - val_decoder_loss: 42.6695 - val_encoder_loss: 1.0813 - val_classifier_loss: 0.0435 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3217 - decoder_loss: 53.1897 - encoder_loss: 2.8670e-04 - classifier_loss: 0.0247 - decoder_accuracy: 0.0699 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 213: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3217 - decoder_loss: 53.1897 - encoder_loss: 2.8670e-04 - classifier_loss: 0.0247 - decoder_accuracy: 0.0699 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3489 - val_decoder_loss: 42.6695 - val_encoder_loss: 1.0776 - val_classifier_loss: 0.0434 - val_decoder_accuracy: 0.0542 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3211 - decoder_loss: 53.1836 - encoder_loss: 2.8120e-04 - classifier_loss: 0.0246 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 214: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3211 - decoder_loss: 53.1836 - encoder_loss: 2.8120e-04 - classifier_loss: 0.0246 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3598 - val_decoder_loss: 42.6664 - val_encoder_loss: 1.0889 - val_classifier_loss: 0.0434 - val_decoder_accuracy: 0.0542 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.3205 - decoder_loss: 53.1801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0246 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 215: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.3205 - decoder_loss: 53.1801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0246 - decoder_accuracy: 0.0698 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.3612 - val_decoder_loss: 42.6651 - val_encoder_loss: 1.0904 - val_classifier_loss: 0.0434 - val_decoder_accuracy: 0.0542 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 215: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xcZZ3n8c+3qrvTuQG5ySUBEzRggjAQQozKKA6Oy0VuoxBQVBg1MwgC3nYyo6uM6846O6OziyKIDiMqEDGKRAdkgQFZh4AEwRDuEcF0ICQEEnLr9KV++8c5VV3d6e5UNzmp7j7f9+vVr1SdS9WvzqtT336e55znKCIwM7P8KtS7ADMzqy8HgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5ZyDwHJF0vckfaXGbZ+V9O6sazKrNweBmVnOOQjMhiFJDfWuwUYOB4ENOWmXzOckrZC0VdK/StpX0q2SNku6Q9KEqu1PlfSopI2S7pY0q2rdUZJ+m+73I6C5x3u9V9LD6b73SjqixhpPlvSQpFclrZZ0WY/1x6avtzFdf166fLSkr0l6TtImSb9Olx0nqaWX4/Du9PFlkpZI+qGkV4HzJM2TtCx9jxckfVNSU9X+h0m6XdLLkl6U9HeS9pO0TdKkqu3mSFovqbGWz24jj4PAhqr3AX8OHAKcAtwK/B0wheT39mIASYcANwCXputuAX4uqSn9UvwZ8ANgIvDj9HVJ9z0KuAb4K2AS8G1gqaRRNdS3FfgwsA9wMnCBpNPT1319Wu830pqOBB5O9/tn4GjgbWlN/xUo1XhMTgOWpO95HdAJfAqYDLwVOB74RFrDeOAO4JfAAcAbgTsjYi1wN3BW1et+CFgcEe011mEjjIPAhqpvRMSLEbEG+H/A/RHxUES0AjcBR6XbLQD+PSJuT7/I/hkYTfJFOx9oBP53RLRHxBLggar3WAh8OyLuj4jOiLgW2JHu16+IuDsiHomIUkSsIAmjd6arPwDcERE3pO+7ISIellQA/hK4JCLWpO95b0TsqPGYLIuIn6XvuT0iHoyI+yKiIyKeJQmycg3vBdZGxNciojUiNkfE/em6a4FzASQVgXNIwtJyykFgQ9WLVY+39/J8XPr4AOC58oqIKAGrganpujXRfWbF56oevx74TNq1slHSRuDAdL9+SXqLpLvSLpVNwF+T/GVO+hq/72W3ySRdU72tq8XqHjUcIukXktam3UX/UEMNADcDsyXNIGl1bYqI3wyyJhsBHAQ23D1P8oUOgCSRfAmuAV4ApqbLyg6qerwa+B8RsU/Vz5iIuKGG970eWAocGBF7A1cB5fdZDbyhl31eAlr7WLcVGFP1OYok3UrVek4VfCXwBDAzIvYi6TqrruHg3gpPW1U3krQKPoRbA7nnILDh7kbgZEnHp4OdnyHp3rkXWAZ0ABdLapT0F8C8qn2/A/x1+te9JI1NB4HH1/C+44GXI6JV0jyS7qCy64B3SzpLUoOkSZKOTFsr1wBfl3SApKKkt6ZjEk8Bzen7NwJfAHY1VjEeeBXYIulNwAVV634B7C/pUkmjJI2X9Jaq9d8HzgNOxUGQew4CG9Yi4kmSv2y/QfIX9ynAKRHRFhFtwF+QfOG9TDKe8NOqfZcDHwe+CbwCrEq3rcUngC9L2gx8kSSQyq/7R+AkklB6mWSg+E/S1Z8FHiEZq3gZ+EegEBGb0tf8LklrZivQ7SyiXnyWJIA2k4Taj6pq2EzS7XMKsBZ4GnhX1fr/JBmk/m1EVHeXWQ7JN6YxyydJ/wFcHxHfrXctVl8OArMcknQMcDvJGMfmetdj9eWuIbOckXQtyTUGlzoEDNwiMDPLPbcIzMxybthNXDV58uSYPn16vcswMxtWHnzwwZcioue1KcAwDILp06ezfPnyepdhZjasSOrzNGF3DZmZ5ZyDwMws5xwEZmY5N+zGCHrT3t5OS0sLra2t9S4lc83NzUybNo3GRt9DxMx2jxERBC0tLYwfP57p06fTfaLJkSUi2LBhAy0tLcyYMaPe5ZjZCJFZ15CkayStk7Syj/WSdLmkVUpuSThnsO/V2trKpEmTRnQIAEhi0qRJuWj5mNmek+UYwfeAE/pZfyIwM/1ZSDK3+qCN9BAoy8vnNLM9J7OuoYi4R9L0fjY5Dfh+eveo+yTtI2n/iHghq5oq2rfD9o2D27fYwKbC3owudNK0Y+fX2NHRSXtnttN27Nj8Mvd999OZvoeZDT0T55zGIXPeuesNB6ieYwRT6X7rvZZ02U5BIGkhSauBgw46qOfqgdu6HrZtGPTuL5TE1MYtNHW+AsDGTZu5/qZbueC8s2gCmmrMgZM/9Emu++Y/sM/etdwHpUtT5xaOWH3NAKs2s+Hugb32hxEWBDWLiKuBqwHmzp372v/cjoBiE+x72MD2274RXvkDRUqUOjsqr7Gx7Vm+df3POf+zX+HpdZs5cMIYJoxtoqOjg4aGvg/xLf/x60GVr1cfp/D3g2zRmNmw9ZZdbzIo9QyCNST3li2bli4bugrF5B9KEJ2ECghYtGgRv//97zlm7hxQkX3Gj2HixIk88cQTPPXUU5x++umsXr2a1tZWLrnkEhYuXAh0TZexZcsWTjzxRI499ljuvfdepk6dys0338zo0aPr+GHNLC/qGQRLgYskLSYJuk27Y3zg73/+KI89/2r/G3W0QnRC4y62S80+YC++dMphoGRsvUiJIiU6o0AD8NWvfpWVK1dyy13LuOvuu/jEh89i5cqVlVM8r7nmGiZOnMj27ds55phjeN/73sekSZO6vcfTTz/NDTfcwHe+8x3OOussfvKTn3DuuecO+PObmQ1UZkEg6QbgOGCypBbgS0AjQERcBdxCcl/XVcA24PysaumjwoHvkrYIykHQEcVuB3BrWwfNDQXmzZvX7Tz/yy+/nJtuugmA1atX8/TTT+8UBDNmzODII48E4Oijj+bZZ58deH1mZoOQ5VlD5+xifQAX7u73/dIpNfT7v/yH5MyhfWcP7MWVBEFjIWgg2B4FmoFtOzro6AzaO0s0NxUZO3ZsZZe7776bO+64g2XLljFmzBiOO+64Xq8DGDVqVOVxsVhk+/btA6vNzGyQ8jvX0GBOxy90BUGREu0l0VkqsTUaeHXzqxQLYnRTsdsumzZtYsKECYwZM4YnnniC++67bzcUb2a2+wyLs4ayMYgkUIESokElRIlOxJYdHTSPm8D8t76NBe95O6NHj2bfffet7HLCCSdw1VVXMWvWLA499FDmz5+/Gz+Dmdlrl9MgGNwZqBFBZxRopBMRdFJk/eY2guDaH/yQ8c07TwQ3atQobr311l5frzwOMHnyZFau7JqJ47Of/eyg6jMzG4z8dg0NokXQWQo6KdBIB5D05W9r60DAmB5dQmZmw0U+g2CQl6S1d5YoUaAY7QA0NiQtgObGIsVCPg+lmQ1/7hrqoa2jxLa2DvYZ08S2tg42bW/vtm4iBVTaAUBTUyO0wthROT2MZjYi5PcbrI+eoQ1bd7B+8w7GjmrghU2tbN3R0W3Gzwnp1cQAzU1NjGoI9h7tm8SY2fCV0yAI+kqCto4SAFt3dLC9rZPJ40ZxwD5VUz1s3ATbtgLJGMGh+3kaCDMb3tyx3UN5CumXtrRRimBsz0FgFXt/bGY2TOUzCAL6ahG0dyYtgm1tyZlBY3r2/xeKvT8egHHjxgHw/PPP8/73v7/XbY477jiWL18+qNc3MxuIfAZBH4PFpUimiSikYwKjGoo0FnscIhV6fzwIBxxwAEuWLHlNr2Fm9lrlNAjotUFQbg3slV4YtlO3EHS1AlSENDAWLVrEFVdcUdnksssu4ytf+QrHH388c+bM4fDDD+fmm2/e6aWeffZZ3vzmNwOwfft2zj77bGbNmsUZZ5zhuYbMbI8ZeYPFty6CtY/0v037tuTfxjHdFjeUShzcXqK5scDkzhJNxQIUCrDf4XDiV5ONyuMCVd1CCxYs4NJLL+XCC5M59G688UZuu+02Lr74Yvbaay9eeukl5s+fz6mnntrnPYevvPJKxowZw+OPP86KFSuYM2fOwD+7mdkgjLwgeA1K6b8FiTGNfRya6hZB6qijjmLdunU8//zzrF+/ngkTJrDffvvxqU99invuuYdCocCaNWt48cUX2W+//Xp92XvuuYeLL74YgCOOOIIjjjhid30sM7N+jbwgKP/l3p/1TyXdOpNndlv88qutvPhqK2+eunel22cnvbQIAM4880yWLFnC2rVrWbBgAddddx3r16/nwQcfpLGxkenTp/c6/bSZWb3ld4ygl0GC9o4SDcVCZbC4V5UWQfdDt2DBAhYvXsySJUs488wz2bRpE6973etobGzkrrvu4rnnnuu3mne84x1cf/31AKxcuZIVK1YM7OOYmQ3SyGsR1CR6HSxuK48L9KfSIuh+6A477DA2b97M1KlT2X///fngBz/IKaecwuGHH87cuXN505ve1O/LXnDBBZx//vnMmjWLWbNmcfTRRw/kA5mZDVpOg6DL5tZ2trQm1wy0tpcYO2oX1waUWwS9TDL3yCNdg9STJ09m2bJlvb7Eli1bgOTm9eXpp0ePHs3ixYsHWr6Z2WuW0yDommJizcbttHdEZUhg3K4mkJNg1HhoHNv/dmZmw0ROgyDR3lmiraPE/nuPZsr4UbveoWzSG7MrysxsDxsxg8URA7jJQDrFxNYdSZfQLruDhpABfU4zsxqMiCBobm5mw4YNA/uSFGxt66QgMbpxeARBRLBhwwaam5vrXYqZjSAjomto2rRptLS0sH79+tp22LwWCg2s69xEQeKJVwfQLVRnzc3NTJs2rd5lmNkIMiKCoLGxkRkzZtS+wxXn0T7xEE5acTaXHD+TS+cdkl1xZmZD3IjoGhqwKLGtvUQEvGm/vepdjZlZXeU2CCI9fbSx2M9VxGZmOZDbICilQdDvdBJmZjmQ2yCI9KM7B8ws7/IbBGkCFAtOAjPLt5wGAZUWgbuGzCzvchoEXYPFzgEzy7v8BoHcIjAzgzwHgc8aMjMDchwEpcoYQZ1rMTOrs9wGQaVF4CQws5xzELhryMxyzkHgHDCznMtpEITPGjIzS+U0CEqUwtcRmJlBxkEg6QRJT0paJWlRL+sPknSXpIckrZB0Upb1dInKFBNuEZhZ3mUWBJKKwBXAicBs4BxJs3ts9gXgxog4Cjgb+FZW9XRTdfqo5xoys7zLskUwD1gVEc9ERBuwGDitxzYBlO8MszfwfIb1VL2rB4vNzMqyDIKpwOqq5y3psmqXAedKagFuAT7Z2wtJWihpuaTlNd+XuD9V9yOQu4bMLOfqPVh8DvC9iJgGnAT8QNJONUXE1RExNyLmTpky5bW/a9X9CDxGYGZ5l2UQrAEOrHo+LV1W7aPAjQARsQxoBiZnWFOi2x3KMn83M7MhLcsgeACYKWmGpCaSweClPbb5I3A8gKRZJEGwG/p+dsFXFpuZVWQWBBHRAVwE3AY8TnJ20KOSvizp1HSzzwAfl/Q74AbgvIiIrGpKC0v+8VxDZmYANGT54hFxC8kgcPWyL1Y9fgx4e5Y17FxUCcBdQ2ZmqXoPFu95lSDwYLGZGeQyCJKuoZJvVWlmBuQyCJIWgQeLzcwSuQ2Ccoug6CAws5zLcRB4jMDMDHIdBOkYQf6OgJlZN/n7GqyMEbhFYGYGOQ6CUnrZmq8jMLO8y2EQdD991C0CM8u7HAaBB4vNzKrlLwhIWwThKSbMzCCPQbDTXENOAjPLt9wHgXPAzPIu10Eg+VaVZma5DgJ3C5mZ5ToICp5nyMyMPAdByOMDZmbkMgjKF5T5jCEzM8hlEHS1CHwNgZlZjoOg04PFZmZALoMg6RoKCh4jMDMjl0GQtghCFN03ZGaW3yDwdQRmZoncBkEn8lXFZmbkOAh81pCZWaKmIJD0U0knSyPgDr/dgsBJYGZW6xf7t4APAE9L+qqkQzOsKVvpWUPJ6aN1rsXMbAioKQgi4o6I+CAwB3gWuEPSvZLOl9SYZYG7XfVgsZPAzKz2MQJJk4DzgI8BDwH/hyQYbs+ksqy4a8jMrJuGWjaSdBNwKPAD4JSIeCFd9SNJy7MqLhPdTh+tcy1mZkNATUEAXB4Rd/W2IiLm7sZ69oBkjKAjPOmcmRnU3jU0W9I+5SeSJkj6REY1ZavSNeQpJszMoPYg+HhEbCw/iYhXgI9nU1LGfGWxmVk3tQZBUVWX4UoqAk3ZlJSxylxDeK4hMzNqHyP4JcnA8LfT53+VLht+KlNMFDzFhJkZtQfB35B8+V+QPr8d+G4mFWXNU0yYmXVTUxBERAm4Mv0Z3spXFvusITMzoPbrCGYC/xOYDTSXl0fEwRnVlZ3KGEHBLQIzM2ofLP43ktZAB/Au4PvAD7MqKlOVs4bwFBNmZtQeBKMj4k5AEfFcRFwGnLyrnSSdIOlJSaskLepjm7MkPSbpUUnX1176IHmKCTOzbmodLN6RTkH9tKSLgDXAuP52SE8xvQL4c6AFeEDS0oh4rGqbmcDfAm+PiFckvW4wH2JAKmMEojD8J9U2M3vNav0qvAQYA1wMHA2cC3xkF/vMA1ZFxDMR0QYsBk7rsc3HgSvSC9SIiHW1Fj5oldNH8emjZmbUEATpX/YLImJLRLRExPkR8b6IuG8Xu04FVlc9b0mXVTsEOETSf0q6T9IJfdSwUNJyScvXr1+/q5L7Vw6CkgeLzcyghiCIiE7g2IzevwGYCRwHnAN8p3pOo6oaro6IuRExd8qUKa/tHataBB4jMDOrfYzgIUlLgR8DW8sLI+Kn/eyzBjiw6vm0dFm1FuD+iGgH/iDpKZJgeKDGugaucvqoPMWEmRm1jxE0AxuAPwNOSX/eu4t9HgBmSpohqQk4G1jaY5ufkbQGkDSZpKvomRprGpyqwWKPEZiZ1X5l8fkDfeGI6EjPMLoNKALXRMSjkr4MLI+Ipem690h6jKS35nMRsWGg7zWwwspdQ55iwswMar+y+N8o39GlSkT8ZX/7RcQtwC09ln2x6nEAn05/9oyqriGPEZiZ1T5G8Iuqx83AGcDzu7+cPaBy1hAUnQNmZjV3Df2k+rmkG4BfZ1JR5tIxAkSDWwRmZjUPFvc0E8j+KuAsVE0xUXQQmJnVPEawme5jBGtJ7lEw/KRB0OEpJszMgNq7hsZnXcgeU3WrSp8+amZWY9eQpDMk7V31fB9Jp2dX1u73y5Vr+di1y+no7ASgFAWfNWRmRu1jBF+KiE3lJxGxEfhSNiVlo+WVbdzx+It0pkHQDr6OwMyM2oOgt+1qPfV0SGgsJh+hHAS+VaWZWaLWIFgu6euS3pD+fB14MMvCdredgqDkriEzM6g9CD4JtAE/IrmvQCtwYVZFZaExvXqse4ugnhWZmQ0NtZ41tBXo9VaTw0VTQ9oiKHmKCTOzarWeNXR79X0CJE2QdFt2Ze1+5a6hUql8HQG+jsDMjNq7hianZwoBkN5aclhdWbzzYLGnoTYzg9qDoCTpoPITSdPpZTbSoaw8RlCqCgKPEZiZ1X4K6OeBX0v6FSDgT4GFmVWVgaZyi6CUBEFH4LmGzMyofbD4l5Lmknz5P0RyZ7HtWRa2uzWmg8Wlzq7BYncNmZnVPuncx4BLSO47/DAwH1hGcuvKYaFrsLi6a8hBYGZW6xjBJcAxwHMR8S7gKGBj/7sMLZXrCKrPGnIOmJnVHAStEdEKIGlURDwBHJpdWbtfU7cWgSgFFJwEZmY1Dxa3pNcR/Ay4XdIrwHPZlbX7desaUoFSgHuGzMxqHyw+I314maS7gL2BX2ZWVQbKg8XRWQKJiPBZQ2ZmDGIG0Yj4VRaFZK3r9NGotAg8WGxmNvh7Fg875SCIKHcNhQeLzczIURA0NqRXFpc6CRUI36rSzAzIUxCUWwSlEih57K4hM7McBUFDoTzXUKlyulAxN5/ezKxvufkqlERTsUApHSMoLzMzy7vcBAEkVxe7a8jMrLt8BUFDIQkCykFQ33rMzIaCfAVBsUCpVCLcIjAzq8hVEDQVC+l1BEkAOAfMzHIWBMkYQZDcWweK7hsyM8tbEBSI8GCxmVm1/AVBtzGCOhdkZjYE5CsIGgqVuYbA1xGYmUHOgqCpKCiViHSMwF1DZmZ5C4KGnmMEdS7IzGwIyFUQlAeLK2METgIzs/wFAaWuSefcNWRmlnEQSDpB0pOSVkla1M9275MUkuZmWU9TsQBRIjzFhJlZRWZBIKkIXAGcCMwGzpE0u5ftxgOXAPdnVUtZY1HpGIFbBGZmZVm2COYBqyLimYhoAxYDp/Wy3X8H/hFozbAWeGQJn/zjJTREe6VF4BwwM8s2CKYCq6uet6TLKiTNAQ6MiH/v74UkLZS0XNLy9evXD66azWt5w7bf0RQ73CIwM6tSt8FiSQXg68BndrVtRFwdEXMjYu6UKVMG94YNowAYFa2VFoHnGjIzyzYI1gAHVj2fli4rGw+8Gbhb0rPAfGBpZgPGlSDY4SkmzMyqZBkEDwAzJc2Q1AScDSwtr4yITRExOSKmR8R04D7g1IhYnkk1xTQIaKuahtpJYGaWWRBERAdwEXAb8DhwY0Q8KunLkk7N6n37lLYImmmrOn3UQWBm1pDli0fELcAtPZZ9sY9tj8uyFhqaARjNDkqVuYYyfUczs2EhP1cWNzQBSYug5EnnzMwqchQESYugWe2UIg0CNwnMzHIUBOlgMeCuITOzKvkJgoauIOgMdw2ZmZXlKAiaKw/LLQLngJlZroKgqfLQLQIzsy45CoKuFoGDwMysS36CoNjVIih3DRXz8+nNzPqUn6/Cbi2C5F9PMWFmlqsg8FlDZma9yU8QSJQKSfdQR/g6AjOzsvwEARDpRWVuEZiZdclZECQtgvIYgYPAzCxnQVAeJ+gslecaqmcxZmZDQ66+CiM9c6jDLQIzs4pcBYEqXUMeLDYzK8tVENCYtAjaw7eqNDMry1UQKB0j6Cglz901ZGaWtyBIWwTlICg6CMzM8hUEhXSwuC0NAueAmVnOgqA8FfWOzuSpb1VpZpa7ICh3DfmsITOzsnwFQTrFRNc9i50EZmb5CoL0rKH0ejKPEZiZkbsgSLqGIv3YPmvIzCx3QZAMFrtryMysS86CIGkROAjMzLrkKwiK5RZB8rGVr09vZtarfH0VVsYI3CIwMyvLWRD0PH20nsWYmQ0NOQ2C5GO7RWBmlrsg8GCxmVlP+QqCdLA43DVkZlaRryDwYLGZ2U5yFgTdB4udA2ZmOQ4CybeqNDODnAZBUPA8Q2ZmqXwFQXka6pDHB8zMUvkKgh5dQ2ZmlnEQSDpB0pOSVkla1Mv6T0t6TNIKSXdKen2W9XRdR1Bwi8DMLJVZEEgqAlcAJwKzgXMkze6x2UPA3Ig4AlgC/K+s6gEqLYJCoeBrCMzMUlm2COYBqyLimYhoAxYDp1VvEBF3RcS29Ol9wLQM66kEQWODWwRmZmVZBsFUYHXV85Z0WV8+Ctza2wpJCyUtl7R8/fr1g6+oaRz82RdY1vg2Cm4SmJkBQ2SwWNK5wFzgn3pbHxFXR8TciJg7ZcqU1/JG8I7PsWH0Qe4aMjNLNWT42muAA6ueT0uXdSPp3cDngXdGxI4M66kY09RAQW174q3MzIa8LFsEDwAzJc2Q1AScDSyt3kDSUcC3gVMjYl2GtXQzblSDryo2M0tlFgQR0QFcBNwGPA7cGBGPSvqypFPTzf4JGAf8WNLDkpb28XK71ZimoruGzMxSWXYNERG3ALf0WPbFqsfvzvL9+zJ2VIPPGjIzS2UaBEPVB95yEPMPnljvMszMhoRcBsEx0ydyzHQHgZkZDJHTR83MrH4cBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnCKi3jUMiKT1wHOD3H0y8NJuLGck8bHpn49P33xs+jaUjs3rI6LXefyHXRC8FpKWR8TcetcxFPnY9M/Hp28+Nn0bLsfGXUNmZjnnIDAzy7m8BcHV9S5gCPOx6Z+PT998bPo2LI5NrsYIzMxsZ3lrEZiZWQ8OAjOznMtNEEg6QdKTklZJWlTveupN0rOSHknvFb08XTZR0u2Snk7/nVDvOvcESddIWidpZdWyXo+FEpenv0crJM2pX+XZ6+PYXCZpTfq787Ckk6rW/W16bJ6U9F/qU/WeIelASXdJekzSo5IuSZcPu9+dXASBpCJwBXAiMBs4R9Ls+lY1JLwrIo6sOs95EXBnRMwE7kyf58H3gBN6LOvrWJwIzEx/FgJX7qEa6+V77HxsAP4l/d05Mr03Oen/qbOBw9J9vpX+3xupOoDPRMRsYD5wYXoMht3vTi6CAJgHrIqIZyKiDVgMnFbnmoai04Br08fXAqfXsZY9JiLuAV7usbivY3Ea8P1I3AfsI2n/PVPpntfHsenLacDiiNgREX8AVpH83xuRIuKFiPht+ngz8DgwlWH4u5OXIJgKrK563pIuy7MA/q+kByUtTJftGxEvpI/XAvvWp7Qhoa9j4d+lxEVp98Y1VV2IuT02kqYDRwH3Mwx/d/ISBLazYyNiDklz9UJJ76heGcl5xT63GB+LXlwJvAE4EngB+Fp9y6kvSeOAnwCXRsSr1euGy+9OXoJgDXBg1fNp6bLciog16b/rgJtImvAvlpuq6b/r6ldh3fV1LHL/uxQRL0ZEZ0SUgO/Q1f2Tu2MjqZEkBK6LiJ+mi4fd705eguABYKakGZKaSAa0lta5prqRNFbS+PJj4D3ASpJj8pF0s48AN9enwiGhr2OxFPhwegbIfGBTVTdALvTo1z6D5HcHkmNztqRRkmaQDIr+Zk/Xt6dIEvCvwOMR8fWqVcPvdycicvEDnAQ8Bfwe+Hy966nzsTgY+F3682j5eACTSM5yeBq4A5hY71r30PG4gaSLo52k3/ajfR0LQCRnoP0eeASYW+/663BsfpB+9hUkX277V23/+fTYPAmcWO/6Mz42x5J0+6wAHk5/ThqOvzueYsLMLOfy0jVkZmZ9cBCYmeWcg8DMLOccBGZmOecgMDPLOQeB2R4k6ThJv6h3HWbVHARmZjnnIDDrhaRzJf0mnW//25KKkrZI+pd07vk7JU1Jtz1S0n3pJGw3Vc0//0ZJd0j6naTfSnpD+vLjJC2R9ISk69IrVM3qxkFg1oOkWcAC4J7zJ6sAAAFNSURBVO0RcSTQCXwQGAssj4jDgF8BX0p3+T7wNxFxBMkVo+Xl1wFXRMSfAG8juUIXklkqLyW5N8bBwNsz/1Bm/WiodwFmQ9DxwNHAA+kf66NJJg4rAT9Kt/kh8FNJewP7RMSv0uXXAj9O53KaGhE3AUREK0D6er+JiJb0+cPAdODX2X8ss945CMx2JuDaiPjbbgul/9Zju8HOz7Kj6nEn/n9odeauIbOd3Qm8X9LroHIP2teT/H95f7rNB4BfR8Qm4BVJf5ou/xDwq0juWNUi6fT0NUZJGrNHP4VZjfyXiFkPEfGYpC+Q3MGtQDLz5oXAVmBeum4dyTgCJFMNX5V+0T8DnJ8u/xDwbUlfTl/jzD34Mcxq5tlHzWokaUtEjKt3HWa7m7uGzMxyzi0CM7Occ4vAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxy7v8DsiUtsz7FfyMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_16 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_17 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_8 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_16 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_17 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_9[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 14.0979 - decoder_loss: 48.1068 - encoder_loss: 9.2356 - classifier_loss: 0.5160 - decoder_accuracy: 0.0381 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7333\n",
            "F1-score is computed based on binary\n",
            "(loss: 14.097868919372559, accuracy: 0.7333333492279053)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.93      0.78        15\n",
            "         1.0       0.89      0.53      0.67        15\n",
            "\n",
            "    accuracy                           0.73        30\n",
            "   macro avg       0.78      0.73      0.72        30\n",
            "weighted avg       0.78      0.73      0.72        30\n",
            "\n",
            "Accuracy: 0.7333333492279053\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEKCAYAAABuTfznAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAX2ElEQVR4nO3debxcZX3H8c/33oTlQkKICXkJyiJLNEQDNJVNKRCruAFWtEWwKijSsFhFqVYUtdJacBepvQJCi4KAUgWVRasFEdBAEkyCQJElkS0hISwJzcKvf5xzyWTuMmcmM/OcufN9v17zysycmef87r2vfF/Pc55znqOIwMzMNuhJXYCZWdk4GM3MqjgYzcyqOBjNzKo4GM3MqjgYzcyqOBjNbNSQdKGkxyUtGGLbaZJC0qRa7TgYzWw0uQg4rPpNSS8FXg88VKQRB6OZjRoRcSOwfIhNXwFOBwpd0TKmmUWVjcZsGdpsXOoyrA57v2LH1CVYHR588AGWLVumTWmjd/xOEetWF/psrF66EHiu4q3+iOgf6TuSjgD+FBHzpWKlju5g3Gwcm099Z+oyrA4333Zu6hKsDgfuO3OT24h1qwv/P31u3jefi4jCO5XUB/wj2TC6sFEdjGbWCQRq2VG9XYFdgIHe4kuAOyS9OiIeHe5LDkYzS0tAT29Lmo6I3wPbvbAr6QFgZkQsG+l7nnwxs/SkYo+azehS4BZgqqQlko5vpBz3GM0sseYNpSPi6Brbdy7SjoPRzNIrOFvcLg5GM0tLtHLypSEORjNLrNjxw3ZyMJpZei2alW6Ug9HMEmvpeYwNcTCaWVrCQ2kzs0HcYzQzq+ShtJnZxgT0evLFzGxjPsZoZlbJQ2kzs8HcYzQzq+Ieo5lZhYJLirWTg9HM0vMlgWZmlTz5YmY2mIfSZmYVvB6jmVk1D6XNzAbz5IuZWRUfYzQzqyAPpc3MBnOP0cxsY3IwmpltkN3ZoFzBWK6BvZl1Hwn1FHvUbkoXSnpc0oKK986R9AdJd0q6StKEWu04GM0sOUmFHgVcBBxW9d4NwPSIeBVwD/CJWo04GM0suWYFY0TcCCyveu/6iFiXv7wVeEmtdnyM0cySq+MY4yRJcype90dEfx27Og74fq0PORjNLC3lj2KWRcTMhnYjfRJYB3y31mcdjGaWlCh8/LDxfUjvBd4CzIqIqPV5B6OZJdfT07rpDkmHAacDfxERqwrV07JqzMwKatbki6RLgVuAqZKWSDoeOBcYB9wgaZ6kb9Vqxz1GM0urvmOMI4qIo4d4+4J623EwmllyZbvyxcFoZkm1Y/KlXg5GM0uuyOV+7eRgNLO05KG0mdkgDkYzsyoORjOzCp58MTMbSrly0cFoZomptZcENsLBaGbJeShtZlatXLnoRSTK7hufOoZ7rvsXfnPZPw7adtIxh7Lid+cycZutElRmRZz8uUvY/fUfZ/+/Pit1KaXWxFsbNEWyYJT0TB2fnSzpNklzJb1W0uxW1lYml15zK0ed+s1B7+8wZQKH7PsKFj+yfIhvWVkc/Zb9uPLrJ6Uuo9SKhmJXBGOdZgG/j4i9gcVA1wTjb+bex4qnBi8hd9aH385nvvFfFFhz0xI6cJ/d2HZ8X+oySq9swViqY4ySdgW+CUwGVgEfALYAzga2lDQTuBvYVdI84IaI+FiqelN540Gv5JGlT7Lg3j+lLsWsKXyt9Mj6gRMj4l5J+wLnRcShkj4NzIyIkyXtDOwZEXsN1YCkE4ATABi7dXuqbqMtNx/LR973Bt5+8rmpSzFrGs9KD0PS1sABwBUVv6TN620nv2NYP0BP33ajbpy5y0sms9P2L+Km72W3xt1+uwn8zyX/wKz3nsPjTzyduDqzBngRiRH1AE8O1xO0zKL7HmaPN2y4X/j8H32WQ/72bJavfDZhVWaNE1CyXCzP5EtEPAXcL+kdAMrMGOKjT5Pdv6ErnP/593L9haex205TWHDNP3Hs4funLsnqcPwnv8Prj/sS//vgY+z55jP4zx/9JnVJJVS+WemUPcY+SUsqXn8ZOAb4N0lnAGOBy4D5lV+KiCck3SxpAfCz0T758v4zLhpx+4wjzmxPIdaQC856X+oSOkKPJ18yETFcb/WwIT57EXBRxet3taYqM2s7lW8oXaZjjGbWhYR7jGZmg7jHaGZWpWyn65RmVtrMulR+jLHIo2ZT0oWSHs8nZwfemyjpBkn35v9uW6sdB6OZJSVET09PoUcBFzF4AvfjwC8iYnfgF/nrETkYzSy5ZvUYI+JGoHrJqSOAi/PnFwNH1mrHxxjNLLk6jjFOkjSn4nV/fhnwSKZExCP580eBKbV24mA0s7TqO49xWUTMbHRXERGSaq6h4KG0mSWVXSvd0ksCH5P0YrL9vBh4vNYXHIxmllyzjjEO48fAe/Ln7wF+VOsLHkqbWXLNuvJF0qXAwWTHIpcAZwJfAC6XdDzwIPDOWu04GM0srSauxxgRRw+zaVY97TgYzSypMq7H6GA0s8Tau9ZiEQ5GM0uuZLnoYDSzxORlx8zMNjJwHmOZOBjNLDkHo5lZlZLlooPRzNJzj9HMrJJvhmVmtrFsodpyJaOD0cyS6ylZl9HBaGbJlSwXHYxmlpaauIhEszgYzSy5kh1iHD4YJX0DGHYJ8Ig4tSUVmVnX6aTJlzkjbDMzawqRzUyXybDBGBEXV76W1BcRq1pfkpl1m5J1GGvf80XS/pIWAX/IX8+QdF7LKzOz7lDwRljtnKApcjOsrwJvAJ4AiIj5wEGtLMrMukuLb4ZVt0Kz0hGxuCqt17emHDPrNqIzT/BeLOkAICSNBT4E3NXassysm5RtVrrIUPpE4CRgB+BhYK/8tZnZJis6jC7VUDoilgHHtKEWM+tSZRtKF5mVfpmkqyUtlfS4pB9Jelk7ijOz7qCCj3YpMpT+HnA58GJge+AK4NJWFmVm3aUTT9fpi4j/jIh1+eMSYItWF2Zm3SGblS72qNmW9GFJCyUtkHSppIayathglDRR0kTgZ5I+LmlnSTtJOh34aSM7MzMbRNlCtUUeIzejHYBTgZkRMR3oBf6mkZJGmny5nWwRiYFqPlixLYBPNLJDM7NqTRwmjwG2lLQW6CM7k6ahRoYUEbs0WJiZWWEDQ+mCJkmqXOCmPyL6ASLiT5K+CDwErAauj4jrG6mp0JUvkqYD06g4thgR/9HIDs3MqtXRY1wWETOHaWNb4AhgF+BJ4ApJx+bzInUpcrrOmcA38schwNnA4fXuyMxsOE06Xed1wP0RsTQi1gI/BA5opJ4is9JHAbOARyPifcAMYJtGdmZmVk2C3h4VetTwELCfpD5lXdBZNHj5cpGh9OqIeF7SOknjgceBlzayMzOzoTRj8iUibpN0JXAHsA6YC/Q30laRYJwjaQLwbbKZ6meAWxrZmZnZUJo1KR0RZwJnbmo7Ra6Vnp0//Zaka4HxEXHnpu7YzAyy2xqU7VrpkW6Gtc9I2yLijtaUZGZdpc0r5xQxUo/xSyNsC+DQJtfSdFN22I7j/tk3M+wkH7zcg5FO8uCK1U1pp2PuKx0Rh7SzEDPrTgJ6OyUYzczapWQLeDsYzSw9B6OZWYXstgXlSsYilwRK0rGSPp2/3lHSq1tfmpl1i2atx9i0egp85jxgf+Do/PXTwDdbVpGZdZ2OuxkWsG9E7CNpLkBErJC0WYvrMrMuIWBMyYbSRYJxraResnMXkTQZeL6lVZlZVylZLhYKxq8DVwHbSTqLbLWdM1palZl1DamDLgkcEBHflXQ72RI+Ao6MiIaW8jEzG0rJcrF2MEraEVgFXF35XkQ81MrCzKx7dOJ5jD9hw02xtiBbNvxuYM8W1mVmXUJQZBHatioylH5l5et81Z3Zw3zczKw+bT5HsYi6r3yJiDsk7duKYsysO6nIHV3aqMgxxo9UvOwB9qHBe7WamVWr8/apbVGkxziu4vk6smOOP2hNOWbWjToqGPMTu8dFxEfbVI+ZdaGyLSIx0q0NxkTEOkkHtrMgM+su2e1TU1exsZF6jL8lO544T9KPgSuAZwc2RsQPW1ybmXWJjrvyhezcxSfI7vEycD5jAA5GM9tknTb5sl0+I72ADYE4IFpalZl1lZJ1GEcMxl5gaxjyBCMHo5k1iehp0nmMkiYA5wPTyXLquIi4pd52RgrGRyLicw3WZ2ZWiGhqj/FrwLURcVS+bmxfI42MFIwl69ya2agkGNOEg4yStgEOAt4LEBFrgDWNtDXSJPmsRho0M6vHQI+x4K0NJkmaU/E4oaKpXYClwHckzZV0vqStGqlp2B5jRCxvpEEzs3rVcbrOsoiYOcy2MWSnGJ4SEbdJ+hrwceBTdddT7xfMzJqtSTfDWgIsiYjb8tdXkgVl3RyMZpaUyIKoyGMkEfEosFjS1PytWcCiRmqqe9kxM7OmUlOvfDkF+G4+I/1H4H2NNOJgNLOksitfmhOMETEPGO4YZGEORjNLrmznBjoYzSy5Trok0MysDdQ56zGambXDwKx0mTgYzSy5TlyP0cysddRBtzYwM2sHD6XNzIbgHqOZWZVyxaKD0cwSE9DrHqOZ2cZKlosORjNLTahkg2kHo5kl5x6jmVmF7HSdciWjg9HM0iq2OndbORjNLDlfEmhmViFbqDZ1FRtzMJpZcp6VNjOrUrKRtIOxkyxfuoKfXPazF16vXL6SA163H/scuHfCqmwks/aYxGt2mUgAf1r5HBf/djHrno/UZZVO1/QYJa0Hfp/v437g3RHxpKTtga9HxFE1vv9MRGw9xPtHAvdEREO3RexkEydvy7tPeRcAzz//PP1fuJDdpu2auCobzoQtx3DobpP4zHV3s3Z98IH9d+TPd5zALQ+sSF1aqZTxGGMrV/tZHRF7RcR0YDlwEkBEPFwrFGs4EpjWjAI72UP3LWbCxG0Yv+341KXYCHp6YGxvDz2CzXp7eHL12tQllY9ET8FHu7RrGbRbgB0AJO0saUH+vE/S5ZIWSbpK0m2SXrj1oaSzJM2XdKukKZIOAA4HzpE0T1LXdpfuvvNeps7YI3UZNoInV6/jhruX8i9vfjlnv3Uaq9eu567HnkldVimp4KNdWh6MknqBWcCPh9g8G1gREdOATwF/VrFtK+DWiJgB3Ah8ICJ+k7fzsbw3et8Q+ztB0hxJc1Y9NTqHLOvXree+u/7IHtN3T12KjaBvbC8ztt+GT/70D5x+9SI2H9PDvjtOSF1W6QzcV7pbeoxbSpoHPApMAW4Y4jOvAS4DiIgFwJ0V29YA1+TPbwd2LrLTiOiPiJkRMbNv/LYNll5u99/zAFO2n8xW4/pSl2IjePmUrVn27Bqe+b/1PB8wd8lKXjbJf7OhNLPHKKlX0lxJ19T+9NBafowR2InsZzqpzu+vjYiB6bv1eAb9BXfPv4epM6amLsNqWL5qDS97UR9je7P/0i+fsjWPPvV/iasqqeaOpT8E3LUp5bR8KB0Rq4BTgdMkVYfbzcA7ASRNA15ZoMmngXFNLbKDrF2zlgf/dzG779m1h1c7xgPLV3PHkpWc8Ze78+k37IEQN/1xeeqySqlZQ2lJLwHeDJy/KfW0pRcWEXMl3QkcDdxUsek84GJJi4A/AAuBlTWauwz4tqRTgaOGOs44mo3dbCyzP3VC6jKsoKsXPsbVCx9LXUbpNfHo4VeB09nEzlPLgrH6HMSIeGvFy+n5v88Bx0bEc/kM88+BB6u/HxFXAlfmz2/Gp+uYjS7Fk3GSpDkVr/sjoh9A0luAxyPidkkHb0o5qY/b9QG/lDSW7FczOyLWJK7JzNooO3xYOBmXRcTMYbYdCBwu6U3AFsB4SZdExLH11pQ0GCPiaWC4H9LMukGT1mOMiE8AnwDIe4wfbSQUIX2P0cysZFdKOxjNLDmhJp+8HRG/An7V6PcdjGaWnJcdMzOr0O7roItwMJpZeiVLRgejmSXXNQvVmpkV5WOMZmaVfF9pM7PBPJQ2M6sg3GM0MxukZLnoYDSzEihZMjoYzSy5dt7PpQgHo5klV65YdDCaWRmULBkdjGaWVJ0L1baFg9HM0vIJ3mZmg5UsFx2MZpZa8xeq3VQORjNLrmS56GA0s7S8UK2Z2VBKlowORjNLzqfrmJlV8TFGM7NKgh4Ho5lZtXIlo4PRzJIq40K1PakLMDNTwceIbUgvlfRLSYskLZT0oUbrcY/RzJJrUo9xHXBaRNwhaRxwu6QbImJRvQ05GM0suWZcEhgRjwCP5M+flnQXsAPgYDSzzlNHLE6SNKfidX9E9A9qT9oZ2Bu4rZF6HIxmlpTqW3ZsWUTMHLk9bQ38APj7iHiqkZocjGaWXLOufJE0liwUvxsRP2y0HQejmaXXhFxUdqDyAuCuiPjyprTl03XMLLlmnK4DHAi8GzhU0rz88aZG6nGP0cwSU1NunxoRv6ZJl9A4GM0sKV/5YmbWAdxjNLPkytZjdDCaWXJeqNbMrJLvK21mtrEyTr44GM0sOQ+lzcyquMdoZlalZLnoYDSzEihZMjoYzSwpQVMuCWwmRUTqGlpG0lLgwdR1tMAkYFnqIqwuo/VvtlNETN6UBiRdS/b7KWJZRBy2KfsrYlQH42glaU6txTqtXPw36yy+VtrMrIqD0cysioOxMw26+Y+Vnv9mHcTHGM3MqrjHaGZWxcFoZlbFwVgykp6p47OTJd0maa6k10qa3craLCNpfX6jpQWSrpY0IX9/e0lXFvj+kH9jSUdKmtbseq1+DsbONgv4fUTsDSwGHIztsToi9oqI6cBy4CSAiHg4Io7ahHaPBByMJeBg7ACSdpV0raTbJd0k6eWS9gLOBo6QNA/4V2DXvCdzTtqKu8otwA4AknaWtCB/3ifpckmLJF2V9+xfOMFb0lmS5ku6VdIUSQcAhwPn5H/DXZP8NAb4WulO0Q+cGBH3StoXOC8iDpX0aWBmRJwsaWdgz4jYK2Wh3URSL1mv/YIhNs8GVkTENEnTgXkV27YCbo2IT0o6G/hARHxe0o+BayKi5nDcWsvBWHKStgYOAK7QhgvtN09XkQFb5r30HYC7gBuG+MxrgK8BRMQCSXdWbFsDXJM/vx34yxbWag3wULr8eoAn82NaA49XpC6qy63Oe+Y7kS0Oc1Kd318bG04gXo87KKXjYCy5iHgKuF/SOwCUmTHER58GxrW1uC4XEauAU4HTJFWH283AOwHymeZXFmjSf8OScDCWT5+kJRWPjwDHAMdLmg8sBI6o/lJEPAHcnJ9C4smXNomIucCdwNFVm84DJktaBHye7O+2skZzlwEfy0+/8uRLQr4k0KwF8omZsRHxXB5yPwemRsSaxKVZAT62YdYafcAvJY0lOw4526HYOdxjNDOr4mOMZmZVHIxmZlUcjGZmVRyMXaxqlZgrJPVtQlsXSToqf37+SKvESDo4vza43n08IGnQ3eSGe7/qM4VXLco//xlJH623RhsdHIzdrXKVmDXAiZUbhzhpuZCIeH9ELBrhIweTXeZoVkoORhtwE7Bb3pu7KV/QYJGkXknnSPqdpDslfRBeuALnXEl3S/o5sN1AQ5J+NbCSjKTDJN2RryTzi3yxixOBD+e91dfm60r+IN/H7yQdmH/3RZKul7RQ0vlkp72MSNJ/5asQLZR0QtW2r+Tv/0LS5Py9QSsXNeOXaZ3N5zHaQM/wjcC1+Vv7ANMj4v48XFZGxJ9L2pzs6prrgb2BqWTrB04BFgEXVrU7Gfg2cFDe1sSIWC7pW8AzEfHF/HPfA74SEb+WtCNwHfAK4Ezg1xHxOUlvBo4v8OMcl+9jS+B3kn6QXxW0FTAnIj6cr0p0JnAyQ6xcBBzawK/RRhEHY3cbWCUGsh7jBWRD3N9GxP35+68HXjVw/BDYBtgdOAi4NCLWAw9L+u8h2t8PuHGgrYhYPkwdrwOmVaweND5fVegg4K/y7/5E0ooCP9Opkt6WP39pXusTwPPA9/P3LwF+6JWLbDgOxu42sErMC/KAeLbyLeCUiLiu6nNvamIdPcB+EfHcELUUJulgspDdPyJWSfoVsMUwHw8qVi6qt2Ab3XyM0Wq5Dvi7/NI2JO0haSvgRuCv82OQLwYOGeK7twIHSdol/+7E/P3qVWSuB04ZeKFsdXLyfbwrf++NwLY1at2GbHHYVfmxwv0qtvUAA73ed5EN0YuuXGRdxsFotZxPdvzwDmXL9v872UjjKuDefNt/kC3xv5GIWAqcQDZsnc+GoezVwNsGJl/Ilu6amU/uLGLD7PhnyYJ1IdmQ+qEatV4LjJF0F/AFsmAe8Czw6vxnOBT4XP5+zZWLrPv4WmkzsyruMZqZVXEwmplVcTCamVVxMJqZVXEwmplVcTCamVVxMJqZVfl/RiKy9LiiX54AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7333333492279053\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fold4"
      ],
      "metadata": {
        "id": "34jgeoKtxNxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=10, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=200,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(4,5):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-7rfB9hrxO8Z",
        "outputId": "18fc580f-24d5-423b-a796-e9154f9c030b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 4\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_26 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_27 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_13 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_26 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_27 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.4811 - decoder_loss: 26.2856 - encoder_loss: 3.7897 - classifier_loss: 0.6279 - decoder_accuracy: 0.0181 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5500\n",
            "Epoch 1: val_loss improved from inf to 1068.83301, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.4811 - decoder_loss: 26.2856 - encoder_loss: 3.7897 - classifier_loss: 0.6279 - decoder_accuracy: 0.0181 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5500 - val_loss: 1068.8330 - val_decoder_loss: 24.8300 - val_encoder_loss: 1066.2393 - val_classifier_loss: 1.1069 - val_decoder_accuracy: 0.0137 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.2246 - decoder_loss: 26.2792 - encoder_loss: 1.5284 - classifier_loss: 0.6828 - decoder_accuracy: 0.0169 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.5750\n",
            "Epoch 2: val_loss improved from 1068.83301 to 6.74726, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 4.2246 - decoder_loss: 26.2792 - encoder_loss: 1.5284 - classifier_loss: 0.6828 - decoder_accuracy: 0.0169 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.5750 - val_loss: 6.7473 - val_decoder_loss: 24.7610 - val_encoder_loss: 4.2023 - val_classifier_loss: 0.6884 - val_decoder_accuracy: 0.0137 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.6124 - decoder_loss: 26.2676 - encoder_loss: 1.9289 - classifier_loss: 0.5673 - decoder_accuracy: 0.0186 - encoder_accuracy: 0.0500 - classifier_accuracy: 0.8250\n",
            "Epoch 3: val_loss did not improve from 6.74726\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 4.6124 - decoder_loss: 26.2676 - encoder_loss: 1.9289 - classifier_loss: 0.5673 - decoder_accuracy: 0.0186 - encoder_accuracy: 0.0500 - classifier_accuracy: 0.8250 - val_loss: 27.1650 - val_decoder_loss: 24.8843 - val_encoder_loss: 24.5896 - val_classifier_loss: 0.8696 - val_decoder_accuracy: 0.0177 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.3000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.7608 - decoder_loss: 26.2889 - encoder_loss: 6.0809 - classifier_loss: 0.5095 - decoder_accuracy: 0.0203 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000\n",
            "Epoch 4: val_loss improved from 6.74726 to 5.54061, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 8.7608 - decoder_loss: 26.2889 - encoder_loss: 6.0809 - classifier_loss: 0.5095 - decoder_accuracy: 0.0203 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000 - val_loss: 5.5406 - val_decoder_loss: 24.7618 - val_encoder_loss: 2.9529 - val_classifier_loss: 1.1149 - val_decoder_accuracy: 0.0135 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.9972 - decoder_loss: 26.2413 - encoder_loss: 4.3197 - classifier_loss: 0.5338 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7250\n",
            "Epoch 5: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 6.9972 - decoder_loss: 26.2413 - encoder_loss: 4.3197 - classifier_loss: 0.5338 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7250 - val_loss: 11.4981 - val_decoder_loss: 24.6540 - val_encoder_loss: 8.9290 - val_classifier_loss: 1.0366 - val_decoder_accuracy: 0.0167 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.3000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.0609 - decoder_loss: 26.1610 - encoder_loss: 5.3862 - classifier_loss: 0.5853 - decoder_accuracy: 0.0195 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750\n",
            "Epoch 6: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.0609 - decoder_loss: 26.1610 - encoder_loss: 5.3862 - classifier_loss: 0.5853 - decoder_accuracy: 0.0195 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750 - val_loss: 53.2653 - val_decoder_loss: 24.5736 - val_encoder_loss: 50.7175 - val_classifier_loss: 0.9049 - val_decoder_accuracy: 0.0103 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.3000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 12.6138 - decoder_loss: 25.8954 - encoder_loss: 9.9822 - classifier_loss: 0.4206 - decoder_accuracy: 0.0178 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 7: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 12.6138 - decoder_loss: 25.8954 - encoder_loss: 9.9822 - classifier_loss: 0.4206 - decoder_accuracy: 0.0178 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 8.9156 - val_decoder_loss: 25.2682 - val_encoder_loss: 6.2621 - val_classifier_loss: 1.2667 - val_decoder_accuracy: 0.0145 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7648 - decoder_loss: 26.3390 - encoder_loss: 1.0854 - classifier_loss: 0.4548 - decoder_accuracy: 0.0174 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000\n",
            "Epoch 8: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3.7648 - decoder_loss: 26.3390 - encoder_loss: 1.0854 - classifier_loss: 0.4548 - decoder_accuracy: 0.0174 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000 - val_loss: 21.5619 - val_decoder_loss: 24.5183 - val_encoder_loss: 18.9911 - val_classifier_loss: 1.1896 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.6363 - decoder_loss: 25.8909 - encoder_loss: 6.0063 - classifier_loss: 0.4093 - decoder_accuracy: 0.0299 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 9: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.6363 - decoder_loss: 25.8909 - encoder_loss: 6.0063 - classifier_loss: 0.4093 - decoder_accuracy: 0.0299 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 12.7561 - val_decoder_loss: 24.3460 - val_encoder_loss: 10.2618 - val_classifier_loss: 0.5966 - val_decoder_accuracy: 0.0297 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9344 - decoder_loss: 25.6032 - encoder_loss: 0.3568 - classifier_loss: 0.1725 - decoder_accuracy: 0.0377 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 10: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.9344 - decoder_loss: 25.6032 - encoder_loss: 0.3568 - classifier_loss: 0.1725 - decoder_accuracy: 0.0377 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 10.8552 - val_decoder_loss: 24.2798 - val_encoder_loss: 8.3661 - val_classifier_loss: 0.6112 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6684 - decoder_loss: 25.5052 - encoder_loss: 0.1046 - classifier_loss: 0.1329 - decoder_accuracy: 0.0431 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 11: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.6684 - decoder_loss: 25.5052 - encoder_loss: 0.1046 - classifier_loss: 0.1329 - decoder_accuracy: 0.0431 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 11.4495 - val_decoder_loss: 24.2772 - val_encoder_loss: 8.9519 - val_classifier_loss: 0.6982 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5694 - decoder_loss: 25.4532 - encoder_loss: 0.0143 - classifier_loss: 0.0981 - decoder_accuracy: 0.0438 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 12: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5694 - decoder_loss: 25.4532 - encoder_loss: 0.0143 - classifier_loss: 0.0981 - decoder_accuracy: 0.0438 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 7.4296 - val_decoder_loss: 24.2685 - val_encoder_loss: 4.9395 - val_classifier_loss: 0.6324 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5579 - decoder_loss: 25.4253 - encoder_loss: 0.0085 - classifier_loss: 0.0687 - decoder_accuracy: 0.0461 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5579 - decoder_loss: 25.4253 - encoder_loss: 0.0085 - classifier_loss: 0.0687 - decoder_accuracy: 0.0461 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0435 - val_decoder_loss: 24.3447 - val_encoder_loss: 5.5457 - val_classifier_loss: 0.6331 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5626 - decoder_loss: 25.5052 - encoder_loss: 0.0068 - classifier_loss: 0.0524 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5626 - decoder_loss: 25.5052 - encoder_loss: 0.0068 - classifier_loss: 0.0524 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 6.3983 - val_decoder_loss: 24.2986 - val_encoder_loss: 3.9022 - val_classifier_loss: 0.6621 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5546 - decoder_loss: 25.4836 - encoder_loss: 0.0023 - classifier_loss: 0.0391 - decoder_accuracy: 0.0471 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.5546 - decoder_loss: 25.4836 - encoder_loss: 0.0023 - classifier_loss: 0.0391 - decoder_accuracy: 0.0471 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 6.8630 - val_decoder_loss: 24.2548 - val_encoder_loss: 4.3717 - val_classifier_loss: 0.6577 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0025\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5317 - decoder_loss: 25.2738 - encoder_loss: 8.2297e-04 - classifier_loss: 0.0353 - decoder_accuracy: 0.0474 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.5317 - decoder_loss: 25.2738 - encoder_loss: 8.2297e-04 - classifier_loss: 0.0353 - decoder_accuracy: 0.0474 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 6.9267 - val_decoder_loss: 24.2560 - val_encoder_loss: 4.4350 - val_classifier_loss: 0.6612 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5298 - decoder_loss: 25.2292 - encoder_loss: 0.0037 - classifier_loss: 0.0321 - decoder_accuracy: 0.0465 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.5298 - decoder_loss: 25.2292 - encoder_loss: 0.0037 - classifier_loss: 0.0321 - decoder_accuracy: 0.0465 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9565 - val_decoder_loss: 24.2452 - val_encoder_loss: 5.4647 - val_classifier_loss: 0.6729 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5232 - decoder_loss: 25.1983 - encoder_loss: 4.7421e-04 - classifier_loss: 0.0286 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.5232 - decoder_loss: 25.1983 - encoder_loss: 4.7421e-04 - classifier_loss: 0.0286 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.6446 - val_decoder_loss: 24.2435 - val_encoder_loss: 5.1529 - val_classifier_loss: 0.6731 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5195 - decoder_loss: 25.1631 - encoder_loss: 5.6502e-04 - classifier_loss: 0.0264 - decoder_accuracy: 0.0463 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5195 - decoder_loss: 25.1631 - encoder_loss: 5.6502e-04 - classifier_loss: 0.0264 - decoder_accuracy: 0.0463 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9404 - val_decoder_loss: 24.2358 - val_encoder_loss: 5.4493 - val_classifier_loss: 0.6748 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5150 - decoder_loss: 25.1259 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0245 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.5150 - decoder_loss: 25.1259 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0245 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9500 - val_decoder_loss: 24.2331 - val_encoder_loss: 5.4590 - val_classifier_loss: 0.6768 - val_decoder_accuracy: 0.0353 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5147 - decoder_loss: 25.1070 - encoder_loss: 0.0017 - classifier_loss: 0.0236 - decoder_accuracy: 0.0468 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.5147 - decoder_loss: 25.1070 - encoder_loss: 0.0017 - classifier_loss: 0.0236 - decoder_accuracy: 0.0468 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8651 - val_decoder_loss: 24.2306 - val_encoder_loss: 5.3744 - val_classifier_loss: 0.6761 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5112 - decoder_loss: 25.0892 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0227 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.5112 - decoder_loss: 25.0892 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0227 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9265 - val_decoder_loss: 24.2266 - val_encoder_loss: 5.4360 - val_classifier_loss: 0.6782 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5092 - decoder_loss: 25.0695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0220 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.5092 - decoder_loss: 25.0695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0220 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9452 - val_decoder_loss: 24.2227 - val_encoder_loss: 5.4550 - val_classifier_loss: 0.6799 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5071 - decoder_loss: 25.0495 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0213 - decoder_accuracy: 0.0473 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5071 - decoder_loss: 25.0495 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0213 - decoder_accuracy: 0.0473 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9610 - val_decoder_loss: 24.2184 - val_encoder_loss: 5.4711 - val_classifier_loss: 0.6815 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5050 - decoder_loss: 25.0290 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0207 - decoder_accuracy: 0.0473 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5050 - decoder_loss: 25.0290 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0207 - decoder_accuracy: 0.0473 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9600 - val_decoder_loss: 24.2161 - val_encoder_loss: 5.4702 - val_classifier_loss: 0.6822 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5039 - decoder_loss: 25.0186 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0204 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.5039 - decoder_loss: 25.0186 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0204 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9675 - val_decoder_loss: 24.2137 - val_encoder_loss: 5.4778 - val_classifier_loss: 0.6830 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5028 - decoder_loss: 25.0079 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0201 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.5028 - decoder_loss: 25.0079 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0201 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9750 - val_decoder_loss: 24.2112 - val_encoder_loss: 5.4855 - val_classifier_loss: 0.6838 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5017 - decoder_loss: 24.9971 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0199 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.5017 - decoder_loss: 24.9971 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0199 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9820 - val_decoder_loss: 24.2085 - val_encoder_loss: 5.4927 - val_classifier_loss: 0.6845 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5006 - decoder_loss: 24.9862 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0196 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5006 - decoder_loss: 24.9862 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0196 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9891 - val_decoder_loss: 24.2058 - val_encoder_loss: 5.5000 - val_classifier_loss: 0.6853 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4995 - decoder_loss: 24.9752 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0194 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.4995 - decoder_loss: 24.9752 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0194 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9899 - val_decoder_loss: 24.2044 - val_encoder_loss: 5.5009 - val_classifier_loss: 0.6856 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4989 - decoder_loss: 24.9696 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0192 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4989 - decoder_loss: 24.9696 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0192 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9932 - val_decoder_loss: 24.2029 - val_encoder_loss: 5.5044 - val_classifier_loss: 0.6860 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4983 - decoder_loss: 24.9640 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0191 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4983 - decoder_loss: 24.9640 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0191 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9966 - val_decoder_loss: 24.2014 - val_encoder_loss: 5.5078 - val_classifier_loss: 0.6863 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4977 - decoder_loss: 24.9583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0190 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4977 - decoder_loss: 24.9583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0190 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9996 - val_decoder_loss: 24.1998 - val_encoder_loss: 5.5110 - val_classifier_loss: 0.6867 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4971 - decoder_loss: 24.9525 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0189 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 34: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.4971 - decoder_loss: 24.9525 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0189 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0025 - val_decoder_loss: 24.1982 - val_encoder_loss: 5.5140 - val_classifier_loss: 0.6871 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4965 - decoder_loss: 24.9467 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0188 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.4965 - decoder_loss: 24.9467 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0188 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0028 - val_decoder_loss: 24.1974 - val_encoder_loss: 5.5144 - val_classifier_loss: 0.6872 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4962 - decoder_loss: 24.9438 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0187 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4962 - decoder_loss: 24.9438 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0187 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0040 - val_decoder_loss: 24.1966 - val_encoder_loss: 5.5156 - val_classifier_loss: 0.6874 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4959 - decoder_loss: 24.9408 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0187 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4959 - decoder_loss: 24.9408 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0187 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0051 - val_decoder_loss: 24.1958 - val_encoder_loss: 5.5168 - val_classifier_loss: 0.6876 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4956 - decoder_loss: 24.9378 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0186 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4956 - decoder_loss: 24.9378 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0186 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0062 - val_decoder_loss: 24.1949 - val_encoder_loss: 5.5179 - val_classifier_loss: 0.6878 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4953 - decoder_loss: 24.9348 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0186 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4953 - decoder_loss: 24.9348 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0186 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0072 - val_decoder_loss: 24.1940 - val_encoder_loss: 5.5190 - val_classifier_loss: 0.6880 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4950 - decoder_loss: 24.9317 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.4950 - decoder_loss: 24.9317 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0075 - val_decoder_loss: 24.1935 - val_encoder_loss: 5.5194 - val_classifier_loss: 0.6881 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4948 - decoder_loss: 24.9298 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4948 - decoder_loss: 24.9298 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0081 - val_decoder_loss: 24.1929 - val_encoder_loss: 5.5200 - val_classifier_loss: 0.6882 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4946 - decoder_loss: 24.9278 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.4946 - decoder_loss: 24.9278 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0086 - val_decoder_loss: 24.1923 - val_encoder_loss: 5.5205 - val_classifier_loss: 0.6883 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4944 - decoder_loss: 24.9258 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4944 - decoder_loss: 24.9258 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0091 - val_decoder_loss: 24.1917 - val_encoder_loss: 5.5210 - val_classifier_loss: 0.6884 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4942 - decoder_loss: 24.9238 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4942 - decoder_loss: 24.9238 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0095 - val_decoder_loss: 24.1911 - val_encoder_loss: 5.5215 - val_classifier_loss: 0.6885 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4940 - decoder_loss: 24.9218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.4940 - decoder_loss: 24.9218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0099 - val_decoder_loss: 24.1905 - val_encoder_loss: 5.5220 - val_classifier_loss: 0.6887 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4938 - decoder_loss: 24.9198 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4938 - decoder_loss: 24.9198 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0103 - val_decoder_loss: 24.1899 - val_encoder_loss: 5.5225 - val_classifier_loss: 0.6888 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4936 - decoder_loss: 24.9178 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4936 - decoder_loss: 24.9178 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0107 - val_decoder_loss: 24.1893 - val_encoder_loss: 5.5229 - val_classifier_loss: 0.6889 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4934 - decoder_loss: 24.9158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4934 - decoder_loss: 24.9158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0111 - val_decoder_loss: 24.1887 - val_encoder_loss: 5.5233 - val_classifier_loss: 0.6890 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4932 - decoder_loss: 24.9137 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 49: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4932 - decoder_loss: 24.9137 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0114 - val_decoder_loss: 24.1881 - val_encoder_loss: 5.5237 - val_classifier_loss: 0.6891 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4930 - decoder_loss: 24.9117 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4930 - decoder_loss: 24.9117 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0117 - val_decoder_loss: 24.1875 - val_encoder_loss: 5.5241 - val_classifier_loss: 0.6892 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4928 - decoder_loss: 24.9096 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4928 - decoder_loss: 24.9096 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0121 - val_decoder_loss: 24.1869 - val_encoder_loss: 5.5244 - val_classifier_loss: 0.6894 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4926 - decoder_loss: 24.9076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4926 - decoder_loss: 24.9076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0123 - val_decoder_loss: 24.1862 - val_encoder_loss: 5.5248 - val_classifier_loss: 0.6895 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4924 - decoder_loss: 24.9055 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4924 - decoder_loss: 24.9055 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0126 - val_decoder_loss: 24.1856 - val_encoder_loss: 5.5251 - val_classifier_loss: 0.6896 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4921 - decoder_loss: 24.9034 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.4921 - decoder_loss: 24.9034 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0129 - val_decoder_loss: 24.1849 - val_encoder_loss: 5.5254 - val_classifier_loss: 0.6897 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4919 - decoder_loss: 24.9013 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.4919 - decoder_loss: 24.9013 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0131 - val_decoder_loss: 24.1843 - val_encoder_loss: 5.5257 - val_classifier_loss: 0.6898 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4917 - decoder_loss: 24.8992 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4917 - decoder_loss: 24.8992 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0134 - val_decoder_loss: 24.1836 - val_encoder_loss: 5.5260 - val_classifier_loss: 0.6900 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4915 - decoder_loss: 24.8971 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.4915 - decoder_loss: 24.8971 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0136 - val_decoder_loss: 24.1830 - val_encoder_loss: 5.5263 - val_classifier_loss: 0.6901 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4913 - decoder_loss: 24.8950 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 58: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.4913 - decoder_loss: 24.8950 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0138 - val_decoder_loss: 24.1823 - val_encoder_loss: 5.5266 - val_classifier_loss: 0.6902 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4911 - decoder_loss: 24.8929 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 59: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4911 - decoder_loss: 24.8929 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0140 - val_decoder_loss: 24.1817 - val_encoder_loss: 5.5268 - val_classifier_loss: 0.6903 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4909 - decoder_loss: 24.8908 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 60: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4909 - decoder_loss: 24.8908 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0142 - val_decoder_loss: 24.1810 - val_encoder_loss: 5.5271 - val_classifier_loss: 0.6904 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4907 - decoder_loss: 24.8887 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 61: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.4907 - decoder_loss: 24.8887 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0144 - val_decoder_loss: 24.1803 - val_encoder_loss: 5.5274 - val_classifier_loss: 0.6906 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4904 - decoder_loss: 24.8865 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 62: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.4904 - decoder_loss: 24.8865 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0146 - val_decoder_loss: 24.1796 - val_encoder_loss: 5.5276 - val_classifier_loss: 0.6907 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4902 - decoder_loss: 24.8844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 63: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4902 - decoder_loss: 24.8844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0148 - val_decoder_loss: 24.1789 - val_encoder_loss: 5.5278 - val_classifier_loss: 0.6908 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4900 - decoder_loss: 24.8822 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4900 - decoder_loss: 24.8822 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0150 - val_decoder_loss: 24.1782 - val_encoder_loss: 5.5281 - val_classifier_loss: 0.6909 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4898 - decoder_loss: 24.8801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 65: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4898 - decoder_loss: 24.8801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0152 - val_decoder_loss: 24.1776 - val_encoder_loss: 5.5283 - val_classifier_loss: 0.6911 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4896 - decoder_loss: 24.8779 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 66: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4896 - decoder_loss: 24.8779 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0153 - val_decoder_loss: 24.1769 - val_encoder_loss: 5.5285 - val_classifier_loss: 0.6912 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4893 - decoder_loss: 24.8758 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 67: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4893 - decoder_loss: 24.8758 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0155 - val_decoder_loss: 24.1761 - val_encoder_loss: 5.5287 - val_classifier_loss: 0.6913 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4891 - decoder_loss: 24.8736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 68: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4891 - decoder_loss: 24.8736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0156 - val_decoder_loss: 24.1754 - val_encoder_loss: 5.5290 - val_classifier_loss: 0.6914 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4889 - decoder_loss: 24.8714 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 69: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4889 - decoder_loss: 24.8714 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0158 - val_decoder_loss: 24.1747 - val_encoder_loss: 5.5292 - val_classifier_loss: 0.6915 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4887 - decoder_loss: 24.8693 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 70: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4887 - decoder_loss: 24.8693 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0159 - val_decoder_loss: 24.1740 - val_encoder_loss: 5.5294 - val_classifier_loss: 0.6917 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4885 - decoder_loss: 24.8671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 71: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4885 - decoder_loss: 24.8671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0161 - val_decoder_loss: 24.1733 - val_encoder_loss: 5.5296 - val_classifier_loss: 0.6918 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4882 - decoder_loss: 24.8649 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 72: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.4882 - decoder_loss: 24.8649 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0162 - val_decoder_loss: 24.1726 - val_encoder_loss: 5.5298 - val_classifier_loss: 0.6919 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4880 - decoder_loss: 24.8627 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 73: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4880 - decoder_loss: 24.8627 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0163 - val_decoder_loss: 24.1718 - val_encoder_loss: 5.5300 - val_classifier_loss: 0.6920 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4878 - decoder_loss: 24.8605 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 74: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2.4878 - decoder_loss: 24.8605 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0165 - val_decoder_loss: 24.1711 - val_encoder_loss: 5.5301 - val_classifier_loss: 0.6922 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4876 - decoder_loss: 24.8583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 75: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 2.4876 - decoder_loss: 24.8583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0166 - val_decoder_loss: 24.1703 - val_encoder_loss: 5.5303 - val_classifier_loss: 0.6923 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4873 - decoder_loss: 24.8561 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 76: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4873 - decoder_loss: 24.8561 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0167 - val_decoder_loss: 24.1696 - val_encoder_loss: 5.5305 - val_classifier_loss: 0.6924 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4871 - decoder_loss: 24.8539 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 77: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2.4871 - decoder_loss: 24.8539 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0168 - val_decoder_loss: 24.1688 - val_encoder_loss: 5.5307 - val_classifier_loss: 0.6926 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4869 - decoder_loss: 24.8516 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 78: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2.4869 - decoder_loss: 24.8516 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0169 - val_decoder_loss: 24.1681 - val_encoder_loss: 5.5308 - val_classifier_loss: 0.6927 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4867 - decoder_loss: 24.8494 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 79: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.4867 - decoder_loss: 24.8494 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0170 - val_decoder_loss: 24.1673 - val_encoder_loss: 5.5310 - val_classifier_loss: 0.6928 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4864 - decoder_loss: 24.8472 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 80: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.4864 - decoder_loss: 24.8472 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0171 - val_decoder_loss: 24.1665 - val_encoder_loss: 5.5312 - val_classifier_loss: 0.6929 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4862 - decoder_loss: 24.8449 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 81: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.4862 - decoder_loss: 24.8449 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0172 - val_decoder_loss: 24.1658 - val_encoder_loss: 5.5313 - val_classifier_loss: 0.6931 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4860 - decoder_loss: 24.8427 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 82: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.4860 - decoder_loss: 24.8427 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0173 - val_decoder_loss: 24.1650 - val_encoder_loss: 5.5315 - val_classifier_loss: 0.6932 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4858 - decoder_loss: 24.8405 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 83: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.4858 - decoder_loss: 24.8405 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0174 - val_decoder_loss: 24.1642 - val_encoder_loss: 5.5317 - val_classifier_loss: 0.6933 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4855 - decoder_loss: 24.8382 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 84: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4855 - decoder_loss: 24.8382 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0175 - val_decoder_loss: 24.1634 - val_encoder_loss: 5.5318 - val_classifier_loss: 0.6934 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4853 - decoder_loss: 24.8360 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 85: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2.4853 - decoder_loss: 24.8360 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0176 - val_decoder_loss: 24.1626 - val_encoder_loss: 5.5320 - val_classifier_loss: 0.6936 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4851 - decoder_loss: 24.8337 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 86: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.4851 - decoder_loss: 24.8337 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0177 - val_decoder_loss: 24.1618 - val_encoder_loss: 5.5321 - val_classifier_loss: 0.6937 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4848 - decoder_loss: 24.8314 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 87: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.4848 - decoder_loss: 24.8314 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0177 - val_decoder_loss: 24.1610 - val_encoder_loss: 5.5322 - val_classifier_loss: 0.6938 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4846 - decoder_loss: 24.8291 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.4846 - decoder_loss: 24.8291 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0178 - val_decoder_loss: 24.1602 - val_encoder_loss: 5.5324 - val_classifier_loss: 0.6940 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4844 - decoder_loss: 24.8269 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.4844 - decoder_loss: 24.8269 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0179 - val_decoder_loss: 24.1594 - val_encoder_loss: 5.5325 - val_classifier_loss: 0.6941 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4842 - decoder_loss: 24.8246 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.4842 - decoder_loss: 24.8246 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0179 - val_decoder_loss: 24.1586 - val_encoder_loss: 5.5327 - val_classifier_loss: 0.6942 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4839 - decoder_loss: 24.8223 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.4839 - decoder_loss: 24.8223 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0180 - val_decoder_loss: 24.1578 - val_encoder_loss: 5.5328 - val_classifier_loss: 0.6943 - val_decoder_accuracy: 0.0353 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4837 - decoder_loss: 24.8200 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.4837 - decoder_loss: 24.8200 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0180 - val_decoder_loss: 24.1569 - val_encoder_loss: 5.5329 - val_classifier_loss: 0.6945 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4835 - decoder_loss: 24.8177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 93: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4835 - decoder_loss: 24.8177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0181 - val_decoder_loss: 24.1561 - val_encoder_loss: 5.5330 - val_classifier_loss: 0.6946 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4832 - decoder_loss: 24.8154 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 94: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4832 - decoder_loss: 24.8154 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0181 - val_decoder_loss: 24.1552 - val_encoder_loss: 5.5331 - val_classifier_loss: 0.6947 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4830 - decoder_loss: 24.8131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4830 - decoder_loss: 24.8131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1544 - val_encoder_loss: 5.5333 - val_classifier_loss: 0.6949 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4828 - decoder_loss: 24.8108 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 96: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.4828 - decoder_loss: 24.8108 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1535 - val_encoder_loss: 5.5334 - val_classifier_loss: 0.6950 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4825 - decoder_loss: 24.8084 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 97: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2.4825 - decoder_loss: 24.8084 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1527 - val_encoder_loss: 5.5335 - val_classifier_loss: 0.6951 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4823 - decoder_loss: 24.8061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 98: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.4823 - decoder_loss: 24.8061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1518 - val_encoder_loss: 5.5336 - val_classifier_loss: 0.6952 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4820 - decoder_loss: 24.8038 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 99: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.4820 - decoder_loss: 24.8038 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1509 - val_encoder_loss: 5.5337 - val_classifier_loss: 0.6954 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4818 - decoder_loss: 24.8014 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.4818 - decoder_loss: 24.8014 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1501 - val_encoder_loss: 5.5338 - val_classifier_loss: 0.6955 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4816 - decoder_loss: 24.7991 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4816 - decoder_loss: 24.7991 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1492 - val_encoder_loss: 5.5339 - val_classifier_loss: 0.6956 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4813 - decoder_loss: 24.7967 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.4813 - decoder_loss: 24.7967 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0184 - val_decoder_loss: 24.1483 - val_encoder_loss: 5.5339 - val_classifier_loss: 0.6958 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4811 - decoder_loss: 24.7944 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.4811 - decoder_loss: 24.7944 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0184 - val_decoder_loss: 24.1474 - val_encoder_loss: 5.5340 - val_classifier_loss: 0.6959 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4809 - decoder_loss: 24.7920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4809 - decoder_loss: 24.7920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0184 - val_decoder_loss: 24.1465 - val_encoder_loss: 5.5341 - val_classifier_loss: 0.6960 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4806 - decoder_loss: 24.7897 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.4806 - decoder_loss: 24.7897 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0184 - val_decoder_loss: 24.1456 - val_encoder_loss: 5.5342 - val_classifier_loss: 0.6961 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4804 - decoder_loss: 24.7873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.4804 - decoder_loss: 24.7873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1447 - val_encoder_loss: 5.5343 - val_classifier_loss: 0.6963 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4801 - decoder_loss: 24.7849 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4801 - decoder_loss: 24.7849 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1438 - val_encoder_loss: 5.5343 - val_classifier_loss: 0.6964 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4799 - decoder_loss: 24.7825 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4799 - decoder_loss: 24.7825 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1428 - val_encoder_loss: 5.5344 - val_classifier_loss: 0.6965 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4797 - decoder_loss: 24.7801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 109: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4797 - decoder_loss: 24.7801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1419 - val_encoder_loss: 5.5344 - val_classifier_loss: 0.6967 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4794 - decoder_loss: 24.7777 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4794 - decoder_loss: 24.7777 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1410 - val_encoder_loss: 5.5345 - val_classifier_loss: 0.6968 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4792 - decoder_loss: 24.7753 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4792 - decoder_loss: 24.7753 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1400 - val_encoder_loss: 5.5345 - val_classifier_loss: 0.6969 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4789 - decoder_loss: 24.7729 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4789 - decoder_loss: 24.7729 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1391 - val_encoder_loss: 5.5346 - val_classifier_loss: 0.6970 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4787 - decoder_loss: 24.7705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4787 - decoder_loss: 24.7705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1381 - val_encoder_loss: 5.5346 - val_classifier_loss: 0.6972 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4784 - decoder_loss: 24.7681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4784 - decoder_loss: 24.7681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0181 - val_decoder_loss: 24.1371 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6973 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4782 - decoder_loss: 24.7657 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4782 - decoder_loss: 24.7657 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0181 - val_decoder_loss: 24.1362 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6974 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4779 - decoder_loss: 24.7632 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4779 - decoder_loss: 24.7632 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0180 - val_decoder_loss: 24.1352 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6976 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4777 - decoder_loss: 24.7608 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4777 - decoder_loss: 24.7608 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0179 - val_decoder_loss: 24.1342 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6977 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4774 - decoder_loss: 24.7583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4774 - decoder_loss: 24.7583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0179 - val_decoder_loss: 24.1332 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6978 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4772 - decoder_loss: 24.7559 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4772 - decoder_loss: 24.7559 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0178 - val_decoder_loss: 24.1322 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6979 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4769 - decoder_loss: 24.7534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4769 - decoder_loss: 24.7534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0177 - val_decoder_loss: 24.1312 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6981 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4767 - decoder_loss: 24.7510 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 121: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4767 - decoder_loss: 24.7510 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0176 - val_decoder_loss: 24.1302 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6982 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4764 - decoder_loss: 24.7485 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4764 - decoder_loss: 24.7485 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0175 - val_decoder_loss: 24.1292 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6983 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4762 - decoder_loss: 24.7460 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4762 - decoder_loss: 24.7460 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0175 - val_decoder_loss: 24.1282 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6984 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4759 - decoder_loss: 24.7436 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4759 - decoder_loss: 24.7436 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0174 - val_decoder_loss: 24.1272 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6986 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4757 - decoder_loss: 24.7411 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4757 - decoder_loss: 24.7411 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0172 - val_decoder_loss: 24.1261 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6987 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4754 - decoder_loss: 24.7386 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4754 - decoder_loss: 24.7386 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0171 - val_decoder_loss: 24.1251 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6988 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4752 - decoder_loss: 24.7361 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4752 - decoder_loss: 24.7361 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0170 - val_decoder_loss: 24.1240 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6990 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4749 - decoder_loss: 24.7336 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.4749 - decoder_loss: 24.7336 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0169 - val_decoder_loss: 24.1230 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6991 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4747 - decoder_loss: 24.7311 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4747 - decoder_loss: 24.7311 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0168 - val_decoder_loss: 24.1219 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6992 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4744 - decoder_loss: 24.7285 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4744 - decoder_loss: 24.7285 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0166 - val_decoder_loss: 24.1209 - val_encoder_loss: 5.5346 - val_classifier_loss: 0.6993 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4742 - decoder_loss: 24.7260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4742 - decoder_loss: 24.7260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0165 - val_decoder_loss: 24.1198 - val_encoder_loss: 5.5346 - val_classifier_loss: 0.6995 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4739 - decoder_loss: 24.7235 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.4739 - decoder_loss: 24.7235 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0163 - val_decoder_loss: 24.1187 - val_encoder_loss: 5.5345 - val_classifier_loss: 0.6996 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4737 - decoder_loss: 24.7210 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.4737 - decoder_loss: 24.7210 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0162 - val_decoder_loss: 24.1176 - val_encoder_loss: 5.5345 - val_classifier_loss: 0.6997 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4734 - decoder_loss: 24.7184 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.4734 - decoder_loss: 24.7184 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0160 - val_decoder_loss: 24.1165 - val_encoder_loss: 5.5344 - val_classifier_loss: 0.6998 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4731 - decoder_loss: 24.7159 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.4731 - decoder_loss: 24.7159 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0159 - val_decoder_loss: 24.1154 - val_encoder_loss: 5.5343 - val_classifier_loss: 0.6999 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4729 - decoder_loss: 24.7133 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.4729 - decoder_loss: 24.7133 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0157 - val_decoder_loss: 24.1143 - val_encoder_loss: 5.5343 - val_classifier_loss: 0.7001 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4726 - decoder_loss: 24.7107 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4726 - decoder_loss: 24.7107 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0155 - val_decoder_loss: 24.1132 - val_encoder_loss: 5.5342 - val_classifier_loss: 0.7002 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4724 - decoder_loss: 24.7082 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.4724 - decoder_loss: 24.7082 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0154 - val_decoder_loss: 24.1121 - val_encoder_loss: 5.5341 - val_classifier_loss: 0.7003 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4721 - decoder_loss: 24.7056 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4721 - decoder_loss: 24.7056 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0152 - val_decoder_loss: 24.1109 - val_encoder_loss: 5.5340 - val_classifier_loss: 0.7004 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4718 - decoder_loss: 24.7030 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2.4718 - decoder_loss: 24.7030 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0150 - val_decoder_loss: 24.1098 - val_encoder_loss: 5.5339 - val_classifier_loss: 0.7006 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4716 - decoder_loss: 24.7004 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 141: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4716 - decoder_loss: 24.7004 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0148 - val_decoder_loss: 24.1087 - val_encoder_loss: 5.5338 - val_classifier_loss: 0.7007 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4713 - decoder_loss: 24.6978 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.4713 - decoder_loss: 24.6978 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0146 - val_decoder_loss: 24.1075 - val_encoder_loss: 5.5337 - val_classifier_loss: 0.7008 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4711 - decoder_loss: 24.6952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4711 - decoder_loss: 24.6952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0144 - val_decoder_loss: 24.1064 - val_encoder_loss: 5.5336 - val_classifier_loss: 0.7009 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4708 - decoder_loss: 24.6926 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.4708 - decoder_loss: 24.6926 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0141 - val_decoder_loss: 24.1052 - val_encoder_loss: 5.5335 - val_classifier_loss: 0.7011 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4705 - decoder_loss: 24.6900 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.4705 - decoder_loss: 24.6900 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0139 - val_decoder_loss: 24.1040 - val_encoder_loss: 5.5334 - val_classifier_loss: 0.7012 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4703 - decoder_loss: 24.6873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.4703 - decoder_loss: 24.6873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0137 - val_decoder_loss: 24.1029 - val_encoder_loss: 5.5333 - val_classifier_loss: 0.7013 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4700 - decoder_loss: 24.6847 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0152 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.4700 - decoder_loss: 24.6847 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0152 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0134 - val_decoder_loss: 24.1017 - val_encoder_loss: 5.5331 - val_classifier_loss: 0.7014 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4697 - decoder_loss: 24.6821 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0152 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4697 - decoder_loss: 24.6821 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0152 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0132 - val_decoder_loss: 24.1005 - val_encoder_loss: 5.5330 - val_classifier_loss: 0.7015 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4695 - decoder_loss: 24.6794 - encoder_loss: 6.9709e-05 - classifier_loss: 0.0152 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.4695 - decoder_loss: 24.6794 - encoder_loss: 6.9709e-05 - classifier_loss: 0.0152 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0158 - val_decoder_loss: 24.0992 - val_encoder_loss: 5.5357 - val_classifier_loss: 0.7012 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4692 - decoder_loss: 24.6774 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4692 - decoder_loss: 24.6774 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0163 - val_decoder_loss: 24.0981 - val_encoder_loss: 5.5364 - val_classifier_loss: 0.7013 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4690 - decoder_loss: 24.6747 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4690 - decoder_loss: 24.6747 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0164 - val_decoder_loss: 24.0969 - val_encoder_loss: 5.5365 - val_classifier_loss: 0.7014 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4687 - decoder_loss: 24.6721 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.4687 - decoder_loss: 24.6721 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0163 - val_decoder_loss: 24.0957 - val_encoder_loss: 5.5366 - val_classifier_loss: 0.7015 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4684 - decoder_loss: 24.6695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4684 - decoder_loss: 24.6695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0163 - val_decoder_loss: 24.0945 - val_encoder_loss: 5.5367 - val_classifier_loss: 0.7016 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4682 - decoder_loss: 24.6668 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4682 - decoder_loss: 24.6668 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0162 - val_decoder_loss: 24.0932 - val_encoder_loss: 5.5367 - val_classifier_loss: 0.7017 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4679 - decoder_loss: 24.6642 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4679 - decoder_loss: 24.6642 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0161 - val_decoder_loss: 24.0920 - val_encoder_loss: 5.5367 - val_classifier_loss: 0.7018 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4676 - decoder_loss: 24.6615 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4676 - decoder_loss: 24.6615 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0159 - val_decoder_loss: 24.0908 - val_encoder_loss: 5.5366 - val_classifier_loss: 0.7019 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4674 - decoder_loss: 24.6588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4674 - decoder_loss: 24.6588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0157 - val_decoder_loss: 24.0895 - val_encoder_loss: 5.5366 - val_classifier_loss: 0.7020 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4671 - decoder_loss: 24.6561 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4671 - decoder_loss: 24.6561 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0156 - val_decoder_loss: 24.0883 - val_encoder_loss: 5.5365 - val_classifier_loss: 0.7021 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4668 - decoder_loss: 24.6534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4668 - decoder_loss: 24.6534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0154 - val_decoder_loss: 24.0870 - val_encoder_loss: 5.5365 - val_classifier_loss: 0.7022 - val_decoder_accuracy: 0.0373 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4666 - decoder_loss: 24.6507 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4666 - decoder_loss: 24.6507 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0152 - val_decoder_loss: 24.0858 - val_encoder_loss: 5.5364 - val_classifier_loss: 0.7023 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4663 - decoder_loss: 24.6480 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4663 - decoder_loss: 24.6480 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0149 - val_decoder_loss: 24.0845 - val_encoder_loss: 5.5362 - val_classifier_loss: 0.7024 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4660 - decoder_loss: 24.6453 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 162: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4660 - decoder_loss: 24.6453 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0147 - val_decoder_loss: 24.0832 - val_encoder_loss: 5.5361 - val_classifier_loss: 0.7025 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4657 - decoder_loss: 24.6426 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 163: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4657 - decoder_loss: 24.6426 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0144 - val_decoder_loss: 24.0819 - val_encoder_loss: 5.5360 - val_classifier_loss: 0.7026 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4655 - decoder_loss: 24.6398 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4655 - decoder_loss: 24.6398 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0141 - val_decoder_loss: 24.0806 - val_encoder_loss: 5.5358 - val_classifier_loss: 0.7027 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4652 - decoder_loss: 24.6371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4652 - decoder_loss: 24.6371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0139 - val_decoder_loss: 24.0793 - val_encoder_loss: 5.5356 - val_classifier_loss: 0.7028 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4649 - decoder_loss: 24.6343 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 166: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4649 - decoder_loss: 24.6343 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0136 - val_decoder_loss: 24.0780 - val_encoder_loss: 5.5355 - val_classifier_loss: 0.7029 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4646 - decoder_loss: 24.6315 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.4646 - decoder_loss: 24.6315 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0133 - val_decoder_loss: 24.0767 - val_encoder_loss: 5.5353 - val_classifier_loss: 0.7030 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4643 - decoder_loss: 24.6288 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4643 - decoder_loss: 24.6288 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0129 - val_decoder_loss: 24.0753 - val_encoder_loss: 5.5351 - val_classifier_loss: 0.7031 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4641 - decoder_loss: 24.6260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.4641 - decoder_loss: 24.6260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0126 - val_decoder_loss: 24.0740 - val_encoder_loss: 5.5349 - val_classifier_loss: 0.7033 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4638 - decoder_loss: 24.6232 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.4638 - decoder_loss: 24.6232 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0372 - val_decoder_loss: 24.0726 - val_encoder_loss: 5.5596 - val_classifier_loss: 0.7034 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4635 - decoder_loss: 24.6205 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4635 - decoder_loss: 24.6205 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0367 - val_decoder_loss: 24.0713 - val_encoder_loss: 5.5593 - val_classifier_loss: 0.7035 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4632 - decoder_loss: 24.6177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.4632 - decoder_loss: 24.6177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0363 - val_decoder_loss: 24.0699 - val_encoder_loss: 5.5589 - val_classifier_loss: 0.7036 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4629 - decoder_loss: 24.6149 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4629 - decoder_loss: 24.6149 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0358 - val_decoder_loss: 24.0685 - val_encoder_loss: 5.5586 - val_classifier_loss: 0.7037 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4627 - decoder_loss: 24.6122 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4627 - decoder_loss: 24.6122 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0353 - val_decoder_loss: 24.0672 - val_encoder_loss: 5.5582 - val_classifier_loss: 0.7038 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4624 - decoder_loss: 24.6094 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4624 - decoder_loss: 24.6094 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0348 - val_decoder_loss: 24.0658 - val_encoder_loss: 5.5579 - val_classifier_loss: 0.7039 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4621 - decoder_loss: 24.6067 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4621 - decoder_loss: 24.6067 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0343 - val_decoder_loss: 24.0644 - val_encoder_loss: 5.5575 - val_classifier_loss: 0.7040 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4618 - decoder_loss: 24.6039 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4618 - decoder_loss: 24.6039 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0338 - val_decoder_loss: 24.0631 - val_encoder_loss: 5.5571 - val_classifier_loss: 0.7041 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4615 - decoder_loss: 24.6012 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4615 - decoder_loss: 24.6012 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0333 - val_decoder_loss: 24.0617 - val_encoder_loss: 5.5567 - val_classifier_loss: 0.7042 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4613 - decoder_loss: 24.5984 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4613 - decoder_loss: 24.5984 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0328 - val_decoder_loss: 24.0603 - val_encoder_loss: 5.5563 - val_classifier_loss: 0.7043 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4610 - decoder_loss: 24.5956 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4610 - decoder_loss: 24.5956 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0323 - val_decoder_loss: 24.0589 - val_encoder_loss: 5.5559 - val_classifier_loss: 0.7044 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4607 - decoder_loss: 24.5928 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4607 - decoder_loss: 24.5928 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0317 - val_decoder_loss: 24.0575 - val_encoder_loss: 5.5555 - val_classifier_loss: 0.7045 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4604 - decoder_loss: 24.5901 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4604 - decoder_loss: 24.5901 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0312 - val_decoder_loss: 24.0561 - val_encoder_loss: 5.5551 - val_classifier_loss: 0.7046 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4601 - decoder_loss: 24.5873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4601 - decoder_loss: 24.5873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0307 - val_decoder_loss: 24.0547 - val_encoder_loss: 5.5547 - val_classifier_loss: 0.7047 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4599 - decoder_loss: 24.5844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4599 - decoder_loss: 24.5844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0301 - val_decoder_loss: 24.0533 - val_encoder_loss: 5.5543 - val_classifier_loss: 0.7048 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4596 - decoder_loss: 24.5816 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4596 - decoder_loss: 24.5816 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0295 - val_decoder_loss: 24.0518 - val_encoder_loss: 5.5539 - val_classifier_loss: 0.7050 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4593 - decoder_loss: 24.5788 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4593 - decoder_loss: 24.5788 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0290 - val_decoder_loss: 24.0504 - val_encoder_loss: 5.5534 - val_classifier_loss: 0.7051 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4590 - decoder_loss: 24.5760 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4590 - decoder_loss: 24.5760 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0284 - val_decoder_loss: 24.0489 - val_encoder_loss: 5.5530 - val_classifier_loss: 0.7052 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4587 - decoder_loss: 24.5732 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4587 - decoder_loss: 24.5732 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0278 - val_decoder_loss: 24.0475 - val_encoder_loss: 5.5525 - val_classifier_loss: 0.7053 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4584 - decoder_loss: 24.5703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4584 - decoder_loss: 24.5703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0272 - val_decoder_loss: 24.0460 - val_encoder_loss: 5.5521 - val_classifier_loss: 0.7054 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4581 - decoder_loss: 24.5675 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4581 - decoder_loss: 24.5675 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0266 - val_decoder_loss: 24.0446 - val_encoder_loss: 5.5516 - val_classifier_loss: 0.7055 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4579 - decoder_loss: 24.5646 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4579 - decoder_loss: 24.5646 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0260 - val_decoder_loss: 24.0431 - val_encoder_loss: 5.5511 - val_classifier_loss: 0.7056 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4576 - decoder_loss: 24.5617 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4576 - decoder_loss: 24.5617 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0255 - val_decoder_loss: 24.0416 - val_encoder_loss: 5.5507 - val_classifier_loss: 0.7057 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4573 - decoder_loss: 24.5589 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4573 - decoder_loss: 24.5589 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0252 - val_decoder_loss: 24.0401 - val_encoder_loss: 5.5506 - val_classifier_loss: 0.7058 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4570 - decoder_loss: 24.5560 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4570 - decoder_loss: 24.5560 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0249 - val_decoder_loss: 24.0386 - val_encoder_loss: 5.5504 - val_classifier_loss: 0.7059 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4567 - decoder_loss: 24.5531 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4567 - decoder_loss: 24.5531 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0245 - val_decoder_loss: 24.0371 - val_encoder_loss: 5.5502 - val_classifier_loss: 0.7060 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4564 - decoder_loss: 24.5502 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4564 - decoder_loss: 24.5502 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0242 - val_decoder_loss: 24.0356 - val_encoder_loss: 5.5500 - val_classifier_loss: 0.7061 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4561 - decoder_loss: 24.5473 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4561 - decoder_loss: 24.5473 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0239 - val_decoder_loss: 24.0341 - val_encoder_loss: 5.5499 - val_classifier_loss: 0.7062 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4558 - decoder_loss: 24.5444 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4558 - decoder_loss: 24.5444 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0236 - val_decoder_loss: 24.0326 - val_encoder_loss: 5.5497 - val_classifier_loss: 0.7063 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4555 - decoder_loss: 24.5415 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4555 - decoder_loss: 24.5415 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0232 - val_decoder_loss: 24.0310 - val_encoder_loss: 5.5495 - val_classifier_loss: 0.7064 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4552 - decoder_loss: 24.5385 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4552 - decoder_loss: 24.5385 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0229 - val_decoder_loss: 24.0295 - val_encoder_loss: 5.5493 - val_classifier_loss: 0.7065 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4549 - decoder_loss: 24.5356 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4549 - decoder_loss: 24.5356 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0225 - val_decoder_loss: 24.0280 - val_encoder_loss: 5.5491 - val_classifier_loss: 0.7066 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4546 - decoder_loss: 24.5326 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.4546 - decoder_loss: 24.5326 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0222 - val_decoder_loss: 24.0264 - val_encoder_loss: 5.5489 - val_classifier_loss: 0.7067 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4544 - decoder_loss: 24.5297 - encoder_loss: 9.2767e-05 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 203: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4544 - decoder_loss: 24.5297 - encoder_loss: 9.2767e-05 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0240 - val_decoder_loss: 24.0249 - val_encoder_loss: 5.5509 - val_classifier_loss: 0.7062 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4541 - decoder_loss: 24.5275 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 204: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4541 - decoder_loss: 24.5275 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0275 - val_decoder_loss: 24.0233 - val_encoder_loss: 5.5546 - val_classifier_loss: 0.7063 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 204: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_28 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_29 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_14 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_28 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_29 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_15[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbb2e0b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 28.0710 - decoder_loss: 26.8003 - encoder_loss: 25.3246 - classifier_loss: 0.6629 - decoder_accuracy: 0.0177 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6333\n",
            "F1-score is computed based on binary\n",
            "(loss: 28.070959091186523, accuracy: 0.6333333253860474)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.87      0.70        15\n",
            "         1.0       0.75      0.40      0.52        15\n",
            "\n",
            "    accuracy                           0.63        30\n",
            "   macro avg       0.67      0.63      0.61        30\n",
            "weighted avg       0.67      0.63      0.61        30\n",
            "\n",
            "Accuracy: 0.6333333253860474\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6333333253860474\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fold5"
      ],
      "metadata": {
        "id": "G5BOBv-zxVPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=10, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=200,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(5,6):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gdf415qQxWaq",
        "outputId": "59efb650-4103-4d9a-834a-14d466eb7069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 5\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_30 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_31 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_15 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_30 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_31 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_16 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_16[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.4839 - decoder_loss: 24.4660 - encoder_loss: 1.9593 - classifier_loss: 0.7794 - decoder_accuracy: 0.0167 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5500\n",
            "Epoch 1: val_loss improved from inf to 1540.75720, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.4839 - decoder_loss: 24.4660 - encoder_loss: 1.9593 - classifier_loss: 0.7794 - decoder_accuracy: 0.0167 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5500 - val_loss: 1540.7572 - val_decoder_loss: 32.1374 - val_encoder_loss: 1537.0433 - val_classifier_loss: 5.0008 - val_decoder_accuracy: 0.0162 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3919 - decoder_loss: 24.4613 - encoder_loss: 0.8710 - classifier_loss: 0.7476 - decoder_accuracy: 0.0172 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.3750\n",
            "Epoch 2: val_loss improved from 1540.75720 to 32.32584, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 3.3919 - decoder_loss: 24.4613 - encoder_loss: 0.8710 - classifier_loss: 0.7476 - decoder_accuracy: 0.0172 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.3750 - val_loss: 32.3258 - val_decoder_loss: 32.0073 - val_encoder_loss: 29.0591 - val_classifier_loss: 0.6601 - val_decoder_accuracy: 0.0157 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.2505 - decoder_loss: 24.4303 - encoder_loss: 5.7397 - classifier_loss: 0.6777 - decoder_accuracy: 0.0204 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5250\n",
            "Epoch 3: val_loss did not improve from 32.32584\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.2505 - decoder_loss: 24.4303 - encoder_loss: 5.7397 - classifier_loss: 0.6777 - decoder_accuracy: 0.0204 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5250 - val_loss: 116.0804 - val_decoder_loss: 32.0644 - val_encoder_loss: 112.8023 - val_classifier_loss: 0.7167 - val_decoder_accuracy: 0.0185 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 26.0857 - decoder_loss: 24.4220 - encoder_loss: 23.5599 - classifier_loss: 0.8358 - decoder_accuracy: 0.0220 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4250\n",
            "Epoch 4: val_loss did not improve from 32.32584\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 26.0857 - decoder_loss: 24.4220 - encoder_loss: 23.5599 - classifier_loss: 0.8358 - decoder_accuracy: 0.0220 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4250 - val_loss: 68.2840 - val_decoder_loss: 32.5103 - val_encoder_loss: 64.9375 - val_classifier_loss: 0.9540 - val_decoder_accuracy: 0.0147 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 15.1498 - decoder_loss: 24.6905 - encoder_loss: 12.6028 - classifier_loss: 0.7790 - decoder_accuracy: 0.0183 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4500\n",
            "Epoch 5: val_loss improved from 32.32584 to 20.64066, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 15.1498 - decoder_loss: 24.6905 - encoder_loss: 12.6028 - classifier_loss: 0.7790 - decoder_accuracy: 0.0183 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4500 - val_loss: 20.6407 - val_decoder_loss: 31.7061 - val_encoder_loss: 17.4115 - val_classifier_loss: 0.5856 - val_decoder_accuracy: 0.0293 - val_encoder_accuracy: 0.2000 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.9795 - decoder_loss: 24.3425 - encoder_loss: 4.4594 - classifier_loss: 0.8587 - decoder_accuracy: 0.0267 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.3500\n",
            "Epoch 6: val_loss did not improve from 20.64066\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 6.9795 - decoder_loss: 24.3425 - encoder_loss: 4.4594 - classifier_loss: 0.8587 - decoder_accuracy: 0.0267 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.3500 - val_loss: 34.5337 - val_decoder_loss: 31.8757 - val_encoder_loss: 31.2589 - val_classifier_loss: 0.8716 - val_decoder_accuracy: 0.0275 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.3000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 17.7256 - decoder_loss: 24.2336 - encoder_loss: 15.2360 - classifier_loss: 0.6618 - decoder_accuracy: 0.0284 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6000\n",
            "Epoch 7: val_loss did not improve from 20.64066\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 17.7256 - decoder_loss: 24.2336 - encoder_loss: 15.2360 - classifier_loss: 0.6618 - decoder_accuracy: 0.0284 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6000 - val_loss: 30.7139 - val_decoder_loss: 33.1447 - val_encoder_loss: 27.3447 - val_classifier_loss: 0.5474 - val_decoder_accuracy: 0.0125 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.6377 - decoder_loss: 24.5800 - encoder_loss: 5.1072 - classifier_loss: 0.7256 - decoder_accuracy: 0.0273 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750\n",
            "Epoch 8: val_loss improved from 20.64066 to 15.67731, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 7.6377 - decoder_loss: 24.5800 - encoder_loss: 5.1072 - classifier_loss: 0.7256 - decoder_accuracy: 0.0273 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750 - val_loss: 15.6773 - val_decoder_loss: 32.1896 - val_encoder_loss: 12.4056 - val_classifier_loss: 0.5278 - val_decoder_accuracy: 0.0182 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 25.1510 - decoder_loss: 24.4430 - encoder_loss: 22.6389 - classifier_loss: 0.6781 - decoder_accuracy: 0.0308 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750\n",
            "Epoch 9: val_loss improved from 15.67731 to 3.85952, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 25.1510 - decoder_loss: 24.4430 - encoder_loss: 22.6389 - classifier_loss: 0.6781 - decoder_accuracy: 0.0308 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750 - val_loss: 3.8595 - val_decoder_loss: 31.7478 - val_encoder_loss: 0.6275 - val_classifier_loss: 0.5723 - val_decoder_accuracy: 0.0262 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.0865 - decoder_loss: 24.2391 - encoder_loss: 1.5992 - classifier_loss: 0.6344 - decoder_accuracy: 0.0248 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6750\n",
            "Epoch 10: val_loss did not improve from 3.85952\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4.0865 - decoder_loss: 24.2391 - encoder_loss: 1.5992 - classifier_loss: 0.6344 - decoder_accuracy: 0.0248 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6750 - val_loss: 5.2617 - val_decoder_loss: 31.6122 - val_encoder_loss: 2.0450 - val_classifier_loss: 0.5551 - val_decoder_accuracy: 0.0282 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8138 - decoder_loss: 24.0072 - encoder_loss: 0.3516 - classifier_loss: 0.6157 - decoder_accuracy: 0.0348 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000\n",
            "Epoch 11: val_loss did not improve from 3.85952\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.8138 - decoder_loss: 24.0072 - encoder_loss: 0.3516 - classifier_loss: 0.6157 - decoder_accuracy: 0.0348 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000 - val_loss: 5.0369 - val_decoder_loss: 31.1197 - val_encoder_loss: 1.8675 - val_classifier_loss: 0.5742 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7684 - decoder_loss: 23.7856 - encoder_loss: 0.3325 - classifier_loss: 0.5739 - decoder_accuracy: 0.0352 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750\n",
            "Epoch 12: val_loss did not improve from 3.85952\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.7684 - decoder_loss: 23.7856 - encoder_loss: 0.3325 - classifier_loss: 0.5739 - decoder_accuracy: 0.0352 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750 - val_loss: 4.5758 - val_decoder_loss: 30.9663 - val_encoder_loss: 1.4210 - val_classifier_loss: 0.5820 - val_decoder_accuracy: 0.0415 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8825 - decoder_loss: 23.7219 - encoder_loss: 0.4564 - classifier_loss: 0.5394 - decoder_accuracy: 0.0418 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 13: val_loss improved from 3.85952 to 3.40258, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.8825 - decoder_loss: 23.7219 - encoder_loss: 0.4564 - classifier_loss: 0.5394 - decoder_accuracy: 0.0418 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 3.4026 - val_decoder_loss: 30.6226 - val_encoder_loss: 0.2791 - val_classifier_loss: 0.6116 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7822 - decoder_loss: 23.5396 - encoder_loss: 0.3776 - classifier_loss: 0.5064 - decoder_accuracy: 0.0386 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 14: val_loss did not improve from 3.40258\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.7822 - decoder_loss: 23.5396 - encoder_loss: 0.3776 - classifier_loss: 0.5064 - decoder_accuracy: 0.0386 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 10.6930 - val_decoder_loss: 30.5927 - val_encoder_loss: 7.5494 - val_classifier_loss: 0.8434 - val_decoder_accuracy: 0.0567 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7565 - decoder_loss: 23.5453 - encoder_loss: 1.3537 - classifier_loss: 0.4828 - decoder_accuracy: 0.0420 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 15: val_loss improved from 3.40258 to 3.35074, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 3.7565 - decoder_loss: 23.5453 - encoder_loss: 1.3537 - classifier_loss: 0.4828 - decoder_accuracy: 0.0420 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 3.3507 - val_decoder_loss: 30.5359 - val_encoder_loss: 0.2453 - val_classifier_loss: 0.5181 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.9997 - decoder_loss: 23.6237 - encoder_loss: 1.5938 - classifier_loss: 0.4350 - decoder_accuracy: 0.0341 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000\n",
            "Epoch 16: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3.9997 - decoder_loss: 23.6237 - encoder_loss: 1.5938 - classifier_loss: 0.4350 - decoder_accuracy: 0.0341 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000 - val_loss: 24.3519 - val_decoder_loss: 30.7501 - val_encoder_loss: 21.1509 - val_classifier_loss: 1.2596 - val_decoder_accuracy: 0.0643 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.7322 - decoder_loss: 23.5006 - encoder_loss: 2.3397 - classifier_loss: 0.4244 - decoder_accuracy: 0.0457 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 17: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.7322 - decoder_loss: 23.5006 - encoder_loss: 2.3397 - classifier_loss: 0.4244 - decoder_accuracy: 0.0457 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 4.2437 - val_decoder_loss: 30.2329 - val_encoder_loss: 1.1516 - val_classifier_loss: 0.6881 - val_decoder_accuracy: 0.0612 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8527 - decoder_loss: 23.2589 - encoder_loss: 0.4909 - classifier_loss: 0.3590 - decoder_accuracy: 0.0505 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 18: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.8527 - decoder_loss: 23.2589 - encoder_loss: 0.4909 - classifier_loss: 0.3590 - decoder_accuracy: 0.0505 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 10.4810 - val_decoder_loss: 30.6402 - val_encoder_loss: 7.3271 - val_classifier_loss: 0.8991 - val_decoder_accuracy: 0.0607 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3731 - decoder_loss: 23.1338 - encoder_loss: 0.0294 - classifier_loss: 0.3027 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 19: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3731 - decoder_loss: 23.1338 - encoder_loss: 0.0294 - classifier_loss: 0.3027 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 13.5869 - val_decoder_loss: 30.1233 - val_encoder_loss: 10.4709 - val_classifier_loss: 1.0368 - val_decoder_accuracy: 0.0520 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3940 - decoder_loss: 23.0684 - encoder_loss: 0.0616 - classifier_loss: 0.2559 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 20: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3940 - decoder_loss: 23.0684 - encoder_loss: 0.0616 - classifier_loss: 0.2559 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 16.1341 - val_decoder_loss: 30.6328 - val_encoder_loss: 12.9528 - val_classifier_loss: 1.1807 - val_decoder_accuracy: 0.0600 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3703 - decoder_loss: 23.1426 - encoder_loss: 0.0343 - classifier_loss: 0.2173 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500\n",
            "Epoch 21: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3703 - decoder_loss: 23.1426 - encoder_loss: 0.0343 - classifier_loss: 0.2173 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500 - val_loss: 16.6069 - val_decoder_loss: 30.1945 - val_encoder_loss: 13.4559 - val_classifier_loss: 1.3158 - val_decoder_accuracy: 0.0622 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3551 - decoder_loss: 22.9823 - encoder_loss: 0.0366 - classifier_loss: 0.2028 - decoder_accuracy: 0.0641 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500\n",
            "Epoch 22: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.3551 - decoder_loss: 22.9823 - encoder_loss: 0.0366 - classifier_loss: 0.2028 - decoder_accuracy: 0.0641 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500 - val_loss: 19.9366 - val_decoder_loss: 30.1818 - val_encoder_loss: 16.7858 - val_classifier_loss: 1.3258 - val_decoder_accuracy: 0.0528 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3722 - decoder_loss: 22.9787 - encoder_loss: 0.0560 - classifier_loss: 0.1830 - decoder_accuracy: 0.0640 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500\n",
            "Epoch 23: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3722 - decoder_loss: 22.9787 - encoder_loss: 0.0560 - classifier_loss: 0.1830 - decoder_accuracy: 0.0640 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500 - val_loss: 22.0151 - val_decoder_loss: 30.1234 - val_encoder_loss: 18.8600 - val_classifier_loss: 1.4276 - val_decoder_accuracy: 0.0527 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3460 - decoder_loss: 23.0108 - encoder_loss: 0.0286 - classifier_loss: 0.1638 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500\n",
            "Epoch 24: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3460 - decoder_loss: 23.0108 - encoder_loss: 0.0286 - classifier_loss: 0.1638 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500 - val_loss: 22.6917 - val_decoder_loss: 30.0547 - val_encoder_loss: 19.5395 - val_classifier_loss: 1.4673 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3473 - decoder_loss: 22.9978 - encoder_loss: 0.0319 - classifier_loss: 0.1559 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9750\n",
            "Epoch 25: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3473 - decoder_loss: 22.9978 - encoder_loss: 0.0319 - classifier_loss: 0.1559 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9750 - val_loss: 22.2330 - val_decoder_loss: 30.0275 - val_encoder_loss: 19.0873 - val_classifier_loss: 1.4295 - val_decoder_accuracy: 0.0505 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3690 - decoder_loss: 22.9954 - encoder_loss: 0.0551 - classifier_loss: 0.1434 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9750\n",
            "Epoch 26: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.3690 - decoder_loss: 22.9954 - encoder_loss: 0.0551 - classifier_loss: 0.1434 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9750 - val_loss: 22.7169 - val_decoder_loss: 30.0154 - val_encoder_loss: 19.5674 - val_classifier_loss: 1.4796 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3363 - decoder_loss: 22.9657 - encoder_loss: 0.0264 - classifier_loss: 0.1327 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 27: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3363 - decoder_loss: 22.9657 - encoder_loss: 0.0264 - classifier_loss: 0.1327 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 23.1889 - val_decoder_loss: 29.9564 - val_encoder_loss: 20.0407 - val_classifier_loss: 1.5248 - val_decoder_accuracy: 0.0468 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3242 - decoder_loss: 22.9388 - encoder_loss: 0.0176 - classifier_loss: 0.1267 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 28: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3242 - decoder_loss: 22.9388 - encoder_loss: 0.0176 - classifier_loss: 0.1267 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 23.7811 - val_decoder_loss: 29.9265 - val_encoder_loss: 20.6343 - val_classifier_loss: 1.5417 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3253 - decoder_loss: 22.9148 - encoder_loss: 0.0218 - classifier_loss: 0.1198 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 29: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3253 - decoder_loss: 22.9148 - encoder_loss: 0.0218 - classifier_loss: 0.1198 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.5863 - val_decoder_loss: 29.8854 - val_encoder_loss: 21.4383 - val_classifier_loss: 1.5944 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3193 - decoder_loss: 22.8837 - encoder_loss: 0.0198 - classifier_loss: 0.1117 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 30: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.3193 - decoder_loss: 22.8837 - encoder_loss: 0.0198 - classifier_loss: 0.1117 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.4862 - val_decoder_loss: 29.8637 - val_encoder_loss: 21.3385 - val_classifier_loss: 1.6141 - val_decoder_accuracy: 0.0430 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3098 - decoder_loss: 22.8632 - encoder_loss: 0.0129 - classifier_loss: 0.1057 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 31: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3098 - decoder_loss: 22.8632 - encoder_loss: 0.0129 - classifier_loss: 0.1057 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.3069 - val_decoder_loss: 29.8513 - val_encoder_loss: 21.1619 - val_classifier_loss: 1.5983 - val_decoder_accuracy: 0.0430 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3081 - decoder_loss: 22.8521 - encoder_loss: 0.0125 - classifier_loss: 0.1034 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 32: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.3081 - decoder_loss: 22.8521 - encoder_loss: 0.0125 - classifier_loss: 0.1034 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.2002 - val_decoder_loss: 29.8440 - val_encoder_loss: 21.0559 - val_classifier_loss: 1.5988 - val_decoder_accuracy: 0.0428 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3077 - decoder_loss: 22.8436 - encoder_loss: 0.0133 - classifier_loss: 0.1002 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 33: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3077 - decoder_loss: 22.8436 - encoder_loss: 0.0133 - classifier_loss: 0.1002 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.0706 - val_decoder_loss: 29.8359 - val_encoder_loss: 20.9279 - val_classifier_loss: 1.5906 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3093 - decoder_loss: 22.8307 - encoder_loss: 0.0165 - classifier_loss: 0.0966 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 34: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3093 - decoder_loss: 22.8307 - encoder_loss: 0.0165 - classifier_loss: 0.0966 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 23.9480 - val_decoder_loss: 29.8275 - val_encoder_loss: 20.8061 - val_classifier_loss: 1.5919 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3034 - decoder_loss: 22.8168 - encoder_loss: 0.0124 - classifier_loss: 0.0930 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3034 - decoder_loss: 22.8168 - encoder_loss: 0.0124 - classifier_loss: 0.0930 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0068 - val_decoder_loss: 29.8198 - val_encoder_loss: 20.8649 - val_classifier_loss: 1.6000 - val_decoder_accuracy: 0.0445 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2976 - decoder_loss: 22.8067 - encoder_loss: 0.0078 - classifier_loss: 0.0905 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2976 - decoder_loss: 22.8067 - encoder_loss: 0.0078 - classifier_loss: 0.0905 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.7912 - val_decoder_loss: 29.8125 - val_encoder_loss: 20.6502 - val_classifier_loss: 1.5975 - val_decoder_accuracy: 0.0445 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2960 - decoder_loss: 22.7997 - encoder_loss: 0.0071 - classifier_loss: 0.0897 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2960 - decoder_loss: 22.7997 - encoder_loss: 0.0071 - classifier_loss: 0.0897 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.7770 - val_decoder_loss: 29.8073 - val_encoder_loss: 20.6364 - val_classifier_loss: 1.5989 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3002 - decoder_loss: 22.7934 - encoder_loss: 0.0120 - classifier_loss: 0.0887 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3002 - decoder_loss: 22.7934 - encoder_loss: 0.0120 - classifier_loss: 0.0887 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.6735 - val_decoder_loss: 29.8056 - val_encoder_loss: 20.5330 - val_classifier_loss: 1.5989 - val_decoder_accuracy: 0.0445 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3009 - decoder_loss: 22.7880 - encoder_loss: 0.0133 - classifier_loss: 0.0873 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3009 - decoder_loss: 22.7880 - encoder_loss: 0.0133 - classifier_loss: 0.0873 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9334 - val_decoder_loss: 29.7997 - val_encoder_loss: 20.7918 - val_classifier_loss: 1.6155 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2990 - decoder_loss: 22.7822 - encoder_loss: 0.0122 - classifier_loss: 0.0853 - decoder_accuracy: 0.0639 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2990 - decoder_loss: 22.7822 - encoder_loss: 0.0122 - classifier_loss: 0.0853 - decoder_accuracy: 0.0639 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.8025 - val_decoder_loss: 29.7944 - val_encoder_loss: 20.6617 - val_classifier_loss: 1.6145 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2948 - decoder_loss: 22.7757 - encoder_loss: 0.0088 - classifier_loss: 0.0843 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2948 - decoder_loss: 22.7757 - encoder_loss: 0.0088 - classifier_loss: 0.0843 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.8946 - val_decoder_loss: 29.7910 - val_encoder_loss: 20.7534 - val_classifier_loss: 1.6215 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2940 - decoder_loss: 22.7733 - encoder_loss: 0.0083 - classifier_loss: 0.0837 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2940 - decoder_loss: 22.7733 - encoder_loss: 0.0083 - classifier_loss: 0.0837 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.8836 - val_decoder_loss: 29.7873 - val_encoder_loss: 20.7424 - val_classifier_loss: 1.6245 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2928 - decoder_loss: 22.7699 - encoder_loss: 0.0074 - classifier_loss: 0.0834 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2928 - decoder_loss: 22.7699 - encoder_loss: 0.0074 - classifier_loss: 0.0834 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.8841 - val_decoder_loss: 29.7844 - val_encoder_loss: 20.7430 - val_classifier_loss: 1.6259 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2938 - decoder_loss: 22.7664 - encoder_loss: 0.0089 - classifier_loss: 0.0829 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2938 - decoder_loss: 22.7664 - encoder_loss: 0.0089 - classifier_loss: 0.0829 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0048 - val_decoder_loss: 29.7811 - val_encoder_loss: 20.8633 - val_classifier_loss: 1.6343 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2944 - decoder_loss: 22.7632 - encoder_loss: 0.0098 - classifier_loss: 0.0823 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2944 - decoder_loss: 22.7632 - encoder_loss: 0.0098 - classifier_loss: 0.0823 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9377 - val_decoder_loss: 29.7795 - val_encoder_loss: 20.7964 - val_classifier_loss: 1.6338 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2930 - decoder_loss: 22.7600 - encoder_loss: 0.0088 - classifier_loss: 0.0816 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2930 - decoder_loss: 22.7600 - encoder_loss: 0.0088 - classifier_loss: 0.0816 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9629 - val_decoder_loss: 29.7781 - val_encoder_loss: 20.8216 - val_classifier_loss: 1.6343 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.5625e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2905 - decoder_loss: 22.7587 - encoder_loss: 0.0065 - classifier_loss: 0.0814 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2905 - decoder_loss: 22.7587 - encoder_loss: 0.0065 - classifier_loss: 0.0814 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9656 - val_decoder_loss: 29.7767 - val_encoder_loss: 20.8244 - val_classifier_loss: 1.6351 - val_decoder_accuracy: 0.0455 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.5625e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2895 - decoder_loss: 22.7570 - encoder_loss: 0.0056 - classifier_loss: 0.0812 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2895 - decoder_loss: 22.7570 - encoder_loss: 0.0056 - classifier_loss: 0.0812 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9868 - val_decoder_loss: 29.7748 - val_encoder_loss: 20.8456 - val_classifier_loss: 1.6367 - val_decoder_accuracy: 0.0455 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2894 - decoder_loss: 22.7552 - encoder_loss: 0.0058 - classifier_loss: 0.0810 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 49: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2894 - decoder_loss: 22.7552 - encoder_loss: 0.0058 - classifier_loss: 0.0810 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0064 - val_decoder_loss: 29.7732 - val_encoder_loss: 20.8652 - val_classifier_loss: 1.6384 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2909 - decoder_loss: 22.7534 - encoder_loss: 0.0075 - classifier_loss: 0.0807 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2909 - decoder_loss: 22.7534 - encoder_loss: 0.0075 - classifier_loss: 0.0807 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0059 - val_decoder_loss: 29.7714 - val_encoder_loss: 20.8646 - val_classifier_loss: 1.6414 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.5625e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2931 - decoder_loss: 22.7518 - encoder_loss: 0.0099 - classifier_loss: 0.0804 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2931 - decoder_loss: 22.7518 - encoder_loss: 0.0099 - classifier_loss: 0.0804 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0246 - val_decoder_loss: 29.7706 - val_encoder_loss: 20.8833 - val_classifier_loss: 1.6431 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2926 - decoder_loss: 22.7507 - encoder_loss: 0.0095 - classifier_loss: 0.0802 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2926 - decoder_loss: 22.7507 - encoder_loss: 0.0095 - classifier_loss: 0.0802 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0330 - val_decoder_loss: 29.7697 - val_encoder_loss: 20.8916 - val_classifier_loss: 1.6440 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2920 - decoder_loss: 22.7497 - encoder_loss: 0.0090 - classifier_loss: 0.0799 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2920 - decoder_loss: 22.7497 - encoder_loss: 0.0090 - classifier_loss: 0.0799 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0704 - val_decoder_loss: 29.7684 - val_encoder_loss: 20.9290 - val_classifier_loss: 1.6457 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2910 - decoder_loss: 22.7485 - encoder_loss: 0.0082 - classifier_loss: 0.0797 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2910 - decoder_loss: 22.7485 - encoder_loss: 0.0082 - classifier_loss: 0.0797 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0739 - val_decoder_loss: 29.7668 - val_encoder_loss: 20.9324 - val_classifier_loss: 1.6482 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2886 - decoder_loss: 22.7472 - encoder_loss: 0.0060 - classifier_loss: 0.0795 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2886 - decoder_loss: 22.7472 - encoder_loss: 0.0060 - classifier_loss: 0.0795 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0796 - val_decoder_loss: 29.7654 - val_encoder_loss: 20.9382 - val_classifier_loss: 1.6490 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2867 - decoder_loss: 22.7458 - encoder_loss: 0.0042 - classifier_loss: 0.0793 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2867 - decoder_loss: 22.7458 - encoder_loss: 0.0042 - classifier_loss: 0.0793 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0775 - val_decoder_loss: 29.7637 - val_encoder_loss: 20.9361 - val_classifier_loss: 1.6502 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2865 - decoder_loss: 22.7443 - encoder_loss: 0.0042 - classifier_loss: 0.0792 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2865 - decoder_loss: 22.7443 - encoder_loss: 0.0042 - classifier_loss: 0.0792 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0785 - val_decoder_loss: 29.7622 - val_encoder_loss: 20.9372 - val_classifier_loss: 1.6510 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2862 - decoder_loss: 22.7429 - encoder_loss: 0.0040 - classifier_loss: 0.0790 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 58: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2862 - decoder_loss: 22.7429 - encoder_loss: 0.0040 - classifier_loss: 0.0790 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0661 - val_decoder_loss: 29.7609 - val_encoder_loss: 20.9249 - val_classifier_loss: 1.6511 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2853 - decoder_loss: 22.7415 - encoder_loss: 0.0033 - classifier_loss: 0.0789 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 59: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2853 - decoder_loss: 22.7415 - encoder_loss: 0.0033 - classifier_loss: 0.0789 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0648 - val_decoder_loss: 29.7595 - val_encoder_loss: 20.9237 - val_classifier_loss: 1.6517 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2866 - decoder_loss: 22.7398 - encoder_loss: 0.0048 - classifier_loss: 0.0787 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 60: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2866 - decoder_loss: 22.7398 - encoder_loss: 0.0048 - classifier_loss: 0.0787 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0475 - val_decoder_loss: 29.7581 - val_encoder_loss: 20.9064 - val_classifier_loss: 1.6519 - val_decoder_accuracy: 0.0467 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2852 - decoder_loss: 22.7383 - encoder_loss: 0.0035 - classifier_loss: 0.0786 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 61: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2852 - decoder_loss: 22.7383 - encoder_loss: 0.0035 - classifier_loss: 0.0786 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0442 - val_decoder_loss: 29.7567 - val_encoder_loss: 20.9033 - val_classifier_loss: 1.6523 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2849 - decoder_loss: 22.7367 - encoder_loss: 0.0034 - classifier_loss: 0.0784 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 62: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2849 - decoder_loss: 22.7367 - encoder_loss: 0.0034 - classifier_loss: 0.0784 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0481 - val_decoder_loss: 29.7552 - val_encoder_loss: 20.9072 - val_classifier_loss: 1.6534 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2847 - decoder_loss: 22.7352 - encoder_loss: 0.0033 - classifier_loss: 0.0783 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 63: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2847 - decoder_loss: 22.7352 - encoder_loss: 0.0033 - classifier_loss: 0.0783 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0446 - val_decoder_loss: 29.7540 - val_encoder_loss: 20.9038 - val_classifier_loss: 1.6543 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2848 - decoder_loss: 22.7337 - encoder_loss: 0.0036 - classifier_loss: 0.0782 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2848 - decoder_loss: 22.7337 - encoder_loss: 0.0036 - classifier_loss: 0.0782 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0539 - val_decoder_loss: 29.7527 - val_encoder_loss: 20.9130 - val_classifier_loss: 1.6558 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2839 - decoder_loss: 22.7322 - encoder_loss: 0.0029 - classifier_loss: 0.0780 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 65: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2839 - decoder_loss: 22.7322 - encoder_loss: 0.0029 - classifier_loss: 0.0780 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0786 - val_decoder_loss: 29.7514 - val_encoder_loss: 20.9377 - val_classifier_loss: 1.6582 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2832 - decoder_loss: 22.7307 - encoder_loss: 0.0023 - classifier_loss: 0.0779 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 66: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2832 - decoder_loss: 22.7307 - encoder_loss: 0.0023 - classifier_loss: 0.0779 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0899 - val_decoder_loss: 29.7502 - val_encoder_loss: 20.9488 - val_classifier_loss: 1.6601 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2870 - decoder_loss: 22.7293 - encoder_loss: 0.0063 - classifier_loss: 0.0777 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 67: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2870 - decoder_loss: 22.7293 - encoder_loss: 0.0063 - classifier_loss: 0.0777 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0967 - val_decoder_loss: 29.7489 - val_encoder_loss: 20.9557 - val_classifier_loss: 1.6613 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2877 - decoder_loss: 22.7279 - encoder_loss: 0.0071 - classifier_loss: 0.0776 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 68: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2877 - decoder_loss: 22.7279 - encoder_loss: 0.0071 - classifier_loss: 0.0776 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1098 - val_decoder_loss: 29.7477 - val_encoder_loss: 20.9687 - val_classifier_loss: 1.6632 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2855 - decoder_loss: 22.7265 - encoder_loss: 0.0051 - classifier_loss: 0.0774 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 69: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2855 - decoder_loss: 22.7265 - encoder_loss: 0.0051 - classifier_loss: 0.0774 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1112 - val_decoder_loss: 29.7464 - val_encoder_loss: 20.9701 - val_classifier_loss: 1.6650 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2867 - decoder_loss: 22.7251 - encoder_loss: 0.0065 - classifier_loss: 0.0773 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 70: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2867 - decoder_loss: 22.7251 - encoder_loss: 0.0065 - classifier_loss: 0.0773 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1443 - val_decoder_loss: 29.7456 - val_encoder_loss: 21.0030 - val_classifier_loss: 1.6672 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2878 - decoder_loss: 22.7238 - encoder_loss: 0.0077 - classifier_loss: 0.0771 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 71: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2878 - decoder_loss: 22.7238 - encoder_loss: 0.0077 - classifier_loss: 0.0771 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1700 - val_decoder_loss: 29.7445 - val_encoder_loss: 21.0286 - val_classifier_loss: 1.6697 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2862 - decoder_loss: 22.7225 - encoder_loss: 0.0063 - classifier_loss: 0.0769 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 72: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2862 - decoder_loss: 22.7225 - encoder_loss: 0.0063 - classifier_loss: 0.0769 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1814 - val_decoder_loss: 29.7435 - val_encoder_loss: 21.0399 - val_classifier_loss: 1.6713 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2850 - decoder_loss: 22.7212 - encoder_loss: 0.0052 - classifier_loss: 0.0768 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 73: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2850 - decoder_loss: 22.7212 - encoder_loss: 0.0052 - classifier_loss: 0.0768 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1922 - val_decoder_loss: 29.7420 - val_encoder_loss: 21.0507 - val_classifier_loss: 1.6733 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2847 - decoder_loss: 22.7198 - encoder_loss: 0.0050 - classifier_loss: 0.0767 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 74: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2847 - decoder_loss: 22.7198 - encoder_loss: 0.0050 - classifier_loss: 0.0767 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1941 - val_decoder_loss: 29.7410 - val_encoder_loss: 21.0526 - val_classifier_loss: 1.6744 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2842 - decoder_loss: 22.7188 - encoder_loss: 0.0047 - classifier_loss: 0.0765 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 75: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2842 - decoder_loss: 22.7188 - encoder_loss: 0.0047 - classifier_loss: 0.0765 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2117 - val_decoder_loss: 29.7399 - val_encoder_loss: 21.0701 - val_classifier_loss: 1.6759 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2830 - decoder_loss: 22.7176 - encoder_loss: 0.0036 - classifier_loss: 0.0764 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 76: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2830 - decoder_loss: 22.7176 - encoder_loss: 0.0036 - classifier_loss: 0.0764 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1934 - val_decoder_loss: 29.7390 - val_encoder_loss: 21.0520 - val_classifier_loss: 1.6749 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2833 - decoder_loss: 22.7165 - encoder_loss: 0.0040 - classifier_loss: 0.0762 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 77: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.2833 - decoder_loss: 22.7165 - encoder_loss: 0.0040 - classifier_loss: 0.0762 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2038 - val_decoder_loss: 29.7378 - val_encoder_loss: 21.0624 - val_classifier_loss: 1.6765 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2868 - decoder_loss: 22.7152 - encoder_loss: 0.0076 - classifier_loss: 0.0761 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 78: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2868 - decoder_loss: 22.7152 - encoder_loss: 0.0076 - classifier_loss: 0.0761 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1841 - val_decoder_loss: 29.7367 - val_encoder_loss: 21.0426 - val_classifier_loss: 1.6780 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2864 - decoder_loss: 22.7140 - encoder_loss: 0.0075 - classifier_loss: 0.0759 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 79: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2864 - decoder_loss: 22.7140 - encoder_loss: 0.0075 - classifier_loss: 0.0759 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2062 - val_decoder_loss: 29.7348 - val_encoder_loss: 21.0645 - val_classifier_loss: 1.6817 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2884 - decoder_loss: 22.7127 - encoder_loss: 0.0095 - classifier_loss: 0.0757 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 80: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2884 - decoder_loss: 22.7127 - encoder_loss: 0.0095 - classifier_loss: 0.0757 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2175 - val_decoder_loss: 29.7332 - val_encoder_loss: 21.0760 - val_classifier_loss: 1.6819 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2864 - decoder_loss: 22.7114 - encoder_loss: 0.0077 - classifier_loss: 0.0756 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 81: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2.2864 - decoder_loss: 22.7114 - encoder_loss: 0.0077 - classifier_loss: 0.0756 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2408 - val_decoder_loss: 29.7316 - val_encoder_loss: 21.0992 - val_classifier_loss: 1.6841 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2881 - decoder_loss: 22.7099 - encoder_loss: 0.0096 - classifier_loss: 0.0754 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 82: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2.2881 - decoder_loss: 22.7099 - encoder_loss: 0.0096 - classifier_loss: 0.0754 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2831 - val_decoder_loss: 29.7309 - val_encoder_loss: 21.1413 - val_classifier_loss: 1.6869 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2858 - decoder_loss: 22.7089 - encoder_loss: 0.0074 - classifier_loss: 0.0752 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 83: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2858 - decoder_loss: 22.7089 - encoder_loss: 0.0074 - classifier_loss: 0.0752 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2741 - val_decoder_loss: 29.7300 - val_encoder_loss: 21.1324 - val_classifier_loss: 1.6875 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2852 - decoder_loss: 22.7080 - encoder_loss: 0.0069 - classifier_loss: 0.0750 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 84: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2852 - decoder_loss: 22.7080 - encoder_loss: 0.0069 - classifier_loss: 0.0750 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2514 - val_decoder_loss: 29.7287 - val_encoder_loss: 21.1097 - val_classifier_loss: 1.6881 - val_decoder_accuracy: 0.0470 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2838 - decoder_loss: 22.7068 - encoder_loss: 0.0056 - classifier_loss: 0.0749 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 85: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2838 - decoder_loss: 22.7068 - encoder_loss: 0.0056 - classifier_loss: 0.0749 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2462 - val_decoder_loss: 29.7274 - val_encoder_loss: 21.1045 - val_classifier_loss: 1.6893 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2837 - decoder_loss: 22.7054 - encoder_loss: 0.0057 - classifier_loss: 0.0748 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 86: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.2837 - decoder_loss: 22.7054 - encoder_loss: 0.0057 - classifier_loss: 0.0748 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2515 - val_decoder_loss: 29.7258 - val_encoder_loss: 21.1098 - val_classifier_loss: 1.6916 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2854 - decoder_loss: 22.7040 - encoder_loss: 0.0076 - classifier_loss: 0.0746 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 87: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.2854 - decoder_loss: 22.7040 - encoder_loss: 0.0076 - classifier_loss: 0.0746 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2802 - val_decoder_loss: 29.7240 - val_encoder_loss: 21.1382 - val_classifier_loss: 1.6956 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2871 - decoder_loss: 22.7024 - encoder_loss: 0.0094 - classifier_loss: 0.0744 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2871 - decoder_loss: 22.7024 - encoder_loss: 0.0094 - classifier_loss: 0.0744 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2558 - val_decoder_loss: 29.7227 - val_encoder_loss: 21.1141 - val_classifier_loss: 1.6948 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2823 - decoder_loss: 22.7010 - encoder_loss: 0.0048 - classifier_loss: 0.0743 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.2823 - decoder_loss: 22.7010 - encoder_loss: 0.0048 - classifier_loss: 0.0743 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2629 - val_decoder_loss: 29.7211 - val_encoder_loss: 21.1210 - val_classifier_loss: 1.6976 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2815 - decoder_loss: 22.6995 - encoder_loss: 0.0041 - classifier_loss: 0.0741 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2815 - decoder_loss: 22.6995 - encoder_loss: 0.0041 - classifier_loss: 0.0741 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2472 - val_decoder_loss: 29.7204 - val_encoder_loss: 21.1054 - val_classifier_loss: 1.6975 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2807 - decoder_loss: 22.6981 - encoder_loss: 0.0035 - classifier_loss: 0.0740 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2807 - decoder_loss: 22.6981 - encoder_loss: 0.0035 - classifier_loss: 0.0740 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2539 - val_decoder_loss: 29.7191 - val_encoder_loss: 21.1121 - val_classifier_loss: 1.6990 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2799 - decoder_loss: 22.6967 - encoder_loss: 0.0028 - classifier_loss: 0.0738 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2799 - decoder_loss: 22.6967 - encoder_loss: 0.0028 - classifier_loss: 0.0738 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2609 - val_decoder_loss: 29.7176 - val_encoder_loss: 21.1190 - val_classifier_loss: 1.7007 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2811 - decoder_loss: 22.6950 - encoder_loss: 0.0043 - classifier_loss: 0.0737 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 93: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2811 - decoder_loss: 22.6950 - encoder_loss: 0.0043 - classifier_loss: 0.0737 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2603 - val_decoder_loss: 29.7159 - val_encoder_loss: 21.1187 - val_classifier_loss: 1.7007 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2805 - decoder_loss: 22.6934 - encoder_loss: 0.0039 - classifier_loss: 0.0735 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 94: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2805 - decoder_loss: 22.6934 - encoder_loss: 0.0039 - classifier_loss: 0.0735 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2954 - val_decoder_loss: 29.7142 - val_encoder_loss: 21.1536 - val_classifier_loss: 1.7032 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2798 - decoder_loss: 22.6916 - encoder_loss: 0.0033 - classifier_loss: 0.0734 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2798 - decoder_loss: 22.6916 - encoder_loss: 0.0033 - classifier_loss: 0.0734 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3131 - val_decoder_loss: 29.7129 - val_encoder_loss: 21.1712 - val_classifier_loss: 1.7055 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2813 - decoder_loss: 22.6902 - encoder_loss: 0.0049 - classifier_loss: 0.0733 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 96: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2813 - decoder_loss: 22.6902 - encoder_loss: 0.0049 - classifier_loss: 0.0733 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3325 - val_decoder_loss: 29.7115 - val_encoder_loss: 21.1906 - val_classifier_loss: 1.7076 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2804 - decoder_loss: 22.6887 - encoder_loss: 0.0042 - classifier_loss: 0.0731 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 97: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2804 - decoder_loss: 22.6887 - encoder_loss: 0.0042 - classifier_loss: 0.0731 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3242 - val_decoder_loss: 29.7102 - val_encoder_loss: 21.1825 - val_classifier_loss: 1.7074 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2776 - decoder_loss: 22.6872 - encoder_loss: 0.0016 - classifier_loss: 0.0729 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 98: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2776 - decoder_loss: 22.6872 - encoder_loss: 0.0016 - classifier_loss: 0.0729 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3274 - val_decoder_loss: 29.7087 - val_encoder_loss: 21.1856 - val_classifier_loss: 1.7088 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2762 - decoder_loss: 22.6857 - encoder_loss: 3.3557e-04 - classifier_loss: 0.0728 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 99: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2762 - decoder_loss: 22.6857 - encoder_loss: 3.3557e-04 - classifier_loss: 0.0728 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3271 - val_decoder_loss: 29.7072 - val_encoder_loss: 21.1855 - val_classifier_loss: 1.7093 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2769 - decoder_loss: 22.6842 - encoder_loss: 0.0012 - classifier_loss: 0.0727 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2769 - decoder_loss: 22.6842 - encoder_loss: 0.0012 - classifier_loss: 0.0727 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3174 - val_decoder_loss: 29.7057 - val_encoder_loss: 21.1758 - val_classifier_loss: 1.7101 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2764 - decoder_loss: 22.6826 - encoder_loss: 8.7143e-04 - classifier_loss: 0.0726 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2764 - decoder_loss: 22.6826 - encoder_loss: 8.7143e-04 - classifier_loss: 0.0726 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3072 - val_decoder_loss: 29.7042 - val_encoder_loss: 21.1656 - val_classifier_loss: 1.7109 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2772 - decoder_loss: 22.6809 - encoder_loss: 0.0019 - classifier_loss: 0.0726 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2772 - decoder_loss: 22.6809 - encoder_loss: 0.0019 - classifier_loss: 0.0726 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3014 - val_decoder_loss: 29.7030 - val_encoder_loss: 21.1600 - val_classifier_loss: 1.7114 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2766 - decoder_loss: 22.6794 - encoder_loss: 0.0014 - classifier_loss: 0.0724 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2766 - decoder_loss: 22.6794 - encoder_loss: 0.0014 - classifier_loss: 0.0724 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2890 - val_decoder_loss: 29.7017 - val_encoder_loss: 21.1476 - val_classifier_loss: 1.7122 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2786 - decoder_loss: 22.6779 - encoder_loss: 0.0036 - classifier_loss: 0.0724 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2786 - decoder_loss: 22.6779 - encoder_loss: 0.0036 - classifier_loss: 0.0724 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2959 - val_decoder_loss: 29.7004 - val_encoder_loss: 21.1545 - val_classifier_loss: 1.7129 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2777 - decoder_loss: 22.6763 - encoder_loss: 0.0029 - classifier_loss: 0.0722 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2777 - decoder_loss: 22.6763 - encoder_loss: 0.0029 - classifier_loss: 0.0722 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2968 - val_decoder_loss: 29.6990 - val_encoder_loss: 21.1555 - val_classifier_loss: 1.7140 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2794 - decoder_loss: 22.6749 - encoder_loss: 0.0047 - classifier_loss: 0.0721 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2794 - decoder_loss: 22.6749 - encoder_loss: 0.0047 - classifier_loss: 0.0721 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2956 - val_decoder_loss: 29.6980 - val_encoder_loss: 21.1544 - val_classifier_loss: 1.7146 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2789 - decoder_loss: 22.6735 - encoder_loss: 0.0044 - classifier_loss: 0.0719 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2789 - decoder_loss: 22.6735 - encoder_loss: 0.0044 - classifier_loss: 0.0719 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3228 - val_decoder_loss: 29.6970 - val_encoder_loss: 21.1814 - val_classifier_loss: 1.7163 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2783 - decoder_loss: 22.6723 - encoder_loss: 0.0039 - classifier_loss: 0.0718 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2783 - decoder_loss: 22.6723 - encoder_loss: 0.0039 - classifier_loss: 0.0718 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3710 - val_decoder_loss: 29.6959 - val_encoder_loss: 21.2296 - val_classifier_loss: 1.7177 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2770 - decoder_loss: 22.6709 - encoder_loss: 0.0027 - classifier_loss: 0.0716 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 109: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2770 - decoder_loss: 22.6709 - encoder_loss: 0.0027 - classifier_loss: 0.0716 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4242 - val_decoder_loss: 29.6947 - val_encoder_loss: 21.2827 - val_classifier_loss: 1.7199 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2774 - decoder_loss: 22.6695 - encoder_loss: 0.0033 - classifier_loss: 0.0714 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2774 - decoder_loss: 22.6695 - encoder_loss: 0.0033 - classifier_loss: 0.0714 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4536 - val_decoder_loss: 29.6931 - val_encoder_loss: 21.3120 - val_classifier_loss: 1.7227 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2773 - decoder_loss: 22.6679 - encoder_loss: 0.0034 - classifier_loss: 0.0713 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2773 - decoder_loss: 22.6679 - encoder_loss: 0.0034 - classifier_loss: 0.0713 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4868 - val_decoder_loss: 29.6913 - val_encoder_loss: 21.3452 - val_classifier_loss: 1.7254 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2801 - decoder_loss: 22.6663 - encoder_loss: 0.0063 - classifier_loss: 0.0711 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2801 - decoder_loss: 22.6663 - encoder_loss: 0.0063 - classifier_loss: 0.0711 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5174 - val_decoder_loss: 29.6905 - val_encoder_loss: 21.3757 - val_classifier_loss: 1.7268 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2777 - decoder_loss: 22.6651 - encoder_loss: 0.0041 - classifier_loss: 0.0710 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2777 - decoder_loss: 22.6651 - encoder_loss: 0.0041 - classifier_loss: 0.0710 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5635 - val_decoder_loss: 29.6897 - val_encoder_loss: 21.4215 - val_classifier_loss: 1.7297 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2777 - decoder_loss: 22.6638 - encoder_loss: 0.0042 - classifier_loss: 0.0709 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2777 - decoder_loss: 22.6638 - encoder_loss: 0.0042 - classifier_loss: 0.0709 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5724 - val_decoder_loss: 29.6889 - val_encoder_loss: 21.4303 - val_classifier_loss: 1.7319 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2781 - decoder_loss: 22.6626 - encoder_loss: 0.0048 - classifier_loss: 0.0708 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2781 - decoder_loss: 22.6626 - encoder_loss: 0.0048 - classifier_loss: 0.0708 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6344 - val_decoder_loss: 29.6881 - val_encoder_loss: 21.4921 - val_classifier_loss: 1.7347 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2756 - decoder_loss: 22.6615 - encoder_loss: 0.0024 - classifier_loss: 0.0706 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2756 - decoder_loss: 22.6615 - encoder_loss: 0.0024 - classifier_loss: 0.0706 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6047 - val_decoder_loss: 29.6869 - val_encoder_loss: 21.4626 - val_classifier_loss: 1.7335 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2758 - decoder_loss: 22.6602 - encoder_loss: 0.0028 - classifier_loss: 0.0705 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2758 - decoder_loss: 22.6602 - encoder_loss: 0.0028 - classifier_loss: 0.0705 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6533 - val_decoder_loss: 29.6855 - val_encoder_loss: 21.5111 - val_classifier_loss: 1.7360 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2750 - decoder_loss: 22.6587 - encoder_loss: 0.0021 - classifier_loss: 0.0704 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2750 - decoder_loss: 22.6587 - encoder_loss: 0.0021 - classifier_loss: 0.0704 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6472 - val_decoder_loss: 29.6844 - val_encoder_loss: 21.5051 - val_classifier_loss: 1.7366 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2743 - decoder_loss: 22.6572 - encoder_loss: 0.0016 - classifier_loss: 0.0703 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2743 - decoder_loss: 22.6572 - encoder_loss: 0.0016 - classifier_loss: 0.0703 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6433 - val_decoder_loss: 29.6832 - val_encoder_loss: 21.5012 - val_classifier_loss: 1.7381 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2739 - decoder_loss: 22.6557 - encoder_loss: 0.0013 - classifier_loss: 0.0702 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2739 - decoder_loss: 22.6557 - encoder_loss: 0.0013 - classifier_loss: 0.0702 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6400 - val_decoder_loss: 29.6821 - val_encoder_loss: 21.4979 - val_classifier_loss: 1.7386 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2733 - decoder_loss: 22.6543 - encoder_loss: 8.8762e-04 - classifier_loss: 0.0701 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 121: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2733 - decoder_loss: 22.6543 - encoder_loss: 8.8762e-04 - classifier_loss: 0.0701 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6445 - val_decoder_loss: 29.6810 - val_encoder_loss: 21.5024 - val_classifier_loss: 1.7400 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2728 - decoder_loss: 22.6528 - encoder_loss: 5.0038e-04 - classifier_loss: 0.0700 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2728 - decoder_loss: 22.6528 - encoder_loss: 5.0038e-04 - classifier_loss: 0.0700 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6480 - val_decoder_loss: 29.6798 - val_encoder_loss: 21.5059 - val_classifier_loss: 1.7414 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2736 - decoder_loss: 22.6513 - encoder_loss: 0.0015 - classifier_loss: 0.0699 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2736 - decoder_loss: 22.6513 - encoder_loss: 0.0015 - classifier_loss: 0.0699 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6384 - val_decoder_loss: 29.6781 - val_encoder_loss: 21.4964 - val_classifier_loss: 1.7424 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2742 - decoder_loss: 22.6496 - encoder_loss: 0.0023 - classifier_loss: 0.0698 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2742 - decoder_loss: 22.6496 - encoder_loss: 0.0023 - classifier_loss: 0.0698 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6446 - val_decoder_loss: 29.6765 - val_encoder_loss: 21.5025 - val_classifier_loss: 1.7441 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2737 - decoder_loss: 22.6480 - encoder_loss: 0.0019 - classifier_loss: 0.0697 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2737 - decoder_loss: 22.6480 - encoder_loss: 0.0019 - classifier_loss: 0.0697 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6214 - val_decoder_loss: 29.6756 - val_encoder_loss: 21.4796 - val_classifier_loss: 1.7427 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2730 - decoder_loss: 22.6465 - encoder_loss: 0.0014 - classifier_loss: 0.0696 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2730 - decoder_loss: 22.6465 - encoder_loss: 0.0014 - classifier_loss: 0.0696 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6277 - val_decoder_loss: 29.6741 - val_encoder_loss: 21.4859 - val_classifier_loss: 1.7441 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2723 - decoder_loss: 22.6449 - encoder_loss: 8.7547e-04 - classifier_loss: 0.0695 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2723 - decoder_loss: 22.6449 - encoder_loss: 8.7547e-04 - classifier_loss: 0.0695 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6321 - val_decoder_loss: 29.6725 - val_encoder_loss: 21.4903 - val_classifier_loss: 1.7455 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2720 - decoder_loss: 22.6434 - encoder_loss: 7.0520e-04 - classifier_loss: 0.0694 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2720 - decoder_loss: 22.6434 - encoder_loss: 7.0520e-04 - classifier_loss: 0.0694 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6137 - val_decoder_loss: 29.6715 - val_encoder_loss: 21.4721 - val_classifier_loss: 1.7443 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2716 - decoder_loss: 22.6416 - encoder_loss: 5.4273e-04 - classifier_loss: 0.0693 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2716 - decoder_loss: 22.6416 - encoder_loss: 5.4273e-04 - classifier_loss: 0.0693 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6178 - val_decoder_loss: 29.6703 - val_encoder_loss: 21.4762 - val_classifier_loss: 1.7452 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2713 - decoder_loss: 22.6400 - encoder_loss: 3.9156e-04 - classifier_loss: 0.0692 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2713 - decoder_loss: 22.6400 - encoder_loss: 3.9156e-04 - classifier_loss: 0.0692 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6211 - val_decoder_loss: 29.6690 - val_encoder_loss: 21.4796 - val_classifier_loss: 1.7460 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2723 - decoder_loss: 22.6383 - encoder_loss: 0.0015 - classifier_loss: 0.0691 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.2723 - decoder_loss: 22.6383 - encoder_loss: 0.0015 - classifier_loss: 0.0691 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6242 - val_decoder_loss: 29.6677 - val_encoder_loss: 21.4827 - val_classifier_loss: 1.7472 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2727 - decoder_loss: 22.6367 - encoder_loss: 0.0022 - classifier_loss: 0.0690 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2727 - decoder_loss: 22.6367 - encoder_loss: 0.0022 - classifier_loss: 0.0690 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6322 - val_decoder_loss: 29.6667 - val_encoder_loss: 21.4906 - val_classifier_loss: 1.7486 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2748 - decoder_loss: 22.6352 - encoder_loss: 0.0044 - classifier_loss: 0.0689 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2748 - decoder_loss: 22.6352 - encoder_loss: 0.0044 - classifier_loss: 0.0689 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7031 - val_decoder_loss: 29.6661 - val_encoder_loss: 21.5612 - val_classifier_loss: 1.7526 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2732 - decoder_loss: 22.6339 - encoder_loss: 0.0029 - classifier_loss: 0.0688 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2732 - decoder_loss: 22.6339 - encoder_loss: 0.0029 - classifier_loss: 0.0688 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7144 - val_decoder_loss: 29.6652 - val_encoder_loss: 21.5725 - val_classifier_loss: 1.7539 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2726 - decoder_loss: 22.6326 - encoder_loss: 0.0025 - classifier_loss: 0.0687 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2726 - decoder_loss: 22.6326 - encoder_loss: 0.0025 - classifier_loss: 0.0687 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7168 - val_decoder_loss: 29.6641 - val_encoder_loss: 21.5750 - val_classifier_loss: 1.7540 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2728 - decoder_loss: 22.6312 - encoder_loss: 0.0028 - classifier_loss: 0.0685 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2728 - decoder_loss: 22.6312 - encoder_loss: 0.0028 - classifier_loss: 0.0685 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7427 - val_decoder_loss: 29.6629 - val_encoder_loss: 21.6009 - val_classifier_loss: 1.7550 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2744 - decoder_loss: 22.6297 - encoder_loss: 0.0046 - classifier_loss: 0.0684 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2744 - decoder_loss: 22.6297 - encoder_loss: 0.0046 - classifier_loss: 0.0684 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7080 - val_decoder_loss: 29.6617 - val_encoder_loss: 21.5663 - val_classifier_loss: 1.7549 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2740 - decoder_loss: 22.6281 - encoder_loss: 0.0044 - classifier_loss: 0.0683 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2.2740 - decoder_loss: 22.6281 - encoder_loss: 0.0044 - classifier_loss: 0.0683 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7224 - val_decoder_loss: 29.6607 - val_encoder_loss: 21.5808 - val_classifier_loss: 1.7559 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2718 - decoder_loss: 22.6266 - encoder_loss: 0.0024 - classifier_loss: 0.0681 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2718 - decoder_loss: 22.6266 - encoder_loss: 0.0024 - classifier_loss: 0.0681 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6739 - val_decoder_loss: 29.6600 - val_encoder_loss: 21.5323 - val_classifier_loss: 1.7555 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2728 - decoder_loss: 22.6252 - encoder_loss: 0.0035 - classifier_loss: 0.0680 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2728 - decoder_loss: 22.6252 - encoder_loss: 0.0035 - classifier_loss: 0.0680 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6848 - val_decoder_loss: 29.6591 - val_encoder_loss: 21.5432 - val_classifier_loss: 1.7562 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2722 - decoder_loss: 22.6237 - encoder_loss: 0.0031 - classifier_loss: 0.0679 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 141: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2722 - decoder_loss: 22.6237 - encoder_loss: 0.0031 - classifier_loss: 0.0679 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6670 - val_decoder_loss: 29.6580 - val_encoder_loss: 21.5255 - val_classifier_loss: 1.7563 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2706 - decoder_loss: 22.6223 - encoder_loss: 0.0016 - classifier_loss: 0.0678 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2706 - decoder_loss: 22.6223 - encoder_loss: 0.0016 - classifier_loss: 0.0678 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6710 - val_decoder_loss: 29.6570 - val_encoder_loss: 21.5296 - val_classifier_loss: 1.7569 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2707 - decoder_loss: 22.6209 - encoder_loss: 0.0018 - classifier_loss: 0.0676 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2707 - decoder_loss: 22.6209 - encoder_loss: 0.0018 - classifier_loss: 0.0676 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6615 - val_decoder_loss: 29.6561 - val_encoder_loss: 21.5203 - val_classifier_loss: 1.7562 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2698 - decoder_loss: 22.6195 - encoder_loss: 0.0011 - classifier_loss: 0.0675 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2698 - decoder_loss: 22.6195 - encoder_loss: 0.0011 - classifier_loss: 0.0675 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6619 - val_decoder_loss: 29.6550 - val_encoder_loss: 21.5207 - val_classifier_loss: 1.7562 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2692 - decoder_loss: 22.6180 - encoder_loss: 7.0945e-04 - classifier_loss: 0.0674 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2692 - decoder_loss: 22.6180 - encoder_loss: 7.0945e-04 - classifier_loss: 0.0674 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6731 - val_decoder_loss: 29.6538 - val_encoder_loss: 21.5321 - val_classifier_loss: 1.7565 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2687 - decoder_loss: 22.6163 - encoder_loss: 3.3447e-04 - classifier_loss: 0.0673 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2687 - decoder_loss: 22.6163 - encoder_loss: 3.3447e-04 - classifier_loss: 0.0673 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6836 - val_decoder_loss: 29.6526 - val_encoder_loss: 21.5427 - val_classifier_loss: 1.7568 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2682 - decoder_loss: 22.6147 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0671 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2682 - decoder_loss: 22.6147 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0671 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6839 - val_decoder_loss: 29.6513 - val_encoder_loss: 21.5430 - val_classifier_loss: 1.7574 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2680 - decoder_loss: 22.6131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0671 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2680 - decoder_loss: 22.6131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0671 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6848 - val_decoder_loss: 29.6499 - val_encoder_loss: 21.5440 - val_classifier_loss: 1.7580 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2678 - decoder_loss: 22.6114 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0670 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2678 - decoder_loss: 22.6114 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0670 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6857 - val_decoder_loss: 29.6486 - val_encoder_loss: 21.5450 - val_classifier_loss: 1.7587 - val_decoder_accuracy: 0.0493 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2702 - decoder_loss: 22.6098 - encoder_loss: 0.0025 - classifier_loss: 0.0669 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2702 - decoder_loss: 22.6098 - encoder_loss: 0.0025 - classifier_loss: 0.0669 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6852 - val_decoder_loss: 29.6473 - val_encoder_loss: 21.5445 - val_classifier_loss: 1.7597 - val_decoder_accuracy: 0.0493 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2758 - decoder_loss: 22.6081 - encoder_loss: 0.0083 - classifier_loss: 0.0668 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2758 - decoder_loss: 22.6081 - encoder_loss: 0.0083 - classifier_loss: 0.0668 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6460 - val_decoder_loss: 29.6467 - val_encoder_loss: 21.5055 - val_classifier_loss: 1.7583 - val_decoder_accuracy: 0.0493 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2715 - decoder_loss: 22.6069 - encoder_loss: 0.0041 - classifier_loss: 0.0666 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2715 - decoder_loss: 22.6069 - encoder_loss: 0.0041 - classifier_loss: 0.0666 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5757 - val_decoder_loss: 29.6460 - val_encoder_loss: 21.4353 - val_classifier_loss: 1.7572 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2716 - decoder_loss: 22.6059 - encoder_loss: 0.0044 - classifier_loss: 0.0664 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2716 - decoder_loss: 22.6059 - encoder_loss: 0.0044 - classifier_loss: 0.0664 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5536 - val_decoder_loss: 29.6448 - val_encoder_loss: 21.4134 - val_classifier_loss: 1.7567 - val_decoder_accuracy: 0.0498 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2702 - decoder_loss: 22.6045 - encoder_loss: 0.0031 - classifier_loss: 0.0663 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2702 - decoder_loss: 22.6045 - encoder_loss: 0.0031 - classifier_loss: 0.0663 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5475 - val_decoder_loss: 29.6435 - val_encoder_loss: 21.4074 - val_classifier_loss: 1.7569 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2705 - decoder_loss: 22.6029 - encoder_loss: 0.0036 - classifier_loss: 0.0662 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2705 - decoder_loss: 22.6029 - encoder_loss: 0.0036 - classifier_loss: 0.0662 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5380 - val_decoder_loss: 29.6422 - val_encoder_loss: 21.3981 - val_classifier_loss: 1.7568 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2709 - decoder_loss: 22.6013 - encoder_loss: 0.0042 - classifier_loss: 0.0660 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2709 - decoder_loss: 22.6013 - encoder_loss: 0.0042 - classifier_loss: 0.0660 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5104 - val_decoder_loss: 29.6410 - val_encoder_loss: 21.3706 - val_classifier_loss: 1.7566 - val_decoder_accuracy: 0.0502 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2694 - decoder_loss: 22.5999 - encoder_loss: 0.0028 - classifier_loss: 0.0659 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2694 - decoder_loss: 22.5999 - encoder_loss: 0.0028 - classifier_loss: 0.0659 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5151 - val_decoder_loss: 29.6396 - val_encoder_loss: 21.3753 - val_classifier_loss: 1.7581 - val_decoder_accuracy: 0.0502 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2682 - decoder_loss: 22.5984 - encoder_loss: 0.0017 - classifier_loss: 0.0658 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2682 - decoder_loss: 22.5984 - encoder_loss: 0.0017 - classifier_loss: 0.0658 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5190 - val_decoder_loss: 29.6382 - val_encoder_loss: 21.3792 - val_classifier_loss: 1.7597 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2705 - decoder_loss: 22.5969 - encoder_loss: 0.0042 - classifier_loss: 0.0656 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2705 - decoder_loss: 22.5969 - encoder_loss: 0.0042 - classifier_loss: 0.0656 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5239 - val_decoder_loss: 29.6370 - val_encoder_loss: 21.3841 - val_classifier_loss: 1.7618 - val_decoder_accuracy: 0.0502 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2683 - decoder_loss: 22.5956 - encoder_loss: 0.0022 - classifier_loss: 0.0655 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2683 - decoder_loss: 22.5956 - encoder_loss: 0.0022 - classifier_loss: 0.0655 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5151 - val_decoder_loss: 29.6361 - val_encoder_loss: 21.3754 - val_classifier_loss: 1.7616 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2686 - decoder_loss: 22.5942 - encoder_loss: 0.0027 - classifier_loss: 0.0654 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2686 - decoder_loss: 22.5942 - encoder_loss: 0.0027 - classifier_loss: 0.0654 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5011 - val_decoder_loss: 29.6348 - val_encoder_loss: 21.3614 - val_classifier_loss: 1.7616 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2699 - decoder_loss: 22.5924 - encoder_loss: 0.0041 - classifier_loss: 0.0653 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 162: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2699 - decoder_loss: 22.5924 - encoder_loss: 0.0041 - classifier_loss: 0.0653 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4950 - val_decoder_loss: 29.6334 - val_encoder_loss: 21.3554 - val_classifier_loss: 1.7617 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2697 - decoder_loss: 22.5906 - encoder_loss: 0.0041 - classifier_loss: 0.0651 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 163: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2697 - decoder_loss: 22.5906 - encoder_loss: 0.0041 - classifier_loss: 0.0651 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5003 - val_decoder_loss: 29.6322 - val_encoder_loss: 21.3607 - val_classifier_loss: 1.7633 - val_decoder_accuracy: 0.0498 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2700 - decoder_loss: 22.5895 - encoder_loss: 0.0045 - classifier_loss: 0.0650 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2700 - decoder_loss: 22.5895 - encoder_loss: 0.0045 - classifier_loss: 0.0650 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4975 - val_decoder_loss: 29.6311 - val_encoder_loss: 21.3580 - val_classifier_loss: 1.7640 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2709 - decoder_loss: 22.5879 - encoder_loss: 0.0056 - classifier_loss: 0.0649 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.2709 - decoder_loss: 22.5879 - encoder_loss: 0.0056 - classifier_loss: 0.0649 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5461 - val_decoder_loss: 29.6299 - val_encoder_loss: 21.4063 - val_classifier_loss: 1.7676 - val_decoder_accuracy: 0.0502 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2676 - decoder_loss: 22.5864 - encoder_loss: 0.0025 - classifier_loss: 0.0648 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 166: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2676 - decoder_loss: 22.5864 - encoder_loss: 0.0025 - classifier_loss: 0.0648 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5840 - val_decoder_loss: 29.6289 - val_encoder_loss: 21.4441 - val_classifier_loss: 1.7700 - val_decoder_accuracy: 0.0503 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2664 - decoder_loss: 22.5851 - encoder_loss: 0.0014 - classifier_loss: 0.0647 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2664 - decoder_loss: 22.5851 - encoder_loss: 0.0014 - classifier_loss: 0.0647 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5796 - val_decoder_loss: 29.6280 - val_encoder_loss: 21.4398 - val_classifier_loss: 1.7695 - val_decoder_accuracy: 0.0507 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2668 - decoder_loss: 22.5838 - encoder_loss: 0.0020 - classifier_loss: 0.0645 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2668 - decoder_loss: 22.5838 - encoder_loss: 0.0020 - classifier_loss: 0.0645 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5893 - val_decoder_loss: 29.6268 - val_encoder_loss: 21.4495 - val_classifier_loss: 1.7709 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2658 - decoder_loss: 22.5825 - encoder_loss: 0.0011 - classifier_loss: 0.0644 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 2.2658 - decoder_loss: 22.5825 - encoder_loss: 0.0011 - classifier_loss: 0.0644 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6000 - val_decoder_loss: 29.6256 - val_encoder_loss: 21.4602 - val_classifier_loss: 1.7723 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2665 - decoder_loss: 22.5811 - encoder_loss: 0.0020 - classifier_loss: 0.0643 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2665 - decoder_loss: 22.5811 - encoder_loss: 0.0020 - classifier_loss: 0.0643 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6033 - val_decoder_loss: 29.6244 - val_encoder_loss: 21.4635 - val_classifier_loss: 1.7735 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2659 - decoder_loss: 22.5796 - encoder_loss: 0.0016 - classifier_loss: 0.0642 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2659 - decoder_loss: 22.5796 - encoder_loss: 0.0016 - classifier_loss: 0.0642 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6070 - val_decoder_loss: 29.6232 - val_encoder_loss: 21.4672 - val_classifier_loss: 1.7748 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2667 - decoder_loss: 22.5781 - encoder_loss: 0.0024 - classifier_loss: 0.0641 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2667 - decoder_loss: 22.5781 - encoder_loss: 0.0024 - classifier_loss: 0.0641 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6127 - val_decoder_loss: 29.6221 - val_encoder_loss: 21.4729 - val_classifier_loss: 1.7753 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2659 - decoder_loss: 22.5766 - encoder_loss: 0.0019 - classifier_loss: 0.0640 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2659 - decoder_loss: 22.5766 - encoder_loss: 0.0019 - classifier_loss: 0.0640 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6223 - val_decoder_loss: 29.6208 - val_encoder_loss: 21.4825 - val_classifier_loss: 1.7766 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2677 - decoder_loss: 22.5750 - encoder_loss: 0.0038 - classifier_loss: 0.0639 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2677 - decoder_loss: 22.5750 - encoder_loss: 0.0038 - classifier_loss: 0.0639 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6462 - val_decoder_loss: 29.6196 - val_encoder_loss: 21.5065 - val_classifier_loss: 1.7780 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2672 - decoder_loss: 22.5732 - encoder_loss: 0.0035 - classifier_loss: 0.0638 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2672 - decoder_loss: 22.5732 - encoder_loss: 0.0035 - classifier_loss: 0.0638 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6415 - val_decoder_loss: 29.6183 - val_encoder_loss: 21.5018 - val_classifier_loss: 1.7788 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2665 - decoder_loss: 22.5719 - encoder_loss: 0.0029 - classifier_loss: 0.0636 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2665 - decoder_loss: 22.5719 - encoder_loss: 0.0029 - classifier_loss: 0.0636 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6692 - val_decoder_loss: 29.6168 - val_encoder_loss: 21.5294 - val_classifier_loss: 1.7804 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - decoder_loss: 22.5703 - encoder_loss: 0.0022 - classifier_loss: 0.0635 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2656 - decoder_loss: 22.5703 - encoder_loss: 0.0022 - classifier_loss: 0.0635 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6367 - val_decoder_loss: 29.6161 - val_encoder_loss: 21.4971 - val_classifier_loss: 1.7796 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - decoder_loss: 22.5692 - encoder_loss: 0.0023 - classifier_loss: 0.0634 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2656 - decoder_loss: 22.5692 - encoder_loss: 0.0023 - classifier_loss: 0.0634 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6538 - val_decoder_loss: 29.6153 - val_encoder_loss: 21.5142 - val_classifier_loss: 1.7809 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2645 - decoder_loss: 22.5678 - encoder_loss: 0.0014 - classifier_loss: 0.0633 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.2645 - decoder_loss: 22.5678 - encoder_loss: 0.0014 - classifier_loss: 0.0633 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6540 - val_decoder_loss: 29.6141 - val_encoder_loss: 21.5143 - val_classifier_loss: 1.7824 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2666 - decoder_loss: 22.5665 - encoder_loss: 0.0036 - classifier_loss: 0.0632 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2666 - decoder_loss: 22.5665 - encoder_loss: 0.0036 - classifier_loss: 0.0632 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6738 - val_decoder_loss: 29.6129 - val_encoder_loss: 21.5340 - val_classifier_loss: 1.7848 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2652 - decoder_loss: 22.5650 - encoder_loss: 0.0024 - classifier_loss: 0.0631 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2652 - decoder_loss: 22.5650 - encoder_loss: 0.0024 - classifier_loss: 0.0631 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6844 - val_decoder_loss: 29.6116 - val_encoder_loss: 21.5446 - val_classifier_loss: 1.7868 - val_decoder_accuracy: 0.0510 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2644 - decoder_loss: 22.5635 - encoder_loss: 0.0017 - classifier_loss: 0.0630 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2644 - decoder_loss: 22.5635 - encoder_loss: 0.0017 - classifier_loss: 0.0630 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6694 - val_decoder_loss: 29.6105 - val_encoder_loss: 21.5297 - val_classifier_loss: 1.7865 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2646 - decoder_loss: 22.5622 - encoder_loss: 0.0021 - classifier_loss: 0.0629 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2646 - decoder_loss: 22.5622 - encoder_loss: 0.0021 - classifier_loss: 0.0629 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6902 - val_decoder_loss: 29.6095 - val_encoder_loss: 21.5503 - val_classifier_loss: 1.7891 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2663 - decoder_loss: 22.5608 - encoder_loss: 0.0039 - classifier_loss: 0.0628 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2663 - decoder_loss: 22.5608 - encoder_loss: 0.0039 - classifier_loss: 0.0628 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7042 - val_decoder_loss: 29.6085 - val_encoder_loss: 21.5643 - val_classifier_loss: 1.7914 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - decoder_loss: 22.5595 - encoder_loss: 0.0034 - classifier_loss: 0.0627 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2656 - decoder_loss: 22.5595 - encoder_loss: 0.0034 - classifier_loss: 0.0627 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6655 - val_decoder_loss: 29.6077 - val_encoder_loss: 21.5258 - val_classifier_loss: 1.7899 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - decoder_loss: 22.5585 - encoder_loss: 0.0035 - classifier_loss: 0.0627 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.2656 - decoder_loss: 22.5585 - encoder_loss: 0.0035 - classifier_loss: 0.0627 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6847 - val_decoder_loss: 29.6071 - val_encoder_loss: 21.5448 - val_classifier_loss: 1.7917 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2651 - decoder_loss: 22.5573 - encoder_loss: 0.0031 - classifier_loss: 0.0626 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.2651 - decoder_loss: 22.5573 - encoder_loss: 0.0031 - classifier_loss: 0.0626 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6903 - val_decoder_loss: 29.6063 - val_encoder_loss: 21.5503 - val_classifier_loss: 1.7933 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2669 - decoder_loss: 22.5562 - encoder_loss: 0.0050 - classifier_loss: 0.0625 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2669 - decoder_loss: 22.5562 - encoder_loss: 0.0050 - classifier_loss: 0.0625 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7057 - val_decoder_loss: 29.6052 - val_encoder_loss: 21.5657 - val_classifier_loss: 1.7947 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2648 - decoder_loss: 22.5552 - encoder_loss: 0.0030 - classifier_loss: 0.0624 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.2648 - decoder_loss: 22.5552 - encoder_loss: 0.0030 - classifier_loss: 0.0624 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7189 - val_decoder_loss: 29.6038 - val_encoder_loss: 21.5789 - val_classifier_loss: 1.7966 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2667 - decoder_loss: 22.5541 - encoder_loss: 0.0051 - classifier_loss: 0.0623 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2667 - decoder_loss: 22.5541 - encoder_loss: 0.0051 - classifier_loss: 0.0623 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7320 - val_decoder_loss: 29.6032 - val_encoder_loss: 21.5919 - val_classifier_loss: 1.7980 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2671 - decoder_loss: 22.5530 - encoder_loss: 0.0056 - classifier_loss: 0.0622 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2671 - decoder_loss: 22.5530 - encoder_loss: 0.0056 - classifier_loss: 0.0622 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7981 - val_decoder_loss: 29.6023 - val_encoder_loss: 21.6577 - val_classifier_loss: 1.8017 - val_decoder_accuracy: 0.0520 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2650 - decoder_loss: 22.5519 - encoder_loss: 0.0036 - classifier_loss: 0.0622 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2650 - decoder_loss: 22.5519 - encoder_loss: 0.0036 - classifier_loss: 0.0622 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7915 - val_decoder_loss: 29.6016 - val_encoder_loss: 21.6511 - val_classifier_loss: 1.8027 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2641 - decoder_loss: 22.5508 - encoder_loss: 0.0028 - classifier_loss: 0.0621 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2641 - decoder_loss: 22.5508 - encoder_loss: 0.0028 - classifier_loss: 0.0621 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7956 - val_decoder_loss: 29.6008 - val_encoder_loss: 21.6551 - val_classifier_loss: 1.8045 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2639 - decoder_loss: 22.5495 - encoder_loss: 0.0027 - classifier_loss: 0.0620 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2639 - decoder_loss: 22.5495 - encoder_loss: 0.0027 - classifier_loss: 0.0620 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.8075 - val_decoder_loss: 29.6005 - val_encoder_loss: 21.6668 - val_classifier_loss: 1.8062 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2646 - decoder_loss: 22.5483 - encoder_loss: 0.0036 - classifier_loss: 0.0620 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2646 - decoder_loss: 22.5483 - encoder_loss: 0.0036 - classifier_loss: 0.0620 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.8024 - val_decoder_loss: 29.6000 - val_encoder_loss: 21.6616 - val_classifier_loss: 1.8074 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2645 - decoder_loss: 22.5473 - encoder_loss: 0.0036 - classifier_loss: 0.0619 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.2645 - decoder_loss: 22.5473 - encoder_loss: 0.0036 - classifier_loss: 0.0619 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7805 - val_decoder_loss: 29.5995 - val_encoder_loss: 21.6398 - val_classifier_loss: 1.8073 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2649 - decoder_loss: 22.5464 - encoder_loss: 0.0041 - classifier_loss: 0.0618 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2649 - decoder_loss: 22.5464 - encoder_loss: 0.0041 - classifier_loss: 0.0618 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.8068 - val_decoder_loss: 29.5983 - val_encoder_loss: 21.6660 - val_classifier_loss: 1.8096 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2641 - decoder_loss: 22.5453 - encoder_loss: 0.0034 - classifier_loss: 0.0617 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2641 - decoder_loss: 22.5453 - encoder_loss: 0.0034 - classifier_loss: 0.0617 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.8181 - val_decoder_loss: 29.5971 - val_encoder_loss: 21.6773 - val_classifier_loss: 1.8110 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2631 - decoder_loss: 22.5442 - encoder_loss: 0.0025 - classifier_loss: 0.0616 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2631 - decoder_loss: 22.5442 - encoder_loss: 0.0025 - classifier_loss: 0.0616 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7974 - val_decoder_loss: 29.5960 - val_encoder_loss: 21.6568 - val_classifier_loss: 1.8100 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2620 - decoder_loss: 22.5429 - encoder_loss: 0.0016 - classifier_loss: 0.0615 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2620 - decoder_loss: 22.5429 - encoder_loss: 0.0016 - classifier_loss: 0.0615 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7889 - val_decoder_loss: 29.5948 - val_encoder_loss: 21.6484 - val_classifier_loss: 1.8101 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2630 - decoder_loss: 22.5414 - encoder_loss: 0.0027 - classifier_loss: 0.0614 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2630 - decoder_loss: 22.5414 - encoder_loss: 0.0027 - classifier_loss: 0.0614 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7586 - val_decoder_loss: 29.5942 - val_encoder_loss: 21.6182 - val_classifier_loss: 1.8097 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2640 - decoder_loss: 22.5400 - encoder_loss: 0.0039 - classifier_loss: 0.0613 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2640 - decoder_loss: 22.5400 - encoder_loss: 0.0039 - classifier_loss: 0.0613 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7279 - val_decoder_loss: 29.5933 - val_encoder_loss: 21.5876 - val_classifier_loss: 1.8099 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2622 - decoder_loss: 22.5386 - encoder_loss: 0.0023 - classifier_loss: 0.0612 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 203: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2622 - decoder_loss: 22.5386 - encoder_loss: 0.0023 - classifier_loss: 0.0612 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6877 - val_decoder_loss: 29.5927 - val_encoder_loss: 21.5474 - val_classifier_loss: 1.8097 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2606 - decoder_loss: 22.5372 - encoder_loss: 7.4019e-04 - classifier_loss: 0.0611 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 204: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.2606 - decoder_loss: 22.5372 - encoder_loss: 7.4019e-04 - classifier_loss: 0.0611 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6770 - val_decoder_loss: 29.5915 - val_encoder_loss: 21.5368 - val_classifier_loss: 1.8107 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2616 - decoder_loss: 22.5358 - encoder_loss: 0.0019 - classifier_loss: 0.0610 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 205: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2616 - decoder_loss: 22.5358 - encoder_loss: 0.0019 - classifier_loss: 0.0610 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6662 - val_decoder_loss: 29.5905 - val_encoder_loss: 21.5262 - val_classifier_loss: 1.8102 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2620 - decoder_loss: 22.5345 - encoder_loss: 0.0024 - classifier_loss: 0.0609 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 206: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2620 - decoder_loss: 22.5345 - encoder_loss: 0.0024 - classifier_loss: 0.0609 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6703 - val_decoder_loss: 29.5895 - val_encoder_loss: 21.5302 - val_classifier_loss: 1.8113 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2647 - decoder_loss: 22.5331 - encoder_loss: 0.0053 - classifier_loss: 0.0608 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 207: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2647 - decoder_loss: 22.5331 - encoder_loss: 0.0053 - classifier_loss: 0.0608 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6920 - val_decoder_loss: 29.5885 - val_encoder_loss: 21.5518 - val_classifier_loss: 1.8133 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2637 - decoder_loss: 22.5318 - encoder_loss: 0.0044 - classifier_loss: 0.0607 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 208: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2637 - decoder_loss: 22.5318 - encoder_loss: 0.0044 - classifier_loss: 0.0607 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7082 - val_decoder_loss: 29.5874 - val_encoder_loss: 21.5679 - val_classifier_loss: 1.8153 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2616 - decoder_loss: 22.5307 - encoder_loss: 0.0024 - classifier_loss: 0.0606 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 209: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.2616 - decoder_loss: 22.5307 - encoder_loss: 0.0024 - classifier_loss: 0.0606 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7055 - val_decoder_loss: 29.5866 - val_encoder_loss: 21.5653 - val_classifier_loss: 1.8154 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2605 - decoder_loss: 22.5296 - encoder_loss: 0.0015 - classifier_loss: 0.0605 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 210: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2605 - decoder_loss: 22.5296 - encoder_loss: 0.0015 - classifier_loss: 0.0605 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6888 - val_decoder_loss: 29.5855 - val_encoder_loss: 21.5487 - val_classifier_loss: 1.8150 - val_decoder_accuracy: 0.0507 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2627 - decoder_loss: 22.5282 - encoder_loss: 0.0038 - classifier_loss: 0.0604 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 211: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2627 - decoder_loss: 22.5282 - encoder_loss: 0.0038 - classifier_loss: 0.0604 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6756 - val_decoder_loss: 29.5848 - val_encoder_loss: 21.5356 - val_classifier_loss: 1.8149 - val_decoder_accuracy: 0.0508 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2612 - decoder_loss: 22.5267 - encoder_loss: 0.0025 - classifier_loss: 0.0602 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 212: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2612 - decoder_loss: 22.5267 - encoder_loss: 0.0025 - classifier_loss: 0.0602 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6351 - val_decoder_loss: 29.5843 - val_encoder_loss: 21.4953 - val_classifier_loss: 1.8136 - val_decoder_accuracy: 0.0508 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2613 - decoder_loss: 22.5254 - encoder_loss: 0.0027 - classifier_loss: 0.0601 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 213: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2613 - decoder_loss: 22.5254 - encoder_loss: 0.0027 - classifier_loss: 0.0601 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6323 - val_decoder_loss: 29.5834 - val_encoder_loss: 21.4925 - val_classifier_loss: 1.8146 - val_decoder_accuracy: 0.0508 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2614 - decoder_loss: 22.5241 - encoder_loss: 0.0030 - classifier_loss: 0.0600 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 214: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2614 - decoder_loss: 22.5241 - encoder_loss: 0.0030 - classifier_loss: 0.0600 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6219 - val_decoder_loss: 29.5826 - val_encoder_loss: 21.4821 - val_classifier_loss: 1.8150 - val_decoder_accuracy: 0.0507 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2604 - decoder_loss: 22.5229 - encoder_loss: 0.0021 - classifier_loss: 0.0598 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 215: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2604 - decoder_loss: 22.5229 - encoder_loss: 0.0021 - classifier_loss: 0.0598 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5914 - val_decoder_loss: 29.5820 - val_encoder_loss: 21.4518 - val_classifier_loss: 1.8142 - val_decoder_accuracy: 0.0507 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 215: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_32 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_33 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_16 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_32 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_33 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_17 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_17[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbb3e563a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 8.3060 - decoder_loss: 25.9992 - encoder_loss: 5.6282 - classifier_loss: 0.7787 - decoder_accuracy: 0.0323 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5667\n",
            "F1-score is computed based on binary\n",
            "(loss: 8.305985450744629, accuracy: 0.5666666626930237)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.53      0.55        15\n",
            "         1.0       0.56      0.60      0.58        15\n",
            "\n",
            "    accuracy                           0.57        30\n",
            "   macro avg       0.57      0.57      0.57        30\n",
            "weighted avg       0.57      0.57      0.57        30\n",
            "\n",
            "Accuracy: 0.5666666626930237\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5666666626930237\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=1, \n",
        "                    data_format='NCTD', # for EEGNet and DeepConvNet (our paper and the original paper set data_format='NDCT')\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')"
      ],
      "metadata": {
        "id": "iOYB3YKBU_bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "X_train, y_train = loader.load_train_set(fold=1)\n",
        "X_val, y_val = loader.load_val_set(fold=1)\n",
        "X_test, y_test = loader.load_test_set(fold=1)\n",
        "\n",
        "from min2net.model import EEGNet\n",
        "# (our paper and the original paper set input_shape=(1,20,400), data_format='channels_first')\n",
        "model = EEGNet(input_shape=(20,400,1), num_class=2, dropout_rate=0.25, shuffle=True, data_format='channels_last')\n",
        "model.fit(X_train, y_train, X_val, y_val)\n",
        "Y, evaluation = model.predict(X_test, y_test)"
      ],
      "metadata": {
        "id": "V5kWzJ9QX19j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "X_train, y_train = loader.load_train_set(fold=1)\n",
        "X_val, y_val = loader.load_val_set(fold=1)\n",
        "X_test, y_test = loader.load_test_set(fold=1)\n",
        "\n",
        "from min2net.model import DeepConvNet\n",
        "# (our paper and the original paper set input_shape=(1,20,400), data_format='channels_first')\n",
        "model = DeepConvNet(input_shape=(20,400,1), num_class=2, dropout_rate=0.25, shuffle=True, data_format='channels_last')\n",
        "model.fit(X_train, y_train, X_val, y_val)\n",
        "Y, evaluation = model.predict(X_test, y_test)"
      ],
      "metadata": {
        "id": "5Z3ugkEfUPIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this model requires spectral-spatial-mapping\n",
        "# see https://min2net.github.io/docs/preprocessing/BCIC2a/#spectral-spatial-mapping\n",
        "\n",
        "# generate fake data\n",
        "import numpy as np\n",
        "X_train = np.random.rand(100,20,28,28,1)\n",
        "y_train = np.concatenate(([0]*50, [1]*50))\n",
        "X_val = np.random.rand(40,20,28,28,1)\n",
        "y_val = np.concatenate(([0]*20, [1]*20))\n",
        "X_test = np.random.rand(40,20,28,28,1)\n",
        "y_test = np.concatenate(([0]*20, [1]*20))\n",
        "\n",
        "from min2net.model import SpectralSpatialCNN\n",
        "model = SpectralSpatialCNN(input_shape=(28, 28, 1), num_class=2, epochs=10, dropout_rate=0.25, shuffle=True)\n",
        "model.fit(X_train, y_train, X_val, y_val)\n",
        "Y, evaluation = model.predict(X_test, y_test)"
      ],
      "metadata": {
        "id": "qxIdFYxTadhd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}