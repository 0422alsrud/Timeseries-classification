{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0422alsrud/Timeseries-classification/blob/main/4_3___MIN2Net_MI_EEG_SMRBCI_dependent_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "TyuGaaagIg8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz\n",
        "!tar xvfz Python-3.6.9.tgz\n",
        "!Python-3.6.9/configure\n",
        "!make\n",
        "!sudo make install\n",
        "\n",
        "# !pip install Python==3.6.9\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!which python\n",
        "!python --version\n",
        "\n",
        "#구글 코랩에 디폴트로 깔려 있는 python 3.6과 매칭이 되는 미니콘다를 깔아야 함\n",
        "#그 미니콘다 버전은 4.5.4\n",
        "!echo $PYTHONPATH\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0sFW9BeRY_C",
        "outputId": "be452f64-4934-4eb8-fa91-96fe60284982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_8.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_9.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/johab.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/koi8_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/koi8_t.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/koi8_u.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/kz1048.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/latin_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_arabic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_centeuro.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_croatian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_cyrillic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_farsi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_greek.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_iceland.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_latin2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_roman.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_romanian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_turkish.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mbcs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/oem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/palmos.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/ptcp154.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/punycode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/quopri_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/raw_unicode_escape.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/rot_13.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/shift_jis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/shift_jis_2004.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/shift_jisx0213.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/tis_620.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/undefined.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/unicode_escape.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/unicode_internal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_16.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_16_be.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_16_le.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_32_be.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_32_le.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_7.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_8.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_8_sig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/uu_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/zlib_codec.py'...\n",
            "Listing '/usr/local/lib/python3.6/ensurepip'...\n",
            "Compiling '/usr/local/lib/python3.6/ensurepip/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ensurepip/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/ensurepip/_bundled'...\n",
            "Compiling '/usr/local/lib/python3.6/ensurepip/_uninstall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/enum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/filecmp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/fileinput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/fnmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/formatter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/fractions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ftplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/functools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/genericpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/getpass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/gettext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/glob.py'...\n",
            "Compiling '/usr/local/lib/python3.6/gzip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/hashlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/heapq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/hmac.py'...\n",
            "Listing '/usr/local/lib/python3.6/html'...\n",
            "Compiling '/usr/local/lib/python3.6/html/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/html/entities.py'...\n",
            "Compiling '/usr/local/lib/python3.6/html/parser.py'...\n",
            "Listing '/usr/local/lib/python3.6/http'...\n",
            "Compiling '/usr/local/lib/python3.6/http/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/client.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/cookiejar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/cookies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/server.py'...\n",
            "Listing '/usr/local/lib/python3.6/idlelib'...\n",
            "Listing '/usr/local/lib/python3.6/idlelib/Icons'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/_pyclbr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/autocomplete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/autocomplete_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/autoexpand.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/browser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/calltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/calltip_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/codecontext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/colorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/config_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/configdialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugger.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugger_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugobj.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugobj_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/delegator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/dynoption.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/editor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/grep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/help_about.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/history.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/hyperparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle.py'...\n",
            "Listing '/usr/local/lib/python3.6/idlelib/idle_test'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/htest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/mock_idle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/mock_tk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/template.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_autocomplete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_autocomplete_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_autoexpand.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_browser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_calltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_calltip_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_codecontext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_colorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_config_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_configdialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugger.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugger_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugobj.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugobj_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_delegator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_editmenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_editor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_grep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_help_about.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_history.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_hyperparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_iomenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_macosx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_mainmenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_multicall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_outwin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_paragraph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_parenmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_pathbrowser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_percolator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_pyparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_pyshell.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_query.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_redirector.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_replace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_rpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_rstrip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_run.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_runscript.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_scrolledlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_searchbase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_searchengine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_squeezer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_stackviewer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_statusbar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_textview.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_tooltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_undo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_warning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_window.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_zoomheight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/iomenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/macosx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/mainmenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/multicall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/outwin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/paragraph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/parenmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/pathbrowser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/percolator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/pyparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/pyshell.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/query.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/redirector.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/replace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/rpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/rstrip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/run.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/runscript.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/scrolledlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/searchbase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/searchengine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/squeezer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/stackviewer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/statusbar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/textview.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/tooltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/undo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/window.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/zoomheight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/zzdummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/imaplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/imghdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/imp.py'...\n",
            "Listing '/usr/local/lib/python3.6/importlib'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/_bootstrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/_bootstrap_external.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/machinery.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/inspect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ipaddress.py'...\n",
            "Listing '/usr/local/lib/python3.6/json'...\n",
            "Compiling '/usr/local/lib/python3.6/json/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/encoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/scanner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/tool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/keyword.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/btm_matcher.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/btm_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixer_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixer_util.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/fixes'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_apply.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_asserts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_basestring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_buffer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_except.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_exec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_execfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_exitfunc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_filter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_funcattrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_future.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_getcwdu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_has_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_idioms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_import.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_imports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_imports2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_input.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_intern.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_isinstance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_itertools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_itertools_imports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_long.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_map.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_metaclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_methodattrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_ne.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_next.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_nonzero.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_numliterals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_operator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_paren.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_print.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_raise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_raw_input.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_reduce.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_reload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_renames.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_repr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_set_literal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_standarderror.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_sys_exc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_throw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_tuple_params.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_urllib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_ws_comma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_xrange.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_xreadlines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_zip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/patcomp.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/pgen2'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/conv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/driver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/grammar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/literals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/parse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/pgen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/token.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/tokenize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pygram.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pytree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/refactor.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests/data'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests/data/fixers'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests/data/fixers/myfixes'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/pytree_idempotency.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_all_fixers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_fixers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_pytree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_refactor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/linecache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/locale.py'...\n",
            "Listing '/usr/local/lib/python3.6/logging'...\n",
            "Compiling '/usr/local/lib/python3.6/logging/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/logging/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/logging/handlers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lzma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/macpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/macurl2path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/mailbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/mailcap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/mimetypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/modulefinder.py'...\n",
            "Listing '/usr/local/lib/python3.6/multiprocessing'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/context.py'...\n",
            "Listing '/usr/local/lib/python3.6/multiprocessing/dummy'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/dummy/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/dummy/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/forkserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/heap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/managers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/pool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_fork.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_forkserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_spawn_posix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_spawn_win32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/process.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/queues.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/reduction.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/resource_sharer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/semaphore_tracker.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/sharedctypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/synchronize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/netrc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/nntplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ntpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/nturl2path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/numbers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/opcode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/operator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/optparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/os.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pathlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pickletools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pipes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pkgutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/platform.py'...\n",
            "Compiling '/usr/local/lib/python3.6/plistlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/poplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/posixpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/profile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/py_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pyclbr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pydoc.py'...\n",
            "Listing '/usr/local/lib/python3.6/pydoc_data'...\n",
            "Compiling '/usr/local/lib/python3.6/pydoc_data/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pydoc_data/topics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/queue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/quopri.py'...\n",
            "Compiling '/usr/local/lib/python3.6/random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/re.py'...\n",
            "Compiling '/usr/local/lib/python3.6/reprlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/rlcompleter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/runpy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sched.py'...\n",
            "Compiling '/usr/local/lib/python3.6/secrets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/selectors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/shelve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/shlex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/shutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/signal.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages'...\n",
            "Compiling '/usr/local/lib/python3.6/site.py'...\n",
            "Compiling '/usr/local/lib/python3.6/smtpd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/smtplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sndhdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/socket.py'...\n",
            "Compiling '/usr/local/lib/python3.6/socketserver.py'...\n",
            "Listing '/usr/local/lib/python3.6/sqlite3'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/dbapi2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/dump.py'...\n",
            "Listing '/usr/local/lib/python3.6/sqlite3/test'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/dbapi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/dump.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/factory.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/hooks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/transactions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/userfunctions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sre_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sre_constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sre_parse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ssl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/stat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/statistics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/string.py'...\n",
            "Compiling '/usr/local/lib/python3.6/stringprep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/struct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sunau.py'...\n",
            "Compiling '/usr/local/lib/python3.6/symbol.py'...\n",
            "Compiling '/usr/local/lib/python3.6/symtable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tabnanny.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tarfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/telnetlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tempfile.py'...\n",
            "Listing '/usr/local/lib/python3.6/test'...\n",
            "Compiling '/usr/local/lib/python3.6/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/_test_multiprocessing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ann_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ann_module2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ann_module3.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/audiodata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/audiotests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/autotest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/bisect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/bytecode_helper.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/capath'...\n",
            "Listing '/usr/local/lib/python3.6/test/cjkencodings'...\n",
            "Compiling '/usr/local/lib/python3.6/test/coding20731.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/curses_tests.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/data'...\n",
            "Compiling '/usr/local/lib/python3.6/test/datetimetester.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/decimaltestdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dis_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/doctest_aliases.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/double_const.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/dtracedata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/call_stack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/gc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/instance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/line.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/eintrdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/eintrdata/eintr_tester.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/encoded_modules'...\n",
            "Compiling '/usr/local/lib/python3.6/test/encoded_modules/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/encoded_modules/module_iso_8859_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/encoded_modules/module_koi8_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/final_a.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/final_b.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/fork_wait.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/future_test1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/future_test2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/gdb_sample.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/imghdrdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/imp_dummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/inspect_fodder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/inspect_fodder2.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/libregrtest'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/cmdline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/refleak.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/runtest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/runtest_mp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/save_env.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/list_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/lock_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/make_ssl_certs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mapping_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/memory_watchdog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mock_socket.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mod_generics_cache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mp_fork_bomb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mp_preload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/multibytecodec_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/outstanding_bugs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pickletester.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/profilee.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pyclbr_input.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pydoc_mod.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pydocfodder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pystone.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pythoninfo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/re_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/regrtest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/relimport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/reperf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sample_doctest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sample_doctest_no_docstrings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sample_doctest_no_doctests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/seq_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/signalinterproctester.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/sndhdrdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sortperf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ssl_servers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ssltests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/string_tests.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/subprocessdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/fd_status.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/input_reader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/qcat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/qgrep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/sigchild_ignore.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/support'...\n",
            "Compiling '/usr/local/lib/python3.6/test/support/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/support/script_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/support/testresult.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test___all__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test___future__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test__locale.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test__opcode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test__osx_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_abstract_numbers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_aifc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_argparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_array.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asdl_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncgen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asynchat.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_asyncio'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/echo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/echo2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/echo3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_base_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_locks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_pep492.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_proactor_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_queues.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_selector_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_sslproto.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_streams.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_tasks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_transports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_unix_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_windows_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_windows_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncore.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_atexit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_audioop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_augassign.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_base64.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_baseexception.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bigaddrspace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bigmem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_binascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_binhex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_binop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bisect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_buffer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bufio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_builtin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bytes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bz2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_calendar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_call.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_capi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cgi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cgitb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_charmapcodec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_class.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmd_line.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmd_line_script.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_code.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_code_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codeccallbacks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_cn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_hk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_iso2022.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_tw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_cn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_hk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_tw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codeop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_collections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_colorsys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_compare.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_compileall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_complex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_concurrent_futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_configparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_contains.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_contextlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_copy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_copyreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_coroutines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cprofile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_crashers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_crypt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_csv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ctypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_curses.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_datetime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm_dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm_gnu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm_ndbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_decimal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_decorators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_defaultdict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_deque.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_descr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_descrtut.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_devpoll.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dict_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dictcomps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dictviews.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_difflib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_distutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_doctest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_doctest2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_docxmlrpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dtrace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dummy_thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dummy_threading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dynamic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dynamicclassattribute.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_eintr.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_email'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_email/data'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test__encoded_words.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test__header_value_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_asian_codecs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_contentmanager.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_defect_handling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_email.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_headerregistry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_inversion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_message.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_pickleable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_policy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/torture_test.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ensurepip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_enum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_enumerate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_eof.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_epoll.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_errno.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_exception_hierarchy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_exception_variations.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_extcall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_faulthandler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fcntl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_file_eintr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_filecmp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fileinput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fileio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_finalization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_float.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_flufl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fnmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fork1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_format.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fractions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_frame.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ftplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_funcattrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_functools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future4.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future5.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_generator_stop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_generators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_genericpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_genexps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_getargs2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_getpass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gettext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_glob.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_global.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_grammar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_grp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gzip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_hash.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_hashlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_heapq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_hmac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_html.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_htmlparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_http_cookiejar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_http_cookies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_httplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_httpservers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_idle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_imaplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_imghdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_imp.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/circular_imports'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/basic2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/indirect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/rebinding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/rebinding2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpackage.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpkg'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpkg/subpackage2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpkg/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/util.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/package'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package/submodule.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/package2'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package2/submodule1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package2/submodule2.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/abc.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/builtin'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/test_loader.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/extension'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_case_sensitivity.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_path_hook.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/frozen'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/test_loader.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/import_'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test___loader__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test___package__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_caching.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_fromlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_meta_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_packages.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_relative_imports.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions/foo/one.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions/foo/two.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/module_and_namespace_package'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/module_and_namespace_package/a_test'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/module_and_namespace_package/a_test.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg/foo/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg/foo/one.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion1'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion1/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion1/foo/one.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion2'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion2/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion2/foo/two.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1/parent'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1/parent/child'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1/parent/child/one.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2/parent'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2/parent/child'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2/parent/child/two.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3/parent'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3/parent/child'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3/parent/child/three.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/source'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_case_sensitivity.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_file_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_path_hook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_source_encoding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_lazy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_locks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_namespace_pkgs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_spec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_windows.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_inspect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_int.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_int_literal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ioctl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ipaddress.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_isinstance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_iter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_iterlen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_itertools.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_json'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_decode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_default.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_dump.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_encode_basestring_ascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_enum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_fail.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_float.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_indent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_pass1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_pass2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_pass3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_recursion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_scanstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_separators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_speedups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_tool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_keyword.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_keywordonlyarg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_kqueue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_largefile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_lib2to3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_linecache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_list.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_listcomps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_locale.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_logging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_long.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_longexp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_lzma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_macpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_macurl2path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mailbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mailcap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_marshal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_math.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_memoryio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_memoryview.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_metaclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mimetypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_minidom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mmap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_modulefinder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_msilib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multibytecodec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_fork.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_forkserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_main_handling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_netrc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_nis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_nntplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_normalization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ntpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_numeric_tower.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_opcodes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_openpty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_operator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_optparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ordered_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_os.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ossaudiodev.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_osx_env.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pathlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_peepholer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pickletools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pipes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pkg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pkgimport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pkgutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_platform.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_plistlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_poll.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_popen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_poplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_posix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_posixpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pow.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_print.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_profile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_property.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pulldom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pwd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_py_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pyclbr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pydoc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pyexpat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_queue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_quopri.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_raise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_range.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_re.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_readline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_regrtest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_repl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_reprlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_resource.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_richcmp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_rlcompleter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_robotparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_runpy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sched.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_scope.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_script_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_secrets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_select.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_selectors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_set.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_setcomps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_shelve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_shlex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_shutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_signal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_site.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_slice.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_smtpd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_smtplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_smtpnet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sndhdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_socket.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_socketserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sort.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_source_encoding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_spwd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sqlite.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ssl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_startfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_stat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_statistics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_strftime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_string.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_string_literals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_stringprep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_strptime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_strtod.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_struct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_structmembers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_structseq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_subclassinit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sunau.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sundry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_super.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_symbol.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_symtable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_syntax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sys_setprofile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sys_settrace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_syslog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tarfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tcl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_telnetlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tempfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_textwrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threaded_import.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threadedtempfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threading_local.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threadsignals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_time.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_timeit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_timeout.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tokenize.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_tools'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_fixcid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_gprof2html.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_i18n.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_md5sum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_pdeps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_pindent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_reindent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_sundry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_unparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_trace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_traceback.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tracemalloc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ttk_guionly.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ttk_textonly.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tuple.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_turtle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_typechecks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_typing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ucn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unary.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode_file_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode_identifiers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicodedata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unittest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_univnewlines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unpack_ex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib2_localnet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib2net.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib_response.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllibnet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urlparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_userdict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_userlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_userstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_utf8source.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_uu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_uuid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_venv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wait3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wait4.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_warnings'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_warnings/data'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/data/import_warning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/data/stacklevel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wave.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_weakref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_weakset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_webbrowser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_winconsoleio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_winreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_winsound.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_with.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wsgiref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xdrlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xml_dom_minicompat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xml_etree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xml_etree_c.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xmlrpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xmlrpc_net.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_yield_from.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipapp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipfile64.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipimport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipimport_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/testcodec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/tf_inherit_check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/threaded_import_hangers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/time_hashlib.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/tracedmodules'...\n",
            "Compiling '/usr/local/lib/python3.6/test/tracedmodules/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/tracedmodules/testmod.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/win_console_handler.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/xmltestdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/xmltests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/textwrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/this.py'...\n",
            "Compiling '/usr/local/lib/python3.6/threading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/timeit.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/colorchooser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/commondialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/dialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/dnd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/filedialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/font.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/messagebox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/scrolledtext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/simpledialog.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter/test'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/runtktests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/support.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter/test/test_tkinter'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_font.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_geometry_managers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_images.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_loadtk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_misc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_variables.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_widgets.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter/test/test_ttk'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_extensions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_style.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_widgets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/widget_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/tix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/ttk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/token.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tokenize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/trace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/traceback.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tracemalloc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtle.py'...\n",
            "Listing '/usr/local/lib/python3.6/turtledemo'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/bytedesign.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/chaos.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/clock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/colormixer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/forest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/fractalcurves.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/lindenmayer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/minimal_hanoi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/nim.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/paint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/peace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/penrose.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/planet_and_moon.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/rosette.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/round_dance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/sorting_animate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/two_canvases.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/yinyang.py'...\n",
            "Compiling '/usr/local/lib/python3.6/types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/typing.py'...\n",
            "Listing '/usr/local/lib/python3.6/unittest'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/case.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/mock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/result.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/runner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/signals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/suite.py'...\n",
            "Listing '/usr/local/lib/python3.6/unittest/test'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/_test_warnings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/dummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_assertions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_break.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_case.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_discovery.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_functiontestcase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_program.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_result.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_runner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_setups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_skipping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_suite.py'...\n",
            "Listing '/usr/local/lib/python3.6/unittest/test/testmock'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testcallable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testhelpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testmagicmethods.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testmock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testpatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testsentinel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testwith.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/util.py'...\n",
            "Listing '/usr/local/lib/python3.6/urllib'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/error.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/parse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/request.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/response.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/robotparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/uu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/uuid.py'...\n",
            "Listing '/usr/local/lib/python3.6/venv'...\n",
            "Compiling '/usr/local/lib/python3.6/venv/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/venv/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/venv/scripts'...\n",
            "Listing '/usr/local/lib/python3.6/venv/scripts/common'...\n",
            "Listing '/usr/local/lib/python3.6/venv/scripts/posix'...\n",
            "Compiling '/usr/local/lib/python3.6/warnings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wave.py'...\n",
            "Compiling '/usr/local/lib/python3.6/weakref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/webbrowser.py'...\n",
            "Listing '/usr/local/lib/python3.6/wsgiref'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/handlers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/simple_server.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/validate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xdrlib.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/dom'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/NodeFilter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/domreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/expatbuilder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/minicompat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/minidom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/pulldom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/xmlbuilder.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/etree'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/ElementInclude.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/ElementPath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/ElementTree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/cElementTree.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/parsers'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/parsers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/parsers/expat.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/sax'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/expatreader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/handler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/saxutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/xmlreader.py'...\n",
            "Listing '/usr/local/lib/python3.6/xmlrpc'...\n",
            "Compiling '/usr/local/lib/python3.6/xmlrpc/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xmlrpc/client.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xmlrpc/server.py'...\n",
            "Compiling '/usr/local/lib/python3.6/zipapp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/zipfile.py'...\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -Wi -O /usr/local/lib/python3.6/compileall.py \\\n",
            "\t-d /usr/local/lib/python3.6 -f \\\n",
            "\t-x 'bad_coding|badsyntax|site-packages|lib2to3/tests/data' \\\n",
            "\t/usr/local/lib/python3.6\n",
            "Listing '/usr/local/lib/python3.6'...\n",
            "Compiling '/usr/local/lib/python3.6/__future__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/__phello__.foo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_bootlocale.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_collections_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_compat_pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_compression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_dummy_thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_markupbase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_osx_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_pydecimal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_pyio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_sitebuiltins.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_strptime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_sysconfigdata_m_linux_x86_64-linux-gnu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_threading_local.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_weakrefset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/aifc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/antigravity.py'...\n",
            "Compiling '/usr/local/lib/python3.6/argparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asynchat.py'...\n",
            "Listing '/usr/local/lib/python3.6/asyncio'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/base_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/base_futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/base_subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/base_tasks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/coroutines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/locks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/log.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/proactor_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/protocols.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/queues.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/selector_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/sslproto.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/streams.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/tasks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/transports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/unix_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/windows_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/windows_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncore.py'...\n",
            "Compiling '/usr/local/lib/python3.6/base64.py'...\n",
            "Compiling '/usr/local/lib/python3.6/bdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/binhex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/bisect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/bz2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/cProfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/calendar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/cgi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/cgitb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/chunk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/code.py'...\n",
            "Compiling '/usr/local/lib/python3.6/codecs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/codeop.py'...\n",
            "Listing '/usr/local/lib/python3.6/collections'...\n",
            "Compiling '/usr/local/lib/python3.6/collections/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/collections/abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/colorsys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/compileall.py'...\n",
            "Listing '/usr/local/lib/python3.6/concurrent'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/concurrent/futures'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/futures/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/futures/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/futures/process.py'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/futures/thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/configparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/contextlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/copy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/copyreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/crypt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/csv.py'...\n",
            "Listing '/usr/local/lib/python3.6/ctypes'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/_endian.py'...\n",
            "Listing '/usr/local/lib/python3.6/ctypes/macholib'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/macholib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/macholib/dyld.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/macholib/dylib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/macholib/framework.py'...\n",
            "Listing '/usr/local/lib/python3.6/ctypes/test'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_anon.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_array_in_pointer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_arrays.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_as_parameter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_bitfields.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_buffers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_bytes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_byteswap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_callbacks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_cast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_cfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_checkretval.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_delattr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_errno.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_find.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_frombuffer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_funcptr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_incomplete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_init.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_internals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_keeprefs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_libc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_loading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_macholib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_memfunctions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_numbers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_objects.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_parameters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_pep3118.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_pickling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_pointers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_prototypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_python_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_random_things.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_refcounts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_repr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_returnfuncptrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_simplesubclasses.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_sizes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_slicing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_stringptr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_strings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_struct_fields.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_unaligned_structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_values.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_varsize_struct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_win32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_wintypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/wintypes.py'...\n",
            "Listing '/usr/local/lib/python3.6/curses'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/ascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/has_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/panel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/textpad.py'...\n",
            "Compiling '/usr/local/lib/python3.6/datetime.py'...\n",
            "Listing '/usr/local/lib/python3.6/dbm'...\n",
            "Compiling '/usr/local/lib/python3.6/dbm/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dbm/dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dbm/gnu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dbm/ndbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/decimal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/difflib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dis.py'...\n",
            "Listing '/usr/local/lib/python3.6/dist-packages'...\n",
            "Listing '/usr/local/lib/python3.6/distutils'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/_msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/archive_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/bcppcompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/ccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/cmd.py'...\n",
            "Listing '/usr/local/lib/python3.6/distutils/command'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist_dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist_msi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist_rpm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist_wininst.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build_py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/clean.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_egg_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_lib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/register.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/upload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/cygwinccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/debug.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/dep_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/dir_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/dist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/errors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/extension.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/fancy_getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/file_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/log.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/msvc9compiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/sysconfig.py'...\n",
            "Listing '/usr/local/lib/python3.6/distutils/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_archive_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist_dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist_msi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist_rpm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist_wininst.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build_py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_clean.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_config_cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_cygwinccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_dep_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_dir_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_dist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_extension.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_file_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install_headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install_lib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_log.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_msvc9compiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_register.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_text_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_unixccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_upload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_versionpredicate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/text_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/unixccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/versionpredicate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/doctest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dummy_threading.py'...\n",
            "Listing '/usr/local/lib/python3.6/email'...\n",
            "Compiling '/usr/local/lib/python3.6/email/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/_encoded_words.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/_header_value_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/_parseaddr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/_policybase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/base64mime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/charset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/contentmanager.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/encoders.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/errors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/feedparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/header.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/headerregistry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/iterators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/message.py'...\n",
            "Listing '/usr/local/lib/python3.6/email/mime'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/application.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/audio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/image.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/message.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/multipart.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/nonmultipart.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/policy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/quoprimime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/encodings'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/aliases.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/ascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/base64_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/big5.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/big5hkscs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/bz2_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/charmap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp037.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1006.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1026.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1125.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1140.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1250.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1251.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1252.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1253.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1254.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1255.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1256.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1257.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1258.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp273.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp424.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp437.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp500.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp65001.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp720.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp737.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp775.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp850.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp852.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp855.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp856.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp857.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp858.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp860.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp861.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp862.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp863.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp864.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp865.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp866.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp869.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp874.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp875.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp932.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp949.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp950.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/euc_jis_2004.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/euc_jisx0213.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/euc_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/euc_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/gb18030.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/gb2312.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/gbk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/hex_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/hp_roman8.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/hz.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/idna.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_2004.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_10.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_11.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_13.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_14.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_15.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_16.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_4.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_5.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_6.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_7.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_8.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_9.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/johab.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/koi8_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/koi8_t.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/koi8_u.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/kz1048.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/latin_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_arabic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_centeuro.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_croatian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_cyrillic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_farsi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_greek.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_iceland.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_latin2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_roman.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_romanian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_turkish.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mbcs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/oem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/palmos.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/ptcp154.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/punycode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/quopri_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/raw_unicode_escape.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/rot_13.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/shift_jis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/shift_jis_2004.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/shift_jisx0213.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/tis_620.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/undefined.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/unicode_escape.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/unicode_internal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_16.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_16_be.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_16_le.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_32_be.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_32_le.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_7.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_8.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_8_sig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/uu_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/zlib_codec.py'...\n",
            "Listing '/usr/local/lib/python3.6/ensurepip'...\n",
            "Compiling '/usr/local/lib/python3.6/ensurepip/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ensurepip/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/ensurepip/_bundled'...\n",
            "Compiling '/usr/local/lib/python3.6/ensurepip/_uninstall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/enum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/filecmp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/fileinput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/fnmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/formatter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/fractions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ftplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/functools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/genericpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/getpass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/gettext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/glob.py'...\n",
            "Compiling '/usr/local/lib/python3.6/gzip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/hashlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/heapq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/hmac.py'...\n",
            "Listing '/usr/local/lib/python3.6/html'...\n",
            "Compiling '/usr/local/lib/python3.6/html/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/html/entities.py'...\n",
            "Compiling '/usr/local/lib/python3.6/html/parser.py'...\n",
            "Listing '/usr/local/lib/python3.6/http'...\n",
            "Compiling '/usr/local/lib/python3.6/http/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/client.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/cookiejar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/cookies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/server.py'...\n",
            "Listing '/usr/local/lib/python3.6/idlelib'...\n",
            "Listing '/usr/local/lib/python3.6/idlelib/Icons'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/_pyclbr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/autocomplete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/autocomplete_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/autoexpand.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/browser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/calltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/calltip_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/codecontext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/colorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/config_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/configdialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugger.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugger_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugobj.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugobj_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/delegator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/dynoption.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/editor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/grep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/help_about.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/history.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/hyperparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle.py'...\n",
            "Listing '/usr/local/lib/python3.6/idlelib/idle_test'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/htest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/mock_idle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/mock_tk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/template.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_autocomplete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_autocomplete_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_autoexpand.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_browser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_calltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_calltip_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_codecontext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_colorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_config_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_configdialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugger.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugger_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugobj.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugobj_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_delegator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_editmenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_editor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_grep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_help_about.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_history.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_hyperparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_iomenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_macosx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_mainmenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_multicall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_outwin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_paragraph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_parenmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_pathbrowser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_percolator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_pyparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_pyshell.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_query.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_redirector.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_replace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_rpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_rstrip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_run.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_runscript.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_scrolledlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_searchbase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_searchengine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_squeezer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_stackviewer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_statusbar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_textview.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_tooltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_undo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_warning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_window.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_zoomheight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/iomenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/macosx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/mainmenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/multicall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/outwin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/paragraph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/parenmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/pathbrowser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/percolator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/pyparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/pyshell.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/query.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/redirector.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/replace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/rpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/rstrip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/run.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/runscript.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/scrolledlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/searchbase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/searchengine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/squeezer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/stackviewer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/statusbar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/textview.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/tooltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/undo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/window.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/zoomheight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/zzdummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/imaplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/imghdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/imp.py'...\n",
            "Listing '/usr/local/lib/python3.6/importlib'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/_bootstrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/_bootstrap_external.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/machinery.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/inspect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ipaddress.py'...\n",
            "Listing '/usr/local/lib/python3.6/json'...\n",
            "Compiling '/usr/local/lib/python3.6/json/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/encoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/scanner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/tool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/keyword.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/btm_matcher.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/btm_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixer_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixer_util.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/fixes'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_apply.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_asserts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_basestring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_buffer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_except.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_exec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_execfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_exitfunc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_filter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_funcattrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_future.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_getcwdu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_has_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_idioms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_import.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_imports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_imports2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_input.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_intern.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_isinstance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_itertools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_itertools_imports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_long.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_map.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_metaclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_methodattrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_ne.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_next.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_nonzero.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_numliterals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_operator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_paren.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_print.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_raise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_raw_input.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_reduce.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_reload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_renames.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_repr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_set_literal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_standarderror.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_sys_exc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_throw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_tuple_params.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_urllib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_ws_comma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_xrange.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_xreadlines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_zip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/patcomp.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/pgen2'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/conv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/driver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/grammar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/literals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/parse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/pgen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/token.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/tokenize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pygram.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pytree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/refactor.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests/data'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests/data/fixers'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests/data/fixers/myfixes'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/pytree_idempotency.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_all_fixers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_fixers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_pytree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_refactor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/linecache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/locale.py'...\n",
            "Listing '/usr/local/lib/python3.6/logging'...\n",
            "Compiling '/usr/local/lib/python3.6/logging/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/logging/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/logging/handlers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lzma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/macpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/macurl2path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/mailbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/mailcap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/mimetypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/modulefinder.py'...\n",
            "Listing '/usr/local/lib/python3.6/multiprocessing'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/context.py'...\n",
            "Listing '/usr/local/lib/python3.6/multiprocessing/dummy'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/dummy/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/dummy/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/forkserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/heap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/managers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/pool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_fork.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_forkserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_spawn_posix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_spawn_win32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/process.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/queues.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/reduction.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/resource_sharer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/semaphore_tracker.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/sharedctypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/synchronize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/netrc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/nntplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ntpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/nturl2path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/numbers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/opcode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/operator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/optparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/os.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pathlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pickletools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pipes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pkgutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/platform.py'...\n",
            "Compiling '/usr/local/lib/python3.6/plistlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/poplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/posixpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/profile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/py_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pyclbr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pydoc.py'...\n",
            "Listing '/usr/local/lib/python3.6/pydoc_data'...\n",
            "Compiling '/usr/local/lib/python3.6/pydoc_data/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pydoc_data/topics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/queue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/quopri.py'...\n",
            "Compiling '/usr/local/lib/python3.6/random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/re.py'...\n",
            "Compiling '/usr/local/lib/python3.6/reprlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/rlcompleter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/runpy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sched.py'...\n",
            "Compiling '/usr/local/lib/python3.6/secrets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/selectors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/shelve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/shlex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/shutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/signal.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages'...\n",
            "Compiling '/usr/local/lib/python3.6/site.py'...\n",
            "Compiling '/usr/local/lib/python3.6/smtpd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/smtplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sndhdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/socket.py'...\n",
            "Compiling '/usr/local/lib/python3.6/socketserver.py'...\n",
            "Listing '/usr/local/lib/python3.6/sqlite3'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/dbapi2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/dump.py'...\n",
            "Listing '/usr/local/lib/python3.6/sqlite3/test'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/dbapi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/dump.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/factory.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/hooks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/transactions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/userfunctions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sre_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sre_constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sre_parse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ssl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/stat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/statistics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/string.py'...\n",
            "Compiling '/usr/local/lib/python3.6/stringprep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/struct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sunau.py'...\n",
            "Compiling '/usr/local/lib/python3.6/symbol.py'...\n",
            "Compiling '/usr/local/lib/python3.6/symtable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tabnanny.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tarfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/telnetlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tempfile.py'...\n",
            "Listing '/usr/local/lib/python3.6/test'...\n",
            "Compiling '/usr/local/lib/python3.6/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/_test_multiprocessing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ann_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ann_module2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ann_module3.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/audiodata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/audiotests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/autotest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/bisect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/bytecode_helper.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/capath'...\n",
            "Listing '/usr/local/lib/python3.6/test/cjkencodings'...\n",
            "Compiling '/usr/local/lib/python3.6/test/coding20731.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/curses_tests.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/data'...\n",
            "Compiling '/usr/local/lib/python3.6/test/datetimetester.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/decimaltestdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dis_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/doctest_aliases.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/double_const.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/dtracedata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/call_stack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/gc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/instance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/line.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/eintrdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/eintrdata/eintr_tester.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/encoded_modules'...\n",
            "Compiling '/usr/local/lib/python3.6/test/encoded_modules/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/encoded_modules/module_iso_8859_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/encoded_modules/module_koi8_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/final_a.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/final_b.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/fork_wait.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/future_test1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/future_test2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/gdb_sample.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/imghdrdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/imp_dummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/inspect_fodder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/inspect_fodder2.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/libregrtest'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/cmdline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/refleak.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/runtest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/runtest_mp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/save_env.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/list_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/lock_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/make_ssl_certs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mapping_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/memory_watchdog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mock_socket.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mod_generics_cache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mp_fork_bomb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mp_preload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/multibytecodec_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/outstanding_bugs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pickletester.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/profilee.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pyclbr_input.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pydoc_mod.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pydocfodder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pystone.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pythoninfo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/re_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/regrtest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/relimport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/reperf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sample_doctest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sample_doctest_no_docstrings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sample_doctest_no_doctests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/seq_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/signalinterproctester.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/sndhdrdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sortperf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ssl_servers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ssltests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/string_tests.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/subprocessdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/fd_status.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/input_reader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/qcat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/qgrep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/sigchild_ignore.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/support'...\n",
            "Compiling '/usr/local/lib/python3.6/test/support/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/support/script_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/support/testresult.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test___all__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test___future__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test__locale.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test__opcode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test__osx_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_abstract_numbers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_aifc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_argparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_array.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asdl_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncgen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asynchat.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_asyncio'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/echo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/echo2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/echo3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_base_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_locks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_pep492.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_proactor_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_queues.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_selector_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_sslproto.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_streams.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_tasks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_transports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_unix_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_windows_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_windows_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncore.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_atexit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_audioop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_augassign.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_base64.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_baseexception.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bigaddrspace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bigmem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_binascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_binhex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_binop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bisect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_buffer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bufio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_builtin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bytes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bz2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_calendar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_call.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_capi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cgi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cgitb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_charmapcodec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_class.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmd_line.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmd_line_script.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_code.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_code_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codeccallbacks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_cn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_hk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_iso2022.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_tw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_cn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_hk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_tw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codeop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_collections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_colorsys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_compare.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_compileall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_complex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_concurrent_futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_configparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_contains.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_contextlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_copy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_copyreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_coroutines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cprofile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_crashers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_crypt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_csv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ctypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_curses.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_datetime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm_dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm_gnu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm_ndbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_decimal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_decorators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_defaultdict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_deque.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_descr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_descrtut.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_devpoll.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dict_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dictcomps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dictviews.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_difflib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_distutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_doctest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_doctest2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_docxmlrpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dtrace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dummy_thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dummy_threading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dynamic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dynamicclassattribute.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_eintr.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_email'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_email/data'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test__encoded_words.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test__header_value_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_asian_codecs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_contentmanager.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_defect_handling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_email.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_headerregistry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_inversion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_message.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_pickleable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_policy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/torture_test.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ensurepip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_enum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_enumerate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_eof.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_epoll.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_errno.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_exception_hierarchy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_exception_variations.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_extcall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_faulthandler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fcntl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_file_eintr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_filecmp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fileinput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fileio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_finalization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_float.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_flufl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fnmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fork1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_format.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fractions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_frame.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ftplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_funcattrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_functools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future4.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future5.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_generator_stop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_generators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_genericpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_genexps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_getargs2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_getpass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gettext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_glob.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_global.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_grammar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_grp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gzip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_hash.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_hashlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_heapq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_hmac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_html.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_htmlparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_http_cookiejar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_http_cookies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_httplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_httpservers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_idle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_imaplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_imghdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_imp.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/circular_imports'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/basic2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/indirect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/rebinding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/rebinding2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpackage.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpkg'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpkg/subpackage2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpkg/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/util.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/package'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package/submodule.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/package2'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package2/submodule1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package2/submodule2.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/abc.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/builtin'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/test_loader.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/extension'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_case_sensitivity.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_path_hook.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/frozen'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/test_loader.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/import_'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test___loader__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test___package__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_caching.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_fromlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_meta_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_packages.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_relative_imports.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions/foo/one.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions/foo/two.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/module_and_namespace_package'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/module_and_namespace_package/a_test'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/module_and_namespace_package/a_test.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg/foo/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg/foo/one.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion1'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion1/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion1/foo/one.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion2'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion2/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion2/foo/two.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1/parent'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1/parent/child'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1/parent/child/one.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2/parent'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2/parent/child'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2/parent/child/two.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3/parent'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3/parent/child'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3/parent/child/three.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/source'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_case_sensitivity.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_file_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_path_hook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_source_encoding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_lazy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_locks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_namespace_pkgs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_spec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_windows.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_inspect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_int.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_int_literal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ioctl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ipaddress.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_isinstance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_iter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_iterlen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_itertools.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_json'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_decode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_default.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_dump.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_encode_basestring_ascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_enum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_fail.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_float.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_indent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_pass1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_pass2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_pass3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_recursion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_scanstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_separators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_speedups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_tool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_keyword.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_keywordonlyarg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_kqueue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_largefile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_lib2to3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_linecache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_list.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_listcomps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_locale.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_logging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_long.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_longexp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_lzma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_macpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_macurl2path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mailbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mailcap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_marshal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_math.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_memoryio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_memoryview.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_metaclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mimetypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_minidom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mmap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_modulefinder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_msilib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multibytecodec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_fork.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_forkserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_main_handling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_netrc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_nis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_nntplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_normalization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ntpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_numeric_tower.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_opcodes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_openpty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_operator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_optparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ordered_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_os.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ossaudiodev.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_osx_env.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pathlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_peepholer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pickletools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pipes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pkg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pkgimport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pkgutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_platform.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_plistlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_poll.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_popen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_poplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_posix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_posixpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pow.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_print.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_profile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_property.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pulldom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pwd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_py_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pyclbr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pydoc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pyexpat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_queue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_quopri.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_raise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_range.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_re.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_readline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_regrtest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_repl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_reprlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_resource.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_richcmp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_rlcompleter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_robotparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_runpy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sched.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_scope.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_script_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_secrets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_select.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_selectors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_set.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_setcomps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_shelve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_shlex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_shutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_signal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_site.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_slice.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_smtpd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_smtplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_smtpnet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sndhdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_socket.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_socketserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sort.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_source_encoding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_spwd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sqlite.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ssl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_startfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_stat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_statistics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_strftime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_string.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_string_literals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_stringprep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_strptime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_strtod.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_struct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_structmembers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_structseq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_subclassinit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sunau.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sundry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_super.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_symbol.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_symtable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_syntax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sys_setprofile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sys_settrace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_syslog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tarfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tcl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_telnetlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tempfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_textwrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threaded_import.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threadedtempfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threading_local.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threadsignals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_time.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_timeit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_timeout.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tokenize.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_tools'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_fixcid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_gprof2html.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_i18n.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_md5sum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_pdeps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_pindent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_reindent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_sundry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_unparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_trace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_traceback.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tracemalloc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ttk_guionly.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ttk_textonly.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tuple.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_turtle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_typechecks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_typing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ucn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unary.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode_file_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode_identifiers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicodedata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unittest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_univnewlines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unpack_ex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib2_localnet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib2net.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib_response.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllibnet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urlparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_userdict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_userlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_userstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_utf8source.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_uu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_uuid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_venv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wait3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wait4.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_warnings'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_warnings/data'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/data/import_warning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/data/stacklevel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wave.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_weakref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_weakset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_webbrowser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_winconsoleio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_winreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_winsound.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_with.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wsgiref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xdrlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xml_dom_minicompat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xml_etree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xml_etree_c.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xmlrpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xmlrpc_net.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_yield_from.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipapp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipfile64.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipimport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipimport_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/testcodec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/tf_inherit_check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/threaded_import_hangers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/time_hashlib.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/tracedmodules'...\n",
            "Compiling '/usr/local/lib/python3.6/test/tracedmodules/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/tracedmodules/testmod.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/win_console_handler.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/xmltestdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/xmltests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/textwrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/this.py'...\n",
            "Compiling '/usr/local/lib/python3.6/threading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/timeit.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/colorchooser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/commondialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/dialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/dnd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/filedialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/font.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/messagebox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/scrolledtext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/simpledialog.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter/test'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/runtktests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/support.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter/test/test_tkinter'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_font.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_geometry_managers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_images.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_loadtk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_misc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_variables.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_widgets.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter/test/test_ttk'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_extensions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_style.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_widgets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/widget_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/tix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/ttk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/token.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tokenize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/trace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/traceback.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tracemalloc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtle.py'...\n",
            "Listing '/usr/local/lib/python3.6/turtledemo'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/bytedesign.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/chaos.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/clock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/colormixer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/forest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/fractalcurves.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/lindenmayer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/minimal_hanoi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/nim.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/paint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/peace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/penrose.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/planet_and_moon.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/rosette.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/round_dance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/sorting_animate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/two_canvases.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/yinyang.py'...\n",
            "Compiling '/usr/local/lib/python3.6/types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/typing.py'...\n",
            "Listing '/usr/local/lib/python3.6/unittest'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/case.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/mock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/result.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/runner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/signals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/suite.py'...\n",
            "Listing '/usr/local/lib/python3.6/unittest/test'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/_test_warnings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/dummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_assertions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_break.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_case.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_discovery.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_functiontestcase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_program.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_result.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_runner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_setups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_skipping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_suite.py'...\n",
            "Listing '/usr/local/lib/python3.6/unittest/test/testmock'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testcallable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testhelpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testmagicmethods.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testmock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testpatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testsentinel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testwith.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/util.py'...\n",
            "Listing '/usr/local/lib/python3.6/urllib'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/error.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/parse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/request.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/response.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/robotparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/uu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/uuid.py'...\n",
            "Listing '/usr/local/lib/python3.6/venv'...\n",
            "Compiling '/usr/local/lib/python3.6/venv/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/venv/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/venv/scripts'...\n",
            "Listing '/usr/local/lib/python3.6/venv/scripts/common'...\n",
            "Listing '/usr/local/lib/python3.6/venv/scripts/posix'...\n",
            "Compiling '/usr/local/lib/python3.6/warnings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wave.py'...\n",
            "Compiling '/usr/local/lib/python3.6/weakref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/webbrowser.py'...\n",
            "Listing '/usr/local/lib/python3.6/wsgiref'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/handlers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/simple_server.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/validate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xdrlib.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/dom'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/NodeFilter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/domreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/expatbuilder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/minicompat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/minidom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/pulldom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/xmlbuilder.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/etree'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/ElementInclude.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/ElementPath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/ElementTree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/cElementTree.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/parsers'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/parsers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/parsers/expat.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/sax'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/expatreader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/handler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/saxutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/xmlreader.py'...\n",
            "Listing '/usr/local/lib/python3.6/xmlrpc'...\n",
            "Compiling '/usr/local/lib/python3.6/xmlrpc/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xmlrpc/client.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xmlrpc/server.py'...\n",
            "Compiling '/usr/local/lib/python3.6/zipapp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/zipfile.py'...\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -Wi -OO /usr/local/lib/python3.6/compileall.py \\\n",
            "\t-d /usr/local/lib/python3.6 -f \\\n",
            "\t-x 'bad_coding|badsyntax|site-packages|lib2to3/tests/data' \\\n",
            "\t/usr/local/lib/python3.6\n",
            "Listing '/usr/local/lib/python3.6'...\n",
            "Compiling '/usr/local/lib/python3.6/__future__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/__phello__.foo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_bootlocale.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_collections_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_compat_pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_compression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_dummy_thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_markupbase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_osx_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_pydecimal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_pyio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_sitebuiltins.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_strptime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_sysconfigdata_m_linux_x86_64-linux-gnu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_threading_local.py'...\n",
            "Compiling '/usr/local/lib/python3.6/_weakrefset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/aifc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/antigravity.py'...\n",
            "Compiling '/usr/local/lib/python3.6/argparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asynchat.py'...\n",
            "Listing '/usr/local/lib/python3.6/asyncio'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/base_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/base_futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/base_subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/base_tasks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/compat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/coroutines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/locks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/log.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/proactor_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/protocols.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/queues.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/selector_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/sslproto.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/streams.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/tasks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/transports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/unix_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/windows_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncio/windows_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/asyncore.py'...\n",
            "Compiling '/usr/local/lib/python3.6/base64.py'...\n",
            "Compiling '/usr/local/lib/python3.6/bdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/binhex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/bisect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/bz2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/cProfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/calendar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/cgi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/cgitb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/chunk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/code.py'...\n",
            "Compiling '/usr/local/lib/python3.6/codecs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/codeop.py'...\n",
            "Listing '/usr/local/lib/python3.6/collections'...\n",
            "Compiling '/usr/local/lib/python3.6/collections/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/collections/abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/colorsys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/compileall.py'...\n",
            "Listing '/usr/local/lib/python3.6/concurrent'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/concurrent/futures'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/futures/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/futures/_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/futures/process.py'...\n",
            "Compiling '/usr/local/lib/python3.6/concurrent/futures/thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/configparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/contextlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/copy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/copyreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/crypt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/csv.py'...\n",
            "Listing '/usr/local/lib/python3.6/ctypes'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/_endian.py'...\n",
            "Listing '/usr/local/lib/python3.6/ctypes/macholib'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/macholib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/macholib/dyld.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/macholib/dylib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/macholib/framework.py'...\n",
            "Listing '/usr/local/lib/python3.6/ctypes/test'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_anon.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_array_in_pointer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_arrays.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_as_parameter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_bitfields.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_buffers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_bytes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_byteswap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_callbacks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_cast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_cfuncs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_checkretval.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_delattr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_errno.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_find.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_frombuffer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_funcptr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_incomplete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_init.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_internals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_keeprefs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_libc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_loading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_macholib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_memfunctions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_numbers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_objects.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_parameters.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_pep3118.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_pickling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_pointers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_prototypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_python_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_random_things.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_refcounts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_repr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_returnfuncptrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_simplesubclasses.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_sizes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_slicing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_stringptr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_strings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_struct_fields.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_unaligned_structures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_values.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_varsize_struct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_win32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/test/test_wintypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ctypes/wintypes.py'...\n",
            "Listing '/usr/local/lib/python3.6/curses'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/ascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/has_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/panel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/curses/textpad.py'...\n",
            "Compiling '/usr/local/lib/python3.6/datetime.py'...\n",
            "Listing '/usr/local/lib/python3.6/dbm'...\n",
            "Compiling '/usr/local/lib/python3.6/dbm/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dbm/dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dbm/gnu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dbm/ndbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/decimal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/difflib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dis.py'...\n",
            "Listing '/usr/local/lib/python3.6/dist-packages'...\n",
            "Listing '/usr/local/lib/python3.6/distutils'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/_msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/archive_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/bcppcompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/ccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/cmd.py'...\n",
            "Listing '/usr/local/lib/python3.6/distutils/command'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist_dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist_msi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist_rpm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/bdist_wininst.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build_py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/build_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/clean.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_egg_info.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_lib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/install_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/register.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/command/upload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/cygwinccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/debug.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/dep_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/dir_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/dist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/errors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/extension.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/fancy_getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/file_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/log.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/msvc9compiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/sysconfig.py'...\n",
            "Listing '/usr/local/lib/python3.6/distutils/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_archive_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist_dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist_msi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist_rpm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_bdist_wininst.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build_clib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build_py.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_build_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_clean.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_config_cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_core.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_cygwinccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_dep_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_dir_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_dist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_extension.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_file_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install_data.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install_headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install_lib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_install_scripts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_log.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_msvc9compiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_msvccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_register.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_sdist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_text_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_unixccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_upload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/tests/test_versionpredicate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/text_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/unixccompiler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/distutils/versionpredicate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/doctest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/dummy_threading.py'...\n",
            "Listing '/usr/local/lib/python3.6/email'...\n",
            "Compiling '/usr/local/lib/python3.6/email/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/_encoded_words.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/_header_value_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/_parseaddr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/_policybase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/base64mime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/charset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/contentmanager.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/encoders.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/errors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/feedparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/header.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/headerregistry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/iterators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/message.py'...\n",
            "Listing '/usr/local/lib/python3.6/email/mime'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/application.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/audio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/image.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/message.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/multipart.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/nonmultipart.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/mime/text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/policy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/quoprimime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/email/utils.py'...\n",
            "Listing '/usr/local/lib/python3.6/encodings'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/aliases.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/ascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/base64_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/big5.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/big5hkscs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/bz2_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/charmap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp037.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1006.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1026.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1125.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1140.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1250.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1251.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1252.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1253.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1254.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1255.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1256.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1257.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp1258.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp273.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp424.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp437.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp500.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp65001.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp720.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp737.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp775.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp850.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp852.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp855.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp856.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp857.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp858.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp860.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp861.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp862.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp863.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp864.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp865.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp866.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp869.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp874.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp875.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp932.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp949.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/cp950.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/euc_jis_2004.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/euc_jisx0213.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/euc_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/euc_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/gb18030.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/gb2312.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/gbk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/hex_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/hp_roman8.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/hz.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/idna.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_2004.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_jp_ext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso2022_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_10.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_11.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_13.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_14.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_15.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_16.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_4.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_5.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_6.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_7.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_8.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/iso8859_9.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/johab.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/koi8_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/koi8_t.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/koi8_u.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/kz1048.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/latin_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_arabic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_centeuro.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_croatian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_cyrillic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_farsi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_greek.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_iceland.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_latin2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_roman.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_romanian.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mac_turkish.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/mbcs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/oem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/palmos.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/ptcp154.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/punycode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/quopri_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/raw_unicode_escape.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/rot_13.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/shift_jis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/shift_jis_2004.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/shift_jisx0213.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/tis_620.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/undefined.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/unicode_escape.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/unicode_internal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_16.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_16_be.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_16_le.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_32_be.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_32_le.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_7.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_8.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/utf_8_sig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/uu_codec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/encodings/zlib_codec.py'...\n",
            "Listing '/usr/local/lib/python3.6/ensurepip'...\n",
            "Compiling '/usr/local/lib/python3.6/ensurepip/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ensurepip/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/ensurepip/_bundled'...\n",
            "Compiling '/usr/local/lib/python3.6/ensurepip/_uninstall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/enum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/filecmp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/fileinput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/fnmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/formatter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/fractions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ftplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/functools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/genericpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/getpass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/gettext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/glob.py'...\n",
            "Compiling '/usr/local/lib/python3.6/gzip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/hashlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/heapq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/hmac.py'...\n",
            "Listing '/usr/local/lib/python3.6/html'...\n",
            "Compiling '/usr/local/lib/python3.6/html/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/html/entities.py'...\n",
            "Compiling '/usr/local/lib/python3.6/html/parser.py'...\n",
            "Listing '/usr/local/lib/python3.6/http'...\n",
            "Compiling '/usr/local/lib/python3.6/http/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/client.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/cookiejar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/cookies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/http/server.py'...\n",
            "Listing '/usr/local/lib/python3.6/idlelib'...\n",
            "Listing '/usr/local/lib/python3.6/idlelib/Icons'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/_pyclbr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/autocomplete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/autocomplete_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/autoexpand.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/browser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/calltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/calltip_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/codecontext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/colorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/config_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/configdialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugger.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugger_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugobj.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/debugobj_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/delegator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/dynoption.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/editor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/grep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/help_about.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/history.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/hyperparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle.py'...\n",
            "Listing '/usr/local/lib/python3.6/idlelib/idle_test'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/htest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/mock_idle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/mock_tk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/template.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_autocomplete.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_autocomplete_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_autoexpand.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_browser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_calltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_calltip_w.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_codecontext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_colorizer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_config_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_configdialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugger.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugger_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugobj.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_debugobj_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_delegator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_editmenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_editor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_filelist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_grep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_help.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_help_about.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_history.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_hyperparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_iomenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_macosx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_mainmenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_multicall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_outwin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_paragraph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_parenmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_pathbrowser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_percolator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_pyparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_pyshell.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_query.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_redirector.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_replace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_rpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_rstrip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_run.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_runscript.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_scrolledlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_searchbase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_searchengine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_squeezer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_stackviewer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_statusbar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_textview.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_tooltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_undo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_warning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_window.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/idle_test/test_zoomheight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/iomenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/macosx.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/mainmenu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/multicall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/outwin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/paragraph.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/parenmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/pathbrowser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/percolator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/pyparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/pyshell.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/query.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/redirector.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/replace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/rpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/rstrip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/run.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/runscript.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/scrolledlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/search.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/searchbase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/searchengine.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/squeezer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/stackviewer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/statusbar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/textview.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/tooltip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/undo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/window.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/zoomheight.py'...\n",
            "Compiling '/usr/local/lib/python3.6/idlelib/zzdummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/imaplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/imghdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/imp.py'...\n",
            "Listing '/usr/local/lib/python3.6/importlib'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/_bootstrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/_bootstrap_external.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/machinery.py'...\n",
            "Compiling '/usr/local/lib/python3.6/importlib/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/inspect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ipaddress.py'...\n",
            "Listing '/usr/local/lib/python3.6/json'...\n",
            "Compiling '/usr/local/lib/python3.6/json/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/decoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/encoder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/scanner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/json/tool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/keyword.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/btm_matcher.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/btm_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixer_base.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixer_util.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/fixes'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_apply.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_asserts.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_basestring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_buffer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_except.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_exec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_execfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_exitfunc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_filter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_funcattrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_future.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_getcwdu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_has_key.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_idioms.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_import.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_imports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_imports2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_input.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_intern.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_isinstance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_itertools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_itertools_imports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_long.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_map.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_metaclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_methodattrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_ne.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_next.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_nonzero.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_numliterals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_operator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_paren.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_print.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_raise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_raw_input.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_reduce.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_reload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_renames.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_repr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_set_literal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_standarderror.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_sys_exc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_throw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_tuple_params.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_urllib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_ws_comma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_xrange.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_xreadlines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/fixes/fix_zip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/patcomp.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/pgen2'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/conv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/driver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/grammar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/literals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/parse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/pgen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/token.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pgen2/tokenize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pygram.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/pytree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/refactor.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests/data'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests/data/fixers'...\n",
            "Listing '/usr/local/lib/python3.6/lib2to3/tests/data/fixers/myfixes'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/pytree_idempotency.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_all_fixers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_fixers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_pytree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_refactor.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lib2to3/tests/test_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/linecache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/locale.py'...\n",
            "Listing '/usr/local/lib/python3.6/logging'...\n",
            "Compiling '/usr/local/lib/python3.6/logging/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/logging/config.py'...\n",
            "Compiling '/usr/local/lib/python3.6/logging/handlers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/lzma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/macpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/macurl2path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/mailbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/mailcap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/mimetypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/modulefinder.py'...\n",
            "Listing '/usr/local/lib/python3.6/multiprocessing'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/context.py'...\n",
            "Listing '/usr/local/lib/python3.6/multiprocessing/dummy'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/dummy/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/dummy/connection.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/forkserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/heap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/managers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/pool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_fork.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_forkserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_spawn_posix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/popen_spawn_win32.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/process.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/queues.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/reduction.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/resource_sharer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/semaphore_tracker.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/sharedctypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/synchronize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/multiprocessing/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/netrc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/nntplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ntpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/nturl2path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/numbers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/opcode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/operator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/optparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/os.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pathlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pickletools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pipes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pkgutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/platform.py'...\n",
            "Compiling '/usr/local/lib/python3.6/plistlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/poplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/posixpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/profile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/py_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pyclbr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pydoc.py'...\n",
            "Listing '/usr/local/lib/python3.6/pydoc_data'...\n",
            "Compiling '/usr/local/lib/python3.6/pydoc_data/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/pydoc_data/topics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/queue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/quopri.py'...\n",
            "Compiling '/usr/local/lib/python3.6/random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/re.py'...\n",
            "Compiling '/usr/local/lib/python3.6/reprlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/rlcompleter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/runpy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sched.py'...\n",
            "Compiling '/usr/local/lib/python3.6/secrets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/selectors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/shelve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/shlex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/shutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/signal.py'...\n",
            "Listing '/usr/local/lib/python3.6/site-packages'...\n",
            "Compiling '/usr/local/lib/python3.6/site.py'...\n",
            "Compiling '/usr/local/lib/python3.6/smtpd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/smtplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sndhdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/socket.py'...\n",
            "Compiling '/usr/local/lib/python3.6/socketserver.py'...\n",
            "Listing '/usr/local/lib/python3.6/sqlite3'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/dbapi2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/dump.py'...\n",
            "Listing '/usr/local/lib/python3.6/sqlite3/test'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/dbapi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/dump.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/factory.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/hooks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/regression.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/transactions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sqlite3/test/userfunctions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sre_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sre_constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sre_parse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/ssl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/stat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/statistics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/string.py'...\n",
            "Compiling '/usr/local/lib/python3.6/stringprep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/struct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sunau.py'...\n",
            "Compiling '/usr/local/lib/python3.6/symbol.py'...\n",
            "Compiling '/usr/local/lib/python3.6/symtable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tabnanny.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tarfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/telnetlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tempfile.py'...\n",
            "Listing '/usr/local/lib/python3.6/test'...\n",
            "Compiling '/usr/local/lib/python3.6/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/_test_multiprocessing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ann_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ann_module2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ann_module3.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/audiodata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/audiotests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/autotest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/bisect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/bytecode_helper.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/capath'...\n",
            "Listing '/usr/local/lib/python3.6/test/cjkencodings'...\n",
            "Compiling '/usr/local/lib/python3.6/test/coding20731.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/curses_tests.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/data'...\n",
            "Compiling '/usr/local/lib/python3.6/test/datetimetester.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/decimaltestdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dis_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/doctest_aliases.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/double_const.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/dtracedata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/call_stack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/gc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/instance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/dtracedata/line.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/eintrdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/eintrdata/eintr_tester.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/encoded_modules'...\n",
            "Compiling '/usr/local/lib/python3.6/test/encoded_modules/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/encoded_modules/module_iso_8859_1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/encoded_modules/module_koi8_r.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/final_a.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/final_b.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/fork_wait.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/future_test1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/future_test2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/gdb_sample.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/imghdrdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/imp_dummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/inspect_fodder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/inspect_fodder2.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/libregrtest'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/cmdline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/refleak.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/runtest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/runtest_mp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/save_env.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/setup.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/libregrtest/utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/list_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/lock_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/make_ssl_certs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mapping_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/memory_watchdog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mock_socket.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mod_generics_cache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mp_fork_bomb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/mp_preload.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/multibytecodec_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/outstanding_bugs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pickletester.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/profilee.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pyclbr_input.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pydoc_mod.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pydocfodder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pystone.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/pythoninfo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/re_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/regrtest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/relimport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/reperf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sample_doctest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sample_doctest_no_docstrings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sample_doctest_no_doctests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/seq_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/signalinterproctester.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/sndhdrdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/sortperf.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ssl_servers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/ssltests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/string_tests.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/subprocessdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/fd_status.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/input_reader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/qcat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/qgrep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/subprocessdata/sigchild_ignore.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/support'...\n",
            "Compiling '/usr/local/lib/python3.6/test/support/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/support/script_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/support/testresult.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test___all__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test___future__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test__locale.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test__opcode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test__osx_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_abstract_numbers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_aifc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_argparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_array.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asdl_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ast.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncgen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asynchat.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_asyncio'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/echo.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/echo2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/echo3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_base_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_locks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_pep492.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_proactor_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_queues.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_selector_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_sslproto.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_streams.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_tasks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_transports.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_unix_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_windows_events.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncio/test_windows_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_asyncore.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_atexit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_audioop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_augassign.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_base64.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_baseexception.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bigaddrspace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bigmem.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_binascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_binhex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_binop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bisect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_buffer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bufio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_builtin.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bytes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_bz2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_calendar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_call.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_capi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cgi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cgitb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_charmapcodec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_class.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmd_line.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cmd_line_script.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_code.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_code_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codeccallbacks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_cn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_hk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_iso2022.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecencodings_tw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_cn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_hk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_jp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_kr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecmaps_tw.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codecs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_codeop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_collections.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_colorsys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_compare.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_compileall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_complex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_concurrent_futures.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_configparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_contains.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_contextlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_copy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_copyreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_coroutines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_cprofile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_crashers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_crypt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_csv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ctypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_curses.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_datetime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm_dumb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm_gnu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dbm_ndbm.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_decimal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_decorators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_defaultdict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_deque.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_descr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_descrtut.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_devpoll.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dict_version.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dictcomps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dictviews.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_difflib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_distutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_doctest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_doctest2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_docxmlrpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dtrace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dummy_thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dummy_threading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dynamic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_dynamicclassattribute.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_eintr.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_email'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_email/data'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test__encoded_words.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test__header_value_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_asian_codecs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_contentmanager.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_defect_handling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_email.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_generator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_headerregistry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_inversion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_message.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_pickleable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_policy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/test_utils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_email/torture_test.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ensurepip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_enum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_enumerate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_eof.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_epoll.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_errno.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_exception_hierarchy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_exception_variations.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_extcall.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_faulthandler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fcntl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_file_eintr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_filecmp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fileinput.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fileio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_finalization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_float.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_flufl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fnmatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fork1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_format.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fractions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_frame.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_fstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ftplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_funcattrs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_functools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future4.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_future5.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_generator_stop.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_generators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_genericpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_genexps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_getargs2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_getopt.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_getpass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gettext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_glob.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_global.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_grammar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_grp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_gzip.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_hash.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_hashlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_heapq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_hmac.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_html.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_htmlparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_http_cookiejar.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_http_cookies.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_httplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_httpservers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_idle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_imaplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_imghdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_imp.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/circular_imports'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/basic.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/basic2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/indirect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/rebinding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/rebinding2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpackage.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpkg'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpkg/subpackage2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/subpkg/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/circular_imports/util.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/package'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package/submodule.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_import/data/package2'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package2/submodule1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_import/data/package2/submodule2.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/abc.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/builtin'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/builtin/test_loader.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/extension'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_case_sensitivity.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/extension/test_path_hook.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/frozen'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/frozen/test_loader.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/import_'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test___loader__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test___package__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_caching.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_fromlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_meta_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_packages.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/import_/test_relative_imports.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions/foo/one.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/both_portions/foo/two.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/module_and_namespace_package'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/module_and_namespace_package/a_test'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/module_and_namespace_package/a_test.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg/foo/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/not_a_namespace_pkg/foo/one.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion1'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion1/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion1/foo/one.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion2'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion2/foo'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/portion2/foo/two.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1/parent'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1/parent/child'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project1/parent/child/one.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2/parent'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2/parent/child'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project2/parent/child/two.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3/parent'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3/parent/child'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/namespace_pkgs/project3/parent/child/three.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_importlib/source'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_case_sensitivity.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_file_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_finder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_path_hook.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/source/test_source_encoding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_abc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_api.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_lazy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_locks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_namespace_pkgs.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_spec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/test_windows.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_importlib/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_index.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_inspect.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_int.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_int_literal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_io.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ioctl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ipaddress.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_isinstance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_iter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_iterlen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_itertools.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_json'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_decode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_default.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_dump.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_encode_basestring_ascii.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_enum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_fail.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_float.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_indent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_pass1.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_pass2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_pass3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_recursion.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_scanstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_separators.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_speedups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_tool.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_json/test_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_keyword.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_keywordonlyarg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_kqueue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_largefile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_lib2to3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_linecache.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_list.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_listcomps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_locale.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_logging.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_long.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_longexp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_lzma.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_macpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_macurl2path.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mailbox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mailcap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_marshal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_math.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_memoryio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_memoryview.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_metaclass.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mimetypes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_minidom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_mmap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_module.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_modulefinder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_msilib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multibytecodec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_fork.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_forkserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_main_handling.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_multiprocessing_spawn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_netrc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_nis.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_nntplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_normalization.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ntpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_numeric_tower.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_opcodes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_openpty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_operator.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_optparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ordered_dict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_os.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ossaudiodev.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_osx_env.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_parser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pathlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pdb.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_peepholer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pickle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pickletools.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pipes.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pkg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pkgimport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pkgutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_platform.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_plistlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_poll.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_popen.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_poplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_posix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_posixpath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pow.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pprint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_print.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_profile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_property.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pstats.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pulldom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pwd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_py_compile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pyclbr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pydoc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_pyexpat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_queue.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_quopri.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_raise.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_random.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_range.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_re.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_readline.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_regrtest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_repl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_reprlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_resource.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_richcmp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_rlcompleter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_robotparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_runpy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sched.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_scope.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_script_helper.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_secrets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_select.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_selectors.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_set.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_setcomps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_shelve.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_shlex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_shutil.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_signal.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_site.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_slice.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_smtpd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_smtplib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_smtpnet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sndhdr.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_socket.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_socketserver.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sort.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_source_encoding.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_spwd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sqlite.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ssl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_startfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_stat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_statistics.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_strftime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_string.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_string_literals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_stringprep.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_strptime.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_strtod.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_struct.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_structmembers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_structseq.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_subclassinit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_subprocess.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sunau.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sundry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_super.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_symbol.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_symtable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_syntax.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sys.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sys_setprofile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sys_settrace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_sysconfig.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_syslog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tarfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tcl.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_telnetlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tempfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_textwrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_thread.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threaded_import.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threadedtempfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threading_local.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_threadsignals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_time.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_timeit.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_timeout.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tokenize.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_tools'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_fixcid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_gprof2html.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_i18n.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_md5sum.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_pdeps.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_pindent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_reindent.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_sundry.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tools/test_unparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_trace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_traceback.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tracemalloc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ttk_guionly.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ttk_textonly.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_tuple.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_turtle.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_typechecks.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_typing.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_ucn.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unary.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode_file.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode_file_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicode_identifiers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unicodedata.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unittest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_univnewlines.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unpack.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_unpack_ex.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib2.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib2_localnet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib2net.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllib_response.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urllibnet.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_urlparse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_userdict.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_userlist.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_userstring.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_utf8source.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_uu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_uuid.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_venv.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wait3.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wait4.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_warnings'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/test_warnings/data'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/data/import_warning.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_warnings/data/stacklevel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wave.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_weakref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_weakset.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_webbrowser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_winconsoleio.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_winreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_winsound.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_with.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_wsgiref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xdrlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xml_dom_minicompat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xml_etree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xml_etree_c.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xmlrpc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_xmlrpc_net.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_yield_from.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipapp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipfile.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipfile64.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipimport.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zipimport_support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/test_zlib.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/testcodec.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/tf_inherit_check.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/threaded_import_hangers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/time_hashlib.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/tracedmodules'...\n",
            "Compiling '/usr/local/lib/python3.6/test/tracedmodules/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/tracedmodules/testmod.py'...\n",
            "Compiling '/usr/local/lib/python3.6/test/win_console_handler.py'...\n",
            "Listing '/usr/local/lib/python3.6/test/xmltestdata'...\n",
            "Compiling '/usr/local/lib/python3.6/test/xmltests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/textwrap.py'...\n",
            "Compiling '/usr/local/lib/python3.6/this.py'...\n",
            "Compiling '/usr/local/lib/python3.6/threading.py'...\n",
            "Compiling '/usr/local/lib/python3.6/timeit.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/colorchooser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/commondialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/constants.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/dialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/dnd.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/filedialog.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/font.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/messagebox.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/scrolledtext.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/simpledialog.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter/test'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/runtktests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/support.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter/test/test_tkinter'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_font.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_geometry_managers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_images.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_loadtk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_misc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_text.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_variables.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_tkinter/test_widgets.py'...\n",
            "Listing '/usr/local/lib/python3.6/tkinter/test/test_ttk'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_extensions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_functions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_style.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/test_ttk/test_widgets.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/test/widget_tests.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/tix.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tkinter/ttk.py'...\n",
            "Compiling '/usr/local/lib/python3.6/token.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tokenize.py'...\n",
            "Compiling '/usr/local/lib/python3.6/trace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/traceback.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tracemalloc.py'...\n",
            "Compiling '/usr/local/lib/python3.6/tty.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtle.py'...\n",
            "Listing '/usr/local/lib/python3.6/turtledemo'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/bytedesign.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/chaos.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/clock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/colormixer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/forest.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/fractalcurves.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/lindenmayer.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/minimal_hanoi.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/nim.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/paint.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/peace.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/penrose.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/planet_and_moon.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/rosette.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/round_dance.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/sorting_animate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/tree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/two_canvases.py'...\n",
            "Compiling '/usr/local/lib/python3.6/turtledemo/yinyang.py'...\n",
            "Compiling '/usr/local/lib/python3.6/types.py'...\n",
            "Compiling '/usr/local/lib/python3.6/typing.py'...\n",
            "Listing '/usr/local/lib/python3.6/unittest'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/case.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/main.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/mock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/result.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/runner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/signals.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/suite.py'...\n",
            "Listing '/usr/local/lib/python3.6/unittest/test'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/_test_warnings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/dummy.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_assertions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_break.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_case.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_discovery.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_functiontestcase.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_loader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_program.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_result.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_runner.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_setups.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_skipping.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/test_suite.py'...\n",
            "Listing '/usr/local/lib/python3.6/unittest/test/testmock'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/__main__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/support.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testcallable.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testhelpers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testmagicmethods.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testmock.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testpatch.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testsentinel.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/test/testmock/testwith.py'...\n",
            "Compiling '/usr/local/lib/python3.6/unittest/util.py'...\n",
            "Listing '/usr/local/lib/python3.6/urllib'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/error.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/parse.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/request.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/response.py'...\n",
            "Compiling '/usr/local/lib/python3.6/urllib/robotparser.py'...\n",
            "Compiling '/usr/local/lib/python3.6/uu.py'...\n",
            "Compiling '/usr/local/lib/python3.6/uuid.py'...\n",
            "Listing '/usr/local/lib/python3.6/venv'...\n",
            "Compiling '/usr/local/lib/python3.6/venv/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/venv/__main__.py'...\n",
            "Listing '/usr/local/lib/python3.6/venv/scripts'...\n",
            "Listing '/usr/local/lib/python3.6/venv/scripts/common'...\n",
            "Listing '/usr/local/lib/python3.6/venv/scripts/posix'...\n",
            "Compiling '/usr/local/lib/python3.6/warnings.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wave.py'...\n",
            "Compiling '/usr/local/lib/python3.6/weakref.py'...\n",
            "Compiling '/usr/local/lib/python3.6/webbrowser.py'...\n",
            "Listing '/usr/local/lib/python3.6/wsgiref'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/handlers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/headers.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/simple_server.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/util.py'...\n",
            "Compiling '/usr/local/lib/python3.6/wsgiref/validate.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xdrlib.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/__init__.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/dom'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/NodeFilter.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/domreg.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/expatbuilder.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/minicompat.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/minidom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/pulldom.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/dom/xmlbuilder.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/etree'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/ElementInclude.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/ElementPath.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/ElementTree.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/etree/cElementTree.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/parsers'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/parsers/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/parsers/expat.py'...\n",
            "Listing '/usr/local/lib/python3.6/xml/sax'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/_exceptions.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/expatreader.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/handler.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/saxutils.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xml/sax/xmlreader.py'...\n",
            "Listing '/usr/local/lib/python3.6/xmlrpc'...\n",
            "Compiling '/usr/local/lib/python3.6/xmlrpc/__init__.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xmlrpc/client.py'...\n",
            "Compiling '/usr/local/lib/python3.6/xmlrpc/server.py'...\n",
            "Compiling '/usr/local/lib/python3.6/zipapp.py'...\n",
            "Compiling '/usr/local/lib/python3.6/zipfile.py'...\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -Wi /usr/local/lib/python3.6/compileall.py \\\n",
            "\t-d /usr/local/lib/python3.6/site-packages -f \\\n",
            "\t-x badsyntax /usr/local/lib/python3.6/site-packages\n",
            "Listing '/usr/local/lib/python3.6/site-packages'...\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -Wi -O /usr/local/lib/python3.6/compileall.py \\\n",
            "\t-d /usr/local/lib/python3.6/site-packages -f \\\n",
            "\t-x badsyntax /usr/local/lib/python3.6/site-packages\n",
            "Listing '/usr/local/lib/python3.6/site-packages'...\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -Wi -OO /usr/local/lib/python3.6/compileall.py \\\n",
            "\t-d /usr/local/lib/python3.6/site-packages -f \\\n",
            "\t-x badsyntax /usr/local/lib/python3.6/site-packages\n",
            "Listing '/usr/local/lib/python3.6/site-packages'...\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -m lib2to3.pgen2.driver /usr/local/lib/python3.6/lib2to3/Grammar.txt\n",
            "Generating grammar tables from /usr/local/lib/python3.6/lib2to3/Grammar.txt\n",
            "Writing grammar tables to /usr/local/lib/python3.6/lib2to3/Grammar3.6.9.final.0.pickle\n",
            "PYTHONPATH=/usr/local/lib/python3.6  \\\n",
            "\t./python -E -m lib2to3.pgen2.driver /usr/local/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "Generating grammar tables from /usr/local/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "Writing grammar tables to /usr/local/lib/python3.6/lib2to3/PatternGrammar3.6.9.final.0.pickle\n",
            "Creating directory /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/Python-ast.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/Python.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/abstract.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/accu.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/asdl.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/ast.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bitset.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bltinmodule.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/boolobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bytearrayobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bytes_methods.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/bytesobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/cellobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/ceval.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/classobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/code.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/codecs.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/compile.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/complexobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/datetime.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/descrobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/dictobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/dtoa.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/dynamic_annotations.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/enumobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/errcode.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/eval.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/fileobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/fileutils.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/floatobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/frameobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/funcobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/genobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/graminit.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/grammar.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/import.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/intrcheck.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/iterobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/listobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/longintrepr.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/longobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/marshal.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/memoryobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/metagrammar.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/methodobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/modsupport.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/moduleobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/namespaceobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/node.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/object.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/objimpl.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/odictobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/opcode.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/osdefs.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/osmodule.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/parsetok.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/patchlevel.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pgen.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pgenheaders.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/py_curses.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyarena.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyatomic.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pycapsule.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyctype.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pydebug.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pydtrace.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyerrors.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyexpat.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyfpe.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pygetopt.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyhash.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pylifecycle.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pymacconfig.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pymacro.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pymath.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pymem.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pyport.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pystate.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pystrcmp.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pystrhex.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pystrtod.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pythonrun.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pythread.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/pytime.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/rangeobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/setobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/sliceobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/structmember.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/structseq.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/symtable.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/sysmodule.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/token.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/traceback.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/tupleobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/typeslots.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/ucnhash.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/unicodeobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/warnings.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Include/weakrefobject.h /usr/local/include/python3.6m\n",
            "/usr/bin/install -c -m 644 pyconfig.h /usr/local/include/python3.6m/pyconfig.h\n",
            "Creating directory /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu\n",
            "Creating directory /usr/local/lib/pkgconfig\n",
            "/usr/bin/install -c -m 644 Modules/config.c /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/config.c\n",
            "/usr/bin/install -c -m 644 Programs/python.o /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/python.o\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Modules/config.c.in /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/config.c.in\n",
            "/usr/bin/install -c -m 644 Makefile /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/Makefile\n",
            "/usr/bin/install -c -m 644 Modules/Setup /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/Setup\n",
            "/usr/bin/install -c -m 644 Modules/Setup.local /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/Setup.local\n",
            "/usr/bin/install -c -m 644 Modules/Setup.config /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/Setup.config\n",
            "/usr/bin/install -c -m 644 Misc/python.pc /usr/local/lib/pkgconfig/python-3.6.pc\n",
            "/usr/bin/install -c Python-3.6.9/Modules/makesetup /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/makesetup\n",
            "/usr/bin/install -c Python-3.6.9/install-sh /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/install-sh\n",
            "/usr/bin/install -c python-config.py /usr/local/lib/python3.6/config-3.6m-x86_64-linux-gnu/python-config.py\n",
            "/usr/bin/install -c python-config /usr/local/bin/python3.6m-config\n",
            "./python -E Python-3.6.9/setup.py install \\\n",
            "   \t--prefix=/usr/local \\\n",
            "\t--install-scripts=/usr/local/bin \\\n",
            "\t--install-platlib=/usr/local/lib/python3.6/lib-dynload \\\n",
            "\t--root=/\n",
            "running install\n",
            "running build\n",
            "running build_ext\n",
            "warning: building with the bundled copy of libffi is deprecated on this platform.  It will not be distributed with Python 3.7\n",
            "\n",
            "Python build finished successfully!\n",
            "The necessary bits to build these optional modules were not found:\n",
            "_dbm                  _gdbm                                    \n",
            "To find the necessary bits, look in setup.py in detect_modules() for the module's name.\n",
            "\n",
            "The following modules found by detect_modules() in setup.py, have been\n",
            "built by the Makefile instead, as configured by the Setup files:\n",
            "atexit                pwd                   time               \n",
            "running build_scripts\n",
            "copying and adjusting /content/Python-3.6.9/Tools/scripts/pydoc3 -> build/scripts-3.6\n",
            "copying and adjusting /content/Python-3.6.9/Tools/scripts/idle3 -> build/scripts-3.6\n",
            "copying and adjusting /content/Python-3.6.9/Tools/scripts/2to3 -> build/scripts-3.6\n",
            "copying and adjusting /content/Python-3.6.9/Tools/scripts/pyvenv -> build/scripts-3.6\n",
            "changing mode of build/scripts-3.6/pydoc3 from 644 to 755\n",
            "changing mode of build/scripts-3.6/idle3 from 644 to 755\n",
            "changing mode of build/scripts-3.6/2to3 from 644 to 755\n",
            "changing mode of build/scripts-3.6/pyvenv from 644 to 755\n",
            "renaming build/scripts-3.6/pydoc3 to build/scripts-3.6/pydoc3.6\n",
            "renaming build/scripts-3.6/idle3 to build/scripts-3.6/idle3.6\n",
            "renaming build/scripts-3.6/2to3 to build/scripts-3.6/2to3-3.6\n",
            "renaming build/scripts-3.6/pyvenv to build/scripts-3.6/pyvenv-3.6\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/grp.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_lsprof.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/nis.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_bisect.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sha512.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/select.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/xxlimited.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/ossaudiodev.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_testimportmultiple.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_pickle.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_heapq.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sysconfigdata_m_linux_x86_64-linux-gnu.py -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_random.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_json.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/readline.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_struct.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/resource.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_posixsubprocess.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/cmath.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_ctypes.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_datetime.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_csv.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_blake2.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_testbuffer.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_ssl.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_md5.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_testcapi.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_testmultiphase.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_jp.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sha1.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/pyexpat.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_curses_panel.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_tkinter.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/zlib.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sqlite3.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_tw.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_lzma.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/array.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_crypt.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/parser.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/termios.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/syslog.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/spwd.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/fcntl.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_bz2.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/audioop.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_multiprocessing.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_cn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "creating /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "copying build/lib.linux-x86_64-3.6/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.opt-1.pyc -> /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "copying build/lib.linux-x86_64-3.6/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.opt-2.pyc -> /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "copying build/lib.linux-x86_64-3.6/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.pyc -> /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "copying build/lib.linux-x86_64-3.6/_sha256.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_ctypes_test.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_socket.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_elementtree.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_asyncio.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_hk.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/math.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/unicodedata.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/mmap.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_hashlib.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_decimal.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_iso2022.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_opcode.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_curses.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/binascii.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_sha3.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_multibytecodec.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "copying build/lib.linux-x86_64-3.6/_codecs_kr.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/lib-dynload\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/grp.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_lsprof.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/nis.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_bisect.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sha512.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/select.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/xxlimited.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/ossaudiodev.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_testimportmultiple.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_pickle.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_heapq.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sysconfigdata_m_linux_x86_64-linux-gnu.py to 644\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_random.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_json.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/readline.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_struct.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/resource.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_posixsubprocess.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/cmath.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_datetime.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_csv.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_blake2.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_testbuffer.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_ssl.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_md5.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_testcapi.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_testmultiphase.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_jp.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sha1.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/pyexpat.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_curses_panel.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_tkinter.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/zlib.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sqlite3.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_tw.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_lzma.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/array.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_crypt.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/parser.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/termios.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/syslog.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/spwd.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/fcntl.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_bz2.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/audioop.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_multiprocessing.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_cn.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.opt-1.pyc to 644\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.opt-2.pyc to 644\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/__pycache__/_sysconfigdata_m_linux_x86_64-linux-gnu.cpython-36.pyc to 644\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sha256.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_ctypes_test.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_socket.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_elementtree.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_asyncio.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_hk.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/math.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/unicodedata.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/mmap.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_hashlib.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_decimal.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_iso2022.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_opcode.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_curses.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/binascii.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_sha3.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_multibytecodec.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/_codecs_kr.cpython-36m-x86_64-linux-gnu.so to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/ to 755\n",
            "changing mode of /usr/local/lib/python3.6/lib-dynload/__pycache__ to 755\n",
            "running install_scripts\n",
            "copying build/scripts-3.6/2to3-3.6 -> /usr/local/bin\n",
            "copying build/scripts-3.6/idle3.6 -> /usr/local/bin\n",
            "copying build/scripts-3.6/pydoc3.6 -> /usr/local/bin\n",
            "copying build/scripts-3.6/pyvenv-3.6 -> /usr/local/bin\n",
            "changing mode of /usr/local/bin/2to3-3.6 to 755\n",
            "changing mode of /usr/local/bin/idle3.6 to 755\n",
            "changing mode of /usr/local/bin/pydoc3.6 to 755\n",
            "changing mode of /usr/local/bin/pyvenv-3.6 to 755\n",
            "rm /usr/local/lib/python3.6/lib-dynload/_sysconfigdata_m_linux_x86_64-linux-gnu.py\n",
            "rm -r /usr/local/lib/python3.6/lib-dynload/__pycache__\n",
            "/usr/bin/install -c -m 644 Python-3.6.9/Misc/python.man \\\n",
            "\t/usr/local/share/man/man1/python3.6.1\n",
            "if test ! -d /usr/local/lib/pkgconfig; then \\\n",
            "\techo \"Creating directory /usr/local/lib/pkgconfig\"; \\\n",
            "\t/usr/bin/install -c -d -m 755 /usr/local/lib/pkgconfig; \\\n",
            "fi\n",
            "if test -f /usr/local/bin/python3 -o -h /usr/local/bin/python3; \\\n",
            "then rm -f /usr/local/bin/python3; \\\n",
            "else true; \\\n",
            "fi\n",
            "(cd /usr/local/bin; ln -s python3.6 python3)\n",
            "if test \"3.6\" != \"3.6m\"; then \\\n",
            "\trm -f /usr/local/bin/python3.6-config; \\\n",
            "\t(cd /usr/local/bin; ln -s python3.6m-config python3.6-config); \\\n",
            "\trm -f /usr/local/lib/pkgconfig/python-3.6m.pc; \\\n",
            "\t(cd /usr/local/lib/pkgconfig; ln -s python-3.6.pc python-3.6m.pc); \\\n",
            "fi\n",
            "rm -f /usr/local/bin/python3-config\n",
            "(cd /usr/local/bin; ln -s python3.6-config python3-config)\n",
            "rm -f /usr/local/lib/pkgconfig/python3.pc\n",
            "(cd /usr/local/lib/pkgconfig; ln -s python-3.6.pc python3.pc)\n",
            "rm -f /usr/local/bin/idle3\n",
            "(cd /usr/local/bin; ln -s idle3.6 idle3)\n",
            "rm -f /usr/local/bin/pydoc3\n",
            "(cd /usr/local/bin; ln -s pydoc3.6 pydoc3)\n",
            "rm -f /usr/local/bin/2to3\n",
            "(cd /usr/local/bin; ln -s 2to3-3.6 2to3)\n",
            "rm -f /usr/local/bin/pyvenv\n",
            "(cd /usr/local/bin; ln -s pyvenv-3.6 pyvenv)\n",
            "if test \"x\" != \"x\" ; then \\\n",
            "\trm -f /usr/local/bin/python3-32; \\\n",
            "\t(cd /usr/local/bin; ln -s python3.6-32 python3-32) \\\n",
            "fi\n",
            "rm -f /usr/local/share/man/man1/python3.1\n",
            "(cd /usr/local/share/man/man1; ln -s python3.6.1 python3.1)\n",
            "if test \"xupgrade\" != \"xno\"  ; then \\\n",
            "\tcase upgrade in \\\n",
            "\t\tupgrade) ensurepip=\"--upgrade\" ;; \\\n",
            "\t\tinstall|*) ensurepip=\"\" ;; \\\n",
            "\tesac; \\\n",
            "\t ./python -E -m ensurepip \\\n",
            "\t\t$ensurepip --root=/ ; \\\n",
            "fi\n",
            "Looking in links: /tmp/tmpxk73_uvi\n",
            "Collecting setuptools\n",
            "Collecting pip\n",
            "Installing collected packages: setuptools, pip\n",
            "Successfully installed pip-18.1 setuptools-40.6.2\n",
            "Mounted at /content/drive\n",
            "/usr/local/bin/python\n",
            "Python 3.6.9\n",
            "/env/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9Z-e7Nd1P8x",
        "outputId": "0e975dc8-ef30-4d51-91a0-7dc6c10f1eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2022-12-13 17:41:26--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2022-12-13 17:41:26--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 4.70M 12s\n",
            "    50K .......... .......... .......... .......... ..........  0% 4.70M 12s\n",
            "   100K .......... .......... .......... .......... ..........  0% 14.8M 9s\n",
            "   150K .......... .......... .......... .......... ..........  0% 13.1M 8s\n",
            "   200K .......... .......... .......... .......... ..........  0% 14.0M 7s\n",
            "   250K .......... .......... .......... .......... ..........  0% 20.7M 6s\n",
            "   300K .......... .......... .......... .......... ..........  0% 18.8M 6s\n",
            "   350K .......... .......... .......... .......... ..........  0% 14.8M 6s\n",
            "   400K .......... .......... .......... .......... ..........  0% 24.6M 5s\n",
            "   450K .......... .......... .......... .......... ..........  0% 26.9M 5s\n",
            "   500K .......... .......... .......... .......... ..........  0% 39.4M 5s\n",
            "   550K .......... .......... .......... .......... ..........  1% 34.9M 4s\n",
            "   600K .......... .......... .......... .......... ..........  1% 49.2M 4s\n",
            "   650K .......... .......... .......... .......... ..........  1% 81.3M 4s\n",
            "   700K .......... .......... .......... .......... ..........  1% 46.5M 4s\n",
            "   750K .......... .......... .......... .......... ..........  1% 17.1M 4s\n",
            "   800K .......... .......... .......... .......... ..........  1% 59.4M 3s\n",
            "   850K .......... .......... .......... .......... ..........  1% 54.8M 3s\n",
            "   900K .......... .......... .......... .......... ..........  1% 58.9M 3s\n",
            "   950K .......... .......... .......... .......... ..........  1% 72.9M 3s\n",
            "  1000K .......... .......... .......... .......... ..........  1% 45.8M 3s\n",
            "  1050K .......... .......... .......... .......... ..........  1% 54.6M 3s\n",
            "  1100K .......... .......... .......... .......... ..........  2% 91.8M 3s\n",
            "  1150K .......... .......... .......... .......... ..........  2% 53.7M 3s\n",
            "  1200K .......... .......... .......... .......... ..........  2% 60.0M 3s\n",
            "  1250K .......... .......... .......... .......... ..........  2% 71.7M 3s\n",
            "  1300K .......... .......... .......... .......... ..........  2% 79.8M 2s\n",
            "  1350K .......... .......... .......... .......... ..........  2%  235M 2s\n",
            "  1400K .......... .......... .......... .......... ..........  2% 74.4M 2s\n",
            "  1450K .......... .......... .......... .......... ..........  2% 73.3M 2s\n",
            "  1500K .......... .......... .......... .......... ..........  2% 81.6M 2s\n",
            "  1550K .......... .......... .......... .......... ..........  2% 72.8M 2s\n",
            "  1600K .......... .......... .......... .......... ..........  2%  230M 2s\n",
            "  1650K .......... .......... .......... .......... ..........  2% 78.1M 2s\n",
            "  1700K .......... .......... .......... .......... ..........  3% 81.9M 2s\n",
            "  1750K .......... .......... .......... .......... ..........  3%  117M 2s\n",
            "  1800K .......... .......... .......... .......... ..........  3%  220M 2s\n",
            "  1850K .......... .......... .......... .......... ..........  3% 63.9M 2s\n",
            "  1900K .......... .......... .......... .......... ..........  3%  107M 2s\n",
            "  1950K .......... .......... .......... .......... ..........  3%  128M 2s\n",
            "  2000K .......... .......... .......... .......... ..........  3% 92.0M 2s\n",
            "  2050K .......... .......... .......... .......... ..........  3%  214M 2s\n",
            "  2100K .......... .......... .......... .......... ..........  3%  123M 2s\n",
            "  2150K .......... .......... .......... .......... ..........  3%  101M 2s\n",
            "  2200K .......... .......... .......... .......... ..........  3%  117M 2s\n",
            "  2250K .......... .......... .......... .......... ..........  4%  235M 2s\n",
            "  2300K .......... .......... .......... .......... ..........  4%  139M 2s\n",
            "  2350K .......... .......... .......... .......... ..........  4%  122M 2s\n",
            "  2400K .......... .......... .......... .......... ..........  4% 93.7M 2s\n",
            "  2450K .......... .......... .......... .......... ..........  4%  139M 2s\n",
            "  2500K .......... .......... .......... .......... ..........  4%  151M 2s\n",
            "  2550K .......... .......... .......... .......... ..........  4%  220M 1s\n",
            "  2600K .......... .......... .......... .......... ..........  4%  155M 1s\n",
            "  2650K .......... .......... .......... .......... ..........  4%  104M 1s\n",
            "  2700K .......... .......... .......... .......... ..........  4%  181M 1s\n",
            "  2750K .......... .......... .......... .......... ..........  4%  125M 1s\n",
            "  2800K .......... .......... .......... .......... ..........  4%  232M 1s\n",
            "  2850K .......... .......... .......... .......... ..........  5%  137M 1s\n",
            "  2900K .......... .......... .......... .......... ..........  5%  144M 1s\n",
            "  2950K .......... .......... .......... .......... ..........  5%  172M 1s\n",
            "  3000K .......... .......... .......... .......... ..........  5%  256M 1s\n",
            "  3050K .......... .......... .......... .......... ..........  5%  161M 1s\n",
            "  3100K .......... .......... .......... .......... ..........  5%  166M 1s\n",
            "  3150K .......... .......... .......... .......... ..........  5%  197M 1s\n",
            "  3200K .......... .......... .......... .......... ..........  5%  244M 1s\n",
            "  3250K .......... .......... .......... .......... ..........  5%  361M 1s\n",
            "  3300K .......... .......... .......... .......... ..........  5%  165M 1s\n",
            "  3350K .......... .......... .......... .......... ..........  5%  205M 1s\n",
            "  3400K .......... .......... .......... .......... ..........  6%  159M 1s\n",
            "  3450K .......... .......... .......... .......... ..........  6%  390M 1s\n",
            "  3500K .......... .......... .......... .......... ..........  6%  218M 1s\n",
            "  3550K .......... .......... .......... .......... ..........  6%  168M 1s\n",
            "  3600K .......... .......... .......... .......... ..........  6%  291M 1s\n",
            "  3650K .......... .......... .......... .......... ..........  6%  209M 1s\n",
            "  3700K .......... .......... .......... .......... ..........  6%  212M 1s\n",
            "  3750K .......... .......... .......... .......... ..........  6%  171M 1s\n",
            "  3800K .......... .......... .......... .......... ..........  6%  322M 1s\n",
            "  3850K .......... .......... .......... .......... ..........  6%  220M 1s\n",
            "  3900K .......... .......... .......... .......... ..........  6%  279M 1s\n",
            "  3950K .......... .......... .......... .......... ..........  7%  214M 1s\n",
            "  4000K .......... .......... .......... .......... ..........  7%  178M 1s\n",
            "  4050K .......... .......... .......... .......... ..........  7%  338M 1s\n",
            "  4100K .......... .......... .......... .......... ..........  7%  258M 1s\n",
            "  4150K .......... .......... .......... .......... ..........  7%  248M 1s\n",
            "  4200K .......... .......... .......... .......... ..........  7%  249M 1s\n",
            "  4250K .......... .......... .......... .......... ..........  7%  360M 1s\n",
            "  4300K .......... .......... .......... .......... ..........  7%  213M 1s\n",
            "  4350K .......... .......... .......... .......... ..........  7%  278M 1s\n",
            "  4400K .......... .......... .......... .......... ..........  7%  209M 1s\n",
            "  4450K .......... .......... .......... .......... ..........  7%  324M 1s\n",
            "  4500K .......... .......... .......... .......... ..........  7%  306M 1s\n",
            "  4550K .......... .......... .......... .......... ..........  8%  213M 1s\n",
            "  4600K .......... .......... .......... .......... ..........  8%  342M 1s\n",
            "  4650K .......... .......... .......... .......... ..........  8%  253M 1s\n",
            "  4700K .......... .......... .......... .......... ..........  8%  298M 1s\n",
            "  4750K .......... .......... .......... .......... ..........  8%  192M 1s\n",
            "  4800K .......... .......... .......... .......... ..........  8%  333M 1s\n",
            "  4850K .......... .......... .......... .......... ..........  8%  293M 1s\n",
            "  4900K .......... .......... .......... .......... ..........  8%  347M 1s\n",
            "  4950K .......... .......... .......... .......... ..........  8%  244M 1s\n",
            "  5000K .......... .......... .......... .......... ..........  8%  320M 1s\n",
            "  5050K .......... .......... .......... .......... ..........  8%  304M 1s\n",
            "  5100K .......... .......... .......... .......... ..........  9%  321M 1s\n",
            "  5150K .......... .......... .......... .......... ..........  9%  263M 1s\n",
            "  5200K .......... .......... .......... .......... ..........  9%  354M 1s\n",
            "  5250K .......... .......... .......... .......... ..........  9%  347M 1s\n",
            "  5300K .......... .......... .......... .......... ..........  9%  336M 1s\n",
            "  5350K .......... .......... .......... .......... ..........  9%  316M 1s\n",
            "  5400K .......... .......... .......... .......... ..........  9%  335M 1s\n",
            "  5450K .......... .......... .......... .......... ..........  9%  336M 1s\n",
            "  5500K .......... .......... .......... .......... ..........  9%  285M 1s\n",
            "  5550K .......... .......... .......... .......... ..........  9%  293M 1s\n",
            "  5600K .......... .......... .......... .......... ..........  9%  345M 1s\n",
            "  5650K .......... .......... .......... .......... ..........  9%  297M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 10%  354M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 10%  302M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 10%  324M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 10%  284M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 10%  337M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 10%  282M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 10%  289M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 10%  289M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 10%  331M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 10%  298M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 10%  344M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 11%  309M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 11%  343M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 11%  280M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 11%  345M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 11%  291M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 11%  383M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 11%  306M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 11%  251M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 11%  200M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 11%  234M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 11%  141M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 11%  367M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 12%  194M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 12%  230M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 12%  264M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 12%  172M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 12%  352M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 12%  228M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 12%  244M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 12%  334M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 12%  324M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 12%  250M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 12%  116M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 13%  324M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 13%  347M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 13%  346M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 13%  265M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 13%  328M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 13%  286M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 13%  273M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 13%  276M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 13%  233M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 13%  342M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 13%  340M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 14% 99.9M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 14%  322M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 14%  346M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 14%  387M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 14%  299M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 14%  332M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 14%  272M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 14%  380M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 14%  259M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 14%  324M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 14%  337M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 14%  383M 1s\n",
            "  8550K .......... .......... .......... .......... .......... 15%  329M 1s\n",
            "  8600K .......... .......... .......... .......... .......... 15%  259M 1s\n",
            "  8650K .......... .......... .......... .......... .......... 15%  363M 1s\n",
            "  8700K .......... .......... .......... .......... .......... 15%  391M 1s\n",
            "  8750K .......... .......... .......... .......... .......... 15%  299M 1s\n",
            "  8800K .......... .......... .......... .......... .......... 15%  321M 1s\n",
            "  8850K .......... .......... .......... .......... .......... 15%  369M 1s\n",
            "  8900K .......... .......... .......... .......... .......... 15%  346M 1s\n",
            "  8950K .......... .......... .......... .......... .......... 15%  326M 1s\n",
            "  9000K .......... .......... .......... .......... .......... 15%  369M 1s\n",
            "  9050K .......... .......... .......... .......... .......... 15%  230M 1s\n",
            "  9100K .......... .......... .......... .......... .......... 16%  323M 1s\n",
            "  9150K .......... .......... .......... .......... .......... 16%  312M 1s\n",
            "  9200K .......... .......... .......... .......... .......... 16%  322M 0s\n",
            "  9250K .......... .......... .......... .......... .......... 16%  324M 0s\n",
            "  9300K .......... .......... .......... .......... .......... 16%  348M 0s\n",
            "  9350K .......... .......... .......... .......... .......... 16%  335M 0s\n",
            "  9400K .......... .......... .......... .......... .......... 16%  371M 0s\n",
            "  9450K .......... .......... .......... .......... .......... 16%  320M 0s\n",
            "  9500K .......... .......... .......... .......... .......... 16%  371M 0s\n",
            "  9550K .......... .......... .......... .......... .......... 16%  172M 0s\n",
            "  9600K .......... .......... .......... .......... .......... 16%  293M 0s\n",
            "  9650K .......... .......... .......... .......... .......... 16%  365M 0s\n",
            "  9700K .......... .......... .......... .......... .......... 17%  361M 0s\n",
            "  9750K .......... .......... .......... .......... .......... 17%  345M 0s\n",
            "  9800K .......... .......... .......... .......... .......... 17%  176M 0s\n",
            "  9850K .......... .......... .......... .......... .......... 17%  253M 0s\n",
            "  9900K .......... .......... .......... .......... .......... 17%  276M 0s\n",
            "  9950K .......... .......... .......... .......... .......... 17% 82.2M 0s\n",
            " 10000K .......... .......... .......... .......... .......... 17%  262M 0s\n",
            " 10050K .......... .......... .......... .......... .......... 17%  314M 0s\n",
            " 10100K .......... .......... .......... .......... .......... 17%  382M 0s\n",
            " 10150K .......... .......... .......... .......... .......... 17%  223M 0s\n",
            " 10200K .......... .......... .......... .......... .......... 17%  341M 0s\n",
            " 10250K .......... .......... .......... .......... .......... 18%  338M 0s\n",
            " 10300K .......... .......... .......... .......... .......... 18%  335M 0s\n",
            " 10350K .......... .......... .......... .......... .......... 18%  170M 0s\n",
            " 10400K .......... .......... .......... .......... .......... 18%  151M 0s\n",
            " 10450K .......... .......... .......... .......... .......... 18%  261M 0s\n",
            " 10500K .......... .......... .......... .......... .......... 18%  284M 0s\n",
            " 10550K .......... .......... .......... .......... .......... 18%  307M 0s\n",
            " 10600K .......... .......... .......... .......... .......... 18%  335M 0s\n",
            " 10650K .......... .......... .......... .......... .......... 18%  382M 0s\n",
            " 10700K .......... .......... .......... .......... .......... 18%  294M 0s\n",
            " 10750K .......... .......... .......... .......... .......... 18%  213M 0s\n",
            " 10800K .......... .......... .......... .......... .......... 19%  317M 0s\n",
            " 10850K .......... .......... .......... .......... .......... 19%  351M 0s\n",
            " 10900K .......... .......... .......... .......... .......... 19%  138M 0s\n",
            " 10950K .......... .......... .......... .......... .......... 19%  323M 0s\n",
            " 11000K .......... .......... .......... .......... .......... 19%  233M 0s\n",
            " 11050K .......... .......... .......... .......... .......... 19%  322M 0s\n",
            " 11100K .......... .......... .......... .......... .......... 19%  161M 0s\n",
            " 11150K .......... .......... .......... .......... .......... 19%  281M 0s\n",
            " 11200K .......... .......... .......... .......... .......... 19%  377M 0s\n",
            " 11250K .......... .......... .......... .......... .......... 19%  379M 0s\n",
            " 11300K .......... .......... .......... .......... .......... 19%  145M 0s\n",
            " 11350K .......... .......... .......... .......... .......... 19%  284M 0s\n",
            " 11400K .......... .......... .......... .......... .......... 20%  367M 0s\n",
            " 11450K .......... .......... .......... .......... .......... 20%  344M 0s\n",
            " 11500K .......... .......... .......... .......... .......... 20%  330M 0s\n",
            " 11550K .......... .......... .......... .......... .......... 20%  292M 0s\n",
            " 11600K .......... .......... .......... .......... .......... 20%  315M 0s\n",
            " 11650K .......... .......... .......... .......... .......... 20%  381M 0s\n",
            " 11700K .......... .......... .......... .......... .......... 20%  342M 0s\n",
            " 11750K .......... .......... .......... .......... .......... 20%  299M 0s\n",
            " 11800K .......... .......... .......... .......... .......... 20%  332M 0s\n",
            " 11850K .......... .......... .......... .......... .......... 20%  389M 0s\n",
            " 11900K .......... .......... .......... .......... .......... 20%  381M 0s\n",
            " 11950K .......... .......... .......... .......... .......... 21%  275M 0s\n",
            " 12000K .......... .......... .......... .......... .......... 21%  347M 0s\n",
            " 12050K .......... .......... .......... .......... .......... 21%  367M 0s\n",
            " 12100K .......... .......... .......... .......... .......... 21%  370M 0s\n",
            " 12150K .......... .......... .......... .......... .......... 21%  299M 0s\n",
            " 12200K .......... .......... .......... .......... .......... 21%  360M 0s\n",
            " 12250K .......... .......... .......... .......... .......... 21%  385M 0s\n",
            " 12300K .......... .......... .......... .......... .......... 21%  337M 0s\n",
            " 12350K .......... .......... .......... .......... .......... 21%  230M 0s\n",
            " 12400K .......... .......... .......... .......... .......... 21% 31.0M 0s\n",
            " 12450K .......... .......... .......... .......... .......... 21%  259M 0s\n",
            " 12500K .......... .......... .......... .......... .......... 21%  307M 0s\n",
            " 12550K .......... .......... .......... .......... .......... 22%  313M 0s\n",
            " 12600K .......... .......... .......... .......... .......... 22%  319M 0s\n",
            " 12650K .......... .......... .......... .......... .......... 22%  342M 0s\n",
            " 12700K .......... .......... .......... .......... .......... 22%  329M 0s\n",
            " 12750K .......... .......... .......... .......... .......... 22%  281M 0s\n",
            " 12800K .......... .......... .......... .......... .......... 22%  272M 0s\n",
            " 12850K .......... .......... .......... .......... .......... 22%  293M 0s\n",
            " 12900K .......... .......... .......... .......... .......... 22%  323M 0s\n",
            " 12950K .......... .......... .......... .......... .......... 22%  338M 0s\n",
            " 13000K .......... .......... .......... .......... .......... 22%  373M 0s\n",
            " 13050K .......... .......... .......... .......... .......... 22%  302M 0s\n",
            " 13100K .......... .......... .......... .......... .......... 23%  336M 0s\n",
            " 13150K .......... .......... .......... .......... .......... 23%  222M 0s\n",
            " 13200K .......... .......... .......... .......... .......... 23%  323M 0s\n",
            " 13250K .......... .......... .......... .......... .......... 23%  326M 0s\n",
            " 13300K .......... .......... .......... .......... .......... 23%  343M 0s\n",
            " 13350K .......... .......... .......... .......... .......... 23%  295M 0s\n",
            " 13400K .......... .......... .......... .......... .......... 23%  289M 0s\n",
            " 13450K .......... .......... .......... .......... .......... 23%  279M 0s\n",
            " 13500K .......... .......... .......... .......... .......... 23%  294M 0s\n",
            " 13550K .......... .......... .......... .......... .......... 23%  309M 0s\n",
            " 13600K .......... .......... .......... .......... .......... 23%  385M 0s\n",
            " 13650K .......... .......... .......... .......... .......... 23%  385M 0s\n",
            " 13700K .......... .......... .......... .......... .......... 24%  353M 0s\n",
            " 13750K .......... .......... .......... .......... .......... 24%  256M 0s\n",
            " 13800K .......... .......... .......... .......... .......... 24%  253M 0s\n",
            " 13850K .......... .......... .......... .......... .......... 24%  228M 0s\n",
            " 13900K .......... .......... .......... .......... .......... 24%  223M 0s\n",
            " 13950K .......... .......... .......... .......... .......... 24%  122M 0s\n",
            " 14000K .......... .......... .......... .......... .......... 24%  235M 0s\n",
            " 14050K .......... .......... .......... .......... .......... 24%  264M 0s\n",
            " 14100K .......... .......... .......... .......... .......... 24%  224M 0s\n",
            " 14150K .......... .......... .......... .......... .......... 24%  217M 0s\n",
            " 14200K .......... .......... .......... .......... .......... 24%  205M 0s\n",
            " 14250K .......... .......... .......... .......... .......... 25%  270M 0s\n",
            " 14300K .......... .......... .......... .......... .......... 25%  269M 0s\n",
            " 14350K .......... .......... .......... .......... .......... 25%  201M 0s\n",
            " 14400K .......... .......... .......... .......... .......... 25%  203M 0s\n",
            " 14450K .......... .......... .......... .......... .......... 25%  249M 0s\n",
            " 14500K .......... .......... .......... .......... .......... 25%  270M 0s\n",
            " 14550K .......... .......... .......... .......... .......... 25%  208M 0s\n",
            " 14600K .......... .......... .......... .......... .......... 25%  230M 0s\n",
            " 14650K .......... .......... .......... .......... .......... 25%  245M 0s\n",
            " 14700K .......... .......... .......... .......... .......... 25%  232M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 25%  208M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 26%  219M 0s\n",
            " 14850K .......... .......... .......... .......... .......... 26%  224M 0s\n",
            " 14900K .......... .......... .......... .......... .......... 26%  234M 0s\n",
            " 14950K .......... .......... .......... .......... .......... 26%  238M 0s\n",
            " 15000K .......... .......... .......... .......... .......... 26%  264M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 26%  268M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 26%  256M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 26%  206M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 26%  228M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 26%  263M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 26%  254M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 26%  180M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 27%  232M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 27%  221M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 27%  240M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 27%  191M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 27%  224M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 27%  248M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 27%  197M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 27%  223M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 27%  200M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 27%  224M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 27%  248M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 28%  181M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 28%  227M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 28%  239M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 28%  237M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 28%  197M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 28%  232M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 28%  214M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 28%  234M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 28%  206M 0s\n",
            " 16400K .......... .......... .......... .......... .......... 28%  237M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 28%  259M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 28%  255M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 29%  239M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 29%  270M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 29%  264M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 29% 10.9M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 29%  179M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 29%  218M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 29%  206M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 29%  201M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 29%  189M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 29%  215M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 29%  220M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 30%  196M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 30%  172M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 30%  210M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 30%  208M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 30%  181M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 30%  190M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 30%  210M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 30%  132M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 30%  205M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 30%  189M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 30%  229M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 30%  260M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 31%  241M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 31%  235M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 31%  229M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 31%  268M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 31%  264M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 31%  205M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 31%  268M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 31%  268M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 31%  264M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 31%  238M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 31%  240M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 32%  268M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 32%  270M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 32%  223M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 32%  271M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 32%  259M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 32%  253M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 32%  238M 0s\n",
            " 18600K .......... .......... .......... .......... .......... 32%  273M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 32%  268M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 32%  257M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 32%  218M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 33%  269M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 33%  265M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 33%  239M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 33%  217M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 33%  226M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 33%  251M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 33%  254M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 33%  150M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 33%  202M 0s\n",
            " 19250K .......... .......... .......... .......... .......... 33%  218M 0s\n",
            " 19300K .......... .......... .......... .......... .......... 33%  250M 0s\n",
            " 19350K .......... .......... .......... .......... .......... 33%  211M 0s\n",
            " 19400K .......... .......... .......... .......... .......... 34%  218M 0s\n",
            " 19450K .......... .......... .......... .......... .......... 34%  211M 0s\n",
            " 19500K .......... .......... .......... .......... .......... 34%  231M 0s\n",
            " 19550K .......... .......... .......... .......... .......... 34%  206M 0s\n",
            " 19600K .......... .......... .......... .......... .......... 34%  232M 0s\n",
            " 19650K .......... .......... .......... .......... .......... 34%  225M 0s\n",
            " 19700K .......... .......... .......... .......... .......... 34%  244M 0s\n",
            " 19750K .......... .......... .......... .......... .......... 34%  223M 0s\n",
            " 19800K .......... .......... .......... .......... .......... 34%  220M 0s\n",
            " 19850K .......... .......... .......... .......... .......... 34%  238M 0s\n",
            " 19900K .......... .......... .......... .......... .......... 34%  229M 0s\n",
            " 19950K .......... .......... .......... .......... .......... 35%  196M 0s\n",
            " 20000K .......... .......... .......... .......... .......... 35%  245M 0s\n",
            " 20050K .......... .......... .......... .......... .......... 35%  250M 0s\n",
            " 20100K .......... .......... .......... .......... .......... 35%  221M 0s\n",
            " 20150K .......... .......... .......... .......... .......... 35%  204M 0s\n",
            " 20200K .......... .......... .......... .......... .......... 35%  256M 0s\n",
            " 20250K .......... .......... .......... .......... .......... 35%  272M 0s\n",
            " 20300K .......... .......... .......... .......... .......... 35%  268M 0s\n",
            " 20350K .......... .......... .......... .......... .......... 35%  209M 0s\n",
            " 20400K .......... .......... .......... .......... .......... 35%  266M 0s\n",
            " 20450K .......... .......... .......... .......... .......... 35%  260M 0s\n",
            " 20500K .......... .......... .......... .......... .......... 35%  270M 0s\n",
            " 20550K .......... .......... .......... .......... .......... 36%  241M 0s\n",
            " 20600K .......... .......... .......... .......... .......... 36%  246M 0s\n",
            " 20650K .......... .......... .......... .......... .......... 36%  269M 0s\n",
            " 20700K .......... .......... .......... .......... .......... 36%  257M 0s\n",
            " 20750K .......... .......... .......... .......... .......... 36%  226M 0s\n",
            " 20800K .......... .......... .......... .......... .......... 36%  251M 0s\n",
            " 20850K .......... .......... .......... .......... .......... 36%  259M 0s\n",
            " 20900K .......... .......... .......... .......... .......... 36%  257M 0s\n",
            " 20950K .......... .......... .......... .......... .......... 36%  234M 0s\n",
            " 21000K .......... .......... .......... .......... .......... 36%  269M 0s\n",
            " 21050K .......... .......... .......... .......... .......... 36%  259M 0s\n",
            " 21100K .......... .......... .......... .......... .......... 37%  257M 0s\n",
            " 21150K .......... .......... .......... .......... .......... 37%  219M 0s\n",
            " 21200K .......... .......... .......... .......... .......... 37%  262M 0s\n",
            " 21250K .......... .......... .......... .......... .......... 37%  271M 0s\n",
            " 21300K .......... .......... .......... .......... .......... 37%  266M 0s\n",
            " 21350K .......... .......... .......... .......... .......... 37% 34.1M 0s\n",
            " 21400K .......... .......... .......... .......... .......... 37%  233M 0s\n",
            " 21450K .......... .......... .......... .......... .......... 37%  181M 0s\n",
            " 21500K .......... .......... .......... .......... .......... 37%  239M 0s\n",
            " 21550K .......... .......... .......... .......... .......... 37%  201M 0s\n",
            " 21600K .......... .......... .......... .......... .......... 37%  266M 0s\n",
            " 21650K .......... .......... .......... .......... .......... 38%  271M 0s\n",
            " 21700K .......... .......... .......... .......... .......... 38%  259M 0s\n",
            " 21750K .......... .......... .......... .......... .......... 38%  243M 0s\n",
            " 21800K .......... .......... .......... .......... .......... 38% 10.7M 0s\n",
            " 21850K .......... .......... .......... .......... .......... 38%  220M 0s\n",
            " 21900K .......... .......... .......... .......... .......... 38%  217M 0s\n",
            " 21950K .......... .......... .......... .......... .......... 38%  158M 0s\n",
            " 22000K .......... .......... .......... .......... .......... 38%  229M 0s\n",
            " 22050K .......... .......... .......... .......... .......... 38%  232M 0s\n",
            " 22100K .......... .......... .......... .......... .......... 38%  223M 0s\n",
            " 22150K .......... .......... .......... .......... .......... 38%  179M 0s\n",
            " 22200K .......... .......... .......... .......... .......... 38%  221M 0s\n",
            " 22250K .......... .......... .......... .......... .......... 39%  238M 0s\n",
            " 22300K .......... .......... .......... .......... .......... 39%  219M 0s\n",
            " 22350K .......... .......... .......... .......... .......... 39%  183M 0s\n",
            " 22400K .......... .......... .......... .......... .......... 39%  194M 0s\n",
            " 22450K .......... .......... .......... .......... .......... 39%  178M 0s\n",
            " 22500K .......... .......... .......... .......... .......... 39%  180M 0s\n",
            " 22550K .......... .......... .......... .......... .......... 39%  181M 0s\n",
            " 22600K .......... .......... .......... .......... .......... 39%  229M 0s\n",
            " 22650K .......... .......... .......... .......... .......... 39%  225M 0s\n",
            " 22700K .......... .......... .......... .......... .......... 39%  217M 0s\n",
            " 22750K .......... .......... .......... .......... .......... 39%  186M 0s\n",
            " 22800K .......... .......... .......... .......... .......... 40%  219M 0s\n",
            " 22850K .......... .......... .......... .......... .......... 40%  237M 0s\n",
            " 22900K .......... .......... .......... .......... .......... 40%  169M 0s\n",
            " 22950K .......... .......... .......... .......... .......... 40%  189M 0s\n",
            " 23000K .......... .......... .......... .......... .......... 40%  203M 0s\n",
            " 23050K .......... .......... .......... .......... .......... 40%  218M 0s\n",
            " 23100K .......... .......... .......... .......... .......... 40%  218M 0s\n",
            " 23150K .......... .......... .......... .......... .......... 40%  216M 0s\n",
            " 23200K .......... .......... .......... .......... .......... 40%  246M 0s\n",
            " 23250K .......... .......... .......... .......... .......... 40%  268M 0s\n",
            " 23300K .......... .......... .......... .......... .......... 40%  265M 0s\n",
            " 23350K .......... .......... .......... .......... .......... 40%  184M 0s\n",
            " 23400K .......... .......... .......... .......... .......... 41%  247M 0s\n",
            " 23450K .......... .......... .......... .......... .......... 41%  229M 0s\n",
            " 23500K .......... .......... .......... .......... .......... 41%  232M 0s\n",
            " 23550K .......... .......... .......... .......... .......... 41%  213M 0s\n",
            " 23600K .......... .......... .......... .......... .......... 41%  250M 0s\n",
            " 23650K .......... .......... .......... .......... .......... 41%  247M 0s\n",
            " 23700K .......... .......... .......... .......... .......... 41%  237M 0s\n",
            " 23750K .......... .......... .......... .......... .......... 41%  225M 0s\n",
            " 23800K .......... .......... .......... .......... .......... 41%  250M 0s\n",
            " 23850K .......... .......... .......... .......... .......... 41%  258M 0s\n",
            " 23900K .......... .......... .......... .......... .......... 41%  244M 0s\n",
            " 23950K .......... .......... .......... .......... .......... 42%  194M 0s\n",
            " 24000K .......... .......... .......... .......... .......... 42%  253M 0s\n",
            " 24050K .......... .......... .......... .......... .......... 42%  250M 0s\n",
            " 24100K .......... .......... .......... .......... .......... 42%  236M 0s\n",
            " 24150K .......... .......... .......... .......... .......... 42%  170M 0s\n",
            " 24200K .......... .......... .......... .......... .......... 42%  219M 0s\n",
            " 24250K .......... .......... .......... .......... .......... 42%  219M 0s\n",
            " 24300K .......... .......... .......... .......... .......... 42%  219M 0s\n",
            " 24350K .......... .......... .......... .......... .......... 42%  169M 0s\n",
            " 24400K .......... .......... .......... .......... .......... 42%  264M 0s\n",
            " 24450K .......... .......... .......... .......... .......... 42%  226M 0s\n",
            " 24500K .......... .......... .......... .......... .......... 42%  223M 0s\n",
            " 24550K .......... .......... .......... .......... .......... 43%  216M 0s\n",
            " 24600K .......... .......... .......... .......... .......... 43%  216M 0s\n",
            " 24650K .......... .......... .......... .......... .......... 43%  227M 0s\n",
            " 24700K .......... .......... .......... .......... .......... 43%  221M 0s\n",
            " 24750K .......... .......... .......... .......... .......... 43%  193M 0s\n",
            " 24800K .......... .......... .......... .......... .......... 43%  206M 0s\n",
            " 24850K .......... .......... .......... .......... .......... 43%  263M 0s\n",
            " 24900K .......... .......... .......... .......... .......... 43%  265M 0s\n",
            " 24950K .......... .......... .......... .......... .......... 43%  239M 0s\n",
            " 25000K .......... .......... .......... .......... .......... 43%  264M 0s\n",
            " 25050K .......... .......... .......... .......... .......... 43%  199M 0s\n",
            " 25100K .......... .......... .......... .......... .......... 44%  250M 0s\n",
            " 25150K .......... .......... .......... .......... .......... 44%  217M 0s\n",
            " 25200K .......... .......... .......... .......... .......... 44%  222M 0s\n",
            " 25250K .......... .......... .......... .......... .......... 44%  219M 0s\n",
            " 25300K .......... .......... .......... .......... .......... 44%  234M 0s\n",
            " 25350K .......... .......... .......... .......... .......... 44%  210M 0s\n",
            " 25400K .......... .......... .......... .......... .......... 44%  229M 0s\n",
            " 25450K .......... .......... .......... .......... .......... 44%  252M 0s\n",
            " 25500K .......... .......... .......... .......... .......... 44%  225M 0s\n",
            " 25550K .......... .......... .......... .......... .......... 44%  185M 0s\n",
            " 25600K .......... .......... .......... .......... .......... 44%  267M 0s\n",
            " 25650K .......... .......... .......... .......... .......... 45%  267M 0s\n",
            " 25700K .......... .......... .......... .......... .......... 45%  266M 0s\n",
            " 25750K .......... .......... .......... .......... .......... 45%  231M 0s\n",
            " 25800K .......... .......... .......... .......... .......... 45%  251M 0s\n",
            " 25850K .......... .......... .......... .......... .......... 45%  262M 0s\n",
            " 25900K .......... .......... .......... .......... .......... 45%  264M 0s\n",
            " 25950K .......... .......... .......... .......... .......... 45%  228M 0s\n",
            " 26000K .......... .......... .......... .......... .......... 45%  243M 0s\n",
            " 26050K .......... .......... .......... .......... .......... 45%  252M 0s\n",
            " 26100K .......... .......... .......... .......... .......... 45%  261M 0s\n",
            " 26150K .......... .......... .......... .......... .......... 45%  240M 0s\n",
            " 26200K .......... .......... .......... .......... .......... 45%  265M 0s\n",
            " 26250K .......... .......... .......... .......... .......... 46%  264M 0s\n",
            " 26300K .......... .......... .......... .......... .......... 46%  250M 0s\n",
            " 26350K .......... .......... .......... .......... .......... 46%  222M 0s\n",
            " 26400K .......... .......... .......... .......... .......... 46%  272M 0s\n",
            " 26450K .......... .......... .......... .......... .......... 46%  270M 0s\n",
            " 26500K .......... .......... .......... .......... .......... 46%  233M 0s\n",
            " 26550K .......... .......... .......... .......... .......... 46%  212M 0s\n",
            " 26600K .......... .......... .......... .......... .......... 46%  270M 0s\n",
            " 26650K .......... .......... .......... .......... .......... 46% 39.8M 0s\n",
            " 26700K .......... .......... .......... .......... .......... 46%  223M 0s\n",
            " 26750K .......... .......... .......... .......... .......... 46%  166M 0s\n",
            " 26800K .......... .......... .......... .......... .......... 47%  222M 0s\n",
            " 26850K .......... .......... .......... .......... .......... 47%  229M 0s\n",
            " 26900K .......... .......... .......... .......... .......... 47%  219M 0s\n",
            " 26950K .......... .......... .......... .......... .......... 47%  197M 0s\n",
            " 27000K .......... .......... .......... .......... .......... 47%  199M 0s\n",
            " 27050K .......... .......... .......... .......... .......... 47%  213M 0s\n",
            " 27100K .......... .......... .......... .......... .......... 47%  215M 0s\n",
            " 27150K .......... .......... .......... .......... .......... 47%  186M 0s\n",
            " 27200K .......... .......... .......... .......... .......... 47%  190M 0s\n",
            " 27250K .......... .......... .......... .......... .......... 47%  207M 0s\n",
            " 27300K .......... .......... .......... .......... .......... 47%  259M 0s\n",
            " 27350K .......... .......... .......... .......... .......... 47%  312M 0s\n",
            " 27400K .......... .......... .......... .......... .......... 48%  337M 0s\n",
            " 27450K .......... .......... .......... .......... .......... 48%  225M 0s\n",
            " 27500K .......... .......... .......... .......... .......... 48%  224M 0s\n",
            " 27550K .......... .......... .......... .......... .......... 48%  213M 0s\n",
            " 27600K .......... .......... .......... .......... .......... 48%  319M 0s\n",
            " 27650K .......... .......... .......... .......... .......... 48%  348M 0s\n",
            " 27700K .......... .......... .......... .......... .......... 48%  288M 0s\n",
            " 27750K .......... .......... .......... .......... .......... 48%  278M 0s\n",
            " 27800K .......... .......... .......... .......... .......... 48%  271M 0s\n",
            " 27850K .......... .......... .......... .......... .......... 48%  215M 0s\n",
            " 27900K .......... .......... .......... .......... .......... 48%  257M 0s\n",
            " 27950K .......... .......... .......... .......... .......... 49%  256M 0s\n",
            " 28000K .......... .......... .......... .......... .......... 49%  326M 0s\n",
            " 28050K .......... .......... .......... .......... .......... 49%  335M 0s\n",
            " 28100K .......... .......... .......... .......... .......... 49%  326M 0s\n",
            " 28150K .......... .......... .......... .......... .......... 49%  403M 0s\n",
            " 28200K .......... .......... .......... .......... .......... 49%  297M 0s\n",
            " 28250K .......... .......... .......... .......... .......... 49%  252M 0s\n",
            " 28300K .......... .......... .......... .......... .......... 49%  272M 0s\n",
            " 28350K .......... .......... .......... .......... .......... 49%  226M 0s\n",
            " 28400K .......... .......... .......... .......... .......... 49%  257M 0s\n",
            " 28450K .......... .......... .......... .......... .......... 49%  269M 0s\n",
            " 28500K .......... .......... .......... .......... .......... 50%  301M 0s\n",
            " 28550K .......... .......... .......... .......... .......... 50%  382M 0s\n",
            " 28600K .......... .......... .......... .......... .......... 50%  257M 0s\n",
            " 28650K .......... .......... .......... .......... .......... 50%  272M 0s\n",
            " 28700K .......... .......... .......... .......... .......... 50%  272M 0s\n",
            " 28750K .......... .......... .......... .......... .......... 50%  207M 0s\n",
            " 28800K .......... .......... .......... .......... .......... 50%  238M 0s\n",
            " 28850K .......... .......... .......... .......... .......... 50%  234M 0s\n",
            " 28900K .......... .......... .......... .......... .......... 50%  255M 0s\n",
            " 28950K .......... .......... .......... .......... .......... 50%  224M 0s\n",
            " 29000K .......... .......... .......... .......... .......... 50%  177M 0s\n",
            " 29050K .......... .......... .......... .......... .......... 50%  196M 0s\n",
            " 29100K .......... .......... .......... .......... .......... 51%  251M 0s\n",
            " 29150K .......... .......... .......... .......... .......... 51%  211M 0s\n",
            " 29200K .......... .......... .......... .......... .......... 51%  248M 0s\n",
            " 29250K .......... .......... .......... .......... .......... 51%  260M 0s\n",
            " 29300K .......... .......... .......... .......... .......... 51%  247M 0s\n",
            " 29350K .......... .......... .......... .......... .......... 51%  239M 0s\n",
            " 29400K .......... .......... .......... .......... .......... 51%  265M 0s\n",
            " 29450K .......... .......... .......... .......... .......... 51%  269M 0s\n",
            " 29500K .......... .......... .......... .......... .......... 51% 6.84M 0s\n",
            " 29550K .......... .......... .......... .......... .......... 51%  175M 0s\n",
            " 29600K .......... .......... .......... .......... .......... 51%  217M 0s\n",
            " 29650K .......... .......... .......... .......... .......... 52%  225M 0s\n",
            " 29700K .......... .......... .......... .......... .......... 52%  227M 0s\n",
            " 29750K .......... .......... .......... .......... .......... 52%  194M 0s\n",
            " 29800K .......... .......... .......... .......... .......... 52%  211M 0s\n",
            " 29850K .......... .......... .......... .......... .......... 52%  221M 0s\n",
            " 29900K .......... .......... .......... .......... .......... 52%  219M 0s\n",
            " 29950K .......... .......... .......... .......... .......... 52%  182M 0s\n",
            " 30000K .......... .......... .......... .......... .......... 52%  202M 0s\n",
            " 30050K .......... .......... .......... .......... .......... 52%  136M 0s\n",
            " 30100K .......... .......... .......... .......... .......... 52%  226M 0s\n",
            " 30150K .......... .......... .......... .......... .......... 52%  236M 0s\n",
            " 30200K .......... .......... .......... .......... .......... 52%  250M 0s\n",
            " 30250K .......... .......... .......... .......... .......... 53%  231M 0s\n",
            " 30300K .......... .......... .......... .......... .......... 53%  239M 0s\n",
            " 30350K .......... .......... .......... .......... .......... 53%  208M 0s\n",
            " 30400K .......... .......... .......... .......... .......... 53%  249M 0s\n",
            " 30450K .......... .......... .......... .......... .......... 53%  264M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 53%  269M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 53%  237M 0s\n",
            " 30600K .......... .......... .......... .......... .......... 53%  257M 0s\n",
            " 30650K .......... .......... .......... .......... .......... 53%  268M 0s\n",
            " 30700K .......... .......... .......... .......... .......... 53%  256M 0s\n",
            " 30750K .......... .......... .......... .......... .......... 53%  220M 0s\n",
            " 30800K .......... .......... .......... .......... .......... 54%  269M 0s\n",
            " 30850K .......... .......... .......... .......... .......... 54%  262M 0s\n",
            " 30900K .......... .......... .......... .......... .......... 54% 31.2M 0s\n",
            " 30950K .......... .......... .......... .......... .......... 54%  186M 0s\n",
            " 31000K .......... .......... .......... .......... .......... 54%  218M 0s\n",
            " 31050K .......... .......... .......... .......... .......... 54%  193M 0s\n",
            " 31100K .......... .......... .......... .......... .......... 54%  210M 0s\n",
            " 31150K .......... .......... .......... .......... .......... 54%  200M 0s\n",
            " 31200K .......... .......... .......... .......... .......... 54%  251M 0s\n",
            " 31250K .......... .......... .......... .......... .......... 54%  269M 0s\n",
            " 31300K .......... .......... .......... .......... .......... 54%  248M 0s\n",
            " 31350K .......... .......... .......... .......... .......... 54%  235M 0s\n",
            " 31400K .......... .......... .......... .......... .......... 55%  262M 0s\n",
            " 31450K .......... .......... .......... .......... .......... 55%  216M 0s\n",
            " 31500K .......... .......... .......... .......... .......... 55%  209M 0s\n",
            " 31550K .......... .......... .......... .......... .......... 55%  150M 0s\n",
            " 31600K .......... .......... .......... .......... .......... 55%  231M 0s\n",
            " 31650K .......... .......... .......... .......... .......... 55%  241M 0s\n",
            " 31700K .......... .......... .......... .......... .......... 55%  202M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 55%  169M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 55%  192M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 55%  220M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 55%  212M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 56%  174M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 56%  217M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 56%  216M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 56%  188M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 56%  187M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 56%  149M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 56%  213M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 56%  226M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 56%  171M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 56%  265M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 56%  271M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 57%  265M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 57%  170M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 57%  237M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 57%  173M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 57%  256M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 57%  227M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 57%  232M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 57%  256M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 57%  270M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 57%  223M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 57%  270M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 57%  250M 0s\n",
            " 33100K .......... .......... .......... .......... .......... 58%  254M 0s\n",
            " 33150K .......... .......... .......... .......... .......... 58%  223M 0s\n",
            " 33200K .......... .......... .......... .......... .......... 58%  202M 0s\n",
            " 33250K .......... .......... .......... .......... .......... 58%  208M 0s\n",
            " 33300K .......... .......... .......... .......... .......... 58%  232M 0s\n",
            " 33350K .......... .......... .......... .......... .......... 58%  238M 0s\n",
            " 33400K .......... .......... .......... .......... .......... 58%  265M 0s\n",
            " 33450K .......... .......... .......... .......... .......... 58%  263M 0s\n",
            " 33500K .......... .......... .......... .......... .......... 58%  252M 0s\n",
            " 33550K .......... .......... .......... .......... .......... 58%  218M 0s\n",
            " 33600K .......... .......... .......... .......... .......... 58%  262M 0s\n",
            " 33650K .......... .......... .......... .......... .......... 59%  272M 0s\n",
            " 33700K .......... .......... .......... .......... .......... 59%  265M 0s\n",
            " 33750K .......... .......... .......... .......... .......... 59%  200M 0s\n",
            " 33800K .......... .......... .......... .......... .......... 59%  220M 0s\n",
            " 33850K .......... .......... .......... .......... .......... 59%  225M 0s\n",
            " 33900K .......... .......... .......... .......... .......... 59%  236M 0s\n",
            " 33950K .......... .......... .......... .......... .......... 59%  179M 0s\n",
            " 34000K .......... .......... .......... .......... .......... 59%  209M 0s\n",
            " 34050K .......... .......... .......... .......... .......... 59%  242M 0s\n",
            " 34100K .......... .......... .......... .......... .......... 59%  268M 0s\n",
            " 34150K .......... .......... .......... .......... .......... 59%  233M 0s\n",
            " 34200K .......... .......... .......... .......... .......... 59%  269M 0s\n",
            " 34250K .......... .......... .......... .......... .......... 60%  205M 0s\n",
            " 34300K .......... .......... .......... .......... .......... 60%  217M 0s\n",
            " 34350K .......... .......... .......... .......... .......... 60%  170M 0s\n",
            " 34400K .......... .......... .......... .......... .......... 60%  215M 0s\n",
            " 34450K .......... .......... .......... .......... .......... 60%  201M 0s\n",
            " 34500K .......... .......... .......... .......... .......... 60%  207M 0s\n",
            " 34550K .......... .......... .......... .......... .......... 60%  189M 0s\n",
            " 34600K .......... .......... .......... .......... .......... 60%  214M 0s\n",
            " 34650K .......... .......... .......... .......... .......... 60%  202M 0s\n",
            " 34700K .......... .......... .......... .......... .......... 60%  219M 0s\n",
            " 34750K .......... .......... .......... .......... .......... 60%  187M 0s\n",
            " 34800K .......... .......... .......... .......... .......... 61%  223M 0s\n",
            " 34850K .......... .......... .......... .......... .......... 61%  238M 0s\n",
            " 34900K .......... .......... .......... .......... .......... 61%  265M 0s\n",
            " 34950K .......... .......... .......... .......... .......... 61%  239M 0s\n",
            " 35000K .......... .......... .......... .......... .......... 61%  270M 0s\n",
            " 35050K .......... .......... .......... .......... .......... 61%  258M 0s\n",
            " 35100K .......... .......... .......... .......... .......... 61%  247M 0s\n",
            " 35150K .......... .......... .......... .......... .......... 61%  217M 0s\n",
            " 35200K .......... .......... .......... .......... .......... 61%  270M 0s\n",
            " 35250K .......... .......... .......... .......... .......... 61%  267M 0s\n",
            " 35300K .......... .......... .......... .......... .......... 61%  257M 0s\n",
            " 35350K .......... .......... .......... .......... .......... 61%  230M 0s\n",
            " 35400K .......... .......... .......... .......... .......... 62%  263M 0s\n",
            " 35450K .......... .......... .......... .......... .......... 62%  260M 0s\n",
            " 35500K .......... .......... .......... .......... .......... 62%  273M 0s\n",
            " 35550K .......... .......... .......... .......... .......... 62%  215M 0s\n",
            " 35600K .......... .......... .......... .......... .......... 62%  271M 0s\n",
            " 35650K .......... .......... .......... .......... .......... 62%  198M 0s\n",
            " 35700K .......... .......... .......... .......... .......... 62%  217M 0s\n",
            " 35750K .......... .......... .......... .......... .......... 62%  211M 0s\n",
            " 35800K .......... .......... .......... .......... .......... 62%  250M 0s\n",
            " 35850K .......... .......... .......... .......... .......... 62%  233M 0s\n",
            " 35900K .......... .......... .......... .......... .......... 62%  222M 0s\n",
            " 35950K .......... .......... .......... .......... .......... 63%  184M 0s\n",
            " 36000K .......... .......... .......... .......... .......... 63%  208M 0s\n",
            " 36050K .......... .......... .......... .......... .......... 63%  247M 0s\n",
            " 36100K .......... .......... .......... .......... .......... 63%  261M 0s\n",
            " 36150K .......... .......... .......... .......... .......... 63%  217M 0s\n",
            " 36200K .......... .......... .......... .......... .......... 63%  227M 0s\n",
            " 36250K .......... .......... .......... .......... .......... 63%  209M 0s\n",
            " 36300K .......... .......... .......... .......... .......... 63%  211M 0s\n",
            " 36350K .......... .......... .......... .......... .......... 63%  201M 0s\n",
            " 36400K .......... .......... .......... .......... .......... 63%  263M 0s\n",
            " 36450K .......... .......... .......... .......... .......... 63%  272M 0s\n",
            " 36500K .......... .......... .......... .......... .......... 64%  257M 0s\n",
            " 36550K .......... .......... .......... .......... .......... 64%  185M 0s\n",
            " 36600K .......... .......... .......... .......... .......... 64%  223M 0s\n",
            " 36650K .......... .......... .......... .......... .......... 64%  240M 0s\n",
            " 36700K .......... .......... .......... .......... .......... 64%  220M 0s\n",
            " 36750K .......... .......... .......... .......... .......... 64%  181M 0s\n",
            " 36800K .......... .......... .......... .......... .......... 64%  211M 0s\n",
            " 36850K .......... .......... .......... .......... .......... 64%  243M 0s\n",
            " 36900K .......... .......... .......... .......... .......... 64%  269M 0s\n",
            " 36950K .......... .......... .......... .......... .......... 64%  214M 0s\n",
            " 37000K .......... .......... .......... .......... .......... 64%  251M 0s\n",
            " 37050K .......... .......... .......... .......... .......... 64%  271M 0s\n",
            " 37100K .......... .......... .......... .......... .......... 65%  257M 0s\n",
            " 37150K .......... .......... .......... .......... .......... 65%  228M 0s\n",
            " 37200K .......... .......... .......... .......... .......... 65%  251M 0s\n",
            " 37250K .......... .......... .......... .......... .......... 65%  247M 0s\n",
            " 37300K .......... .......... .......... .......... .......... 65%  267M 0s\n",
            " 37350K .......... .......... .......... .......... .......... 65%  238M 0s\n",
            " 37400K .......... .......... .......... .......... .......... 65%  269M 0s\n",
            " 37450K .......... .......... .......... .......... .......... 65%  229M 0s\n",
            " 37500K .......... .......... .......... .......... .......... 65%  241M 0s\n",
            " 37550K .......... .......... .......... .......... .......... 65%  210M 0s\n",
            " 37600K .......... .......... .......... .......... .......... 65%  218M 0s\n",
            " 37650K .......... .......... .......... .......... .......... 66%  198M 0s\n",
            " 37700K .......... .......... .......... .......... .......... 66%  196M 0s\n",
            " 37750K .......... .......... .......... .......... .......... 66%  172M 0s\n",
            " 37800K .......... .......... .......... .......... .......... 66%  268M 0s\n",
            " 37850K .......... .......... .......... .......... .......... 66%  262M 0s\n",
            " 37900K .......... .......... .......... .......... .......... 66%  257M 0s\n",
            " 37950K .......... .......... .......... .......... .......... 66%  215M 0s\n",
            " 38000K .......... .......... .......... .......... .......... 66%  270M 0s\n",
            " 38050K .......... .......... .......... .......... .......... 66%  244M 0s\n",
            " 38100K .......... .......... .......... .......... .......... 66%  218M 0s\n",
            " 38150K .......... .......... .......... .......... .......... 66%  194M 0s\n",
            " 38200K .......... .......... .......... .......... .......... 66%  209M 0s\n",
            " 38250K .......... .......... .......... .......... .......... 67%  248M 0s\n",
            " 38300K .......... .......... .......... .......... .......... 67%  240M 0s\n",
            " 38350K .......... .......... .......... .......... .......... 67%  176M 0s\n",
            " 38400K .......... .......... .......... .......... .......... 67%  213M 0s\n",
            " 38450K .......... .......... .......... .......... .......... 67%  242M 0s\n",
            " 38500K .......... .......... .......... .......... .......... 67%  264M 0s\n",
            " 38550K .......... .......... .......... .......... .......... 67%  233M 0s\n",
            " 38600K .......... .......... .......... .......... .......... 67%  230M 0s\n",
            " 38650K .......... .......... .......... .......... .......... 67%  216M 0s\n",
            " 38700K .......... .......... .......... .......... .......... 67%  224M 0s\n",
            " 38750K .......... .......... .......... .......... .......... 67%  203M 0s\n",
            " 38800K .......... .......... .......... .......... .......... 68%  263M 0s\n",
            " 38850K .......... .......... .......... .......... .......... 68%  260M 0s\n",
            " 38900K .......... .......... .......... .......... .......... 68%  246M 0s\n",
            " 38950K .......... .......... .......... .......... .......... 68%  240M 0s\n",
            " 39000K .......... .......... .......... .......... .......... 68%  220M 0s\n",
            " 39050K .......... .......... .......... .......... .......... 68%  217M 0s\n",
            " 39100K .......... .......... .......... .......... .......... 68%  207M 0s\n",
            " 39150K .......... .......... .......... .......... .......... 68%  208M 0s\n",
            " 39200K .......... .......... .......... .......... .......... 68%  256M 0s\n",
            " 39250K .......... .......... .......... .......... .......... 68%  241M 0s\n",
            " 39300K .......... .......... .......... .......... .......... 68%  215M 0s\n",
            " 39350K .......... .......... .......... .......... .......... 69%  221M 0s\n",
            " 39400K .......... .......... .......... .......... .......... 69%  227M 0s\n",
            " 39450K .......... .......... .......... .......... .......... 69%  270M 0s\n",
            " 39500K .......... .......... .......... .......... .......... 69%  262M 0s\n",
            " 39550K .......... .......... .......... .......... .......... 69%  220M 0s\n",
            " 39600K .......... .......... .......... .......... .......... 69%  249M 0s\n",
            " 39650K .......... .......... .......... .......... .......... 69%  264M 0s\n",
            " 39700K .......... .......... .......... .......... .......... 69%  258M 0s\n",
            " 39750K .......... .......... .......... .......... .......... 69%  241M 0s\n",
            " 39800K .......... .......... .......... .......... .......... 69%  258M 0s\n",
            " 39850K .......... .......... .......... .......... .......... 69%  253M 0s\n",
            " 39900K .......... .......... .......... .......... .......... 69%  265M 0s\n",
            " 39950K .......... .......... .......... .......... .......... 70%  222M 0s\n",
            " 40000K .......... .......... .......... .......... .......... 70%  271M 0s\n",
            " 40050K .......... .......... .......... .......... .......... 70%  263M 0s\n",
            " 40100K .......... .......... .......... .......... .......... 70%  201M 0s\n",
            " 40150K .......... .......... .......... .......... .......... 70%  171M 0s\n",
            " 40200K .......... .......... .......... .......... .......... 70%  213M 0s\n",
            " 40250K .......... .......... .......... .......... .......... 70%  218M 0s\n",
            " 40300K .......... .......... .......... .......... .......... 70%  235M 0s\n",
            " 40350K .......... .......... .......... .......... .......... 70%  200M 0s\n",
            " 40400K .......... .......... .......... .......... .......... 70%  267M 0s\n",
            " 40450K .......... .......... .......... .......... .......... 70%  272M 0s\n",
            " 40500K .......... .......... .......... .......... .......... 71%  232M 0s\n",
            " 40550K .......... .......... .......... .......... .......... 71%  173M 0s\n",
            " 40600K .......... .......... .......... .......... .......... 71%  206M 0s\n",
            " 40650K .......... .......... .......... .......... .......... 71%  222M 0s\n",
            " 40700K .......... .......... .......... .......... .......... 71%  219M 0s\n",
            " 40750K .......... .......... .......... .......... .......... 71%  189M 0s\n",
            " 40800K .......... .......... .......... .......... .......... 71%  266M 0s\n",
            " 40850K .......... .......... .......... .......... .......... 71%  234M 0s\n",
            " 40900K .......... .......... .......... .......... .......... 71%  237M 0s\n",
            " 40950K .......... .......... .......... .......... .......... 71%  229M 0s\n",
            " 41000K .......... .......... .......... .......... .......... 71%  253M 0s\n",
            " 41050K .......... .......... .......... .......... .......... 71%  244M 0s\n",
            " 41100K .......... .......... .......... .......... .......... 72%  212M 0s\n",
            " 41150K .......... .......... .......... .......... .......... 72%  150M 0s\n",
            " 41200K .......... .......... .......... .......... .......... 72%  205M 0s\n",
            " 41250K .......... .......... .......... .......... .......... 72%  249M 0s\n",
            " 41300K .......... .......... .......... .......... .......... 72%  241M 0s\n",
            " 41350K .......... .......... .......... .......... .......... 72%  237M 0s\n",
            " 41400K .......... .......... .......... .......... .......... 72%  252M 0s\n",
            " 41450K .......... .......... .......... .......... .......... 72%  249M 0s\n",
            " 41500K .......... .......... .......... .......... .......... 72%  267M 0s\n",
            " 41550K .......... .......... .......... .......... .......... 72%  197M 0s\n",
            " 41600K .......... .......... .......... .......... .......... 72%  250M 0s\n",
            " 41650K .......... .......... .......... .......... .......... 73%  241M 0s\n",
            " 41700K .......... .......... .......... .......... .......... 73%  242M 0s\n",
            " 41750K .......... .......... .......... .......... .......... 73%  190M 0s\n",
            " 41800K .......... .......... .......... .......... .......... 73%  215M 0s\n",
            " 41850K .......... .......... .......... .......... .......... 73%  219M 0s\n",
            " 41900K .......... .......... .......... .......... .......... 73%  206M 0s\n",
            " 41950K .......... .......... .......... .......... .......... 73%  220M 0s\n",
            " 42000K .......... .......... .......... .......... .......... 73%  272M 0s\n",
            " 42050K .......... .......... .......... .......... .......... 73%  259M 0s\n",
            " 42100K .......... .......... .......... .......... .......... 73%  257M 0s\n",
            " 42150K .......... .......... .......... .......... .......... 73%  233M 0s\n",
            " 42200K .......... .......... .......... .......... .......... 73%  264M 0s\n",
            " 42250K .......... .......... .......... .......... .......... 74%  271M 0s\n",
            " 42300K .......... .......... .......... .......... .......... 74%  261M 0s\n",
            " 42350K .......... .......... .......... .......... .......... 74%  218M 0s\n",
            " 42400K .......... .......... .......... .......... .......... 74%  270M 0s\n",
            " 42450K .......... .......... .......... .......... .......... 74%  248M 0s\n",
            " 42500K .......... .......... .......... .......... .......... 74%  231M 0s\n",
            " 42550K .......... .......... .......... .......... .......... 74%  194M 0s\n",
            " 42600K .......... .......... .......... .......... .......... 74%  212M 0s\n",
            " 42650K .......... .......... .......... .......... .......... 74%  204M 0s\n",
            " 42700K .......... .......... .......... .......... .......... 74%  212M 0s\n",
            " 42750K .......... .......... .......... .......... .......... 74%  197M 0s\n",
            " 42800K .......... .......... .......... .......... .......... 75%  256M 0s\n",
            " 42850K .......... .......... .......... .......... .......... 75%  260M 0s\n",
            " 42900K .......... .......... .......... .......... .......... 75%  253M 0s\n",
            " 42950K .......... .......... .......... .......... .......... 75%  205M 0s\n",
            " 43000K .......... .......... .......... .......... .......... 75%  241M 0s\n",
            " 43050K .......... .......... .......... .......... .......... 75%  255M 0s\n",
            " 43100K .......... .......... .......... .......... .......... 75%  241M 0s\n",
            " 43150K .......... .......... .......... .......... .......... 75%  185M 0s\n",
            " 43200K .......... .......... .......... .......... .......... 75%  245M 0s\n",
            " 43250K .......... .......... .......... .......... .......... 75%  249M 0s\n",
            " 43300K .......... .......... .......... .......... .......... 75%  256M 0s\n",
            " 43350K .......... .......... .......... .......... .......... 76%  219M 0s\n",
            " 43400K .......... .......... .......... .......... .......... 76%  268M 0s\n",
            " 43450K .......... .......... .......... .......... .......... 76%  221M 0s\n",
            " 43500K .......... .......... .......... .......... .......... 76%  246M 0s\n",
            " 43550K .......... .......... .......... .......... .......... 76%  218M 0s\n",
            " 43600K .......... .......... .......... .......... .......... 76%  246M 0s\n",
            " 43650K .......... .......... .......... .......... .......... 76%  266M 0s\n",
            " 43700K .......... .......... .......... .......... .......... 76%  265M 0s\n",
            " 43750K .......... .......... .......... .......... .......... 76%  242M 0s\n",
            " 43800K .......... .......... .......... .......... .......... 76%  255M 0s\n",
            " 43850K .......... .......... .......... .......... .......... 76%  254M 0s\n",
            " 43900K .......... .......... .......... .......... .......... 76%  261M 0s\n",
            " 43950K .......... .......... .......... .......... .......... 77%  208M 0s\n",
            " 44000K .......... .......... .......... .......... .......... 77%  248M 0s\n",
            " 44050K .......... .......... .......... .......... .......... 77%  157M 0s\n",
            " 44100K .......... .......... .......... .......... .......... 77%  208M 0s\n",
            " 44150K .......... .......... .......... .......... .......... 77%  207M 0s\n",
            " 44200K .......... .......... .......... .......... .......... 77%  237M 0s\n",
            " 44250K .......... .......... .......... .......... .......... 77%  190M 0s\n",
            " 44300K .......... .......... .......... .......... .......... 77%  216M 0s\n",
            " 44350K .......... .......... .......... .......... .......... 77%  178M 0s\n",
            " 44400K .......... .......... .......... .......... .......... 77%  194M 0s\n",
            " 44450K .......... .......... .......... .......... .......... 77%  194M 0s\n",
            " 44500K .......... .......... .......... .......... .......... 78%  251M 0s\n",
            " 44550K .......... .......... .......... .......... .......... 78%  246M 0s\n",
            " 44600K .......... .......... .......... .......... .......... 78%  361M 0s\n",
            " 44650K .......... .......... .......... .......... .......... 78%  358M 0s\n",
            " 44700K .......... .......... .......... .......... .......... 78%  289M 0s\n",
            " 44750K .......... .......... .......... .......... .......... 78%  288M 0s\n",
            " 44800K .......... .......... .......... .......... .......... 78%  312M 0s\n",
            " 44850K .......... .......... .......... .......... .......... 78%  367M 0s\n",
            " 44900K .......... .......... .......... .......... .......... 78%  354M 0s\n",
            " 44950K .......... .......... .......... .......... .......... 78%  328M 0s\n",
            " 45000K .......... .......... .......... .......... .......... 78%  367M 0s\n",
            " 45050K .......... .......... .......... .......... .......... 78%  306M 0s\n",
            " 45100K .......... .......... .......... .......... .......... 79%  310M 0s\n",
            " 45150K .......... .......... .......... .......... .......... 79%  249M 0s\n",
            " 45200K .......... .......... .......... .......... .......... 79%  341M 0s\n",
            " 45250K .......... .......... .......... .......... .......... 79%  340M 0s\n",
            " 45300K .......... .......... .......... .......... .......... 79%  356M 0s\n",
            " 45350K .......... .......... .......... .......... .......... 79%  312M 0s\n",
            " 45400K .......... .......... .......... .......... .......... 79%  341M 0s\n",
            " 45450K .......... .......... .......... .......... .......... 79%  287M 0s\n",
            " 45500K .......... .......... .......... .......... .......... 79%  313M 0s\n",
            " 45550K .......... .......... .......... .......... .......... 79%  294M 0s\n",
            " 45600K .......... .......... .......... .......... .......... 79%  387M 0s\n",
            " 45650K .......... .......... .......... .......... .......... 80%  379M 0s\n",
            " 45700K .......... .......... .......... .......... .......... 80%  348M 0s\n",
            " 45750K .......... .......... .......... .......... .......... 80%  257M 0s\n",
            " 45800K .......... .......... .......... .......... .......... 80%  292M 0s\n",
            " 45850K .......... .......... .......... .......... .......... 80%  390M 0s\n",
            " 45900K .......... .......... .......... .......... .......... 80%  326M 0s\n",
            " 45950K .......... .......... .......... .......... .......... 80%  305M 0s\n",
            " 46000K .......... .......... .......... .......... .......... 80%  316M 0s\n",
            " 46050K .......... .......... .......... .......... .......... 80%  333M 0s\n",
            " 46100K .......... .......... .......... .......... .......... 80%  355M 0s\n",
            " 46150K .......... .......... .......... .......... .......... 80%  258M 0s\n",
            " 46200K .......... .......... .......... .......... .......... 81%  371M 0s\n",
            " 46250K .......... .......... .......... .......... .......... 81%  371M 0s\n",
            " 46300K .......... .......... .......... .......... .......... 81%  366M 0s\n",
            " 46350K .......... .......... .......... .......... .......... 81%  287M 0s\n",
            " 46400K .......... .......... .......... .......... .......... 81%  325M 0s\n",
            " 46450K .......... .......... .......... .......... .......... 81%  293M 0s\n",
            " 46500K .......... .......... .......... .......... .......... 81%  359M 0s\n",
            " 46550K .......... .......... .......... .......... .......... 81%  324M 0s\n",
            " 46600K .......... .......... .......... .......... .......... 81%  393M 0s\n",
            " 46650K .......... .......... .......... .......... .......... 81%  367M 0s\n",
            " 46700K .......... .......... .......... .......... .......... 81%  377M 0s\n",
            " 46750K .......... .......... .......... .......... .......... 81% 40.2M 0s\n",
            " 46800K .......... .......... .......... .......... .......... 82%  265M 0s\n",
            " 46850K .......... .......... .......... .......... .......... 82%  354M 0s\n",
            " 46900K .......... .......... .......... .......... .......... 82%  326M 0s\n",
            " 46950K .......... .......... .......... .......... .......... 82%  345M 0s\n",
            " 47000K .......... .......... .......... .......... .......... 82%  383M 0s\n",
            " 47050K .......... .......... .......... .......... .......... 82%  368M 0s\n",
            " 47100K .......... .......... .......... .......... .......... 82%  390M 0s\n",
            " 47150K .......... .......... .......... .......... .......... 82%  145M 0s\n",
            " 47200K .......... .......... .......... .......... .......... 82%  377M 0s\n",
            " 47250K .......... .......... .......... .......... .......... 82% 27.3M 0s\n",
            " 47300K .......... .......... .......... .......... .......... 82%  273M 0s\n",
            " 47350K .......... .......... .......... .......... .......... 83%  318M 0s\n",
            " 47400K .......... .......... .......... .......... .......... 83%  329M 0s\n",
            " 47450K .......... .......... .......... .......... .......... 83%  299M 0s\n",
            " 47500K .......... .......... .......... .......... .......... 83%  299M 0s\n",
            " 47550K .......... .......... .......... .......... .......... 83%  255M 0s\n",
            " 47600K .......... .......... .......... .......... .......... 83%  368M 0s\n",
            " 47650K .......... .......... .......... .......... .......... 83%  317M 0s\n",
            " 47700K .......... .......... .......... .......... .......... 83%  317M 0s\n",
            " 47750K .......... .......... .......... .......... .......... 83%  291M 0s\n",
            " 47800K .......... .......... .......... .......... .......... 83%  351M 0s\n",
            " 47850K .......... .......... .......... .......... .......... 83%  272M 0s\n",
            " 47900K .......... .......... .......... .......... .......... 83%  339M 0s\n",
            " 47950K .......... .......... .......... .......... .......... 84%  289M 0s\n",
            " 48000K .......... .......... .......... .......... .......... 84%  391M 0s\n",
            " 48050K .......... .......... .......... .......... .......... 84%  385M 0s\n",
            " 48100K .......... .......... .......... .......... .......... 84%  372M 0s\n",
            " 48150K .......... .......... .......... .......... .......... 84%  335M 0s\n",
            " 48200K .......... .......... .......... .......... .......... 84%  328M 0s\n",
            " 48250K .......... .......... .......... .......... .......... 84%  386M 0s\n",
            " 48300K .......... .......... .......... .......... .......... 84%  386M 0s\n",
            " 48350K .......... .......... .......... .......... .......... 84% 60.0M 0s\n",
            " 48400K .......... .......... .......... .......... .......... 84%  110M 0s\n",
            " 48450K .......... .......... .......... .......... .......... 84%  307M 0s\n",
            " 48500K .......... .......... .......... .......... .......... 85%  272M 0s\n",
            " 48550K .......... .......... .......... .......... .......... 85%  264M 0s\n",
            " 48600K .......... .......... .......... .......... .......... 85%  335M 0s\n",
            " 48650K .......... .......... .......... .......... .......... 85%  333M 0s\n",
            " 48700K .......... .......... .......... .......... .......... 85%  158M 0s\n",
            " 48750K .......... .......... .......... .......... .......... 85%  247M 0s\n",
            " 48800K .......... .......... .......... .......... .......... 85%  225M 0s\n",
            " 48850K .......... .......... .......... .......... .......... 85%  198M 0s\n",
            " 48900K .......... .......... .......... .......... .......... 85%  312M 0s\n",
            " 48950K .......... .......... .......... .......... .......... 85%  249M 0s\n",
            " 49000K .......... .......... .......... .......... .......... 85%  360M 0s\n",
            " 49050K .......... .......... .......... .......... .......... 85% 13.0M 0s\n",
            " 49100K .......... .......... .......... .......... .......... 86%  293M 0s\n",
            " 49150K .......... .......... .......... .......... .......... 86%  334M 0s\n",
            " 49200K .......... .......... .......... .......... .......... 86%  334M 0s\n",
            " 49250K .......... .......... .......... .......... .......... 86%  244M 0s\n",
            " 49300K .......... .......... .......... .......... .......... 86%  255M 0s\n",
            " 49350K .......... .......... .......... .......... .......... 86%  328M 0s\n",
            " 49400K .......... .......... .......... .......... .......... 86%  447M 0s\n",
            " 49450K .......... .......... .......... .......... .......... 86%  466M 0s\n",
            " 49500K .......... .......... .......... .......... .......... 86%  419M 0s\n",
            " 49550K .......... .......... .......... .......... .......... 86%  242M 0s\n",
            " 49600K .......... .......... .......... .......... .......... 86% 33.9M 0s\n",
            " 49650K .......... .......... .......... .......... .......... 87%  235M 0s\n",
            " 49700K .......... .......... .......... .......... .......... 87%  261M 0s\n",
            " 49750K .......... .......... .......... .......... .......... 87%  225M 0s\n",
            " 49800K .......... .......... .......... .......... .......... 87%  290M 0s\n",
            " 49850K .......... .......... .......... .......... .......... 87%  289M 0s\n",
            " 49900K .......... .......... .......... .......... .......... 87%  271M 0s\n",
            " 49950K .......... .......... .......... .......... .......... 87%  221M 0s\n",
            " 50000K .......... .......... .......... .......... .......... 87%  253M 0s\n",
            " 50050K .......... .......... .......... .......... .......... 87%  279M 0s\n",
            " 50100K .......... .......... .......... .......... .......... 87%  286M 0s\n",
            " 50150K .......... .......... .......... .......... .......... 87%  263M 0s\n",
            " 50200K .......... .......... .......... .......... .......... 88%  297M 0s\n",
            " 50250K .......... .......... .......... .......... .......... 88%  266M 0s\n",
            " 50300K .......... .......... .......... .......... .......... 88%  283M 0s\n",
            " 50350K .......... .......... .......... .......... .......... 88%  233M 0s\n",
            " 50400K .......... .......... .......... .......... .......... 88%  289M 0s\n",
            " 50450K .......... .......... .......... .......... .......... 88%  283M 0s\n",
            " 50500K .......... .......... .......... .......... .......... 88%  257M 0s\n",
            " 50550K .......... .......... .......... .......... .......... 88%  268M 0s\n",
            " 50600K .......... .......... .......... .......... .......... 88%  337M 0s\n",
            " 50650K .......... .......... .......... .......... .......... 88%  414M 0s\n",
            " 50700K .......... .......... .......... .......... .......... 88%  452M 0s\n",
            " 50750K .......... .......... .......... .......... .......... 88%  330M 0s\n",
            " 50800K .......... .......... .......... .......... .......... 89%  393M 0s\n",
            " 50850K .......... .......... .......... .......... .......... 89%  423M 0s\n",
            " 50900K .......... .......... .......... .......... .......... 89%  285M 0s\n",
            " 50950K .......... .......... .......... .......... .......... 89%  232M 0s\n",
            " 51000K .......... .......... .......... .......... .......... 89%  211M 0s\n",
            " 51050K .......... .......... .......... .......... .......... 89%  228M 0s\n",
            " 51100K .......... .......... .......... .......... .......... 89%  234M 0s\n",
            " 51150K .......... .......... .......... .......... .......... 89%  214M 0s\n",
            " 51200K .......... .......... .......... .......... .......... 89%  255M 0s\n",
            " 51250K .......... .......... .......... .......... .......... 89%  264M 0s\n",
            " 51300K .......... .......... .......... .......... .......... 89%  267M 0s\n",
            " 51350K .......... .......... .......... .......... .......... 90%  235M 0s\n",
            " 51400K .......... .......... .......... .......... .......... 90%  251M 0s\n",
            " 51450K .......... .......... .......... .......... .......... 90%  258M 0s\n",
            " 51500K .......... .......... .......... .......... .......... 90%  270M 0s\n",
            " 51550K .......... .......... .......... .......... .......... 90%  223M 0s\n",
            " 51600K .......... .......... .......... .......... .......... 90%  247M 0s\n",
            " 51650K .......... .......... .......... .......... .......... 90%  211M 0s\n",
            " 51700K .......... .......... .......... .......... .......... 90%  241M 0s\n",
            " 51750K .......... .......... .......... .......... .......... 90%  191M 0s\n",
            " 51800K .......... .......... .......... .......... .......... 90%  250M 0s\n",
            " 51850K .......... .......... .......... .......... .......... 90% 5.16M 0s\n",
            " 51900K .......... .......... .......... .......... .......... 90%  265M 0s\n",
            " 51950K .......... .......... .......... .......... .......... 91% 3.70M 0s\n",
            " 52000K .......... .......... .......... .......... .......... 91%  166M 0s\n",
            " 52050K .......... .......... .......... .......... .......... 91%  222M 0s\n",
            " 52100K .......... .......... .......... .......... .......... 91%  242M 0s\n",
            " 52150K .......... .......... .......... .......... .......... 91%  233M 0s\n",
            " 52200K .......... .......... .......... .......... .......... 91%  212M 0s\n",
            " 52250K .......... .......... .......... .......... .......... 91%  230M 0s\n",
            " 52300K .......... .......... .......... .......... .......... 91%  246M 0s\n",
            " 52350K .......... .......... .......... .......... .......... 91%  210M 0s\n",
            " 52400K .......... .......... .......... .......... .......... 91%  239M 0s\n",
            " 52450K .......... .......... .......... .......... .......... 91%  233M 0s\n",
            " 52500K .......... .......... .......... .......... .......... 92%  225M 0s\n",
            " 52550K .......... .......... .......... .......... .......... 92%  196M 0s\n",
            " 52600K .......... .......... .......... .......... .......... 92%  240M 0s\n",
            " 52650K .......... .......... .......... .......... .......... 92%  216M 0s\n",
            " 52700K .......... .......... .......... .......... .......... 92%  232M 0s\n",
            " 52750K .......... .......... .......... .......... .......... 92%  186M 0s\n",
            " 52800K .......... .......... .......... .......... .......... 92%  206M 0s\n",
            " 52850K .......... .......... .......... .......... .......... 92%  235M 0s\n",
            " 52900K .......... .......... .......... .......... .......... 92%  245M 0s\n",
            " 52950K .......... .......... .......... .......... .......... 92% 2.84M 0s\n",
            " 53000K .......... .......... .......... .......... .......... 92%  235M 0s\n",
            " 53050K .......... .......... .......... .......... .......... 92% 7.88M 0s\n",
            " 53100K .......... .......... .......... .......... .......... 93%  238M 0s\n",
            " 53150K .......... .......... .......... .......... .......... 93%  195M 0s\n",
            " 53200K .......... .......... .......... .......... .......... 93%  225M 0s\n",
            " 53250K .......... .......... .......... .......... .......... 93%  243M 0s\n",
            " 53300K .......... .......... .......... .......... .......... 93%  252M 0s\n",
            " 53350K .......... .......... .......... .......... .......... 93%  226M 0s\n",
            " 53400K .......... .......... .......... .......... .......... 93%  246M 0s\n",
            " 53450K .......... .......... .......... .......... .......... 93%  230M 0s\n",
            " 53500K .......... .......... .......... .......... .......... 93%  244M 0s\n",
            " 53550K .......... .......... .......... .......... .......... 93%  211M 0s\n",
            " 53600K .......... .......... .......... .......... .......... 93%  256M 0s\n",
            " 53650K .......... .......... .......... .......... .......... 94%  249M 0s\n",
            " 53700K .......... .......... .......... .......... .......... 94%  235M 0s\n",
            " 53750K .......... .......... .......... .......... .......... 94%  221M 0s\n",
            " 53800K .......... .......... .......... .......... .......... 94%  253M 0s\n",
            " 53850K .......... .......... .......... .......... .......... 94%  174M 0s\n",
            " 53900K .......... .......... .......... .......... .......... 94%  193M 0s\n",
            " 53950K .......... .......... .......... .......... .......... 94%  155M 0s\n",
            " 54000K .......... .......... .......... .......... .......... 94%  121M 0s\n",
            " 54050K .......... .......... .......... .......... .......... 94%  110M 0s\n",
            " 54100K .......... .......... .......... .......... .......... 94%  107M 0s\n",
            " 54150K .......... .......... .......... .......... .......... 94%  115M 0s\n",
            " 54200K .......... .......... .......... .......... .......... 95%  229M 0s\n",
            " 54250K .......... .......... .......... .......... .......... 95%  251M 0s\n",
            " 54300K .......... .......... .......... .......... .......... 95%  152M 0s\n",
            " 54350K .......... .......... .......... .......... .......... 95%  128M 0s\n",
            " 54400K .......... .......... .......... .......... .......... 95%  131M 0s\n",
            " 54450K .......... .......... .......... .......... .......... 95%  157M 0s\n",
            " 54500K .......... .......... .......... .......... .......... 95%  233M 0s\n",
            " 54550K .......... .......... .......... .......... .......... 95%  223M 0s\n",
            " 54600K .......... .......... .......... .......... .......... 95%  242M 0s\n",
            " 54650K .......... .......... .......... .......... .......... 95%  241M 0s\n",
            " 54700K .......... .......... .......... .......... .......... 95%  216M 0s\n",
            " 54750K .......... .......... .......... .......... .......... 95%  209M 0s\n",
            " 54800K .......... .......... .......... .......... .......... 96%  253M 0s\n",
            " 54850K .......... .......... .......... .......... .......... 96%  243M 0s\n",
            " 54900K .......... .......... .......... .......... .......... 96%  249M 0s\n",
            " 54950K .......... .......... .......... .......... .......... 96%  209M 0s\n",
            " 55000K .......... .......... .......... .......... .......... 96%  249M 0s\n",
            " 55050K .......... .......... .......... .......... .......... 96%  253M 0s\n",
            " 55100K .......... .......... .......... .......... .......... 96%  255M 0s\n",
            " 55150K .......... .......... .......... .......... .......... 96%  209M 0s\n",
            " 55200K .......... .......... .......... .......... .......... 96%  234M 0s\n",
            " 55250K .......... .......... .......... .......... .......... 96%  251M 0s\n",
            " 55300K .......... .......... .......... .......... .......... 96%  251M 0s\n",
            " 55350K .......... .......... .......... .......... .......... 97%  198M 0s\n",
            " 55400K .......... .......... .......... .......... .......... 97%  231M 0s\n",
            " 55450K .......... .......... .......... .......... .......... 97%  225M 0s\n",
            " 55500K .......... .......... .......... .......... .......... 97%  235M 0s\n",
            " 55550K .......... .......... .......... .......... .......... 97%  201M 0s\n",
            " 55600K .......... .......... .......... .......... .......... 97%  230M 0s\n",
            " 55650K .......... .......... .......... .......... .......... 97%  224M 0s\n",
            " 55700K .......... .......... .......... .......... .......... 97%  230M 0s\n",
            " 55750K .......... .......... .......... .......... .......... 97%  204M 0s\n",
            " 55800K .......... .......... .......... .......... .......... 97%  216M 0s\n",
            " 55850K .......... .......... .......... .......... .......... 97%  227M 0s\n",
            " 55900K .......... .......... .......... .......... .......... 97%  225M 0s\n",
            " 55950K .......... .......... .......... .......... .......... 98%  192M 0s\n",
            " 56000K .......... .......... .......... .......... .......... 98%  236M 0s\n",
            " 56050K .......... .......... .......... .......... .......... 98%  234M 0s\n",
            " 56100K .......... .......... .......... .......... .......... 98%  237M 0s\n",
            " 56150K .......... .......... .......... .......... .......... 98%  266M 0s\n",
            " 56200K .......... .......... .......... .......... .......... 98%  370M 0s\n",
            " 56250K .......... .......... .......... .......... .......... 98%  365M 0s\n",
            " 56300K .......... .......... .......... .......... .......... 98%  371M 0s\n",
            " 56350K .......... .......... .......... .......... .......... 98%  301M 0s\n",
            " 56400K .......... .......... .......... .......... .......... 98%  319M 0s\n",
            " 56450K .......... .......... .......... .......... .......... 98%  314M 0s\n",
            " 56500K .......... .......... .......... .......... .......... 99%  373M 0s\n",
            " 56550K .......... .......... .......... .......... .......... 99%  334M 0s\n",
            " 56600K .......... .......... .......... .......... .......... 99%  366M 0s\n",
            " 56650K .......... .......... .......... .......... .......... 99%  375M 0s\n",
            " 56700K .......... .......... .......... .......... .......... 99%  351M 0s\n",
            " 56750K .......... .......... .......... .......... .......... 99%  289M 0s\n",
            " 56800K .......... .......... .......... .......... .......... 99%  308M 0s\n",
            " 56850K .......... .......... .......... .......... .......... 99%  382M 0s\n",
            " 56900K .......... .......... .......... .......... .......... 99%  383M 0s\n",
            " 56950K .......... .......... .......... .......... .......... 99%  332M 0s\n",
            " 57000K .......... .......... .......... .......... .......... 99%  366M 0s\n",
            " 57050K .......... .......... .......... .......... ........  100%  352M=0.4s\n",
            "\n",
            "2022-12-13 17:41:27 (153 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which conda\n",
        "!conda --version\n",
        "!which python \n",
        "#미니 콘다가 설치된 후에는 파이썬 버젼이 살짝 바뀜\n",
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0eOTJBC1QmR",
        "outputId": "b9037bb0-9df0-4ef9-d8c4-8303409dbb37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/conda\n",
            "conda 4.5.4\n",
            "/usr/local/bin/python\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "conda install --channel defaults conda python=3.6 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThK436gh067J",
        "outputId": "e2b91618-c34c-4e5f-cc1e-26a16bbc0c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    tqdm-4.63.0                |     pyhd3eb1b0_0          80 KB\n",
            "    libstdcxx-ng-9.1.0         |       hdf63c60_0         4.0 MB\n",
            "    pysocks-1.7.1              |   py36h06a4308_0          30 KB\n",
            "    ld_impl_linux-64-2.38      |       h1181459_1         732 KB\n",
            "    readline-8.1.2             |       h7f8727e_1         423 KB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    zlib-1.2.12                |       h7f8727e_2         130 KB\n",
            "    pycparser-2.21             |     pyhd3eb1b0_0          94 KB\n",
            "    wheel-0.37.1               |     pyhd3eb1b0_0          31 KB\n",
            "    cffi-1.14.6                |   py36h400218f_0         224 KB\n",
            "    pyopenssl-22.0.0           |     pyhd3eb1b0_0          49 KB\n",
            "    ca-certificates-2022.10.11 |       h06a4308_0         131 KB\n",
            "    cryptography-35.0.0        |   py36hd23ed53_0         1.5 MB\n",
            "    sqlite-3.38.5              |       hc218d9a_0         1.5 MB\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         141 KB\n",
            "    ruamel_yaml-0.15.100       |   py36h27cfd23_0         268 KB\n",
            "    urllib3-1.26.8             |     pyhd3eb1b0_0         100 KB\n",
            "    xz-5.2.5                   |       h7f8727e_1         389 KB\n",
            "    ncurses-6.3                |       h7f8727e_2         1.0 MB\n",
            "    openssl-1.1.1s             |       h7f8727e_0         3.8 MB\n",
            "    pip-21.2.2                 |   py36h06a4308_0         2.1 MB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    six-1.16.0                 |     pyhd3eb1b0_1          19 KB\n",
            "    requests-2.27.1            |     pyhd3eb1b0_0          52 KB\n",
            "    conda-package-handling-1.7.3|   py36h27cfd23_1         946 KB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    conda-4.10.3               |   py36h06a4308_0         3.1 MB\n",
            "    pycosat-0.6.3              |   py36h27cfd23_0         107 KB\n",
            "    tk-8.6.12                  |       h1ccaba5_0         3.3 MB\n",
            "    idna-3.3                   |     pyhd3eb1b0_0          55 KB\n",
            "    setuptools-58.0.4          |   py36h06a4308_0         979 KB\n",
            "    yaml-0.2.5                 |       h7b6447c_0          87 KB\n",
            "    charset-normalizer-2.0.4   |     pyhd3eb1b0_0          33 KB\n",
            "    brotlipy-0.7.0             |py36h27cfd23_1003         349 KB\n",
            "    colorama-0.4.4             |     pyhd3eb1b0_0          21 KB\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        66.3 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:          0.1-main               \n",
            "    brotlipy:               0.7.0-py36h27cfd23_1003\n",
            "    charset-normalizer:     2.0.4-pyhd3eb1b0_0     \n",
            "    colorama:               0.4.4-pyhd3eb1b0_0     \n",
            "    conda-package-handling: 1.7.3-py36h27cfd23_1   \n",
            "    ld_impl_linux-64:       2.38-h1181459_1        \n",
            "    tqdm:                   4.63.0-pyhd3eb1b0_0    \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2022.10.11-h06a4308_0   \n",
            "    certifi:                2018.4.16-py36_0        --> 2021.5.30-py36h06a4308_0\n",
            "    cffi:                   1.11.5-py36h9745a5d_0   --> 1.14.6-py36h400218f_0   \n",
            "    conda:                  4.5.4-py36_0            --> 4.10.3-py36h06a4308_0   \n",
            "    cryptography:           2.2.2-py36h14c3975_0    --> 35.0.0-py36hd23ed53_0   \n",
            "    idna:                   2.6-py36h82fb2a8_1      --> 3.3-pyhd3eb1b0_0        \n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:              7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0        \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0        \n",
            "    ncurses:                6.1-hf484d3e_0          --> 6.3-h7f8727e_2          \n",
            "    openssl:                1.0.2o-h20670df_0       --> 1.1.1s-h7f8727e_0       \n",
            "    pip:                    10.0.1-py36_0           --> 21.2.2-py36h06a4308_0   \n",
            "    pycosat:                0.6.3-py36h0a5515d_0    --> 0.6.3-py36h27cfd23_0    \n",
            "    pycparser:              2.18-py36hf9f622e_1     --> 2.21-pyhd3eb1b0_0       \n",
            "    pyopenssl:              18.0.0-py36_0           --> 22.0.0-pyhd3eb1b0_0     \n",
            "    pysocks:                1.6.8-py36_0            --> 1.7.1-py36h06a4308_0    \n",
            "    python:                 3.6.5-hc3d631a_2        --> 3.6.13-h12debd9_1       \n",
            "    readline:               7.0-ha6073c6_4          --> 8.1.2-h7f8727e_1        \n",
            "    requests:               2.18.4-py36he2e5f8d_1   --> 2.27.1-pyhd3eb1b0_0     \n",
            "    ruamel_yaml:            0.15.37-py36h14c3975_2  --> 0.15.100-py36h27cfd23_0 \n",
            "    setuptools:             39.2.0-py36_0           --> 58.0.4-py36h06a4308_0   \n",
            "    six:                    1.11.0-py36h372c433_1   --> 1.16.0-pyhd3eb1b0_1     \n",
            "    sqlite:                 3.23.1-he433501_0       --> 3.38.5-hc218d9a_0       \n",
            "    tk:                     8.6.7-hc745277_3        --> 8.6.12-h1ccaba5_0       \n",
            "    urllib3:                1.22-py36hbe7ace6_0     --> 1.26.8-pyhd3eb1b0_0     \n",
            "    wheel:                  0.31.1-py36_0           --> 0.37.1-pyhd3eb1b0_0     \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7f8727e_1        \n",
            "    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0        \n",
            "    zlib:                   1.2.11-ha838bed_2       --> 1.2.12-h7f8727e_2       \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         5.3 MB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n",
            "    ncurses-6.3                |       h5eee18b_3         781 KB\n",
            "    readline-8.2               |       h5eee18b_0         357 KB\n",
            "    sqlite-3.40.0              |       h5082296_0         1.2 MB\n",
            "    xz-5.2.8                   |       h5eee18b_0         429 KB\n",
            "    zlib-1.2.13                |       h5eee18b_0         103 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        13.3 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  asn1crypto-0.24.0-py36_0\n",
            "  chardet-3.0.4-py36h0f667ec_1\n",
            "  conda-env-2.6.0-h36134e3_1\n",
            "  libedit-3.1.20170329-h6b74fdf_2\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  libgcc-ng                                9.1.0-hdf63c60_0 --> 11.2.0-h1234567_1\n",
            "  libstdcxx-ng                             9.1.0-hdf63c60_0 --> 11.2.0-h1234567_1\n",
            "  ncurses                                    6.3-h7f8727e_2 --> 6.3-h5eee18b_3\n",
            "  readline                                 8.1.2-h7f8727e_1 --> 8.2-h5eee18b_0\n",
            "  sqlite                                  3.38.5-hc218d9a_0 --> 3.40.0-h5082296_0\n",
            "  xz                                       5.2.5-h7f8727e_1 --> 5.2.8-h5eee18b_0\n",
            "  zlib                                    1.2.12-h7f8727e_2 --> 1.2.13-h5eee18b_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\rlibgomp-11.2.0       | 474 KB    |            |   0% \rlibgomp-11.2.0       | 474 KB    | ####       |  41% \rlibgomp-11.2.0       | 474 KB    | ########## | 100% \n",
            "\rlibgcc-ng-11.2.0     | 5.3 MB    |            |   0% \rlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \rlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \n",
            "\rzlib-1.2.13          | 103 KB    |            |   0% \rzlib-1.2.13          | 103 KB    | ########## | 100% \n",
            "\rsqlite-3.40.0        | 1.2 MB    |            |   0% \rsqlite-3.40.0        | 1.2 MB    | ########## | 100% \n",
            "\rreadline-8.2         | 357 KB    |            |   0% \rreadline-8.2         | 357 KB    | ########## | 100% \n",
            "\r_openmp_mutex-5.1    | 21 KB     |            |   0% \r_openmp_mutex-5.1    | 21 KB     | ########## | 100% \n",
            "\rlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \rlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \rlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \n",
            "\rncurses-6.3          | 781 KB    |            |   0% \rncurses-6.3          | 781 KB    | ########## | 100% \rncurses-6.3          | 781 KB    | ########## | 100% \n",
            "\rxz-5.2.8             | 429 KB    |            |   0% \rxz-5.2.8             | 429 KB    | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtqdm-4.63.0          |   80 KB |            |   0% \rtqdm-4.63.0          |   80 KB | ########## | 100% \n",
            "\rlibstdcxx-ng-9.1.0   |  4.0 MB |            |   0% \rlibstdcxx-ng-9.1.0   |  4.0 MB | #######6   |  76% \rlibstdcxx-ng-9.1.0   |  4.0 MB | #########9 |  99% \rlibstdcxx-ng-9.1.0   |  4.0 MB | ########## | 100% \n",
            "\rpysocks-1.7.1        |   30 KB |            |   0% \rpysocks-1.7.1        |   30 KB | ########## | 100% \n",
            "\rld_impl_linux-64-2.3 |  732 KB |            |   0% \rld_impl_linux-64-2.3 |  732 KB | #########5 |  96% \rld_impl_linux-64-2.3 |  732 KB | ########## | 100% \n",
            "\rreadline-8.1.2       |  423 KB |            |   0% \rreadline-8.1.2       |  423 KB | #########9 |  99% \rreadline-8.1.2       |  423 KB | ########## | 100% \n",
            "\rpython-3.6.13        | 32.5 MB |            |   0% \rpython-3.6.13        | 32.5 MB | ##3        |  24% \rpython-3.6.13        | 32.5 MB | #####5     |  55% \rpython-3.6.13        | 32.5 MB | #######5   |  75% \rpython-3.6.13        | 32.5 MB | #########  |  91% \rpython-3.6.13        | 32.5 MB | ########## | 100% \n",
            "\rzlib-1.2.12          |  130 KB |            |   0% \rzlib-1.2.12          |  130 KB | ########## | 100% \n",
            "\rpycparser-2.21       |   94 KB |            |   0% \rpycparser-2.21       |   94 KB | ########## | 100% \n",
            "\rwheel-0.37.1         |   31 KB |            |   0% \rwheel-0.37.1         |   31 KB | ########## | 100% \n",
            "\rcffi-1.14.6          |  224 KB |            |   0% \rcffi-1.14.6          |  224 KB | ########## | 100% \n",
            "\rpyopenssl-22.0.0     |   49 KB |            |   0% \rpyopenssl-22.0.0     |   49 KB | ########## | 100% \n",
            "\rca-certificates-2022 |  131 KB |            |   0% \rca-certificates-2022 |  131 KB | ########## | 100% \n",
            "\rcryptography-35.0.0  |  1.5 MB |            |   0% \rcryptography-35.0.0  |  1.5 MB | #######7   |  77% \rcryptography-35.0.0  |  1.5 MB | ########## | 100% \n",
            "\rsqlite-3.38.5        |  1.5 MB |            |   0% \rsqlite-3.38.5        |  1.5 MB | #######9   |  79% \rsqlite-3.38.5        |  1.5 MB | ########## | 100% \n",
            "\rcertifi-2021.5.30    |  141 KB |            |   0% \rcertifi-2021.5.30    |  141 KB | ########## | 100% \n",
            "\rruamel_yaml-0.15.100 |  268 KB |            |   0% \rruamel_yaml-0.15.100 |  268 KB | #########5 |  96% \rruamel_yaml-0.15.100 |  268 KB | ########## | 100% \n",
            "\rurllib3-1.26.8       |  100 KB |            |   0% \rurllib3-1.26.8       |  100 KB | ########## | 100% \n",
            "\rxz-5.2.5             |  389 KB |            |   0% \rxz-5.2.5             |  389 KB | #########  |  91% \rxz-5.2.5             |  389 KB | ########## | 100% \n",
            "\rncurses-6.3          |  1.0 MB |            |   0% \rncurses-6.3          |  1.0 MB | ########7  |  87% \rncurses-6.3          |  1.0 MB | ########## | 100% \n",
            "\ropenssl-1.1.1s       |  3.8 MB |            |   0% \ropenssl-1.1.1s       |  3.8 MB | #######7   |  77% \ropenssl-1.1.1s       |  3.8 MB | ########## | 100% \n",
            "\rpip-21.2.2           |  2.1 MB |            |   0% \rpip-21.2.2           |  2.1 MB | #######8   |  79% \rpip-21.2.2           |  2.1 MB | #########9 |  99% \rpip-21.2.2           |  2.1 MB | ########## | 100% \n",
            "\rlibffi-3.3           |   54 KB |            |   0% \rlibffi-3.3           |   54 KB | ########## | 100% \n",
            "\rsix-1.16.0           |   19 KB |            |   0% \rsix-1.16.0           |   19 KB | ########## | 100% \n",
            "\rrequests-2.27.1      |   52 KB |            |   0% \rrequests-2.27.1      |   52 KB | ########## | 100% \n",
            "\rconda-package-handli |  946 KB |            |   0% \rconda-package-handli |  946 KB | ########6  |  87% \rconda-package-handli |  946 KB | ########## | 100% \n",
            "\r_libgcc_mutex-0.1    |    3 KB |            |   0% \r_libgcc_mutex-0.1    |    3 KB | ########## | 100% \n",
            "\rconda-4.10.3         |  3.1 MB |            |   0% \rconda-4.10.3         |  3.1 MB | ########1  |  81% \rconda-4.10.3         |  3.1 MB | ########## | 100% \n",
            "\rpycosat-0.6.3        |  107 KB |            |   0% \rpycosat-0.6.3        |  107 KB | ########## | 100% \n",
            "\rtk-8.6.12            |  3.3 MB |            |   0% \rtk-8.6.12            |  3.3 MB | #######6   |  77% \rtk-8.6.12            |  3.3 MB | #########5 |  95% \rtk-8.6.12            |  3.3 MB | ########## | 100% \n",
            "\ridna-3.3             |   55 KB |            |   0% \ridna-3.3             |   55 KB | ########## | 100% \n",
            "\rsetuptools-58.0.4    |  979 KB |            |   0% \rsetuptools-58.0.4    |  979 KB | ########1  |  82% \rsetuptools-58.0.4    |  979 KB | ########## | 100% \n",
            "\ryaml-0.2.5           |   87 KB |            |   0% \ryaml-0.2.5           |   87 KB | ########## | 100% \n",
            "\rcharset-normalizer-2 |   33 KB |            |   0% \rcharset-normalizer-2 |   33 KB | ########## | 100% \n",
            "\rbrotlipy-0.7.0       |  349 KB |            |   0% \rbrotlipy-0.7.0       |  349 KB | ########## | 100% \n",
            "\rcolorama-0.4.4       |   21 KB |            |   0% \rcolorama-0.4.4       |   21 KB | ########## | 100% \n",
            "\rlibgcc-ng-9.1.0      |  8.1 MB |            |   0% \rlibgcc-ng-9.1.0      |  8.1 MB | #######5   |  76% \rlibgcc-ng-9.1.0      |  8.1 MB | #########5 |  95% \rlibgcc-ng-9.1.0      |  8.1 MB | ########## | 100% \n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.10.3\n",
            "  latest version: 22.11.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version\n",
        "!python --version\n",
        "import sys\n",
        "sys.path\n",
        "import sys\n",
        "_ = (sys.path.append(\"/usr/local/lib/python3.6/site-packages\"))\n",
        "sys.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYynodme0-Jh",
        "outputId": "a7790896-29e6-4987-a104-af175421e572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 4.10.3\n",
            "Python 3.6.13 :: Anaconda, Inc.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python38.zip',\n",
              " '/usr/lib/python3.8',\n",
              " '/usr/lib/python3.8/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.8/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.8/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/usr/local/lib/python3.6/site-packages']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/IoBT-VISTEC/MIN2Net/main/environment.yml\n",
        "!conda env create -f environment.yml\n",
        "!conda activate min2net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqigmR9iuSKH",
        "outputId": "eca2f694-cba8-4dce-f32b-b6162e0da450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-13 17:42:27--  https://raw.githubusercontent.com/IoBT-VISTEC/MIN2Net/main/environment.yml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 265 [text/plain]\n",
            "Saving to: ‘environment.yml’\n",
            "\n",
            "environment.yml     100%[===================>]     265  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-13 17:42:27 (14.5 MB/s) - ‘environment.yml’ saved [265/265]\n",
            "\n",
            "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.10.3\n",
            "  latest version: 22.11.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "gast-0.3.3           | 14 KB     | : 100% 1.0/1 [00:00<00:00,  3.13it/s]\n",
            "pyasn1-modules-0.2.8 | 72 KB     | : 100% 1.0/1 [00:00<00:00,  5.52it/s]               \n",
            "wheel-0.37.0         | 33 KB     | : 100% 1.0/1 [00:00<00:00,  4.57it/s]                \n",
            "libgfortran-ng-7.5.0 | 22 KB     | : 100% 1.0/1 [00:00<00:00,  3.03it/s]               \n",
            "coverage-5.5         | 258 KB    | : 100% 1.0/1 [00:00<00:00,  8.76it/s]\n",
            "keras-preprocessing- | 35 KB     | : 100% 1.0/1 [00:00<00:00,  7.78it/s]\n",
            "yarl-1.6.3           | 133 KB    | : 100% 1.0/1 [00:00<00:00,  5.83it/s]                \n",
            "google-auth-oauthlib | 18 KB     | : 100% 1.0/1 [00:00<00:00,  9.65it/s]\n",
            "protobuf-3.17.2      | 319 KB    | : 100% 1.0/1 [00:00<00:00,  5.09it/s]                \n",
            "pyjwt-2.1.0          | 31 KB     | : 100% 1.0/1 [00:00<00:00,  6.87it/s]               \n",
            "mkl-2020.2           | 138.3 MB  | : 100% 1.0/1 [00:05<00:00,  5.75s/it]\n",
            "importlib-metadata-4 | 38 KB     | : 100% 1.0/1 [00:00<00:00, 15.05it/s]\n",
            "libffi-3.2.1         | 48 KB     | : 100% 1.0/1 [00:00<00:00, 15.08it/s]\n",
            "requests-oauthlib-1. | 23 KB     | : 100% 1.0/1 [00:00<00:00, 13.49it/s]\n",
            "attrs-21.4.0         | 51 KB     | : 100% 1.0/1 [00:00<00:00, 13.47it/s]\n",
            "hdf5-1.10.6          | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  6.37it/s]\n",
            "cudnn-7.6.5          | 179.9 MB  | : 100% 1.0/1 [00:05<00:00,  5.81s/it]               \n",
            "mkl_random-1.1.1     | 327 KB    | : 100% 1.0/1 [00:00<00:00, 10.09it/s]\n",
            "blinker-1.4          | 22 KB     | : 100% 1.0/1 [00:00<00:00,  8.56it/s]\n",
            "intel-openmp-2022.1. | 4.5 MB    | : 100% 1.0/1 [00:00<00:00,  4.65it/s]               \n",
            "mkl-service-2.3.0    | 52 KB     | : 100% 1.0/1 [00:00<00:00, 12.71it/s]\n",
            "cython-0.29.24       | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  5.60it/s]\n",
            "termcolor-1.1.0      | 9 KB      | : 100% 1.0/1 [00:00<00:00,  9.13it/s]\n",
            "tensorboard-plugin-w | 630 KB    | : 100% 1.0/1 [00:00<00:00,  9.23it/s]\n",
            "idna_ssl-1.1.0       | 8 KB      | : 100% 1.0/1 [00:00<00:00, 11.21it/s]\n",
            "mkl_fft-1.3.0        | 170 KB    | : 100% 1.0/1 [00:00<00:00,  9.90it/s]\n",
            "oauthlib-3.2.0       | 130 KB    | : 100% 1.0/1 [00:00<00:00,  7.32it/s]\n",
            "tensorflow-2.2.0     | 4 KB      | : 100% 1.0/1 [00:00<00:00, 17.81it/s]\n",
            "_tflow_select-2.1.0  | 2 KB      | : 100% 1.0/1 [00:00<00:00, 10.59it/s]\n",
            "aiohttp-3.7.4.post0  | 540 KB    | : 100% 1.0/1 [00:00<00:00,  8.42it/s]\n",
            "pyopenssl-21.0.0     | 49 KB     | : 100% 1.0/1 [00:00<00:00,  5.70it/s]                \n",
            "async-timeout-3.0.1  | 13 KB     | : 100% 1.0/1 [00:00<00:00, 15.72it/s]\n",
            "chardet-4.0.0        | 199 KB    | : 100% 1.0/1 [00:00<00:00, 14.65it/s]\n",
            "opt_einsum-3.3.0     | 57 KB     | : 100% 1.0/1 [00:00<00:00, 14.56it/s]\n",
            "absl-py-0.15.0       | 103 KB    | : 100% 1.0/1 [00:00<00:00, 16.98it/s]\n",
            "libgfortran4-7.5.0   | 995 KB    | : 100% 1.0/1 [00:00<00:00, 12.30it/s]\n",
            "google-auth-2.6.0    | 83 KB     | : 100% 1.0/1 [00:00<00:00, 14.51it/s]\n",
            "cupti-10.1.168       | 1.4 MB    | : 100% 1.0/1 [00:00<00:00, 10.81it/s]\n",
            "libedit-3.1.20221030 | 181 KB    | : 100% 1.0/1 [00:00<00:00, 14.81it/s]\n",
            "zipp-3.6.0           | 17 KB     | : 100% 1.0/1 [00:00<00:00, 15.10it/s]\n",
            "cachetools-4.2.2     | 13 KB     | : 100% 1.0/1 [00:00<00:00, 18.95it/s]\n",
            "tensorflow-base-2.2. | 180.2 MB  | : 100% 1.0/1 [00:08<00:00,  8.67s/it]              \n",
            "readline-7.0         | 324 KB    | : 100% 1.0/1 [00:00<00:00, 14.14it/s]\n",
            "sqlite-3.33.0        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00, 11.19it/s]\n",
            "h5py-2.10.0          | 901 KB    | : 100% 1.0/1 [00:00<00:00, 11.91it/s]\n",
            "numpy-base-1.19.2    | 4.1 MB    | : 100% 1.0/1 [00:00<00:00,  4.20it/s]\n",
            "rsa-4.7.2            | 28 KB     | : 100% 1.0/1 [00:00<00:00, 16.44it/s]\n",
            "astunparse-1.6.3     | 17 KB     | : 100% 1.0/1 [00:00<00:00, 17.14it/s]\n",
            "typing_extensions-4. | 28 KB     | : 100% 1.0/1 [00:00<00:00, 17.85it/s]\n",
            "libprotobuf-3.17.2   | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  8.78it/s]\n",
            "astor-0.8.1          | 47 KB     | : 100% 1.0/1 [00:00<00:00, 15.25it/s]\n",
            "tensorflow-gpu-2.2.0 | 3 KB      | : 100% 1.0/1 [00:00<00:00, 14.65it/s]\n",
            "numpy-1.19.2         | 22 KB     | : 100% 1.0/1 [00:00<00:00, 18.06it/s]\n",
            "dataclasses-0.8      | 22 KB     | : 100% 1.0/1 [00:00<00:00, 17.41it/s]\n",
            "werkzeug-2.0.3       | 221 KB    | : 100% 1.0/1 [00:00<00:00, 14.42it/s]\n",
            "wrapt-1.12.1         | 49 KB     | : 100% 1.0/1 [00:00<00:00, 17.12it/s]\n",
            "typing-extensions-4. | 8 KB      | : 100% 1.0/1 [00:00<00:00, 17.19it/s]\n",
            "cudatoolkit-10.1.243 | 347.4 MB  | : 100% 1.0/1 [00:07<00:00,  7.09s/it]               \n",
            "click-8.0.3          | 79 KB     | : 100% 1.0/1 [00:00<00:00, 13.02it/s]\n",
            "blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00, 15.69it/s]\n",
            "tensorboard-2.4.0    | 8.8 MB    | : 100% 1.0/1 [00:00<00:00,  4.75it/s]\n",
            "cryptography-3.4.7   | 903 KB    | : 100% 1.0/1 [00:00<00:00,  9.76it/s]\n",
            "pyasn1-0.4.8         | 54 KB     | : 100% 1.0/1 [00:00<00:00, 16.03it/s]\n",
            "tensorflow-estimator | 267 KB    | : 100% 1.0/1 [00:00<00:00, 14.24it/s]\n",
            "cffi-1.14.0          | 223 KB    | : 100% 1.0/1 [00:00<00:00, 14.24it/s]\n",
            "python-3.6.9         | 30.2 MB   | : 100% 1.0/1 [00:00<00:00,  1.57it/s]               \n",
            "multidict-5.1.0      | 66 KB     | : 100% 1.0/1 [00:00<00:00, 16.75it/s]\n",
            "scipy-1.5.2          | 14.4 MB   | : 100% 1.0/1 [00:00<00:00,  2.05it/s]               \n",
            "google-pasta-0.2.0   | 46 KB     | : 100% 1.0/1 [00:00<00:00, 17.25it/s]\n",
            "grpcio-1.36.1        | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  9.86it/s]\n",
            "markdown-3.3.4       | 127 KB    | : 100% 1.0/1 [00:00<00:00, 15.85it/s]\n",
            "c-ares-1.18.1        | 114 KB    | : 100% 1.0/1 [00:00<00:00, 15.32it/s]\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Installing pip dependencies: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/min2net/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/condaenv.5mhdda15.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn>=0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
            "Collecting wget>=3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting tensorflow-addons==0.9.1\n",
            "  Downloading tensorflow_addons-0.9.1-cp36-cp36m-manylinux2010_x86_64.whl (1.0 MB)\n",
            "Collecting typeguard>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/envs/min2net/lib/python3.6/site-packages (from scikit-learn>=0.24.2->-r /content/condaenv.5mhdda15.requirements.txt (line 1)) (1.5.2)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/envs/min2net/lib/python3.6/site-packages (from scikit-learn>=0.24.2->-r /content/condaenv.5mhdda15.requirements.txt (line 1)) (1.19.2)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py): started\n",
            "  Building wheel for wget (setup.py): finished with status 'done'\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=01ed0cda091b141cf7891e0a7c55e4be3d347a9336cf4bb599bb186d9f38f3f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/1d/93/c863ee832230df5cfc25ca497b3e88e0ee3ea9e44adc46ac62\n",
            "Successfully built wget\n",
            "Installing collected packages: typeguard, threadpoolctl, joblib, wget, tensorflow-addons, scikit-learn\n",
            "Successfully installed joblib-1.1.1 scikit-learn-0.24.2 tensorflow-addons-0.9.1 threadpoolctl-3.1.0 typeguard-2.13.3 wget-3.2\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate min2net\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install min2net\n",
        "! wget https://github.com/IoBT-VISTEC/MIN2Net/releases/download/v1.0.1/min2net-1.0.1-py3-none-any.whl\n",
        "! pip install min2net-1.0.1-py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJZ7j5iGfqZt",
        "outputId": "30fa722b-8e46-4226-b219-abc2af3da09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting min2net\n",
            "  Downloading min2net-1.0.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.24.1\n",
            "  Using cached scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
            "Collecting tensorflow-addons==0.9.1\n",
            "  Using cached tensorflow_addons-0.9.1-cp36-cp36m-manylinux2010_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.6/site-packages (from min2net) (58.0.4)\n",
            "Requirement already satisfied: wheel>=0.37.0 in /usr/local/lib/python3.6/site-packages (from min2net) (0.37.1)\n",
            "Collecting wget>=3.2\n",
            "  Using cached wget-3.2-py3-none-any.whl\n",
            "Collecting typeguard>=2.7\n",
            "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Using cached joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
            "Collecting scipy>=0.19.1\n",
            "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 383 kB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting numpy>=1.13.3\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 63.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy, typeguard, threadpoolctl, scipy, joblib, wget, tensorflow-addons, scikit-learn, min2net\n",
            "Successfully installed joblib-1.1.1 min2net-1.0.1 numpy-1.19.5 scikit-learn-0.24.2 scipy-1.5.4 tensorflow-addons-0.9.1 threadpoolctl-3.1.0 typeguard-2.13.3 wget-3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "--2022-12-13 17:43:42--  https://github.com/IoBT-VISTEC/MIN2Net/releases/download/v1.0.1/min2net-1.0.1-py3-none-any.whl\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/367768855/01697e89-2959-4692-b687-cbbe1f9f9f25?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221213T174342Z&X-Amz-Expires=300&X-Amz-Signature=ee28c2d81185bdc0cb011a0c7a939d0460fd2d176a1b314f47f2a604edeaad29&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=367768855&response-content-disposition=attachment%3B%20filename%3Dmin2net-1.0.1-py3-none-any.whl&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-13 17:43:42--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/367768855/01697e89-2959-4692-b687-cbbe1f9f9f25?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221213T174342Z&X-Amz-Expires=300&X-Amz-Signature=ee28c2d81185bdc0cb011a0c7a939d0460fd2d176a1b314f47f2a604edeaad29&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=367768855&response-content-disposition=attachment%3B%20filename%3Dmin2net-1.0.1-py3-none-any.whl&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58196 (57K) [application/octet-stream]\n",
            "Saving to: ‘min2net-1.0.1-py3-none-any.whl’\n",
            "\n",
            "min2net-1.0.1-py3-n 100%[===================>]  56.83K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-12-13 17:43:43 (4.16 MB/s) - ‘min2net-1.0.1-py3-none-any.whl’ saved [58196/58196]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./min2net-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (0.24.2)\n",
            "Requirement already satisfied: wheel>=0.37.0 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-addons==0.9.1 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (0.9.1)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (58.0.4)\n",
            "Requirement already satisfied: wget>=3.2 in /usr/local/lib/python3.6/site-packages (from min2net==1.0.1) (3.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/site-packages (from tensorflow-addons==0.9.1->min2net==1.0.1) (2.13.3)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net==1.0.1) (1.5.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net==1.0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net==1.0.1) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.24.1->min2net==1.0.1) (1.19.5)\n",
            "min2net is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!cd drive/MyDrive/Term\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, filtfilt\n",
        "import wget\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "from scipy.interpolate import CubicSpline \n",
        "from scipy import ndimage\n",
        "import argparse\n",
        "PATH = os.getcwd()\n",
        "\n",
        "print(PATH)\n",
        "\n",
        "folder_name = str(PATH)+'/datasets'\n",
        "print(folder_name)"
      ],
      "metadata": {
        "id": "R1qzHWR1nke6",
        "outputId": "22f3c28d-290d-47ed-ede4-6a55817b04e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!cd drive/MyDrive/Term"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD2SleoIlx9A",
        "outputId": "98eb382a-f5c6-44ac-9871-b67339357f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, filtfilt\n",
        "import wget\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "from scipy.interpolate import CubicSpline \n",
        "from scipy import ndimage\n",
        "import argparse\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "# !cd drive/MyDrive/Term\n",
        "PATH= '/content/drive/MyDrive/Term'\n",
        "# PATH = os.getcwd()\n",
        "print(PATH)\n",
        "\n",
        "folder_name = str(PATH)+'/datasets'\n",
        "print(folder_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8TT2JKBl9ze",
        "outputId": "baa76865-f321-4d2a-8edc-4c5267b649e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Term\n",
            "/content/drive/MyDrive/Term/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, filtfilt\n",
        "import wget\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "from scipy.interpolate import CubicSpline \n",
        "from scipy import ndimage\n",
        "import argparse\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "# !cd drive/MyDrive/Term\n",
        "PATH= '/content/drive/MyDrive/Term'\n",
        "# PATH = os.getcwd()\n",
        "print(PATH)\n",
        "\n",
        "folder_name = str(PATH)+'/datasets'\n",
        "print(folder_name)\n",
        "# lib path\n",
        "# PATH = os.path.dirname(os.path.realpath(__file__))\n",
        "\n",
        "# def load_raw(dataset):\n",
        "  \n",
        "#     PATH= '/content/drive/MyDrive/Term'\n",
        "#     folder_name = str(PATH)+'/datasets'\n",
        "#     # folder_name = 'datasets'\n",
        "#     if dataset == 'OpenBMI':\n",
        "#         try:\n",
        "#             num_subjects = 54\n",
        "#             sessions = [1, 2]\n",
        "#             save_path = folder_name + '/' + dataset + '/raw'\n",
        "#             if save_path is not None:\n",
        "#                 if not os.path.exists(save_path):\n",
        "#                     os.makedirs(save_path)\n",
        "#             for session in sessions:\n",
        "#                 for person in range(1, num_subjects+1):\n",
        "#                     file_name = '/sess{:02d}_subj{:02d}_EEG_MI.mat'.format(session,person)\n",
        "#                     if os.path.exists(save_path+file_name):\n",
        "#                         os.remove(save_path+file_name) # if exist, remove file\n",
        "#                     print('\\n===Download is being processed on session: {} subject: {}==='.format(session, person))\n",
        "#                     url = 'ftp://parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100542/session{}/s{}{}'.format(session, person, file_name)\n",
        "#                     print('save to: '+save_path+file_name)\n",
        "#                     wget.download(url,  save_path+file_name)\n",
        "#             print('\\nDone!')\n",
        "#         except:\n",
        "#             raise Exception('Path Error: file does not exist, please direccly download at http://gigadb.org/dataset/100542')\n",
        "#     elif dataset == 'BCIC2a':\n",
        "#         try:\n",
        "#             num_subjects = 9\n",
        "#             sessions = ['T', 'E']\n",
        "#             save_path = folder_name + '/' + dataset + '/raw'\n",
        "#             if save_path is not None:\n",
        "#                 if not os.path.exists(save_path):\n",
        "#                     os.makedirs(save_path)\n",
        "\n",
        "#             for session in sessions:\n",
        "#                 for person in range(1, num_subjects+1):\n",
        "#                     file_name = '/A{:02d}{}.mat'.format(person, session)\n",
        "#                     if os.path.exists(save_path+file_name):\n",
        "#                         os.remove(save_path+file_name) # if exist, remove file\n",
        "#                     print('\\n===Download is being processed on session: {} subject: {}==='.format(session, person))\n",
        "#                     url = 'https://lampx.tugraz.at/~bci/database/001-2014'+file_name\n",
        "#                     print('save to: '+save_path+file_name)\n",
        "#                     wget.download(url, save_path+file_name)\n",
        "#             print('\\nDone!')\n",
        "#         except:\n",
        "#             raise Exception('Path Error: file does not exist, please direccly download at http://bnci-horizon-2020.eu/database/data-sets')\n",
        "#     elif dataset == 'SMR_BCI':\n",
        "#         try:\n",
        "#             num_subjects = 14\n",
        "#             sessions = ['T', 'E']\n",
        "#             save_path = folder_name + '/' + dataset + '/raw'\n",
        "#             print(save_path)\n",
        "#             if save_path is not None:\n",
        "#                 if not os.path.exists(save_path):\n",
        "#                     os.makedirs(save_path)\n",
        "#             for session in sessions:\n",
        "#                 for person in range(1, num_subjects+1):\n",
        "#                     file_name = '/S{:02d}{}.mat'.format(person, session)\n",
        "#                     if os.path.exists(save_path+file_name):\n",
        "#                         os.remove(save_path+file_name) # if exist, remove file\n",
        "#                     print('\\n===Download is being processed on session: {} subject: {}==='.format(session, person))\n",
        "#                     # url = 'https://lampx.tugraz.at/~bci/database/002-2014'+file_name\n",
        "#                     url='https://drive.google.com/uc?id=1AJV8otG_SWXOou3LbJTJsRaSls2AlTZH'\n",
        "#                     print('save to: '+save_path+file_name)\n",
        "#                     print(save_path)\n",
        "#                     wget.download(url,  save_path+file_name) # 이거 느낌표 안먹힐텐데..\n",
        "#                     #혹시 데이터 몇개야?\n",
        "#             print('\\nDone!')\n",
        "#         except:\n",
        "#             raise Exception('Path Error: file does not exist, please direccly download at http://bnci-horizon-2020.eu/database/data-sets')\n"
      ],
      "metadata": {
        "id": "l8gVNcAc1r2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4bef18-60a4-45e3-9d9f-9198951f3660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Term\n",
            "/content/drive/MyDrive/Term/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, dataset, train_type=None, data_type=None, num_class=2, subject=None, data_format=None, dataset_path='/datasets', **kwargs):\n",
        "\n",
        "        self.dataset = dataset #Dataset name: 'OpenBMI', 'SMR_BCI', 'BCIC2a'\n",
        "        self.train_type = train_type # 'subject_dependent', 'subject_independent'\n",
        "        self.data_type = data_type # 'fbcsp', 'spectral_spatial', 'time_domain'\n",
        "        self.dataset_path = dataset_path\n",
        "        self.subject = subject # id, start at 1\n",
        "        self.data_format = data_format # 'channels_first', 'channels_last'\n",
        "        self.fold = None # fold, start at 1\n",
        "        self.prefix_name = 'S'\n",
        "        self.num_class = num_class\n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "\n",
        "\n",
        "        self.path = self.dataset_path+'/'+self.dataset+'/'+self.data_type+'/'+str(self.num_class)+'_class/'+self.train_type\n",
        "    \n",
        "    def _change_data_format(self, X):\n",
        "        if self.data_format == 'NCTD':\n",
        "            # (#n_trial, #channels, #time, #depth)\n",
        "            X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
        "        elif self.data_format == 'NDCT':\n",
        "            # (#n_trial, #depth, #channels, #time)\n",
        "            X = X.reshape(X.shape[0], 1, X.shape[1], X.shape[2])\n",
        "        elif self.data_format == 'NTCD':\n",
        "            # (#n_trial, #time, #channels, #depth)\n",
        "            X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
        "            X = np.swapaxes(X, 1, 3)\n",
        "        elif self.data_format == 'NSHWD':\n",
        "            # (#n_trial, #Freqs, #height, #width, #depth)\n",
        "            X = zero_padding(X)\n",
        "            X = X.reshape(X.shape[0], X.shape[1], X.shape[2], X.shape[3], 1)\n",
        "        elif self.data_format == None:\n",
        "            pass\n",
        "        else:\n",
        "            raise Exception('Value Error: data_format requires None, \\'NCTD\\', \\'NDCT\\', \\'NTCD\\' or \\'NSHWD\\', found data_format={}'.format(self.data_format))\n",
        "        print('change data_format to \\'{}\\', new dimention is {}'.format(self.data_format, X.shape))\n",
        "        return X\n",
        "\n",
        "    def load_train_set(self, fold, **kwargs):\n",
        "        self.fold = fold\n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "    \n",
        "        # load \n",
        "        X, y =  np.array([]),  np.array([])\n",
        "        try:\n",
        "            self.file_x = self.path+'/X_train_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            self.file_y = self.path+'/y_train_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            X = self._change_data_format(np.load(self.file_x))\n",
        "            y = np.load(self.file_y)\n",
        "        except:\n",
        "            raise Exception('Path Error: file does not exist, please check this path {}, and {}'.format(self.file_x, self.file_y))\n",
        "        return X, y\n",
        "\n",
        "    def load_val_set(self, fold, **kwargs):\n",
        "        self.fold = fold\n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "\n",
        "        # load \n",
        "        X, y =  np.array([]),  np.array([])\n",
        "        try:\n",
        "            self.file_x = self.path+'/X_val_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            self.file_y = self.path+'/y_val_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            X = self._change_data_format(np.load(self.file_x))\n",
        "            y = np.load(self.file_y)\n",
        "        except:\n",
        "            raise Exception('Path Error: file does not exist, please check this path {}, and {}'.format(self.file_x, self.file_y))\n",
        "        return X, y\n",
        "    \n",
        "    def load_test_set(self, fold, **kwargs):\n",
        "        self.fold = fold\n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "\n",
        "        # load \n",
        "        X, y =  np.array([]),  np.array([])\n",
        "        try:\n",
        "            self.file_x = self.path+'/X_test_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            self.file_y = self.path+'/y_test_{}{:03d}_fold{:03d}.npy'.format(self.prefix_name, self.subject, self.fold)\n",
        "            X = self._change_data_format(np.load(self.file_x))\n",
        "            y = np.load(self.file_y)\n",
        "        except:\n",
        "            raise Exception('Path Error: file does not exist, please check this path {}, and {}'.format(self.file_x, self.file_y))\n",
        "        return X, y\n",
        "\n",
        "def compute_class_weight(y_train):\n",
        "    \"\"\"compute class balancing\n",
        "    Args:\n",
        "        y_train (list, ndarray): [description]\n",
        "    Returns:\n",
        "        (dict): class weight balancing\n",
        "    \"\"\"\n",
        "    return dict(zip(np.unique(y_train), \n",
        "                    class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                      classes=np.unique(y_train),\n",
        "                                                      y=y_train))) \n",
        "        \n",
        "def str2bool(v):\n",
        "    if isinstance(v, bool):\n",
        "       return v\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, save_path=None):\n",
        "        self.save_path = save_path\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.logs = []\n",
        "        if self.save_path:\n",
        "            write_log(filepath=self.save_path, data=['time_log'], mode='w')\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.start_time = time.time()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        time_diff = time.time()-self.start_time\n",
        "        self.logs.append(time_diff)\n",
        "        if self.save_path:\n",
        "            write_log(filepath=self.save_path, data=[time_diff], mode='a')\n",
        "\n",
        "def write_log(filepath='test.log', data=[], mode='w'):\n",
        "    '''\n",
        "    filepath: path to save\n",
        "    data: list of data\n",
        "    mode: a = update data to file, w = write a new file\n",
        "    '''\n",
        "    try:\n",
        "        with open(filepath, mode) as csvFile:\n",
        "            writer = csv.writer(csvFile)\n",
        "            writer.writerow(data)\n",
        "    except IOError:\n",
        "        raise Exception('I/O error')\n",
        "\n",
        "def zero_padding(data, pad_size=4):\n",
        "    if len(data.shape) != 4:\n",
        "        raise Exception('Dimension is not match!, must have 4 dims')\n",
        "    new_shape = int(data.shape[2]+(2*pad_size))\n",
        "    data_pad = np.zeros((data.shape[0], data.shape[1], new_shape, new_shape))\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            data_pad[i,j,:,:] = np.pad(data[i,j,:,:], [pad_size, pad_size], mode='constant')\n",
        "    print(data_pad.shape)\n",
        "    return data_pad \n",
        "\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def resampling(data, new_smp_freq, data_len):\n",
        "    if len(data.shape) != 3:\n",
        "        raise Exception('Dimesion error', \"--> please use three-dimensional input\")\n",
        "    new_smp_point = int(data_len*new_smp_freq)\n",
        "    data_resampled = np.zeros((data.shape[0], data.shape[1], new_smp_point))\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            data_resampled[i,j,:] = signal.resample(data[i,j,:], new_smp_point)\n",
        "    return data_resampled\n",
        "\n",
        "def psd_welch(data, smp_freq):\n",
        "    if len(data.shape) != 3:\n",
        "        raise Exception(\"Dimension Error, must have 3 dimension\")\n",
        "    n_samples,n_chs,n_points = data.shape\n",
        "    data_psd = np.zeros((n_samples,n_chs,89))\n",
        "    for i in range(n_samples):\n",
        "        for j in range(n_chs):\n",
        "            freq, power_den = signal.welch(data[i,j], smp_freq, nperseg=n_points)\n",
        "            index = np.where((freq>=8) & (freq<=30))[0].tolist()\n",
        "            # print(\"the length of---\", len(index))\n",
        "            data_psd[i,j] = power_den[index]\n",
        "    return data_psd\n",
        "    "
      ],
      "metadata": {
        "id": "a-1aXK5vwbC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess dada"
      ],
      "metadata": {
        "id": "OpUnRxfNWc9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import min2net\n",
        "# import min2net.preprocessing as prep\n",
        "\n",
        "# load_raw('SMR_BCI')\n",
        "# 이건 인터넷에있는 거 다운로드해서 matlab(.mat)로 저장하는거\n",
        "#.... 클래스 안에 있는거 코드만 끌어오면 이름 바꿔야 되나본데? 이해했니???설마 나한테 이거 맡겨놓고 씻으러가다거나 그런건가\n",
        "\n",
        "# min2net.utils.load_raw('OpenBMI')\n"
      ],
      "metadata": {
        "id": "VHtg7Tu5WdVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from min2net.utils import PATH\n",
        "\n",
        "CONSTANT = {\n",
        "    'BCIC2a': {\n",
        "        'raw_path': 'datasets/BCIC2a/raw', # raw data path 'raw_path': 'datasets/BCIC2a'\n",
        "        'n_subjs': 9,\n",
        "        'n_trials': 144,\n",
        "        'n_trials_per_class': 72,\n",
        "        'n_chs': 20,\n",
        "        'orig_smp_freq': 250,                  # Original sampling frequency (Hz)\n",
        "        'trial_len': 7,                        # 7s\n",
        "        'MI': {\n",
        "            'start': 2,                        # start at time = 2 s\n",
        "            'stop': 6,                         # stop at time = 6 s\n",
        "            'len': 4,                          # 4s\n",
        "        },\n",
        "        'orig_chs': ['FC3', 'FC1', 'FCz', 'FC2', 'FC4',\n",
        "                    'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6',\n",
        "                    'CP3', 'CP1', 'CPz', 'CP2', 'CP4',\n",
        "                    'P1', 'Pz', 'P2'],\n",
        "        'sel_chs': ['FC3', 'FC1', 'FCz', 'FC2', 'FC4', \n",
        "                    'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6',\n",
        "                    'CP3', 'CP1', 'CPz', 'CP2', 'CP4',\n",
        "                    'P1', 'Pz', 'P2'] \n",
        "    },\n",
        "    'SMR_BCI': {\n",
        "        'raw_path': '/content/drive/MyDrive/Term/datasets/SMR_BCI/raw', # raw data path\n",
        "        'n_subjs': 15,\n",
        "        'n_trials_tr': 50,\n",
        "        'n_trials_te': 30, \n",
        "        'n_chs': 63,\n",
        "        'orig_smp_freq': 512,                   # Original sampling frequency  (Hz)\n",
        "        'trial_len': 6,                         # 7s\n",
        "        'MI': {\n",
        "            'start': 0,                         # start at time = 4 s\n",
        "            'stop': 6,                          # stop at time = 8 s\n",
        "            'len': 6,                           # 4s\n",
        "        },\n",
        "        # 'orig_chs': ['FCC3',                   'FCCz',                 'FCC4',\n",
        "        #             'C5h', 'C3', 'C3h',       'C1h', 'Cz', 'C2h',       'C4h', 'C4', 'C6h',\n",
        "        #                    'CCP3',                   'CCPz',                 'CCP4'],\n",
        "        'orig_chs': ['Fp1', 'Fp2', 'F7', 'FCC3', 'FCCz', 'FCC4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'T7', \n",
        "                    'C3','Cz','C4', 'T8', 'TP9', 'C5h', 'CP1', 'CP2', 'CP6', 'TP10', 'P7', 'CCP3', \n",
        "                    'CCPz', 'CCP4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10', 'FC3', 'FC4', 'C5', 'C1h',\n",
        "                    'C2h', 'C6h', 'C3h','CPz', 'C4h', 'P1', 'P2', 'POz', 'FT9', 'FTT9h', 'TTP7h', \n",
        "                    'TP7', 'TPP9h', 'FT10','FTT10h','TPP8h', 'TP8', 'TPP10h', 'F9', 'F10', \n",
        "                    'AF7', 'AF3', 'AF4', 'AF8', 'PO3','PO4','M'],\n",
        "        'sel_chs': ['Fp1', 'Fp2', 'F7', 'FCC3', 'FCCz', 'FCC4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'T7', \n",
        "                    'C3','Cz','C4', 'T8', 'TP9', 'C5h', 'CP1', 'CP2', 'CP6', 'TP10', 'P7', 'CCP3', \n",
        "                    'CCPz', 'CCP4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10', 'FC3', 'FC4', 'C5', 'C1h',\n",
        "                    'C2h', 'C6h', 'C3h','CPz', 'C4h', 'P1', 'P2', 'POz', 'FT9', 'FTT9h', 'TTP7h', \n",
        "                    'TP7', 'TPP9h', 'FT10','FTT10h','TPP8h', 'TP8', 'TPP10h', 'F9', 'F10', \n",
        "                    'AF7', 'AF3', 'AF4', 'AF8', 'PO3','PO4','M']\n",
        "        # 'sel_chs': [       'FCC3',                   'FCCz',                 'FCC4', \n",
        "        #             'C5h', 'C3', 'C3h',       'C1h', 'Cz', 'C2h',       'C4h','C4', 'C6h', \n",
        "        #                    'CCP3',                   'CCPz',                 'CCP4']  \n",
        "    },\n",
        "    'OpenBMI': {\n",
        "        'raw_path': 'datasets/OpenBMI/raw', # raw data path\n",
        "        'n_subjs': 54,\n",
        "        'n_trials_2_class': 100,\n",
        "        'n_trials_3_class': 150, \n",
        "        'n_chs': 62,\n",
        "        'orig_smp_freq': 1000,                  # Original sampling frequency  (Hz)\n",
        "        'trial_len': 8,                         # 8s (cut-off)\n",
        "        'MI': {\n",
        "            'start': 0,                         # start at time = 0 s\n",
        "            'stop': 4,                          # stop at time = 0 s\n",
        "            'len': 4,                           # 4s\n",
        "        },\n",
        "        'orig_chs': ['Fp1', 'Fp2', 'F7', 'FCC3', 'FCCz', 'FCC4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'T7', \n",
        "                    'C3','Cz','C4', 'T8', 'TP9', 'CP5', 'CP1', 'CP2', 'CP6', 'TP10', 'P7', 'P3', \n",
        "                    'Pz', 'P4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10', 'FC3', 'FC4', 'C5', 'C1',\n",
        "                    'C2', 'C6', 'CP3','CPz', 'CP4', 'P1', 'P2', 'POz', 'FT9', 'FTT9h', 'TTP7h', \n",
        "                    'TP7', 'TPP9h', 'FT10','FTT10h','TPP8h', 'TP8', 'TPP10h', 'F9', 'F10', \n",
        "                    'AF7', 'AF3', 'AF4', 'AF8', 'PO3','PO4'],\n",
        "        'sel_chs': ['FC5', 'FC3', 'FC1', 'FC2', 'FC4','FC6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', \n",
        "                    'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6']  \n",
        "    }\n",
        "\n",
        "}\n",
        "CONSTANT = CONSTANT['SMR_BCI']\n",
        "\n"
      ],
      "metadata": {
        "id": "T3z808Zsoj__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "# from min2net.utils import resampling\n",
        "# from min2net.preprocessing.config import CONSTANT\n",
        "# load variable form config file\n",
        "orig_chs = CONSTANT['orig_chs']\n",
        "orig_smp_freq = CONSTANT['orig_smp_freq']\n",
        "trial_len = CONSTANT['trial_len'] \n",
        "n_chs = CONSTANT['n_chs'] # 15\n",
        "window_len = CONSTANT['trial_len']*CONSTANT['orig_smp_freq'] # 8*512\n",
        "\n",
        "def read_raw(PATH, subject , training, id_chosen_chs):\n",
        "    if training:\n",
        "        mat = sio.loadmat(PATH+'/P'+str(subject).zfill(2)+'T.mat')['Data']\n",
        "        n_trials = CONSTANT['n_trials_tr'] # 100\n",
        "        label = np.zeros(n_trials)\n",
        "        data = np.zeros((n_trials, n_chs, window_len))\n",
        "    else:\n",
        "        mat = sio.loadmat(PATH+'/P'+str(subject).zfill(2)+'E.mat')['Data']\n",
        "        n_trials = CONSTANT['n_trials_te'] # 60\n",
        "        label = np.zeros(n_trials)\n",
        "        data = np.zeros((n_trials, n_chs, window_len))\n",
        "    NO_valid_trial = 0\n",
        "    for ii in range(0,mat.size):\n",
        "        mat_1 = mat[0,ii]\n",
        "        mat_2 = [mat_1[0,0]]\n",
        "        mat_info = mat_2[0]\n",
        "        _X = mat_info[3]\n",
        "        _trial = mat_info[2]\n",
        "        _y = mat_info[4]\n",
        "        _fs = mat_info[0]\n",
        "        _classes = mat_info[1]\n",
        "        # _X = mat_info[0]\n",
        "        # _trial = mat_info[1]\n",
        "        # _y = mat_info[2]\n",
        "        # _fs = mat_info[3]\n",
        "        # _classes = mat_info[4]\n",
        "        for trial in range(0, _trial.size):\n",
        "            # class 1 (right hand) and class 2 (feet) \n",
        "            _data = np.transpose(_X[_trial[0][trial]:int(_trial[0][trial]+window_len),id_chosen_chs])\n",
        "            _label = int(_y[0][trial])\n",
        "            data[NO_valid_trial,:,:] =  _data\n",
        "            label[NO_valid_trial] = _label\n",
        "            NO_valid_trial +=1\n",
        "    return data, label-1\n",
        "\n",
        "def chanel_selection(sel_chs): \n",
        "    chs_id = []\n",
        "    for name_ch in sel_chs:\n",
        "        ch_id = np.where(np.array(orig_chs) == name_ch)[0][0]\n",
        "        chs_id.append(ch_id)\n",
        "        print('chosen_channel:', name_ch, '---', 'Index_is:', ch_id)\n",
        "    return chs_id\n",
        "\n",
        "def load_crop_data(PATH, subject, start, stop, new_smp_freq, id_chosen_chs):\n",
        "    start_time = int(start*new_smp_freq) # 4*\n",
        "    stop_time = int(stop*new_smp_freq) # 8*\n",
        "    X_train, y_tr = read_raw(PATH=PATH, subject=subject, training=True, id_chosen_chs=id_chosen_chs)\n",
        "    X_test, y_te = read_raw(PATH=PATH, subject=subject, training=False, id_chosen_chs=id_chosen_chs)\n",
        "    if new_smp_freq < orig_smp_freq:\n",
        "        X_train = resampling(X_train, new_smp_freq, trial_len)\n",
        "        X_test = resampling(X_test, new_smp_freq, trial_len)\n",
        "    X_train = X_train[:,:,start_time:stop_time]\n",
        "    X_test = X_test[:,:,start_time:stop_time]\n",
        "    return X_train, y_tr, X_test, y_te  "
      ],
      "metadata": {
        "id": "MYvJqFFnooXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split \n",
        "import os\n",
        "# from min2net.utils import butter_bandpass_filter\n",
        "# from min2net.preprocessing.SMR_BCI import raw\n",
        "# from min2net.preprocessing.config import CONSTANT\n",
        "raw_path = CONSTANT['raw_path']\n",
        "n_subjs = CONSTANT['n_subjs']\n",
        "n_trials_tr = CONSTANT['n_trials_tr'] \n",
        "n_trials_te = CONSTANT['n_trials_te']\n",
        "n_chs = CONSTANT['n_chs']\n",
        "orig_smp_freq = CONSTANT['orig_smp_freq']\n",
        "MI_len = CONSTANT['MI']['len']\n",
        "\n",
        "def subject_dependent_setting(k_folds, pick_smp_freq, bands, order, save_path, num_class=2, sel_chs=None):\n",
        "    sel_chs = CONSTANT['sel_chs'] if sel_chs == None else sel_chs\n",
        "    n_folds = k_folds\n",
        "    save_path = save_path + '/SMR_BCI/time_domain/{}_class/subject_dependent'.format(num_class)\n",
        "\n",
        "    X_train_all, y_train_all = np.zeros((n_subjs, n_trials_tr, n_chs, int(MI_len*pick_smp_freq))), np.zeros((n_subjs, n_trials_tr))\n",
        "    X_test_all, y_test_all = np.zeros((n_subjs, n_trials_te, n_chs, int(MI_len*pick_smp_freq))), np.zeros((n_subjs, n_trials_te))\n",
        "\n",
        "    id_chosen_chs = chanel_selection(sel_chs)\n",
        "    for s in range(n_subjs):\n",
        "        X_train, y_train, X_test, y_test = __load_SMR_BCI(raw_path, s+1, pick_smp_freq, id_chosen_chs)\n",
        "        X_train_all[s], y_train_all[s] = X_train, y_train\n",
        "        X_test_all[s], y_test_all[s] = X_test, y_test\n",
        "\n",
        "    for directory in [save_path]:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "    # Carry out subject-dependent setting with 5-fold cross validation\n",
        "    for person, (X_tr, y_tr, X_te, y_te) in enumerate(zip(X_train_all, y_train_all, X_test_all, y_test_all)):\n",
        "        if len(X_tr.shape) != 3:\n",
        "            raise Exception('Dimension Error, must have 3 dimension')\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
        "        for fold, (train_index, val_index) in enumerate(skf.split(X_tr , y_tr)):\n",
        "            print('FOLD:', fold+1, 'TRAIN:', len(train_index), 'VALIDATION:', len(val_index))\n",
        "            X_tr_cv, X_val_cv = X_tr[train_index], X_tr[val_index]\n",
        "            y_tr_cv, y_val_cv = y_tr[train_index], y_tr[val_index]\n",
        "\n",
        "            print('Band-pass filtering from {} to {} Hz.'.format(bands[0],  bands[1]))\n",
        "            X_tr_fil = butter_bandpass_filter(X_tr_cv,  bands[0],  bands[1], pick_smp_freq, order)\n",
        "            X_val_fil = butter_bandpass_filter(X_val_cv,  bands[0],  bands[1], pick_smp_freq, order)\n",
        "            X_te_fil = butter_bandpass_filter(X_te,  bands[0],  bands[1], pick_smp_freq, order)\n",
        "            print('Check dimension of training data {}, val data {} and testing data {}'.format(X_tr_fil.shape, X_val_fil.shape, X_te_fil.shape))\n",
        "            SAVE_NAME = 'S{:03d}_fold{:03d}'.format(person+1, fold+1)\n",
        "            __save_data_with_valset(save_path, SAVE_NAME, X_tr_fil, y_tr_cv, X_val_fil, y_val_cv, X_te_fil, y_te)\n",
        "            print('The preprocessing of subject {} from fold {} is DONE!!!'.format(person+1, fold+1))\n",
        "\n",
        "def subject_independent_setting(k_folds, pick_smp_freq, bands, order, save_path, num_class=2, sel_chs=None):\n",
        "    sel_chs = CONSTANT['sel_chs'] if sel_chs == None else sel_chs\n",
        "    n_folds = k_folds\n",
        "    save_path = save_path + '/SMR_BCI/time_domain/{}_class/subject_independent'.format(num_class)\n",
        "\n",
        "    X_train_all, y_train_all = np.zeros((n_subjs, n_trials_tr, n_chs, int(MI_len*pick_smp_freq))), np.zeros((n_subjs, n_trials_tr))\n",
        "    X_test_all, y_test_all = np.zeros((n_subjs, n_trials_te, n_chs, int(MI_len*pick_smp_freq))), np.zeros((n_subjs, n_trials_te))\n",
        "\n",
        "    id_chosen_chs = chanel_selection(sel_chs)\n",
        "    for s in range(n_subjs):\n",
        "        X_train, y_train, X_test, y_test = __load_SMR_BCI(raw_path, s+1, pick_smp_freq, id_chosen_chs)\n",
        "        X_train_all[s], y_train_all[s] = X_train, y_train\n",
        "        X_test_all[s], y_test_all[s] = X_test, y_test\n",
        "\n",
        "    for directory in [save_path]:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "    # Carry out subject-independent setting with 5-fold cross validation\n",
        "    for person, (X_val, y_val, X_te, y_te) in enumerate(zip(X_train_all, y_train_all, X_test_all, y_test_all)):\n",
        "        train_subj = [i for i in range(n_subjs)]\n",
        "        train_subj = np.delete(train_subj, person) # remove test subject\n",
        "\n",
        "         # Generating fake data to used for k-fold cross-validation only\n",
        "        fake_tr = np.zeros((len(train_subj), 2))\n",
        "        fake_tr_la = np.zeros((len(train_subj)))\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
        "        for fold, (train_ind, val_ind) in enumerate(skf.split(fake_tr , fake_tr_la)):\n",
        "            print('FOLD:', fold+1, 'TRAIN:', len(train_ind), 'VALIDATION:', len(val_ind))\n",
        "            train_index, val_index = train_subj[train_ind], train_subj[val_ind]\n",
        "            X_train_cat = np.concatenate((X_train_all[train_index].reshape(-1,n_chs,int(MI_len*pick_smp_freq)), X_test_all[train_index].reshape(-1,n_chs,int(MI_len*pick_smp_freq))), axis=0)\n",
        "            X_val_cat = np.concatenate((X_train_all[val_index].reshape(-1,n_chs,int(MI_len*pick_smp_freq)), X_test_all[val_index].reshape(-1,n_chs,int(MI_len*pick_smp_freq))), axis=0)\n",
        "            y_train_cat = np.concatenate((y_train_all[train_index].reshape(-1), y_test_all[train_index].reshape(-1)), axis=0)\n",
        "            y_val_cat = np.concatenate((y_train_all[val_index].reshape(-1), y_test_all[val_index].reshape(-1)), axis=0)\n",
        "\n",
        "            # Performing bandpass-filtering\n",
        "            print('Band-pass filtering from {} to {} Hz.'.format(bands[0],  bands[1]))\n",
        "            X_train_fil =  butter_bandpass_filter(X_train_cat, bands[0],  bands[1], pick_smp_freq, order)\n",
        "            X_val_fil = butter_bandpass_filter(X_val_cat, bands[0],  bands[1], pick_smp_freq, order)\n",
        "            X_test_fil = butter_bandpass_filter(X_te, bands[0],  bands[1], pick_smp_freq, order)\n",
        "\n",
        "            print('Verify the final dimesion of training data {}, val data {} and testing data {}'.format(X_train_fil.shape, X_val_fil.shape,X_test_fil.shape))\n",
        "            SAVE_NAME = 'S{:03d}_fold{:03d}'.format(person+1, fold+1)\n",
        "            __save_data_with_valset(save_path, SAVE_NAME, X_train_fil, y_train_cat, X_val_fil, y_val_cat, X_test_fil, y_te)\n",
        "            print('The preprocessing of subject {} from fold {} is DONE!!!'.format(person+1, fold+1))\n",
        "                      \n",
        "def __load_SMR_BCI(PATH, subject, new_smp_freq, id_chosen_chs):\n",
        "    start = CONSTANT['MI']['start'] # 4\n",
        "    stop = CONSTANT['MI']['stop'] # 8\n",
        "    X_train, y_tr, X_test, y_te  = load_crop_data(PATH=PATH, subject=subject, start=start, stop=stop, new_smp_freq=new_smp_freq, id_chosen_chs=id_chosen_chs)\n",
        "    return X_train, y_tr, X_test, y_te\n",
        "\n",
        "def __save_data_with_valset(save_path, NAME, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    np.save(save_path+'/X_train_'+NAME+'.npy', X_train)\n",
        "    np.save(save_path+'/X_val_'+NAME+'.npy', X_val)\n",
        "    np.save(save_path+'/X_test_'+NAME+'.npy', X_test)\n",
        "    np.save(save_path+'/y_train_'+NAME+'.npy', y_train)\n",
        "    np.save(save_path+'/y_val_'+NAME+'.npy', y_val)\n",
        "    np.save(save_path+'/y_test_'+NAME+'.npy', y_test)\n",
        "    print('save DONE')\n"
      ],
      "metadata": {
        "id": "NS384SKZoj1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prep.SMR_BCI.time_domain.\n",
        "subject_dependent_setting(k_folds=5,\n",
        "                                                 pick_smp_freq=100, \n",
        "                                                 bands=[0.1, 30], \n",
        "                                                 order=3, \n",
        "                                                 save_path='datasets')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__9yZ0H7Dylq",
        "outputId": "02935acd-c255-4b40-e4a4-5cc93c015061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chosen_channel: Fp1 --- Index_is: 0\n",
            "chosen_channel: Fp2 --- Index_is: 1\n",
            "chosen_channel: F7 --- Index_is: 2\n",
            "chosen_channel: FCC3 --- Index_is: 3\n",
            "chosen_channel: FCCz --- Index_is: 4\n",
            "chosen_channel: FCC4 --- Index_is: 5\n",
            "chosen_channel: F8 --- Index_is: 6\n",
            "chosen_channel: FC5 --- Index_is: 7\n",
            "chosen_channel: FC1 --- Index_is: 8\n",
            "chosen_channel: FC2 --- Index_is: 9\n",
            "chosen_channel: FC6 --- Index_is: 10\n",
            "chosen_channel: T7 --- Index_is: 11\n",
            "chosen_channel: C3 --- Index_is: 12\n",
            "chosen_channel: Cz --- Index_is: 13\n",
            "chosen_channel: C4 --- Index_is: 14\n",
            "chosen_channel: T8 --- Index_is: 15\n",
            "chosen_channel: TP9 --- Index_is: 16\n",
            "chosen_channel: C5h --- Index_is: 17\n",
            "chosen_channel: CP1 --- Index_is: 18\n",
            "chosen_channel: CP2 --- Index_is: 19\n",
            "chosen_channel: CP6 --- Index_is: 20\n",
            "chosen_channel: TP10 --- Index_is: 21\n",
            "chosen_channel: P7 --- Index_is: 22\n",
            "chosen_channel: CCP3 --- Index_is: 23\n",
            "chosen_channel: CCPz --- Index_is: 24\n",
            "chosen_channel: CCP4 --- Index_is: 25\n",
            "chosen_channel: P8 --- Index_is: 26\n",
            "chosen_channel: PO9 --- Index_is: 27\n",
            "chosen_channel: O1 --- Index_is: 28\n",
            "chosen_channel: Oz --- Index_is: 29\n",
            "chosen_channel: O2 --- Index_is: 30\n",
            "chosen_channel: PO10 --- Index_is: 31\n",
            "chosen_channel: FC3 --- Index_is: 32\n",
            "chosen_channel: FC4 --- Index_is: 33\n",
            "chosen_channel: C5 --- Index_is: 34\n",
            "chosen_channel: C1h --- Index_is: 35\n",
            "chosen_channel: C2h --- Index_is: 36\n",
            "chosen_channel: C6h --- Index_is: 37\n",
            "chosen_channel: C3h --- Index_is: 38\n",
            "chosen_channel: CPz --- Index_is: 39\n",
            "chosen_channel: C4h --- Index_is: 40\n",
            "chosen_channel: P1 --- Index_is: 41\n",
            "chosen_channel: P2 --- Index_is: 42\n",
            "chosen_channel: POz --- Index_is: 43\n",
            "chosen_channel: FT9 --- Index_is: 44\n",
            "chosen_channel: FTT9h --- Index_is: 45\n",
            "chosen_channel: TTP7h --- Index_is: 46\n",
            "chosen_channel: TP7 --- Index_is: 47\n",
            "chosen_channel: TPP9h --- Index_is: 48\n",
            "chosen_channel: FT10 --- Index_is: 49\n",
            "chosen_channel: FTT10h --- Index_is: 50\n",
            "chosen_channel: TPP8h --- Index_is: 51\n",
            "chosen_channel: TP8 --- Index_is: 52\n",
            "chosen_channel: TPP10h --- Index_is: 53\n",
            "chosen_channel: F9 --- Index_is: 54\n",
            "chosen_channel: F10 --- Index_is: 55\n",
            "chosen_channel: AF7 --- Index_is: 56\n",
            "chosen_channel: AF3 --- Index_is: 57\n",
            "chosen_channel: AF4 --- Index_is: 58\n",
            "chosen_channel: AF8 --- Index_is: 59\n",
            "chosen_channel: PO3 --- Index_is: 60\n",
            "chosen_channel: PO4 --- Index_is: 61\n",
            "chosen_channel: M --- Index_is: 62\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 10 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 11 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 12 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 13 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 14 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 40 VALIDATION: 10\n",
            "Band-pass filtering from 0.1 to 30 Hz.\n",
            "Check dimension of training data (40, 63, 600), val data (10, 63, 600) and testing data (30, 63, 600)\n",
            "save DONE\n",
            "The preprocessing of subject 15 from fold 5 is DONE!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Create DataLoader"
      ],
      "metadata": {
        "id": "3IhZkgNJW_cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=10, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n"
      ],
      "metadata": {
        "id": "uZhGpGOaW_9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49002027-2cf5-4e57-d828-0aaa4c5abecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.1.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.9.2 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "axilFwgjt2F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIN2NET"
      ],
      "metadata": {
        "id": "buhJeFIGbd33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.3,\n",
        "                patience=5, \n",
        "                es_patience=20,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(1,2):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)"
      ],
      "metadata": {
        "id": "bl-5wVomt1ig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac41ecbb-ca52-4c33-c6fb-ffc235d48a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 1\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 1, 600, 63)       252       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 1, 100, 63)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1, 100, 10)       40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 1, 25, 10)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 250)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 1, 100, 10)       6410      \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 1, 600, 63)       20223     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.8044 - decoder_loss: 25.1448 - encoder_loss: 4.2128 - classifier_loss: 0.7719 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5250\n",
            "Epoch 1: val_loss improved from inf to 63.38371, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 14s 14s/step - loss: 6.8044 - decoder_loss: 25.1448 - encoder_loss: 4.2128 - classifier_loss: 0.7719 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5250 - val_loss: 63.3837 - val_decoder_loss: 29.3490 - val_encoder_loss: 60.3898 - val_classifier_loss: 0.5902 - val_decoder_accuracy: 0.0175 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.6313 - decoder_loss: 25.1386 - encoder_loss: 1.0524 - classifier_loss: 0.6503 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6500\n",
            "Epoch 2: val_loss improved from 63.38371 to 8.73835, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 3.6313 - decoder_loss: 25.1386 - encoder_loss: 1.0524 - classifier_loss: 0.6503 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6500 - val_loss: 8.7383 - val_decoder_loss: 29.3206 - val_encoder_loss: 5.7510 - val_classifier_loss: 0.5524 - val_decoder_accuracy: 0.0185 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 13.7852 - decoder_loss: 25.1008 - encoder_loss: 11.2198 - classifier_loss: 0.5541 - decoder_accuracy: 0.0210 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7500\n",
            "Epoch 3: val_loss improved from 8.73835 to 4.32618, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 13.7852 - decoder_loss: 25.1008 - encoder_loss: 11.2198 - classifier_loss: 0.5541 - decoder_accuracy: 0.0210 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7500 - val_loss: 4.3262 - val_decoder_loss: 29.3225 - val_encoder_loss: 1.3368 - val_classifier_loss: 0.5709 - val_decoder_accuracy: 0.0177 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.2007 - decoder_loss: 25.0732 - encoder_loss: 1.6385 - classifier_loss: 0.5490 - decoder_accuracy: 0.0196 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7250\n",
            "Epoch 4: val_loss did not improve from 4.32618\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.2007 - decoder_loss: 25.0732 - encoder_loss: 1.6385 - classifier_loss: 0.5490 - decoder_accuracy: 0.0196 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7250 - val_loss: 8.3630 - val_decoder_loss: 29.2609 - val_encoder_loss: 5.3901 - val_classifier_loss: 0.4682 - val_decoder_accuracy: 0.0185 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.5919 - decoder_loss: 24.7926 - encoder_loss: 1.0745 - classifier_loss: 0.3821 - decoder_accuracy: 0.0253 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9000\n",
            "Epoch 5: val_loss did not improve from 4.32618\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.5919 - decoder_loss: 24.7926 - encoder_loss: 1.0745 - classifier_loss: 0.3821 - decoder_accuracy: 0.0253 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9000 - val_loss: 7.5307 - val_decoder_loss: 29.9638 - val_encoder_loss: 4.4751 - val_classifier_loss: 0.5913 - val_decoder_accuracy: 0.0247 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.6289 - decoder_loss: 25.4692 - encoder_loss: 2.0453 - classifier_loss: 0.3666 - decoder_accuracy: 0.0225 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 6: val_loss did not improve from 4.32618\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.6289 - decoder_loss: 25.4692 - encoder_loss: 2.0453 - classifier_loss: 0.3666 - decoder_accuracy: 0.0225 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 28.4483 - val_decoder_loss: 29.5885 - val_encoder_loss: 25.4127 - val_classifier_loss: 0.7667 - val_decoder_accuracy: 0.0133 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.1547 - decoder_loss: 25.1379 - encoder_loss: 4.5994 - classifier_loss: 0.4157 - decoder_accuracy: 0.0183 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 7: val_loss did not improve from 4.32618\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.1547 - decoder_loss: 25.1379 - encoder_loss: 4.5994 - classifier_loss: 0.4157 - decoder_accuracy: 0.0183 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 12.5290 - val_decoder_loss: 29.4319 - val_encoder_loss: 9.5177 - val_classifier_loss: 0.6812 - val_decoder_accuracy: 0.0278 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.3295 - decoder_loss: 24.7247 - encoder_loss: 3.8007 - classifier_loss: 0.5640 - decoder_accuracy: 0.0448 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000\n",
            "Epoch 8: val_loss improved from 4.32618 to 2.98691, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 6.3295 - decoder_loss: 24.7247 - encoder_loss: 3.8007 - classifier_loss: 0.5640 - decoder_accuracy: 0.0448 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000 - val_loss: 2.9869 - val_decoder_loss: 29.3628 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.5063 - val_decoder_accuracy: 0.0278 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.4250 - decoder_loss: 24.6603 - encoder_loss: 0.9275 - classifier_loss: 0.3147 - decoder_accuracy: 0.0337 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 9: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.4250 - decoder_loss: 24.6603 - encoder_loss: 0.9275 - classifier_loss: 0.3147 - decoder_accuracy: 0.0337 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 3.0041 - val_decoder_loss: 29.5472 - val_encoder_loss: 0.0229 - val_classifier_loss: 0.2646 - val_decoder_accuracy: 0.0218 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 11.0763 - decoder_loss: 24.3739 - encoder_loss: 8.6205 - classifier_loss: 0.1839 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 10: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 11.0763 - decoder_loss: 24.3739 - encoder_loss: 8.6205 - classifier_loss: 0.1839 - decoder_accuracy: 0.0437 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 3.7794 - val_decoder_loss: 29.7847 - val_encoder_loss: 0.7709 - val_classifier_loss: 0.3007 - val_decoder_accuracy: 0.0220 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5177 - decoder_loss: 24.7234 - encoder_loss: 0.0371 - classifier_loss: 0.0827 - decoder_accuracy: 0.0334 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 11: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.5177 - decoder_loss: 24.7234 - encoder_loss: 0.0371 - classifier_loss: 0.0827 - decoder_accuracy: 0.0334 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 4.6514 - val_decoder_loss: 29.6035 - val_encoder_loss: 1.6538 - val_classifier_loss: 0.3727 - val_decoder_accuracy: 0.0267 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4690 - decoder_loss: 24.5476 - encoder_loss: 0.0079 - classifier_loss: 0.0635 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 12: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4690 - decoder_loss: 24.5476 - encoder_loss: 0.0079 - classifier_loss: 0.0635 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 4.0666 - val_decoder_loss: 29.5402 - val_encoder_loss: 1.0782 - val_classifier_loss: 0.3432 - val_decoder_accuracy: 0.0307 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4406 - decoder_loss: 24.3229 - encoder_loss: 0.0036 - classifier_loss: 0.0475 - decoder_accuracy: 0.0395 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0029999999329447745.\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.4406 - decoder_loss: 24.3229 - encoder_loss: 0.0036 - classifier_loss: 0.0475 - decoder_accuracy: 0.0395 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.4324 - val_decoder_loss: 29.2303 - val_encoder_loss: 0.4747 - val_classifier_loss: 0.3471 - val_decoder_accuracy: 0.0303 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4287 - decoder_loss: 24.2565 - encoder_loss: 1.1443e-04 - classifier_loss: 0.0296 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.4287 - decoder_loss: 24.2565 - encoder_loss: 1.1443e-04 - classifier_loss: 0.0296 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.4872 - val_decoder_loss: 29.3417 - val_encoder_loss: 0.5203 - val_classifier_loss: 0.3270 - val_decoder_accuracy: 0.0272 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0030\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4185 - decoder_loss: 24.1424 - encoder_loss: 0.0015 - classifier_loss: 0.0279 - decoder_accuracy: 0.0507 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.4185 - decoder_loss: 24.1424 - encoder_loss: 0.0015 - classifier_loss: 0.0279 - decoder_accuracy: 0.0507 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.3729 - val_decoder_loss: 29.2863 - val_encoder_loss: 0.4123 - val_classifier_loss: 0.3191 - val_decoder_accuracy: 0.0258 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0030\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4115 - decoder_loss: 24.0891 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0263 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4115 - decoder_loss: 24.0891 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0263 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.3698 - val_decoder_loss: 29.1969 - val_encoder_loss: 0.4184 - val_classifier_loss: 0.3176 - val_decoder_accuracy: 0.0250 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0030\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4061 - decoder_loss: 24.0256 - encoder_loss: 0.0010 - classifier_loss: 0.0249 - decoder_accuracy: 0.0529 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4061 - decoder_loss: 24.0256 - encoder_loss: 0.0010 - classifier_loss: 0.0249 - decoder_accuracy: 0.0529 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.3397 - val_decoder_loss: 29.1164 - val_encoder_loss: 0.3967 - val_classifier_loss: 0.3139 - val_decoder_accuracy: 0.0245 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0030\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4014 - decoder_loss: 23.9721 - encoder_loss: 0.0019 - classifier_loss: 0.0237 - decoder_accuracy: 0.0541 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0009000000078231095.\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.4014 - decoder_loss: 23.9721 - encoder_loss: 0.0019 - classifier_loss: 0.0237 - decoder_accuracy: 0.0541 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2529 - val_decoder_loss: 29.0134 - val_encoder_loss: 0.3198 - val_classifier_loss: 0.3174 - val_decoder_accuracy: 0.0252 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0030\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3939 - decoder_loss: 23.9121 - encoder_loss: 5.1530e-04 - classifier_loss: 0.0220 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3939 - decoder_loss: 23.9121 - encoder_loss: 5.1530e-04 - classifier_loss: 0.0220 - decoder_accuracy: 0.0582 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2626 - val_decoder_loss: 28.9885 - val_encoder_loss: 0.3323 - val_classifier_loss: 0.3148 - val_decoder_accuracy: 0.0253 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 9.0000e-04\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3915 - decoder_loss: 23.8932 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0217 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.3915 - decoder_loss: 23.8932 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0217 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2562 - val_decoder_loss: 28.9592 - val_encoder_loss: 0.3289 - val_classifier_loss: 0.3141 - val_decoder_accuracy: 0.0248 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 9.0000e-04\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3892 - decoder_loss: 23.8711 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0213 - decoder_accuracy: 0.0596 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.3892 - decoder_loss: 23.8711 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0213 - decoder_accuracy: 0.0596 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2469 - val_decoder_loss: 28.9278 - val_encoder_loss: 0.3227 - val_classifier_loss: 0.3138 - val_decoder_accuracy: 0.0253 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 9.0000e-04\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3881 - decoder_loss: 23.8485 - encoder_loss: 0.0012 - classifier_loss: 0.0210 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.3881 - decoder_loss: 23.8485 - encoder_loss: 0.0012 - classifier_loss: 0.0210 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2138 - val_decoder_loss: 28.8964 - val_encoder_loss: 0.2928 - val_classifier_loss: 0.3137 - val_decoder_accuracy: 0.0252 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 9.0000e-04\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3849 - decoder_loss: 23.8286 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0207 - decoder_accuracy: 0.0598 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00026999999536201356.\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.3849 - decoder_loss: 23.8286 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0207 - decoder_accuracy: 0.0598 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2050 - val_decoder_loss: 28.8626 - val_encoder_loss: 0.2875 - val_classifier_loss: 0.3132 - val_decoder_accuracy: 0.0260 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 9.0000e-04\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3825 - decoder_loss: 23.8049 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0204 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.3825 - decoder_loss: 23.8049 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0204 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2096 - val_decoder_loss: 28.8525 - val_encoder_loss: 0.2930 - val_classifier_loss: 0.3128 - val_decoder_accuracy: 0.0267 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 2.7000e-04\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3818 - decoder_loss: 23.7976 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0204 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3818 - decoder_loss: 23.7976 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0204 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2079 - val_decoder_loss: 28.8419 - val_encoder_loss: 0.2925 - val_classifier_loss: 0.3126 - val_decoder_accuracy: 0.0263 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 2.7000e-04\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3810 - decoder_loss: 23.7902 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0203 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3810 - decoder_loss: 23.7902 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0203 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2057 - val_decoder_loss: 28.8310 - val_encoder_loss: 0.2913 - val_classifier_loss: 0.3126 - val_decoder_accuracy: 0.0267 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 2.7000e-04\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3803 - decoder_loss: 23.7826 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0202 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 2.98691\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3803 - decoder_loss: 23.7826 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0202 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2035 - val_decoder_loss: 28.8199 - val_encoder_loss: 0.2902 - val_classifier_loss: 0.3125 - val_decoder_accuracy: 0.0277 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 2.7000e-04\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3795 - decoder_loss: 23.7748 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0201 - decoder_accuracy: 0.0607 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 2.98691\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3795 - decoder_loss: 23.7748 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0201 - decoder_accuracy: 0.0607 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 3.2013 - val_decoder_loss: 28.8087 - val_encoder_loss: 0.2892 - val_classifier_loss: 0.3124 - val_decoder_accuracy: 0.0272 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 2.7000e-04\n",
            "Epoch 28: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1, 600, 63)       252       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_2 (Averag  (None, 1, 100, 63)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 1, 100, 10)       40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_3 (Averag  (None, 1, 25, 10)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 1, 100, 10)       6410      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 1, 600, 63)       20223     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 310ms/step\n",
            "1/1 [==============================] - 1s 543ms/step - loss: 5.9640 - decoder_loss: 26.4712 - encoder_loss: 3.2477 - classifier_loss: 0.6917 - decoder_accuracy: 0.0257 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7333\n",
            "F1-score is computed based on binary\n",
            "(loss: 5.964024543762207, accuracy: 0.7333333492279053)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.73      0.73        15\n",
            "         1.0       0.73      0.73      0.73        15\n",
            "\n",
            "    accuracy                           0.73        30\n",
            "   macro avg       0.73      0.73      0.73        30\n",
            "weighted avg       0.73      0.73      0.73        30\n",
            "\n",
            "Accuracy: 0.7333333492279053\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7333333492279053\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fold2"
      ],
      "metadata": {
        "id": "ciHvOA0swdBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=1, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=20,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(2,3):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZPkBNE4LweMV",
        "outputId": "de01607b-db5d-4f07-8371-c5113a63d7ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 2\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_57 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_156 (Conv2D)         (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_28 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_157 (Conv2D)         (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_39 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_29 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_54 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_12 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_24 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_25 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_57 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_57[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 23.8337 - decoder_loss: 207.4274 - encoder_loss: 3.0008 - classifier_loss: 0.9019 - decoder_accuracy: 0.0154 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4000\n",
            "Epoch 1: val_loss improved from inf to 932.97784, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 23.8337 - decoder_loss: 207.4274 - encoder_loss: 3.0008 - classifier_loss: 0.9019 - decoder_accuracy: 0.0154 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4000 - val_loss: 932.9778 - val_decoder_loss: 202.4912 - val_encoder_loss: 912.5449 - val_classifier_loss: 1.8375 - val_decoder_accuracy: 0.0177 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 21.1487 - decoder_loss: 207.4019 - encoder_loss: 0.3423 - classifier_loss: 0.6625 - decoder_accuracy: 0.0114 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750\n",
            "Epoch 2: val_loss improved from 932.97784 to 26.91570, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 21.1487 - decoder_loss: 207.4019 - encoder_loss: 0.3423 - classifier_loss: 0.6625 - decoder_accuracy: 0.0114 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750 - val_loss: 26.9157 - val_decoder_loss: 202.3545 - val_encoder_loss: 6.6321 - val_classifier_loss: 0.4811 - val_decoder_accuracy: 0.0115 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 21.4552 - decoder_loss: 207.3039 - encoder_loss: 0.6719 - classifier_loss: 0.5288 - decoder_accuracy: 0.0116 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6750\n",
            "Epoch 3: val_loss did not improve from 26.91570\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 21.4552 - decoder_loss: 207.3039 - encoder_loss: 0.6719 - classifier_loss: 0.5288 - decoder_accuracy: 0.0116 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6750 - val_loss: 29.0749 - val_decoder_loss: 201.1594 - val_encoder_loss: 8.9188 - val_classifier_loss: 0.4020 - val_decoder_accuracy: 0.0218 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 25.5001 - decoder_loss: 206.3593 - encoder_loss: 4.8164 - classifier_loss: 0.4780 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000\n",
            "Epoch 4: val_loss did not improve from 26.91570\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 25.5001 - decoder_loss: 206.3593 - encoder_loss: 4.8164 - classifier_loss: 0.4780 - decoder_accuracy: 0.0168 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000 - val_loss: 39.1653 - val_decoder_loss: 203.0442 - val_encoder_loss: 18.7149 - val_classifier_loss: 1.4594 - val_decoder_accuracy: 0.0185 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.2000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 21.7361 - decoder_loss: 208.1329 - encoder_loss: 0.8379 - classifier_loss: 0.8487 - decoder_accuracy: 0.0154 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5000\n",
            "Epoch 5: val_loss did not improve from 26.91570\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 21.7361 - decoder_loss: 208.1329 - encoder_loss: 0.8379 - classifier_loss: 0.8487 - decoder_accuracy: 0.0154 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5000 - val_loss: 34.5336 - val_decoder_loss: 200.9135 - val_encoder_loss: 14.3405 - val_classifier_loss: 1.0169 - val_decoder_accuracy: 0.0233 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.2000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 24.0151 - decoder_loss: 205.5689 - encoder_loss: 3.3824 - classifier_loss: 0.7582 - decoder_accuracy: 0.0208 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6000\n",
            "Epoch 6: val_loss improved from 26.91570 to 25.67945, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 24.0151 - decoder_loss: 205.5689 - encoder_loss: 3.3824 - classifier_loss: 0.7582 - decoder_accuracy: 0.0208 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6000 - val_loss: 25.6794 - val_decoder_loss: 199.7421 - val_encoder_loss: 5.6150 - val_classifier_loss: 0.9024 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 23.4203 - decoder_loss: 205.4917 - encoder_loss: 2.8156 - classifier_loss: 0.5552 - decoder_accuracy: 0.0268 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000\n",
            "Epoch 7: val_loss did not improve from 25.67945\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 23.4203 - decoder_loss: 205.4917 - encoder_loss: 2.8156 - classifier_loss: 0.5552 - decoder_accuracy: 0.0268 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000 - val_loss: 28.2684 - val_decoder_loss: 203.7535 - val_encoder_loss: 7.8331 - val_classifier_loss: 0.5990 - val_decoder_accuracy: 0.0212 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 26.8054 - decoder_loss: 207.0563 - encoder_loss: 6.0643 - classifier_loss: 0.3544 - decoder_accuracy: 0.0330 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 8: val_loss improved from 25.67945 to 24.96730, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 26.8054 - decoder_loss: 207.0563 - encoder_loss: 6.0643 - classifier_loss: 0.3544 - decoder_accuracy: 0.0330 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 24.9673 - val_decoder_loss: 200.5223 - val_encoder_loss: 4.8142 - val_classifier_loss: 1.0082 - val_decoder_accuracy: 0.0285 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 24.6382 - decoder_loss: 205.0784 - encoder_loss: 4.0581 - classifier_loss: 0.7223 - decoder_accuracy: 0.0375 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6500\n",
            "Epoch 9: val_loss improved from 24.96730 to 24.14332, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 24.6382 - decoder_loss: 205.0784 - encoder_loss: 4.0581 - classifier_loss: 0.7223 - decoder_accuracy: 0.0375 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6500 - val_loss: 24.1433 - val_decoder_loss: 197.9163 - val_encoder_loss: 4.2746 - val_classifier_loss: 0.7705 - val_decoder_accuracy: 0.0398 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 25.2912 - decoder_loss: 202.5807 - encoder_loss: 4.9868 - classifier_loss: 0.4636 - decoder_accuracy: 0.0436 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000\n",
            "Epoch 10: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 25.2912 - decoder_loss: 202.5807 - encoder_loss: 4.9868 - classifier_loss: 0.4636 - decoder_accuracy: 0.0436 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000 - val_loss: 32.2144 - val_decoder_loss: 192.5280 - val_encoder_loss: 12.8924 - val_classifier_loss: 0.6924 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 23.2634 - decoder_loss: 197.9623 - encoder_loss: 3.4272 - classifier_loss: 0.4003 - decoder_accuracy: 0.0462 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750\n",
            "Epoch 11: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 23.2634 - decoder_loss: 197.9623 - encoder_loss: 3.4272 - classifier_loss: 0.4003 - decoder_accuracy: 0.0462 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750 - val_loss: 28.9908 - val_decoder_loss: 199.1390 - val_encoder_loss: 9.0102 - val_classifier_loss: 0.6662 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 20.8254 - decoder_loss: 201.5126 - encoder_loss: 0.6426 - classifier_loss: 0.3149 - decoder_accuracy: 0.0441 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750\n",
            "Epoch 12: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 20.8254 - decoder_loss: 201.5126 - encoder_loss: 0.6426 - classifier_loss: 0.3149 - decoder_accuracy: 0.0441 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750 - val_loss: 27.9899 - val_decoder_loss: 195.8836 - val_encoder_loss: 8.3360 - val_classifier_loss: 0.6554 - val_decoder_accuracy: 0.0633 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 20.1901 - decoder_loss: 199.7033 - encoder_loss: 0.1991 - classifier_loss: 0.2063 - decoder_accuracy: 0.0524 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 13: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 20.1901 - decoder_loss: 199.7033 - encoder_loss: 0.1991 - classifier_loss: 0.2063 - decoder_accuracy: 0.0524 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 29.4852 - val_decoder_loss: 194.6248 - val_encoder_loss: 9.9603 - val_classifier_loss: 0.6244 - val_decoder_accuracy: 0.0630 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 20.0430 - decoder_loss: 198.2423 - encoder_loss: 0.2018 - classifier_loss: 0.1700 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 14: val_loss did not improve from 24.14332\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 20.0430 - decoder_loss: 198.2423 - encoder_loss: 0.2018 - classifier_loss: 0.1700 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 28.0851 - val_decoder_loss: 193.0585 - val_encoder_loss: 8.7232 - val_classifier_loss: 0.5603 - val_decoder_accuracy: 0.0657 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.7591 - decoder_loss: 197.3040 - encoder_loss: 0.0184 - classifier_loss: 0.1027 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 19.7591 - decoder_loss: 197.3040 - encoder_loss: 0.0184 - classifier_loss: 0.1027 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 27.6248 - val_decoder_loss: 192.4844 - val_encoder_loss: 8.3190 - val_classifier_loss: 0.5735 - val_decoder_accuracy: 0.0655 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.6557 - decoder_loss: 196.3955 - encoder_loss: 0.0076 - classifier_loss: 0.0857 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 19.6557 - decoder_loss: 196.3955 - encoder_loss: 0.0076 - classifier_loss: 0.0857 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 27.3494 - val_decoder_loss: 191.7775 - val_encoder_loss: 8.1153 - val_classifier_loss: 0.5637 - val_decoder_accuracy: 0.0683 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.5914 - decoder_loss: 195.7814 - encoder_loss: 0.0059 - classifier_loss: 0.0735 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 19.5914 - decoder_loss: 195.7814 - encoder_loss: 0.0059 - classifier_loss: 0.0735 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 26.8653 - val_decoder_loss: 190.6750 - val_encoder_loss: 7.7405 - val_classifier_loss: 0.5731 - val_decoder_accuracy: 0.0640 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.5083 - decoder_loss: 194.9656 - encoder_loss: 0.0054 - classifier_loss: 0.0632 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 19.5083 - decoder_loss: 194.9656 - encoder_loss: 0.0054 - classifier_loss: 0.0632 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 27.4851 - val_decoder_loss: 189.6997 - val_encoder_loss: 8.4568 - val_classifier_loss: 0.5837 - val_decoder_accuracy: 0.0650 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.4277 - decoder_loss: 194.2211 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0555 - decoder_accuracy: 0.0641 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 24.14332\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 19.4277 - decoder_loss: 194.2211 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0555 - decoder_accuracy: 0.0641 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 27.3502 - val_decoder_loss: 188.8310 - val_encoder_loss: 8.4086 - val_classifier_loss: 0.5848 - val_decoder_accuracy: 0.0602 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.3623 - decoder_loss: 193.5518 - encoder_loss: 0.0020 - classifier_loss: 0.0515 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 19.3623 - decoder_loss: 193.5518 - encoder_loss: 0.0020 - classifier_loss: 0.0515 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 27.1361 - val_decoder_loss: 188.4456 - val_encoder_loss: 8.2335 - val_classifier_loss: 0.5800 - val_decoder_accuracy: 0.0628 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0025\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.3075 - decoder_loss: 193.0187 - encoder_loss: 6.7831e-04 - classifier_loss: 0.0491 - decoder_accuracy: 0.0618 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 19.3075 - decoder_loss: 193.0187 - encoder_loss: 6.7831e-04 - classifier_loss: 0.0491 - decoder_accuracy: 0.0618 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 26.9922 - val_decoder_loss: 188.0849 - val_encoder_loss: 8.1258 - val_classifier_loss: 0.5784 - val_decoder_accuracy: 0.0632 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0025\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.2705 - decoder_loss: 192.6508 - encoder_loss: 6.3861e-04 - classifier_loss: 0.0474 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 19.2705 - decoder_loss: 192.6508 - encoder_loss: 6.3861e-04 - classifier_loss: 0.0474 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 26.9950 - val_decoder_loss: 187.6988 - val_encoder_loss: 8.1684 - val_classifier_loss: 0.5665 - val_decoder_accuracy: 0.0627 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0025\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.2355 - decoder_loss: 192.3017 - encoder_loss: 7.9470e-04 - classifier_loss: 0.0456 - decoder_accuracy: 0.0621 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 19.2355 - decoder_loss: 192.3017 - encoder_loss: 7.9470e-04 - classifier_loss: 0.0456 - decoder_accuracy: 0.0621 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 27.0350 - val_decoder_loss: 187.3164 - val_encoder_loss: 8.2470 - val_classifier_loss: 0.5640 - val_decoder_accuracy: 0.0620 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0025\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.1999 - decoder_loss: 191.9392 - encoder_loss: 0.0015 - classifier_loss: 0.0444 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 24.14332\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 19.1999 - decoder_loss: 191.9392 - encoder_loss: 0.0015 - classifier_loss: 0.0444 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 27.1043 - val_decoder_loss: 187.0198 - val_encoder_loss: 8.3461 - val_classifier_loss: 0.5618 - val_decoder_accuracy: 0.0633 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0025\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.1701 - decoder_loss: 191.6487 - encoder_loss: 9.1434e-04 - classifier_loss: 0.0428 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 19.1701 - decoder_loss: 191.6487 - encoder_loss: 9.1434e-04 - classifier_loss: 0.0428 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 26.9955 - val_decoder_loss: 186.8626 - val_encoder_loss: 8.2534 - val_classifier_loss: 0.5586 - val_decoder_accuracy: 0.0638 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0012\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.1523 - decoder_loss: 191.4804 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0422 - decoder_accuracy: 0.0612 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 19.1523 - decoder_loss: 191.4804 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0422 - decoder_accuracy: 0.0612 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 26.9408 - val_decoder_loss: 186.6965 - val_encoder_loss: 8.2154 - val_classifier_loss: 0.5574 - val_decoder_accuracy: 0.0637 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0012\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.1355 - decoder_loss: 191.2988 - encoder_loss: 0.0014 - classifier_loss: 0.0418 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 19.1355 - decoder_loss: 191.2988 - encoder_loss: 0.0014 - classifier_loss: 0.0418 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 26.8968 - val_decoder_loss: 186.5752 - val_encoder_loss: 8.1838 - val_classifier_loss: 0.5552 - val_decoder_accuracy: 0.0638 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0012\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.1198 - decoder_loss: 191.1566 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0412 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 24.14332\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 19.1198 - decoder_loss: 191.1566 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0412 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 26.8502 - val_decoder_loss: 186.4194 - val_encoder_loss: 8.1529 - val_classifier_loss: 0.5540 - val_decoder_accuracy: 0.0638 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0012\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 19.1029 - decoder_loss: 190.9770 - encoder_loss: 0.0012 - classifier_loss: 0.0409 - decoder_accuracy: 0.0623 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 24.14332\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 19.1029 - decoder_loss: 190.9770 - encoder_loss: 0.0012 - classifier_loss: 0.0409 - decoder_accuracy: 0.0623 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 26.8498 - val_decoder_loss: 186.3106 - val_encoder_loss: 8.1633 - val_classifier_loss: 0.5552 - val_decoder_accuracy: 0.0637 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0012\n",
            "Epoch 29: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_58 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_158 (Conv2D)         (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_40 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_30 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_159 (Conv2D)         (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_31 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_55 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_13 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_26 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_27 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_58 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_58[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 23.5242 - decoder_loss: 210.6027 - encoder_loss: 2.3935 - classifier_loss: 0.7043 - decoder_accuracy: 0.0522 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7333\n",
            "F1-score is computed based on binary\n",
            "(loss: 23.52422523498535, accuracy: 0.7333333492279053)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.67      0.71        15\n",
            "         1.0       0.71      0.80      0.75        15\n",
            "\n",
            "    accuracy                           0.73        30\n",
            "   macro avg       0.74      0.73      0.73        30\n",
            "weighted avg       0.74      0.73      0.73        30\n",
            "\n",
            "Accuracy: 0.7333333492279053\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7333333492279053\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fold3"
      ],
      "metadata": {
        "id": "dGkjzHq8w0L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=10, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=200,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(3,4):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vcRgq-HKwcdX",
        "outputId": "0ab64ad6-55b2-43ee-ef6f-bbd7de966676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 3\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 1, 600, 63)       252       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_8 (Averag  (None, 1, 100, 63)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 1, 100, 10)       40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_9 (Averag  (None, 1, 25, 10)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_4 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_8 (Conv2DT  (None, 1, 100, 10)       6410      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_9 (Conv2DT  (None, 1, 600, 63)       20223     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.2092 - decoder_loss: 27.4664 - encoder_loss: 3.3959 - classifier_loss: 0.6669 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6500\n",
            "Epoch 1: val_loss improved from inf to 83.45239, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.2092 - decoder_loss: 27.4664 - encoder_loss: 3.3959 - classifier_loss: 0.6669 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6500 - val_loss: 83.4524 - val_decoder_loss: 20.0633 - val_encoder_loss: 81.3367 - val_classifier_loss: 1.0931 - val_decoder_accuracy: 0.0147 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.8173 - decoder_loss: 27.4597 - encoder_loss: 1.0037 - classifier_loss: 0.6755 - decoder_accuracy: 0.0151 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6000\n",
            "Epoch 2: val_loss improved from 83.45239 to 10.20811, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 3.8173 - decoder_loss: 27.4597 - encoder_loss: 1.0037 - classifier_loss: 0.6755 - decoder_accuracy: 0.0151 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.6000 - val_loss: 10.2081 - val_decoder_loss: 20.0475 - val_encoder_loss: 8.1425 - val_classifier_loss: 0.6085 - val_decoder_accuracy: 0.0132 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 12.3077 - decoder_loss: 27.4680 - encoder_loss: 9.5096 - classifier_loss: 0.5131 - decoder_accuracy: 0.0162 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000\n",
            "Epoch 3: val_loss improved from 10.20811 to 5.89887, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 12.3077 - decoder_loss: 27.4680 - encoder_loss: 9.5096 - classifier_loss: 0.5131 - decoder_accuracy: 0.0162 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000 - val_loss: 5.8989 - val_decoder_loss: 20.0343 - val_encoder_loss: 3.8361 - val_classifier_loss: 0.5930 - val_decoder_accuracy: 0.0167 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5288 - decoder_loss: 27.4413 - encoder_loss: 2.7169 - classifier_loss: 0.6773 - decoder_accuracy: 0.0185 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6250\n",
            "Epoch 4: val_loss did not improve from 5.89887\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.5288 - decoder_loss: 27.4413 - encoder_loss: 2.7169 - classifier_loss: 0.6773 - decoder_accuracy: 0.0185 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6250 - val_loss: 8.7538 - val_decoder_loss: 19.9888 - val_encoder_loss: 6.6741 - val_classifier_loss: 0.8080 - val_decoder_accuracy: 0.0165 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7261 - decoder_loss: 27.3864 - encoder_loss: 0.9348 - classifier_loss: 0.5267 - decoder_accuracy: 0.0195 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.7750\n",
            "Epoch 5: val_loss did not improve from 5.89887\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.7261 - decoder_loss: 27.3864 - encoder_loss: 0.9348 - classifier_loss: 0.5267 - decoder_accuracy: 0.0195 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.7750 - val_loss: 12.7941 - val_decoder_loss: 19.8363 - val_encoder_loss: 10.7242 - val_classifier_loss: 0.8625 - val_decoder_accuracy: 0.0113 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.7442 - decoder_loss: 27.1254 - encoder_loss: 3.9867 - classifier_loss: 0.4491 - decoder_accuracy: 0.0161 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750\n",
            "Epoch 6: val_loss improved from 5.89887 to 3.81789, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 6.7442 - decoder_loss: 27.1254 - encoder_loss: 3.9867 - classifier_loss: 0.4491 - decoder_accuracy: 0.0161 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750 - val_loss: 3.8179 - val_decoder_loss: 19.7607 - val_encoder_loss: 1.7711 - val_classifier_loss: 0.7075 - val_decoder_accuracy: 0.0180 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1362 - decoder_loss: 26.9674 - encoder_loss: 0.4043 - classifier_loss: 0.3511 - decoder_accuracy: 0.0169 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750\n",
            "Epoch 7: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3.1362 - decoder_loss: 26.9674 - encoder_loss: 0.4043 - classifier_loss: 0.3511 - decoder_accuracy: 0.0169 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750 - val_loss: 6.0212 - val_decoder_loss: 20.0120 - val_encoder_loss: 3.9441 - val_classifier_loss: 0.7588 - val_decoder_accuracy: 0.0152 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.2501 - decoder_loss: 27.0968 - encoder_loss: 0.5178 - classifier_loss: 0.2264 - decoder_accuracy: 0.0227 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250\n",
            "Epoch 8: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3.2501 - decoder_loss: 27.0968 - encoder_loss: 0.5178 - classifier_loss: 0.2264 - decoder_accuracy: 0.0227 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250 - val_loss: 5.2996 - val_decoder_loss: 19.5370 - val_encoder_loss: 3.2878 - val_classifier_loss: 0.5803 - val_decoder_accuracy: 0.0318 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1970 - decoder_loss: 26.7690 - encoder_loss: 0.4956 - classifier_loss: 0.2450 - decoder_accuracy: 0.0328 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 9: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.1970 - decoder_loss: 26.7690 - encoder_loss: 0.4956 - classifier_loss: 0.2450 - decoder_accuracy: 0.0328 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 14.7865 - val_decoder_loss: 19.8268 - val_encoder_loss: 12.7237 - val_classifier_loss: 0.8011 - val_decoder_accuracy: 0.0187 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.6981 - decoder_loss: 26.9432 - encoder_loss: 0.9882 - classifier_loss: 0.1550 - decoder_accuracy: 0.0309 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 10: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3.6981 - decoder_loss: 26.9432 - encoder_loss: 0.9882 - classifier_loss: 0.1550 - decoder_accuracy: 0.0309 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 10.7949 - val_decoder_loss: 19.6000 - val_encoder_loss: 8.7115 - val_classifier_loss: 1.2340 - val_decoder_accuracy: 0.0235 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.0715 - decoder_loss: 27.4496 - encoder_loss: 4.2881 - classifier_loss: 0.3840 - decoder_accuracy: 0.0264 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 11: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 7.0715 - decoder_loss: 27.4496 - encoder_loss: 4.2881 - classifier_loss: 0.3840 - decoder_accuracy: 0.0264 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 14.1779 - val_decoder_loss: 20.1938 - val_encoder_loss: 12.0713 - val_classifier_loss: 0.8724 - val_decoder_accuracy: 0.0202 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7534 - decoder_loss: 27.3845 - encoder_loss: 0.0096 - classifier_loss: 0.0537 - decoder_accuracy: 0.0351 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 12: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.7534 - decoder_loss: 27.3845 - encoder_loss: 0.0096 - classifier_loss: 0.0537 - decoder_accuracy: 0.0351 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 12.7341 - val_decoder_loss: 19.7806 - val_encoder_loss: 10.6796 - val_classifier_loss: 0.7642 - val_decoder_accuracy: 0.0202 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7020 - decoder_loss: 26.9376 - encoder_loss: 0.0046 - classifier_loss: 0.0355 - decoder_accuracy: 0.0355 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.7020 - decoder_loss: 26.9376 - encoder_loss: 0.0046 - classifier_loss: 0.0355 - decoder_accuracy: 0.0355 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 12.2875 - val_decoder_loss: 19.6591 - val_encoder_loss: 10.2460 - val_classifier_loss: 0.7558 - val_decoder_accuracy: 0.0267 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6853 - decoder_loss: 26.8019 - encoder_loss: 0.0023 - classifier_loss: 0.0279 - decoder_accuracy: 0.0370 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.6853 - decoder_loss: 26.8019 - encoder_loss: 0.0023 - classifier_loss: 0.0279 - decoder_accuracy: 0.0370 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 12.7702 - val_decoder_loss: 19.5967 - val_encoder_loss: 10.7336 - val_classifier_loss: 0.7695 - val_decoder_accuracy: 0.0233 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6740 - decoder_loss: 26.7042 - encoder_loss: 0.0012 - classifier_loss: 0.0235 - decoder_accuracy: 0.0383 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.6740 - decoder_loss: 26.7042 - encoder_loss: 0.0012 - classifier_loss: 0.0235 - decoder_accuracy: 0.0383 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6832 - val_decoder_loss: 19.5339 - val_encoder_loss: 11.6485 - val_classifier_loss: 0.8128 - val_decoder_accuracy: 0.0242 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6653 - decoder_loss: 26.6227 - encoder_loss: 0.0010 - classifier_loss: 0.0197 - decoder_accuracy: 0.0412 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.6653 - decoder_loss: 26.6227 - encoder_loss: 0.0010 - classifier_loss: 0.0197 - decoder_accuracy: 0.0412 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.2863 - val_decoder_loss: 19.4990 - val_encoder_loss: 12.2539 - val_classifier_loss: 0.8252 - val_decoder_accuracy: 0.0267 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6559 - decoder_loss: 26.5343 - encoder_loss: 7.6877e-04 - classifier_loss: 0.0172 - decoder_accuracy: 0.0450 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.6559 - decoder_loss: 26.5343 - encoder_loss: 7.6877e-04 - classifier_loss: 0.0172 - decoder_accuracy: 0.0450 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0204 - val_decoder_loss: 19.4369 - val_encoder_loss: 11.9934 - val_classifier_loss: 0.8338 - val_decoder_accuracy: 0.0267 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6493 - decoder_loss: 26.4758 - encoder_loss: 1.7484e-04 - classifier_loss: 0.0156 - decoder_accuracy: 0.0454 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.6493 - decoder_loss: 26.4758 - encoder_loss: 1.7484e-04 - classifier_loss: 0.0156 - decoder_accuracy: 0.0454 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 14.0099 - val_decoder_loss: 19.4312 - val_encoder_loss: 11.9827 - val_classifier_loss: 0.8409 - val_decoder_accuracy: 0.0273 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6434 - decoder_loss: 26.4130 - encoder_loss: 6.4561e-04 - classifier_loss: 0.0148 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.6434 - decoder_loss: 26.4130 - encoder_loss: 6.4561e-04 - classifier_loss: 0.0148 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7468 - val_decoder_loss: 19.3599 - val_encoder_loss: 11.7267 - val_classifier_loss: 0.8407 - val_decoder_accuracy: 0.0270 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6360 - decoder_loss: 26.3388 - encoder_loss: 7.0646e-04 - classifier_loss: 0.0141 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.6360 - decoder_loss: 26.3388 - encoder_loss: 7.0646e-04 - classifier_loss: 0.0141 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9366 - val_decoder_loss: 19.3612 - val_encoder_loss: 11.9151 - val_classifier_loss: 0.8539 - val_decoder_accuracy: 0.0282 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6280 - decoder_loss: 26.2663 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0133 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.6280 - decoder_loss: 26.2663 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0133 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9399 - val_decoder_loss: 19.2705 - val_encoder_loss: 11.9270 - val_classifier_loss: 0.8580 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6199 - decoder_loss: 26.1866 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.6199 - decoder_loss: 26.1866 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0128 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9456 - val_decoder_loss: 19.2791 - val_encoder_loss: 11.9315 - val_classifier_loss: 0.8625 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6141 - decoder_loss: 26.1282 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0507 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.6141 - decoder_loss: 26.1282 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0125 - decoder_accuracy: 0.0507 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9574 - val_decoder_loss: 19.2535 - val_encoder_loss: 11.9456 - val_classifier_loss: 0.8653 - val_decoder_accuracy: 0.0297 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6092 - decoder_loss: 26.0800 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0513 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.6092 - decoder_loss: 26.0800 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0123 - decoder_accuracy: 0.0513 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9681 - val_decoder_loss: 19.2329 - val_encoder_loss: 11.9581 - val_classifier_loss: 0.8678 - val_decoder_accuracy: 0.0298 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6042 - decoder_loss: 26.0304 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0519 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.6042 - decoder_loss: 26.0304 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0121 - decoder_accuracy: 0.0519 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9762 - val_decoder_loss: 19.2113 - val_encoder_loss: 11.9681 - val_classifier_loss: 0.8701 - val_decoder_accuracy: 0.0300 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5991 - decoder_loss: 25.9791 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0119 - decoder_accuracy: 0.0521 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5991 - decoder_loss: 25.9791 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0119 - decoder_accuracy: 0.0521 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9820 - val_decoder_loss: 19.1902 - val_encoder_loss: 11.9757 - val_classifier_loss: 0.8723 - val_decoder_accuracy: 0.0325 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5941 - decoder_loss: 25.9265 - encoder_loss: 3.3216e-04 - classifier_loss: 0.0117 - decoder_accuracy: 0.0528 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5941 - decoder_loss: 25.9265 - encoder_loss: 3.3216e-04 - classifier_loss: 0.0117 - decoder_accuracy: 0.0528 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9443 - val_decoder_loss: 19.1794 - val_encoder_loss: 11.9391 - val_classifier_loss: 0.8727 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5911 - decoder_loss: 25.8995 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0116 - decoder_accuracy: 0.0529 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5911 - decoder_loss: 25.8995 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0116 - decoder_accuracy: 0.0529 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9485 - val_decoder_loss: 19.1692 - val_encoder_loss: 11.9442 - val_classifier_loss: 0.8742 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5884 - decoder_loss: 25.8722 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0115 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5884 - decoder_loss: 25.8722 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0115 - decoder_accuracy: 0.0532 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9439 - val_decoder_loss: 19.1589 - val_encoder_loss: 11.9405 - val_classifier_loss: 0.8752 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5856 - decoder_loss: 25.8445 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0114 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5856 - decoder_loss: 25.8445 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0114 - decoder_accuracy: 0.0538 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9379 - val_decoder_loss: 19.1486 - val_encoder_loss: 11.9355 - val_classifier_loss: 0.8760 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5828 - decoder_loss: 25.8166 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0113 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5828 - decoder_loss: 25.8166 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0113 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9316 - val_decoder_loss: 19.1385 - val_encoder_loss: 11.9301 - val_classifier_loss: 0.8767 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5801 - decoder_loss: 25.7884 - encoder_loss: 1.2922e-04 - classifier_loss: 0.0112 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5801 - decoder_loss: 25.7884 - encoder_loss: 1.2922e-04 - classifier_loss: 0.0112 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9131 - val_decoder_loss: 19.1341 - val_encoder_loss: 11.9121 - val_classifier_loss: 0.8760 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5785 - decoder_loss: 25.7743 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0112 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5785 - decoder_loss: 25.7743 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0112 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9110 - val_decoder_loss: 19.1290 - val_encoder_loss: 11.9105 - val_classifier_loss: 0.8764 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5771 - decoder_loss: 25.7602 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0111 - decoder_accuracy: 0.0550 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 34: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5771 - decoder_loss: 25.7602 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0111 - decoder_accuracy: 0.0550 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9313 - val_decoder_loss: 19.1240 - val_encoder_loss: 11.9312 - val_classifier_loss: 0.8767 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5757 - decoder_loss: 25.7461 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0111 - decoder_accuracy: 0.0553 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5757 - decoder_loss: 25.7461 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0111 - decoder_accuracy: 0.0553 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9262 - val_decoder_loss: 19.1192 - val_encoder_loss: 11.9266 - val_classifier_loss: 0.8769 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5743 - decoder_loss: 25.7320 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0110 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5743 - decoder_loss: 25.7320 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0110 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9212 - val_decoder_loss: 19.1144 - val_encoder_loss: 11.9220 - val_classifier_loss: 0.8772 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5729 - decoder_loss: 25.7179 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0110 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5729 - decoder_loss: 25.7179 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0110 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9187 - val_decoder_loss: 19.1121 - val_encoder_loss: 11.9197 - val_classifier_loss: 0.8773 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5722 - decoder_loss: 25.7109 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0110 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5722 - decoder_loss: 25.7109 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0110 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9162 - val_decoder_loss: 19.1097 - val_encoder_loss: 11.9175 - val_classifier_loss: 0.8775 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5715 - decoder_loss: 25.7038 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0110 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5715 - decoder_loss: 25.7038 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0110 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9137 - val_decoder_loss: 19.1074 - val_encoder_loss: 11.9152 - val_classifier_loss: 0.8776 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5708 - decoder_loss: 25.6966 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5708 - decoder_loss: 25.6966 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9117 - val_decoder_loss: 19.1051 - val_encoder_loss: 11.9134 - val_classifier_loss: 0.8776 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5700 - decoder_loss: 25.6895 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 3.81789\n",
            "\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5700 - decoder_loss: 25.6895 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9099 - val_decoder_loss: 19.1028 - val_encoder_loss: 11.9118 - val_classifier_loss: 0.8777 - val_decoder_accuracy: 0.0353 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5693 - decoder_loss: 25.6823 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5693 - decoder_loss: 25.6823 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9087 - val_decoder_loss: 19.1013 - val_encoder_loss: 11.9107 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0353 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5689 - decoder_loss: 25.6778 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5689 - decoder_loss: 25.6778 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0556 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.9074 - val_decoder_loss: 19.0998 - val_encoder_loss: 11.9097 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5697 - decoder_loss: 25.6732 - encoder_loss: 0.0013 - classifier_loss: 0.0109 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5697 - decoder_loss: 25.6732 - encoder_loss: 0.0013 - classifier_loss: 0.0109 - decoder_accuracy: 0.0557 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8937 - val_decoder_loss: 19.0984 - val_encoder_loss: 11.8961 - val_classifier_loss: 0.8777 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5679 - decoder_loss: 25.6686 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5679 - decoder_loss: 25.6686 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8933 - val_decoder_loss: 19.0969 - val_encoder_loss: 11.8958 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0353 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5675 - decoder_loss: 25.6640 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5675 - decoder_loss: 25.6640 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0109 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8916 - val_decoder_loss: 19.0955 - val_encoder_loss: 11.8943 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5670 - decoder_loss: 25.6594 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0559 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5670 - decoder_loss: 25.6594 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0559 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8898 - val_decoder_loss: 19.0940 - val_encoder_loss: 11.8926 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5666 - decoder_loss: 25.6548 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0562 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5666 - decoder_loss: 25.6548 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0562 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8880 - val_decoder_loss: 19.0926 - val_encoder_loss: 11.8910 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5661 - decoder_loss: 25.6501 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 49: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5661 - decoder_loss: 25.6501 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8863 - val_decoder_loss: 19.0911 - val_encoder_loss: 11.8894 - val_classifier_loss: 0.8780 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5656 - decoder_loss: 25.6455 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5656 - decoder_loss: 25.6455 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8846 - val_decoder_loss: 19.0897 - val_encoder_loss: 11.8878 - val_classifier_loss: 0.8780 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5652 - decoder_loss: 25.6409 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5652 - decoder_loss: 25.6409 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8829 - val_decoder_loss: 19.0883 - val_encoder_loss: 11.8863 - val_classifier_loss: 0.8781 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5647 - decoder_loss: 25.6362 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5647 - decoder_loss: 25.6362 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8813 - val_decoder_loss: 19.0869 - val_encoder_loss: 11.8848 - val_classifier_loss: 0.8781 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5642 - decoder_loss: 25.6316 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5642 - decoder_loss: 25.6316 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8797 - val_decoder_loss: 19.0855 - val_encoder_loss: 11.8833 - val_classifier_loss: 0.8782 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5638 - decoder_loss: 25.6270 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5638 - decoder_loss: 25.6270 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8781 - val_decoder_loss: 19.0841 - val_encoder_loss: 11.8819 - val_classifier_loss: 0.8782 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5633 - decoder_loss: 25.6224 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5633 - decoder_loss: 25.6224 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0108 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8766 - val_decoder_loss: 19.0827 - val_encoder_loss: 11.8805 - val_classifier_loss: 0.8782 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5629 - decoder_loss: 25.6178 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5629 - decoder_loss: 25.6178 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8750 - val_decoder_loss: 19.0813 - val_encoder_loss: 11.8791 - val_classifier_loss: 0.8783 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5624 - decoder_loss: 25.6132 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5624 - decoder_loss: 25.6132 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8735 - val_decoder_loss: 19.0800 - val_encoder_loss: 11.8777 - val_classifier_loss: 0.8783 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5619 - decoder_loss: 25.6086 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 58: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5619 - decoder_loss: 25.6086 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8720 - val_decoder_loss: 19.0786 - val_encoder_loss: 11.8763 - val_classifier_loss: 0.8784 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5615 - decoder_loss: 25.6040 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0566 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 59: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5615 - decoder_loss: 25.6040 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0566 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8705 - val_decoder_loss: 19.0772 - val_encoder_loss: 11.8750 - val_classifier_loss: 0.8784 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5610 - decoder_loss: 25.5995 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0566 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 60: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5610 - decoder_loss: 25.5995 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0566 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8690 - val_decoder_loss: 19.0759 - val_encoder_loss: 11.8736 - val_classifier_loss: 0.8785 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5606 - decoder_loss: 25.5950 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 61: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5606 - decoder_loss: 25.5950 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0564 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8425 - val_decoder_loss: 19.0745 - val_encoder_loss: 11.8472 - val_classifier_loss: 0.8785 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5601 - decoder_loss: 25.5904 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 62: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5601 - decoder_loss: 25.5904 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0563 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8407 - val_decoder_loss: 19.0732 - val_encoder_loss: 11.8455 - val_classifier_loss: 0.8785 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5597 - decoder_loss: 25.5859 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 63: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5597 - decoder_loss: 25.5859 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0107 - decoder_accuracy: 0.0565 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8389 - val_decoder_loss: 19.0719 - val_encoder_loss: 11.8439 - val_classifier_loss: 0.8786 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5592 - decoder_loss: 25.5814 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5592 - decoder_loss: 25.5814 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8371 - val_decoder_loss: 19.0705 - val_encoder_loss: 11.8422 - val_classifier_loss: 0.8786 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5588 - decoder_loss: 25.5769 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 65: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5588 - decoder_loss: 25.5769 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8353 - val_decoder_loss: 19.0692 - val_encoder_loss: 11.8405 - val_classifier_loss: 0.8787 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5583 - decoder_loss: 25.5723 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 66: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5583 - decoder_loss: 25.5723 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0567 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8335 - val_decoder_loss: 19.0679 - val_encoder_loss: 11.8388 - val_classifier_loss: 0.8787 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5578 - decoder_loss: 25.5678 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 67: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5578 - decoder_loss: 25.5678 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0568 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8317 - val_decoder_loss: 19.0666 - val_encoder_loss: 11.8371 - val_classifier_loss: 0.8787 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5574 - decoder_loss: 25.5633 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 68: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5574 - decoder_loss: 25.5633 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8299 - val_decoder_loss: 19.0653 - val_encoder_loss: 11.8354 - val_classifier_loss: 0.8788 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5569 - decoder_loss: 25.5588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 69: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5569 - decoder_loss: 25.5588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0569 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8280 - val_decoder_loss: 19.0641 - val_encoder_loss: 11.8338 - val_classifier_loss: 0.8788 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5565 - decoder_loss: 25.5543 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 70: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5565 - decoder_loss: 25.5543 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0570 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8262 - val_decoder_loss: 19.0628 - val_encoder_loss: 11.8321 - val_classifier_loss: 0.8788 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5560 - decoder_loss: 25.5498 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 71: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5560 - decoder_loss: 25.5498 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8244 - val_decoder_loss: 19.0615 - val_encoder_loss: 11.8304 - val_classifier_loss: 0.8789 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5556 - decoder_loss: 25.5454 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 72: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5556 - decoder_loss: 25.5454 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0106 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8226 - val_decoder_loss: 19.0603 - val_encoder_loss: 11.8287 - val_classifier_loss: 0.8789 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5551 - decoder_loss: 25.5409 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 73: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5551 - decoder_loss: 25.5409 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8208 - val_decoder_loss: 19.0590 - val_encoder_loss: 11.8270 - val_classifier_loss: 0.8790 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5547 - decoder_loss: 25.5364 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 74: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.5547 - decoder_loss: 25.5364 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8190 - val_decoder_loss: 19.0578 - val_encoder_loss: 11.8253 - val_classifier_loss: 0.8790 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5542 - decoder_loss: 25.5319 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 75: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5542 - decoder_loss: 25.5319 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8172 - val_decoder_loss: 19.0566 - val_encoder_loss: 11.8236 - val_classifier_loss: 0.8790 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5538 - decoder_loss: 25.5275 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 76: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5538 - decoder_loss: 25.5275 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0571 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8154 - val_decoder_loss: 19.0554 - val_encoder_loss: 11.8219 - val_classifier_loss: 0.8791 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5534 - decoder_loss: 25.5231 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 77: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5534 - decoder_loss: 25.5231 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0572 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8136 - val_decoder_loss: 19.0542 - val_encoder_loss: 11.8202 - val_classifier_loss: 0.8791 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5529 - decoder_loss: 25.5187 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 78: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5529 - decoder_loss: 25.5187 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0573 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8118 - val_decoder_loss: 19.0530 - val_encoder_loss: 11.8185 - val_classifier_loss: 0.8791 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5525 - decoder_loss: 25.5143 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 79: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5525 - decoder_loss: 25.5143 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0575 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8099 - val_decoder_loss: 19.0518 - val_encoder_loss: 11.8168 - val_classifier_loss: 0.8792 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5520 - decoder_loss: 25.5100 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 80: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5520 - decoder_loss: 25.5100 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0105 - decoder_accuracy: 0.0574 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8081 - val_decoder_loss: 19.0507 - val_encoder_loss: 11.8151 - val_classifier_loss: 0.8792 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5516 - decoder_loss: 25.5056 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 81: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.5516 - decoder_loss: 25.5056 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8063 - val_decoder_loss: 19.0495 - val_encoder_loss: 11.8134 - val_classifier_loss: 0.8792 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5512 - decoder_loss: 25.5012 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 82: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5512 - decoder_loss: 25.5012 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8045 - val_decoder_loss: 19.0483 - val_encoder_loss: 11.8117 - val_classifier_loss: 0.8793 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5507 - decoder_loss: 25.4968 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 83: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5507 - decoder_loss: 25.4968 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0576 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8026 - val_decoder_loss: 19.0472 - val_encoder_loss: 11.8100 - val_classifier_loss: 0.8793 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5503 - decoder_loss: 25.4925 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 84: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5503 - decoder_loss: 25.4925 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.8008 - val_decoder_loss: 19.0461 - val_encoder_loss: 11.8082 - val_classifier_loss: 0.8793 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5499 - decoder_loss: 25.4882 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 85: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5499 - decoder_loss: 25.4882 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7990 - val_decoder_loss: 19.0450 - val_encoder_loss: 11.8065 - val_classifier_loss: 0.8794 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5494 - decoder_loss: 25.4839 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 86: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5494 - decoder_loss: 25.4839 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7971 - val_decoder_loss: 19.0439 - val_encoder_loss: 11.8048 - val_classifier_loss: 0.8794 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5490 - decoder_loss: 25.4797 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 87: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5490 - decoder_loss: 25.4797 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0579 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7953 - val_decoder_loss: 19.0428 - val_encoder_loss: 11.8030 - val_classifier_loss: 0.8794 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5486 - decoder_loss: 25.4755 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5486 - decoder_loss: 25.4755 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0577 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7934 - val_decoder_loss: 19.0417 - val_encoder_loss: 11.8013 - val_classifier_loss: 0.8794 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5482 - decoder_loss: 25.4713 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5482 - decoder_loss: 25.4713 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0104 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7916 - val_decoder_loss: 19.0406 - val_encoder_loss: 11.7996 - val_classifier_loss: 0.8795 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5477 - decoder_loss: 25.4671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5477 - decoder_loss: 25.4671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0578 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7897 - val_decoder_loss: 19.0395 - val_encoder_loss: 11.7978 - val_classifier_loss: 0.8795 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5473 - decoder_loss: 25.4630 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5473 - decoder_loss: 25.4630 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0580 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7879 - val_decoder_loss: 19.0385 - val_encoder_loss: 11.7961 - val_classifier_loss: 0.8795 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5482 - decoder_loss: 25.4588 - encoder_loss: 0.0013 - classifier_loss: 0.0103 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5482 - decoder_loss: 25.4588 - encoder_loss: 0.0013 - classifier_loss: 0.0103 - decoder_accuracy: 0.0581 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7645 - val_decoder_loss: 19.0373 - val_encoder_loss: 11.7729 - val_classifier_loss: 0.8789 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5465 - decoder_loss: 25.4544 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 93: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5465 - decoder_loss: 25.4544 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7636 - val_decoder_loss: 19.0363 - val_encoder_loss: 11.7720 - val_classifier_loss: 0.8791 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5461 - decoder_loss: 25.4502 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 94: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5461 - decoder_loss: 25.4502 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0584 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7608 - val_decoder_loss: 19.0353 - val_encoder_loss: 11.7693 - val_classifier_loss: 0.8791 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5456 - decoder_loss: 25.4461 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5456 - decoder_loss: 25.4461 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7579 - val_decoder_loss: 19.0342 - val_encoder_loss: 11.7666 - val_classifier_loss: 0.8791 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5452 - decoder_loss: 25.4420 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 96: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5452 - decoder_loss: 25.4420 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7551 - val_decoder_loss: 19.0332 - val_encoder_loss: 11.7639 - val_classifier_loss: 0.8791 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5448 - decoder_loss: 25.4378 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 97: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5448 - decoder_loss: 25.4378 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0103 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7524 - val_decoder_loss: 19.0322 - val_encoder_loss: 11.7612 - val_classifier_loss: 0.8791 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5444 - decoder_loss: 25.4337 - encoder_loss: 5.0796e-06 - classifier_loss: 0.0102 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 98: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5444 - decoder_loss: 25.4337 - encoder_loss: 5.0796e-06 - classifier_loss: 0.0102 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7522 - val_decoder_loss: 19.0314 - val_encoder_loss: 11.7612 - val_classifier_loss: 0.8782 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5440 - decoder_loss: 25.4298 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0102 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 99: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5440 - decoder_loss: 25.4298 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0102 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7499 - val_decoder_loss: 19.0304 - val_encoder_loss: 11.7590 - val_classifier_loss: 0.8782 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5436 - decoder_loss: 25.4257 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0102 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5436 - decoder_loss: 25.4257 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0102 - decoder_accuracy: 0.0585 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7476 - val_decoder_loss: 19.0294 - val_encoder_loss: 11.7568 - val_classifier_loss: 0.8782 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5432 - decoder_loss: 25.4216 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0102 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5432 - decoder_loss: 25.4216 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0102 - decoder_accuracy: 0.0586 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7453 - val_decoder_loss: 19.0285 - val_encoder_loss: 11.7546 - val_classifier_loss: 0.8781 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5428 - decoder_loss: 25.4175 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5428 - decoder_loss: 25.4175 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0587 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7430 - val_decoder_loss: 19.0275 - val_encoder_loss: 11.7524 - val_classifier_loss: 0.8781 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5424 - decoder_loss: 25.4135 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5424 - decoder_loss: 25.4135 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0588 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7408 - val_decoder_loss: 19.0265 - val_encoder_loss: 11.7503 - val_classifier_loss: 0.8781 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5420 - decoder_loss: 25.4094 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5420 - decoder_loss: 25.4094 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0589 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7386 - val_decoder_loss: 19.0256 - val_encoder_loss: 11.7482 - val_classifier_loss: 0.8780 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5416 - decoder_loss: 25.4054 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5416 - decoder_loss: 25.4054 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7364 - val_decoder_loss: 19.0246 - val_encoder_loss: 11.7462 - val_classifier_loss: 0.8780 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5411 - decoder_loss: 25.4014 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5411 - decoder_loss: 25.4014 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7343 - val_decoder_loss: 19.0237 - val_encoder_loss: 11.7441 - val_classifier_loss: 0.8780 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5407 - decoder_loss: 25.3974 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5407 - decoder_loss: 25.3974 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7322 - val_decoder_loss: 19.0228 - val_encoder_loss: 11.7421 - val_classifier_loss: 0.8780 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5403 - decoder_loss: 25.3934 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5403 - decoder_loss: 25.3934 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0101 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7301 - val_decoder_loss: 19.0219 - val_encoder_loss: 11.7401 - val_classifier_loss: 0.8780 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5399 - decoder_loss: 25.3894 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 109: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5399 - decoder_loss: 25.3894 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7280 - val_decoder_loss: 19.0210 - val_encoder_loss: 11.7381 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5395 - decoder_loss: 25.3854 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5395 - decoder_loss: 25.3854 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7259 - val_decoder_loss: 19.0201 - val_encoder_loss: 11.7361 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5391 - decoder_loss: 25.3815 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5391 - decoder_loss: 25.3815 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0591 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7239 - val_decoder_loss: 19.0192 - val_encoder_loss: 11.7342 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5388 - decoder_loss: 25.3775 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5388 - decoder_loss: 25.3775 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7461 - val_decoder_loss: 19.0183 - val_encoder_loss: 11.7565 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5384 - decoder_loss: 25.3736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5384 - decoder_loss: 25.3736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7430 - val_decoder_loss: 19.0174 - val_encoder_loss: 11.7534 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5380 - decoder_loss: 25.3696 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5380 - decoder_loss: 25.3696 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7398 - val_decoder_loss: 19.0166 - val_encoder_loss: 11.7503 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5376 - decoder_loss: 25.3657 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5376 - decoder_loss: 25.3657 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0100 - decoder_accuracy: 0.0590 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7366 - val_decoder_loss: 19.0157 - val_encoder_loss: 11.7473 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5372 - decoder_loss: 25.3618 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5372 - decoder_loss: 25.3618 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7335 - val_decoder_loss: 19.0149 - val_encoder_loss: 11.7442 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5368 - decoder_loss: 25.3579 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5368 - decoder_loss: 25.3579 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7304 - val_decoder_loss: 19.0140 - val_encoder_loss: 11.7412 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5364 - decoder_loss: 25.3540 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5364 - decoder_loss: 25.3540 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0592 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7272 - val_decoder_loss: 19.0132 - val_encoder_loss: 11.7381 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5360 - decoder_loss: 25.3501 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5360 - decoder_loss: 25.3501 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7241 - val_decoder_loss: 19.0123 - val_encoder_loss: 11.7351 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5356 - decoder_loss: 25.3462 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5356 - decoder_loss: 25.3462 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7210 - val_decoder_loss: 19.0115 - val_encoder_loss: 11.7321 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5352 - decoder_loss: 25.3424 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 121: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5352 - decoder_loss: 25.3424 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7179 - val_decoder_loss: 19.0107 - val_encoder_loss: 11.7291 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5348 - decoder_loss: 25.3385 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5348 - decoder_loss: 25.3385 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7148 - val_decoder_loss: 19.0099 - val_encoder_loss: 11.7261 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5345 - decoder_loss: 25.3347 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5345 - decoder_loss: 25.3347 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0099 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7117 - val_decoder_loss: 19.0091 - val_encoder_loss: 11.7230 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5341 - decoder_loss: 25.3309 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5341 - decoder_loss: 25.3309 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0594 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7087 - val_decoder_loss: 19.0083 - val_encoder_loss: 11.7200 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5337 - decoder_loss: 25.3270 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5337 - decoder_loss: 25.3270 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7056 - val_decoder_loss: 19.0075 - val_encoder_loss: 11.7170 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5333 - decoder_loss: 25.3232 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5333 - decoder_loss: 25.3232 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.7025 - val_decoder_loss: 19.0068 - val_encoder_loss: 11.7140 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5329 - decoder_loss: 25.3194 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5329 - decoder_loss: 25.3194 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0595 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6994 - val_decoder_loss: 19.0060 - val_encoder_loss: 11.7111 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5325 - decoder_loss: 25.3157 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5325 - decoder_loss: 25.3157 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6964 - val_decoder_loss: 19.0052 - val_encoder_loss: 11.7081 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5322 - decoder_loss: 25.3119 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5322 - decoder_loss: 25.3119 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6933 - val_decoder_loss: 19.0045 - val_encoder_loss: 11.7051 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5318 - decoder_loss: 25.3081 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5318 - decoder_loss: 25.3081 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6902 - val_decoder_loss: 19.0037 - val_encoder_loss: 11.7021 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5314 - decoder_loss: 25.3043 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5314 - decoder_loss: 25.3043 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6872 - val_decoder_loss: 19.0030 - val_encoder_loss: 11.6991 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5310 - decoder_loss: 25.3006 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5310 - decoder_loss: 25.3006 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0098 - decoder_accuracy: 0.0599 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6841 - val_decoder_loss: 19.0023 - val_encoder_loss: 11.6961 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5307 - decoder_loss: 25.2969 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5307 - decoder_loss: 25.2969 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6811 - val_decoder_loss: 19.0015 - val_encoder_loss: 11.6931 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5303 - decoder_loss: 25.2931 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5303 - decoder_loss: 25.2931 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0600 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6792 - val_decoder_loss: 19.0008 - val_encoder_loss: 11.6913 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0388 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5299 - decoder_loss: 25.2894 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.5299 - decoder_loss: 25.2894 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6773 - val_decoder_loss: 19.0001 - val_encoder_loss: 11.6895 - val_classifier_loss: 0.8779 - val_decoder_accuracy: 0.0388 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5295 - decoder_loss: 25.2857 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0603 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5295 - decoder_loss: 25.2857 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0603 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6754 - val_decoder_loss: 18.9994 - val_encoder_loss: 11.6877 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0392 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5292 - decoder_loss: 25.2820 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5292 - decoder_loss: 25.2820 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0602 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6735 - val_decoder_loss: 18.9987 - val_encoder_loss: 11.6859 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5288 - decoder_loss: 25.2783 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5288 - decoder_loss: 25.2783 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0601 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6717 - val_decoder_loss: 18.9980 - val_encoder_loss: 11.6841 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5284 - decoder_loss: 25.2746 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5284 - decoder_loss: 25.2746 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0604 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6698 - val_decoder_loss: 18.9973 - val_encoder_loss: 11.6823 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0388 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5281 - decoder_loss: 25.2710 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0603 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5281 - decoder_loss: 25.2710 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0097 - decoder_accuracy: 0.0603 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6679 - val_decoder_loss: 18.9967 - val_encoder_loss: 11.6805 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5277 - decoder_loss: 25.2673 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0603 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 141: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5277 - decoder_loss: 25.2673 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0603 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6661 - val_decoder_loss: 18.9960 - val_encoder_loss: 11.6787 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5273 - decoder_loss: 25.2637 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5273 - decoder_loss: 25.2637 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0605 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6642 - val_decoder_loss: 18.9953 - val_encoder_loss: 11.6769 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5270 - decoder_loss: 25.2600 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0606 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5270 - decoder_loss: 25.2600 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0606 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6623 - val_decoder_loss: 18.9947 - val_encoder_loss: 11.6751 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5266 - decoder_loss: 25.2564 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0608 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5266 - decoder_loss: 25.2564 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0608 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6605 - val_decoder_loss: 18.9940 - val_encoder_loss: 11.6733 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0388 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5262 - decoder_loss: 25.2528 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0607 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5262 - decoder_loss: 25.2528 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0607 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6586 - val_decoder_loss: 18.9934 - val_encoder_loss: 11.6715 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0390 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5259 - decoder_loss: 25.2492 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0607 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5259 - decoder_loss: 25.2492 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0607 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6568 - val_decoder_loss: 18.9928 - val_encoder_loss: 11.6697 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0392 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5255 - decoder_loss: 25.2456 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0608 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5255 - decoder_loss: 25.2456 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0608 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6549 - val_decoder_loss: 18.9922 - val_encoder_loss: 11.6679 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0397 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5252 - decoder_loss: 25.2420 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5252 - decoder_loss: 25.2420 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0611 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6531 - val_decoder_loss: 18.9915 - val_encoder_loss: 11.6662 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0397 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5248 - decoder_loss: 25.2384 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.5248 - decoder_loss: 25.2384 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0096 - decoder_accuracy: 0.0613 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6512 - val_decoder_loss: 18.9909 - val_encoder_loss: 11.6644 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0400 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5244 - decoder_loss: 25.2349 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5244 - decoder_loss: 25.2349 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0614 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6494 - val_decoder_loss: 18.9904 - val_encoder_loss: 11.6626 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0397 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5241 - decoder_loss: 25.2314 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5241 - decoder_loss: 25.2314 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0615 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6476 - val_decoder_loss: 18.9898 - val_encoder_loss: 11.6608 - val_classifier_loss: 0.8778 - val_decoder_accuracy: 0.0397 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5237 - decoder_loss: 25.2279 - encoder_loss: 3.7545e-06 - classifier_loss: 0.0095 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5237 - decoder_loss: 25.2279 - encoder_loss: 3.7545e-06 - classifier_loss: 0.0095 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6212 - val_decoder_loss: 18.9892 - val_encoder_loss: 11.6345 - val_classifier_loss: 0.8772 - val_decoder_accuracy: 0.0398 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5234 - decoder_loss: 25.2246 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5234 - decoder_loss: 25.2246 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6207 - val_decoder_loss: 18.9886 - val_encoder_loss: 11.6342 - val_classifier_loss: 0.8774 - val_decoder_accuracy: 0.0398 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5231 - decoder_loss: 25.2211 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5231 - decoder_loss: 25.2211 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6179 - val_decoder_loss: 18.9880 - val_encoder_loss: 11.6314 - val_classifier_loss: 0.8773 - val_decoder_accuracy: 0.0397 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5227 - decoder_loss: 25.2177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5227 - decoder_loss: 25.2177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6149 - val_decoder_loss: 18.9875 - val_encoder_loss: 11.6285 - val_classifier_loss: 0.8773 - val_decoder_accuracy: 0.0398 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5224 - decoder_loss: 25.2142 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5224 - decoder_loss: 25.2142 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6121 - val_decoder_loss: 18.9869 - val_encoder_loss: 11.6256 - val_classifier_loss: 0.8773 - val_decoder_accuracy: 0.0398 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5220 - decoder_loss: 25.2108 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5220 - decoder_loss: 25.2108 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0620 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6093 - val_decoder_loss: 18.9864 - val_encoder_loss: 11.6229 - val_classifier_loss: 0.8773 - val_decoder_accuracy: 0.0400 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5217 - decoder_loss: 25.2074 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0621 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5217 - decoder_loss: 25.2074 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0095 - decoder_accuracy: 0.0621 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6066 - val_decoder_loss: 18.9859 - val_encoder_loss: 11.6203 - val_classifier_loss: 0.8772 - val_decoder_accuracy: 0.0402 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5213 - decoder_loss: 25.2040 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0622 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5213 - decoder_loss: 25.2040 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0622 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6040 - val_decoder_loss: 18.9853 - val_encoder_loss: 11.6177 - val_classifier_loss: 0.8772 - val_decoder_accuracy: 0.0400 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5210 - decoder_loss: 25.2005 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5210 - decoder_loss: 25.2005 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6015 - val_decoder_loss: 18.9848 - val_encoder_loss: 11.6153 - val_classifier_loss: 0.8772 - val_decoder_accuracy: 0.0400 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5207 - decoder_loss: 25.1972 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5207 - decoder_loss: 25.1972 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5990 - val_decoder_loss: 18.9843 - val_encoder_loss: 11.6129 - val_classifier_loss: 0.8772 - val_decoder_accuracy: 0.0400 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5203 - decoder_loss: 25.1938 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0623 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 162: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5203 - decoder_loss: 25.1938 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0623 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6212 - val_decoder_loss: 18.9838 - val_encoder_loss: 11.6351 - val_classifier_loss: 0.8771 - val_decoder_accuracy: 0.0402 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5200 - decoder_loss: 25.1904 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 163: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5200 - decoder_loss: 25.1904 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6184 - val_decoder_loss: 18.9833 - val_encoder_loss: 11.6323 - val_classifier_loss: 0.8771 - val_decoder_accuracy: 0.0405 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5196 - decoder_loss: 25.1870 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5196 - decoder_loss: 25.1870 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6156 - val_decoder_loss: 18.9828 - val_encoder_loss: 11.6296 - val_classifier_loss: 0.8771 - val_decoder_accuracy: 0.0408 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5193 - decoder_loss: 25.1837 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.5193 - decoder_loss: 25.1837 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6129 - val_decoder_loss: 18.9823 - val_encoder_loss: 11.6270 - val_classifier_loss: 0.8771 - val_decoder_accuracy: 0.0408 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5190 - decoder_loss: 25.1803 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 166: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5190 - decoder_loss: 25.1803 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6102 - val_decoder_loss: 18.9818 - val_encoder_loss: 11.6243 - val_classifier_loss: 0.8771 - val_decoder_accuracy: 0.0408 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5186 - decoder_loss: 25.1770 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5186 - decoder_loss: 25.1770 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0094 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6076 - val_decoder_loss: 18.9814 - val_encoder_loss: 11.6218 - val_classifier_loss: 0.8770 - val_decoder_accuracy: 0.0413 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5183 - decoder_loss: 25.1736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5183 - decoder_loss: 25.1736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6050 - val_decoder_loss: 18.9809 - val_encoder_loss: 11.6192 - val_classifier_loss: 0.8770 - val_decoder_accuracy: 0.0412 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5180 - decoder_loss: 25.1703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5180 - decoder_loss: 25.1703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.6025 - val_decoder_loss: 18.9804 - val_encoder_loss: 11.6167 - val_classifier_loss: 0.8770 - val_decoder_accuracy: 0.0413 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5176 - decoder_loss: 25.1670 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5176 - decoder_loss: 25.1670 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5999 - val_decoder_loss: 18.9800 - val_encoder_loss: 11.6142 - val_classifier_loss: 0.8770 - val_decoder_accuracy: 0.0413 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5173 - decoder_loss: 25.1637 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5173 - decoder_loss: 25.1637 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5974 - val_decoder_loss: 18.9795 - val_encoder_loss: 11.6118 - val_classifier_loss: 0.8770 - val_decoder_accuracy: 0.0417 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5170 - decoder_loss: 25.1604 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5170 - decoder_loss: 25.1604 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5950 - val_decoder_loss: 18.9791 - val_encoder_loss: 11.6094 - val_classifier_loss: 0.8769 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5166 - decoder_loss: 25.1571 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5166 - decoder_loss: 25.1571 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5925 - val_decoder_loss: 18.9787 - val_encoder_loss: 11.6070 - val_classifier_loss: 0.8769 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5163 - decoder_loss: 25.1538 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.5163 - decoder_loss: 25.1538 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5901 - val_decoder_loss: 18.9782 - val_encoder_loss: 11.6046 - val_classifier_loss: 0.8769 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5160 - decoder_loss: 25.1506 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5160 - decoder_loss: 25.1506 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5877 - val_decoder_loss: 18.9778 - val_encoder_loss: 11.6022 - val_classifier_loss: 0.8769 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5157 - decoder_loss: 25.1473 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5157 - decoder_loss: 25.1473 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0093 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5853 - val_decoder_loss: 18.9774 - val_encoder_loss: 11.5999 - val_classifier_loss: 0.8769 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5153 - decoder_loss: 25.1441 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5153 - decoder_loss: 25.1441 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5830 - val_decoder_loss: 18.9770 - val_encoder_loss: 11.5976 - val_classifier_loss: 0.8768 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5150 - decoder_loss: 25.1409 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5150 - decoder_loss: 25.1409 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5806 - val_decoder_loss: 18.9765 - val_encoder_loss: 11.5953 - val_classifier_loss: 0.8768 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5147 - decoder_loss: 25.1377 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5147 - decoder_loss: 25.1377 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5783 - val_decoder_loss: 18.9761 - val_encoder_loss: 11.5930 - val_classifier_loss: 0.8768 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5144 - decoder_loss: 25.1345 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5144 - decoder_loss: 25.1345 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5759 - val_decoder_loss: 18.9757 - val_encoder_loss: 11.5907 - val_classifier_loss: 0.8768 - val_decoder_accuracy: 0.0423 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5141 - decoder_loss: 25.1313 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5141 - decoder_loss: 25.1313 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5736 - val_decoder_loss: 18.9753 - val_encoder_loss: 11.5884 - val_classifier_loss: 0.8768 - val_decoder_accuracy: 0.0425 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5137 - decoder_loss: 25.1281 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5137 - decoder_loss: 25.1281 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5713 - val_decoder_loss: 18.9749 - val_encoder_loss: 11.5862 - val_classifier_loss: 0.8767 - val_decoder_accuracy: 0.0423 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5134 - decoder_loss: 25.1250 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5134 - decoder_loss: 25.1250 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5690 - val_decoder_loss: 18.9745 - val_encoder_loss: 11.5839 - val_classifier_loss: 0.8767 - val_decoder_accuracy: 0.0425 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5131 - decoder_loss: 25.1218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5131 - decoder_loss: 25.1218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5668 - val_decoder_loss: 18.9741 - val_encoder_loss: 11.5817 - val_classifier_loss: 0.8767 - val_decoder_accuracy: 0.0428 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5128 - decoder_loss: 25.1187 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5128 - decoder_loss: 25.1187 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5645 - val_decoder_loss: 18.9738 - val_encoder_loss: 11.5794 - val_classifier_loss: 0.8767 - val_decoder_accuracy: 0.0427 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5125 - decoder_loss: 25.1155 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5125 - decoder_loss: 25.1155 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0092 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5622 - val_decoder_loss: 18.9734 - val_encoder_loss: 11.5772 - val_classifier_loss: 0.8767 - val_decoder_accuracy: 0.0430 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5122 - decoder_loss: 25.1124 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5122 - decoder_loss: 25.1124 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5600 - val_decoder_loss: 18.9730 - val_encoder_loss: 11.5750 - val_classifier_loss: 0.8766 - val_decoder_accuracy: 0.0427 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5118 - decoder_loss: 25.1093 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5118 - decoder_loss: 25.1093 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5577 - val_decoder_loss: 18.9726 - val_encoder_loss: 11.5728 - val_classifier_loss: 0.8766 - val_decoder_accuracy: 0.0427 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5115 - decoder_loss: 25.1061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5115 - decoder_loss: 25.1061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5555 - val_decoder_loss: 18.9723 - val_encoder_loss: 11.5706 - val_classifier_loss: 0.8766 - val_decoder_accuracy: 0.0423 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5112 - decoder_loss: 25.1030 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5112 - decoder_loss: 25.1030 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5532 - val_decoder_loss: 18.9719 - val_encoder_loss: 11.5684 - val_classifier_loss: 0.8766 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5109 - decoder_loss: 25.0999 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5109 - decoder_loss: 25.0999 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5510 - val_decoder_loss: 18.9715 - val_encoder_loss: 11.5662 - val_classifier_loss: 0.8766 - val_decoder_accuracy: 0.0422 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5106 - decoder_loss: 25.0968 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5106 - decoder_loss: 25.0968 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5488 - val_decoder_loss: 18.9712 - val_encoder_loss: 11.5640 - val_classifier_loss: 0.8765 - val_decoder_accuracy: 0.0427 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5103 - decoder_loss: 25.0937 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5103 - decoder_loss: 25.0937 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5466 - val_decoder_loss: 18.9708 - val_encoder_loss: 11.5619 - val_classifier_loss: 0.8765 - val_decoder_accuracy: 0.0428 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5100 - decoder_loss: 25.0907 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5100 - decoder_loss: 25.0907 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5445 - val_decoder_loss: 18.9705 - val_encoder_loss: 11.5598 - val_classifier_loss: 0.8765 - val_decoder_accuracy: 0.0428 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5097 - decoder_loss: 25.0876 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.5097 - decoder_loss: 25.0876 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5425 - val_decoder_loss: 18.9701 - val_encoder_loss: 11.5578 - val_classifier_loss: 0.8765 - val_decoder_accuracy: 0.0430 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5094 - decoder_loss: 25.0845 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5094 - decoder_loss: 25.0845 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0091 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5404 - val_decoder_loss: 18.9698 - val_encoder_loss: 11.5558 - val_classifier_loss: 0.8764 - val_decoder_accuracy: 0.0430 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5091 - decoder_loss: 25.0815 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0638 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5091 - decoder_loss: 25.0815 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0638 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5384 - val_decoder_loss: 18.9694 - val_encoder_loss: 11.5538 - val_classifier_loss: 0.8764 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5087 - decoder_loss: 25.0784 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5087 - decoder_loss: 25.0784 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5364 - val_decoder_loss: 18.9691 - val_encoder_loss: 11.5518 - val_classifier_loss: 0.8764 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5084 - decoder_loss: 25.0754 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0638 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5084 - decoder_loss: 25.0754 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0638 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5343 - val_decoder_loss: 18.9688 - val_encoder_loss: 11.5498 - val_classifier_loss: 0.8764 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5081 - decoder_loss: 25.0723 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0639 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5081 - decoder_loss: 25.0723 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0639 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5323 - val_decoder_loss: 18.9685 - val_encoder_loss: 11.5479 - val_classifier_loss: 0.8764 - val_decoder_accuracy: 0.0433 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5078 - decoder_loss: 25.0693 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0640 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5078 - decoder_loss: 25.0693 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0640 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5303 - val_decoder_loss: 18.9681 - val_encoder_loss: 11.5459 - val_classifier_loss: 0.8763 - val_decoder_accuracy: 0.0435 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5075 - decoder_loss: 25.0663 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0642 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5075 - decoder_loss: 25.0663 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0642 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5283 - val_decoder_loss: 18.9678 - val_encoder_loss: 11.5439 - val_classifier_loss: 0.8763 - val_decoder_accuracy: 0.0433 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5072 - decoder_loss: 25.0633 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0643 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 203: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5072 - decoder_loss: 25.0633 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0643 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5263 - val_decoder_loss: 18.9675 - val_encoder_loss: 11.5419 - val_classifier_loss: 0.8763 - val_decoder_accuracy: 0.0435 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5069 - decoder_loss: 25.0603 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0642 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 204: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.5069 - decoder_loss: 25.0603 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0642 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5243 - val_decoder_loss: 18.9672 - val_encoder_loss: 11.5400 - val_classifier_loss: 0.8763 - val_decoder_accuracy: 0.0437 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5066 - decoder_loss: 25.0573 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0643 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 205: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5066 - decoder_loss: 25.0573 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0643 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5223 - val_decoder_loss: 18.9669 - val_encoder_loss: 11.5380 - val_classifier_loss: 0.8762 - val_decoder_accuracy: 0.0438 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5063 - decoder_loss: 25.0543 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0642 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 206: val_loss did not improve from 3.81789\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5063 - decoder_loss: 25.0543 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0090 - decoder_accuracy: 0.0642 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 13.5204 - val_decoder_loss: 18.9665 - val_encoder_loss: 11.5361 - val_classifier_loss: 0.8762 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 206: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_10 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_11 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_5 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_10 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_11 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 7.1741 - decoder_loss: 26.4136 - encoder_loss: 4.4725 - classifier_loss: 0.6024 - decoder_accuracy: 0.0134 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6333\n",
            "F1-score is computed based on binary\n",
            "(loss: 7.174051761627197, accuracy: 0.6333333253860474)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.73      0.67        15\n",
            "         1.0       0.67      0.53      0.59        15\n",
            "\n",
            "    accuracy                           0.63        30\n",
            "   macro avg       0.64      0.63      0.63        30\n",
            "weighted avg       0.64      0.63      0.63        30\n",
            "\n",
            "Accuracy: 0.6333333253860474\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6333333253860474\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIN2Net model example"
      ],
      "metadata": {
        "id": "K-Kn7p1VVXsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=15, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=20,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(1,2):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        " \n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "id": "lPyutATxGTua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6120405b-1e03-4c0b-8339-01a206f0d927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 1\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_59 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_160 (Conv2D)         (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_32 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_161 (Conv2D)         (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_33 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_56 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_14 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_28 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_29 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_59 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_59[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 26.2897 - decoder_loss: 62.8253 - encoder_loss: 19.9228 - classifier_loss: 0.8441 - decoder_accuracy: 0.0153 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.5500\n",
            "Epoch 1: val_loss improved from inf to 114.08508, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 26.2897 - decoder_loss: 62.8253 - encoder_loss: 19.9228 - classifier_loss: 0.8441 - decoder_accuracy: 0.0153 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.5500 - val_loss: 114.0851 - val_decoder_loss: 43.9175 - val_encoder_loss: 109.4757 - val_classifier_loss: 2.1767 - val_decoder_accuracy: 0.0172 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.8892 - decoder_loss: 62.8212 - encoder_loss: 0.5273 - classifier_loss: 0.7979 - decoder_accuracy: 0.0153 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.3000\n",
            "Epoch 2: val_loss improved from 114.08508 to 4.67016, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 6.8892 - decoder_loss: 62.8212 - encoder_loss: 0.5273 - classifier_loss: 0.7979 - decoder_accuracy: 0.0153 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.3000 - val_loss: 4.6702 - val_decoder_loss: 43.9199 - val_encoder_loss: 0.1882 - val_classifier_loss: 0.8998 - val_decoder_accuracy: 0.0202 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.2000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 16.0045 - decoder_loss: 62.7292 - encoder_loss: 9.6416 - classifier_loss: 0.8995 - decoder_accuracy: 0.0212 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.1750\n",
            "Epoch 3: val_loss improved from 4.67016 to 4.45908, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 16.0045 - decoder_loss: 62.7292 - encoder_loss: 9.6416 - classifier_loss: 0.8995 - decoder_accuracy: 0.0212 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.1750 - val_loss: 4.4591 - val_decoder_loss: 43.8694 - val_encoder_loss: 0.0259 - val_classifier_loss: 0.4627 - val_decoder_accuracy: 0.0182 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.2901 - decoder_loss: 62.5224 - encoder_loss: 1.9882 - classifier_loss: 0.4967 - decoder_accuracy: 0.0235 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750\n",
            "Epoch 4: val_loss did not improve from 4.45908\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.2901 - decoder_loss: 62.5224 - encoder_loss: 1.9882 - classifier_loss: 0.4967 - decoder_accuracy: 0.0235 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8750 - val_loss: 5.1451 - val_decoder_loss: 43.7901 - val_encoder_loss: 0.7166 - val_classifier_loss: 0.4946 - val_decoder_accuracy: 0.0208 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.2957 - decoder_loss: 62.3733 - encoder_loss: 1.0079 - classifier_loss: 0.5049 - decoder_accuracy: 0.0250 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 5: val_loss improved from 4.45908 to 4.40844, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 7.2957 - decoder_loss: 62.3733 - encoder_loss: 1.0079 - classifier_loss: 0.5049 - decoder_accuracy: 0.0250 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 4.4084 - val_decoder_loss: 43.7930 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.2914 - val_decoder_accuracy: 0.0213 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 10.4274 - decoder_loss: 63.1054 - encoder_loss: 4.0820 - classifier_loss: 0.3491 - decoder_accuracy: 0.0238 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 6: val_loss did not improve from 4.40844\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 10.4274 - decoder_loss: 63.1054 - encoder_loss: 4.0820 - classifier_loss: 0.3491 - decoder_accuracy: 0.0238 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 6.5705 - val_decoder_loss: 43.6881 - val_encoder_loss: 2.1571 - val_classifier_loss: 0.4460 - val_decoder_accuracy: 0.0225 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.6203 - decoder_loss: 62.3633 - encoder_loss: 0.3417 - classifier_loss: 0.4230 - decoder_accuracy: 0.0282 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 7: val_loss improved from 4.40844 to 4.39243, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 6.6203 - decoder_loss: 62.3633 - encoder_loss: 0.3417 - classifier_loss: 0.4230 - decoder_accuracy: 0.0282 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 4.3924 - val_decoder_loss: 43.6789 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.2454 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 9.0973 - decoder_loss: 61.9154 - encoder_loss: 2.8760 - classifier_loss: 0.2975 - decoder_accuracy: 0.0406 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 8: val_loss did not improve from 4.39243\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 9.0973 - decoder_loss: 61.9154 - encoder_loss: 2.8760 - classifier_loss: 0.2975 - decoder_accuracy: 0.0406 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.6045 - val_decoder_loss: 43.6662 - val_encoder_loss: 0.2077 - val_classifier_loss: 0.3014 - val_decoder_accuracy: 0.0277 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.8387 - decoder_loss: 61.4488 - encoder_loss: 0.6627 - classifier_loss: 0.3114 - decoder_accuracy: 0.0436 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250\n",
            "Epoch 9: val_loss improved from 4.39243 to 4.36333, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 6.8387 - decoder_loss: 61.4488 - encoder_loss: 0.6627 - classifier_loss: 0.3114 - decoder_accuracy: 0.0436 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9250 - val_loss: 4.3633 - val_decoder_loss: 43.3595 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.2739 - val_decoder_accuracy: 0.0327 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.1499 - decoder_loss: 60.0089 - encoder_loss: 0.1189 - classifier_loss: 0.3014 - decoder_accuracy: 0.0522 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 10: val_loss did not improve from 4.36333\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.1499 - decoder_loss: 60.0089 - encoder_loss: 0.1189 - classifier_loss: 0.3014 - decoder_accuracy: 0.0522 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.3832 - val_decoder_loss: 43.4308 - val_encoder_loss: 0.0146 - val_classifier_loss: 0.2555 - val_decoder_accuracy: 0.0393 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.0095 - decoder_loss: 59.1885 - encoder_loss: 0.0611 - classifier_loss: 0.2948 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 11: val_loss did not improve from 4.36333\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.0095 - decoder_loss: 59.1885 - encoder_loss: 0.0611 - classifier_loss: 0.2948 - decoder_accuracy: 0.0583 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.3876 - val_decoder_loss: 43.4645 - val_encoder_loss: 0.0129 - val_classifier_loss: 0.2824 - val_decoder_accuracy: 0.0315 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.1244 - decoder_loss: 58.3554 - encoder_loss: 0.2594 - classifier_loss: 0.2950 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 12: val_loss did not improve from 4.36333\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.1244 - decoder_loss: 58.3554 - encoder_loss: 0.2594 - classifier_loss: 0.2950 - decoder_accuracy: 0.0545 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.5337 - val_decoder_loss: 45.0344 - val_encoder_loss: 0.0117 - val_classifier_loss: 0.1861 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.2011 - decoder_loss: 60.1704 - encoder_loss: 0.1618 - classifier_loss: 0.2218 - decoder_accuracy: 0.0393 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 13: val_loss did not improve from 4.36333\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.2011 - decoder_loss: 60.1704 - encoder_loss: 0.1618 - classifier_loss: 0.2218 - decoder_accuracy: 0.0393 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 6.1833 - val_decoder_loss: 46.2756 - val_encoder_loss: 1.5370 - val_classifier_loss: 0.1874 - val_decoder_accuracy: 0.0410 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0100\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.5337 - decoder_loss: 64.8923 - encoder_loss: 0.0244 - classifier_loss: 0.2004 - decoder_accuracy: 0.0375 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 4.36333\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.5337 - decoder_loss: 64.8923 - encoder_loss: 0.0244 - classifier_loss: 0.2004 - decoder_accuracy: 0.0375 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 6.4689 - val_decoder_loss: 43.2528 - val_encoder_loss: 2.1168 - val_classifier_loss: 0.2677 - val_decoder_accuracy: 0.0420 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.0644 - decoder_loss: 59.9355 - encoder_loss: 1.0410 - classifier_loss: 0.2987 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.1250 - classifier_accuracy: 0.9750\n",
            "Epoch 15: val_loss improved from 4.36333 to 4.34922, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 7.0644 - decoder_loss: 59.9355 - encoder_loss: 1.0410 - classifier_loss: 0.2987 - decoder_accuracy: 0.0558 - encoder_accuracy: 0.1250 - classifier_accuracy: 0.9750 - val_loss: 4.3492 - val_decoder_loss: 43.4118 - val_encoder_loss: 0.0000e+00 - val_classifier_loss: 0.0805 - val_decoder_accuracy: 0.0418 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.2114 - decoder_loss: 61.6818 - encoder_loss: 1.0311 - classifier_loss: 0.1215 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 16: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 7.2114 - decoder_loss: 61.6818 - encoder_loss: 1.0311 - classifier_loss: 0.1215 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 4.3690 - val_decoder_loss: 43.4903 - val_encoder_loss: 0.0132 - val_classifier_loss: 0.0682 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.1355 - decoder_loss: 60.4549 - encoder_loss: 0.0810 - classifier_loss: 0.0899 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 17: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.1355 - decoder_loss: 60.4549 - encoder_loss: 0.0810 - classifier_loss: 0.0899 - decoder_accuracy: 0.0517 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 4.4052 - val_decoder_loss: 43.5865 - val_encoder_loss: 0.0399 - val_classifier_loss: 0.0657 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.9813 - decoder_loss: 59.6866 - encoder_loss: 0.0055 - classifier_loss: 0.0712 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 18: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 5.9813 - decoder_loss: 59.6866 - encoder_loss: 0.0055 - classifier_loss: 0.0712 - decoder_accuracy: 0.0593 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 4.6521 - val_decoder_loss: 43.6808 - val_encoder_loss: 0.2770 - val_classifier_loss: 0.0703 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.8810 - decoder_loss: 58.7313 - encoder_loss: 0.0011 - classifier_loss: 0.0676 - decoder_accuracy: 0.0670 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.8810 - decoder_loss: 58.7313 - encoder_loss: 0.0011 - classifier_loss: 0.0676 - decoder_accuracy: 0.0670 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.6682 - val_decoder_loss: 43.5455 - val_encoder_loss: 0.3071 - val_classifier_loss: 0.0658 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.7976 - decoder_loss: 57.8814 - encoder_loss: 0.0033 - classifier_loss: 0.0617 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.7976 - decoder_loss: 57.8814 - encoder_loss: 0.0033 - classifier_loss: 0.0617 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.7098 - val_decoder_loss: 43.4271 - val_encoder_loss: 0.3605 - val_classifier_loss: 0.0659 - val_decoder_accuracy: 0.0523 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.7191 - decoder_loss: 57.1128 - encoder_loss: 0.0024 - classifier_loss: 0.0545 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.7191 - decoder_loss: 57.1128 - encoder_loss: 0.0024 - classifier_loss: 0.0545 - decoder_accuracy: 0.0695 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.8099 - val_decoder_loss: 43.4294 - val_encoder_loss: 0.4604 - val_classifier_loss: 0.0659 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.6779 - decoder_loss: 56.7225 - encoder_loss: 3.7090e-04 - classifier_loss: 0.0524 - decoder_accuracy: 0.0701 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 5.6779 - decoder_loss: 56.7225 - encoder_loss: 3.7090e-04 - classifier_loss: 0.0524 - decoder_accuracy: 0.0701 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.8319 - val_decoder_loss: 43.4312 - val_encoder_loss: 0.4825 - val_classifier_loss: 0.0637 - val_decoder_accuracy: 0.0510 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.6392 - decoder_loss: 56.3372 - encoder_loss: 5.3408e-04 - classifier_loss: 0.0494 - decoder_accuracy: 0.0709 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.6392 - decoder_loss: 56.3372 - encoder_loss: 5.3408e-04 - classifier_loss: 0.0494 - decoder_accuracy: 0.0709 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.8974 - val_decoder_loss: 43.3774 - val_encoder_loss: 0.5532 - val_classifier_loss: 0.0647 - val_decoder_accuracy: 0.0543 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.6016 - decoder_loss: 55.9581 - encoder_loss: 9.0688e-04 - classifier_loss: 0.0486 - decoder_accuracy: 0.0707 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.6016 - decoder_loss: 55.9581 - encoder_loss: 9.0688e-04 - classifier_loss: 0.0486 - decoder_accuracy: 0.0707 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.8913 - val_decoder_loss: 43.3206 - val_encoder_loss: 0.5530 - val_classifier_loss: 0.0623 - val_decoder_accuracy: 0.0563 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5686 - decoder_loss: 55.6304 - encoder_loss: 9.8009e-04 - classifier_loss: 0.0459 - decoder_accuracy: 0.0710 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.5686 - decoder_loss: 55.6304 - encoder_loss: 9.8009e-04 - classifier_loss: 0.0459 - decoder_accuracy: 0.0710 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9161 - val_decoder_loss: 43.2478 - val_encoder_loss: 0.5853 - val_classifier_loss: 0.0607 - val_decoder_accuracy: 0.0585 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0025\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5417 - decoder_loss: 55.3735 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0433 - decoder_accuracy: 0.0691 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.5417 - decoder_loss: 55.3735 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0433 - decoder_accuracy: 0.0691 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9310 - val_decoder_loss: 43.2443 - val_encoder_loss: 0.6006 - val_classifier_loss: 0.0598 - val_decoder_accuracy: 0.0575 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5288 - decoder_loss: 55.2384 - encoder_loss: 7.2253e-04 - classifier_loss: 0.0424 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 5.5288 - decoder_loss: 55.2384 - encoder_loss: 7.2253e-04 - classifier_loss: 0.0424 - decoder_accuracy: 0.0683 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9501 - val_decoder_loss: 43.2167 - val_encoder_loss: 0.6225 - val_classifier_loss: 0.0589 - val_decoder_accuracy: 0.0570 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5173 - decoder_loss: 55.1273 - encoder_loss: 4.1496e-04 - classifier_loss: 0.0411 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 5.5173 - decoder_loss: 55.1273 - encoder_loss: 4.1496e-04 - classifier_loss: 0.0411 - decoder_accuracy: 0.0679 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9546 - val_decoder_loss: 43.2018 - val_encoder_loss: 0.6287 - val_classifier_loss: 0.0579 - val_decoder_accuracy: 0.0563 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.5038 - decoder_loss: 54.9985 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0398 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.5038 - decoder_loss: 54.9985 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0398 - decoder_accuracy: 0.0675 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9608 - val_decoder_loss: 43.1856 - val_encoder_loss: 0.6365 - val_classifier_loss: 0.0571 - val_decoder_accuracy: 0.0563 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4937 - decoder_loss: 54.8765 - encoder_loss: 0.0021 - classifier_loss: 0.0389 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.4937 - decoder_loss: 54.8765 - encoder_loss: 0.0021 - classifier_loss: 0.0389 - decoder_accuracy: 0.0666 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9883 - val_decoder_loss: 43.1735 - val_encoder_loss: 0.6653 - val_classifier_loss: 0.0570 - val_decoder_accuracy: 0.0540 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 0.0012\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4818 - decoder_loss: 54.7722 - encoder_loss: 7.0961e-04 - classifier_loss: 0.0383 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4818 - decoder_loss: 54.7722 - encoder_loss: 7.0961e-04 - classifier_loss: 0.0383 - decoder_accuracy: 0.0653 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 4.9902 - val_decoder_loss: 43.1646 - val_encoder_loss: 0.6681 - val_classifier_loss: 0.0564 - val_decoder_accuracy: 0.0523 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4770 - decoder_loss: 54.7190 - encoder_loss: 0.0013 - classifier_loss: 0.0378 - decoder_accuracy: 0.0651 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.4770 - decoder_loss: 54.7190 - encoder_loss: 0.0013 - classifier_loss: 0.0378 - decoder_accuracy: 0.0651 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0153 - val_decoder_loss: 43.1381 - val_encoder_loss: 0.6959 - val_classifier_loss: 0.0563 - val_decoder_accuracy: 0.0522 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4730 - decoder_loss: 54.6818 - encoder_loss: 0.0011 - classifier_loss: 0.0373 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 5.4730 - decoder_loss: 54.6818 - encoder_loss: 0.0011 - classifier_loss: 0.0373 - decoder_accuracy: 0.0648 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0232 - val_decoder_loss: 43.1226 - val_encoder_loss: 0.7054 - val_classifier_loss: 0.0557 - val_decoder_accuracy: 0.0505 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4662 - decoder_loss: 54.6256 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0368 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 34: val_loss did not improve from 4.34922\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.4662 - decoder_loss: 54.6256 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0368 - decoder_accuracy: 0.0645 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0286 - val_decoder_loss: 43.1129 - val_encoder_loss: 0.7118 - val_classifier_loss: 0.0553 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.4608 - decoder_loss: 54.5712 - encoder_loss: 1.0741e-05 - classifier_loss: 0.0364 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 4.34922\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.4608 - decoder_loss: 54.5712 - encoder_loss: 1.0741e-05 - classifier_loss: 0.0364 - decoder_accuracy: 0.0644 - encoder_accuracy: 0.0250 - classifier_accuracy: 1.0000 - val_loss: 5.0266 - val_decoder_loss: 43.1065 - val_encoder_loss: 0.7105 - val_classifier_loss: 0.0547 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 1.0000 - lr: 6.2500e-04\n",
            "Epoch 35: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_60 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_162 (Conv2D)         (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_34 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_163 (Conv2D)         (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_45 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_35 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_57 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_15 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_30 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_31 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_60 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_60[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 1s 540ms/step - loss: 14.0979 - decoder_loss: 48.1068 - encoder_loss: 9.2356 - classifier_loss: 0.5160 - decoder_accuracy: 0.0381 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7333\n",
            "F1-score is computed based on binary\n",
            "(loss: 14.097868919372559, accuracy: 0.7333333492279053)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.93      0.78        15\n",
            "         1.0       0.89      0.53      0.67        15\n",
            "\n",
            "    accuracy                           0.73        30\n",
            "   macro avg       0.78      0.73      0.72        30\n",
            "weighted avg       0.78      0.73      0.72        30\n",
            "\n",
            "Accuracy: 0.7333333492279053\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEKCAYAAABuTfznAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAX2ElEQVR4nO3debxcZX3H8c/33oTlQkKICXkJyiJLNEQDNJVNKRCruAFWtEWwKijSsFhFqVYUtdJacBepvQJCi4KAUgWVRasFEdBAEkyCQJElkS0hISwJzcKvf5xzyWTuMmcmM/OcufN9v17zysycmef87r2vfF/Pc55znqOIwMzMNuhJXYCZWdk4GM3MqjgYzcyqOBjNzKo4GM3MqjgYzcyqOBjNbNSQdKGkxyUtGGLbaZJC0qRa7TgYzWw0uQg4rPpNSS8FXg88VKQRB6OZjRoRcSOwfIhNXwFOBwpd0TKmmUWVjcZsGdpsXOoyrA57v2LH1CVYHR588AGWLVumTWmjd/xOEetWF/psrF66EHiu4q3+iOgf6TuSjgD+FBHzpWKlju5g3Gwcm099Z+oyrA4333Zu6hKsDgfuO3OT24h1qwv/P31u3jefi4jCO5XUB/wj2TC6sFEdjGbWCQRq2VG9XYFdgIHe4kuAOyS9OiIeHe5LDkYzS0tAT29Lmo6I3wPbvbAr6QFgZkQsG+l7nnwxs/SkYo+azehS4BZgqqQlko5vpBz3GM0sseYNpSPi6Brbdy7SjoPRzNIrOFvcLg5GM0tLtHLypSEORjNLrNjxw3ZyMJpZei2alW6Ug9HMEmvpeYwNcTCaWVrCQ2kzs0HcYzQzq+ShtJnZxgT0evLFzGxjPsZoZlbJQ2kzs8HcYzQzq+Ieo5lZhYJLirWTg9HM0vMlgWZmlTz5YmY2mIfSZmYVvB6jmVk1D6XNzAbz5IuZWRUfYzQzqyAPpc3MBnOP0cxsY3IwmpltkN3ZoFzBWK6BvZl1Hwn1FHvUbkoXSnpc0oKK986R9AdJd0q6StKEWu04GM0sOUmFHgVcBBxW9d4NwPSIeBVwD/CJWo04GM0suWYFY0TcCCyveu/6iFiXv7wVeEmtdnyM0cySq+MY4yRJcype90dEfx27Og74fq0PORjNLC3lj2KWRcTMhnYjfRJYB3y31mcdjGaWlCh8/LDxfUjvBd4CzIqIqPV5B6OZJdfT07rpDkmHAacDfxERqwrV07JqzMwKatbki6RLgVuAqZKWSDoeOBcYB9wgaZ6kb9Vqxz1GM0urvmOMI4qIo4d4+4J623EwmllyZbvyxcFoZkm1Y/KlXg5GM0uuyOV+7eRgNLO05KG0mdkgDkYzsyoORjOzCp58MTMbSrly0cFoZomptZcENsLBaGbJeShtZlatXLnoRSTK7hufOoZ7rvsXfnPZPw7adtIxh7Lid+cycZutElRmRZz8uUvY/fUfZ/+/Pit1KaXWxFsbNEWyYJT0TB2fnSzpNklzJb1W0uxW1lYml15zK0ed+s1B7+8wZQKH7PsKFj+yfIhvWVkc/Zb9uPLrJ6Uuo9SKhmJXBGOdZgG/j4i9gcVA1wTjb+bex4qnBi8hd9aH385nvvFfFFhz0xI6cJ/d2HZ8X+oySq9swViqY4ySdgW+CUwGVgEfALYAzga2lDQTuBvYVdI84IaI+FiqelN540Gv5JGlT7Lg3j+lLsWsKXyt9Mj6gRMj4l5J+wLnRcShkj4NzIyIkyXtDOwZEXsN1YCkE4ATABi7dXuqbqMtNx/LR973Bt5+8rmpSzFrGs9KD0PS1sABwBUVv6TN620nv2NYP0BP33ajbpy5y0sms9P2L+Km72W3xt1+uwn8zyX/wKz3nsPjTzyduDqzBngRiRH1AE8O1xO0zKL7HmaPN2y4X/j8H32WQ/72bJavfDZhVWaNE1CyXCzP5EtEPAXcL+kdAMrMGOKjT5Pdv6ErnP/593L9haex205TWHDNP3Hs4funLsnqcPwnv8Prj/sS//vgY+z55jP4zx/9JnVJJVS+WemUPcY+SUsqXn8ZOAb4N0lnAGOBy4D5lV+KiCck3SxpAfCz0T758v4zLhpx+4wjzmxPIdaQC856X+oSOkKPJ18yETFcb/WwIT57EXBRxet3taYqM2s7lW8oXaZjjGbWhYR7jGZmg7jHaGZWpWyn65RmVtrMulR+jLHIo2ZT0oWSHs8nZwfemyjpBkn35v9uW6sdB6OZJSVET09PoUcBFzF4AvfjwC8iYnfgF/nrETkYzSy5ZvUYI+JGoHrJqSOAi/PnFwNH1mrHxxjNLLk6jjFOkjSn4nV/fhnwSKZExCP580eBKbV24mA0s7TqO49xWUTMbHRXERGSaq6h4KG0mSWVXSvd0ksCH5P0YrL9vBh4vNYXHIxmllyzjjEO48fAe/Ln7wF+VOsLHkqbWXLNuvJF0qXAwWTHIpcAZwJfAC6XdDzwIPDOWu04GM0srSauxxgRRw+zaVY97TgYzSypMq7H6GA0s8Tau9ZiEQ5GM0uuZLnoYDSzxORlx8zMNjJwHmOZOBjNLDkHo5lZlZLlooPRzNJzj9HMrJJvhmVmtrFsodpyJaOD0cyS6ylZl9HBaGbJlSwXHYxmlpaauIhEszgYzSy5kh1iHD4YJX0DGHYJ8Ig4tSUVmVnX6aTJlzkjbDMzawqRzUyXybDBGBEXV76W1BcRq1pfkpl1m5J1GGvf80XS/pIWAX/IX8+QdF7LKzOz7lDwRljtnKApcjOsrwJvAJ4AiIj5wEGtLMrMukuLb4ZVt0Kz0hGxuCqt17emHDPrNqIzT/BeLOkAICSNBT4E3NXassysm5RtVrrIUPpE4CRgB+BhYK/8tZnZJis6jC7VUDoilgHHtKEWM+tSZRtKF5mVfpmkqyUtlfS4pB9Jelk7ijOz7qCCj3YpMpT+HnA58GJge+AK4NJWFmVm3aUTT9fpi4j/jIh1+eMSYItWF2Zm3SGblS72qNmW9GFJCyUtkHSppIayathglDRR0kTgZ5I+LmlnSTtJOh34aSM7MzMbRNlCtUUeIzejHYBTgZkRMR3oBf6mkZJGmny5nWwRiYFqPlixLYBPNLJDM7NqTRwmjwG2lLQW6CM7k6ahRoYUEbs0WJiZWWEDQ+mCJkmqXOCmPyL6ASLiT5K+CDwErAauj4jrG6mp0JUvkqYD06g4thgR/9HIDs3MqtXRY1wWETOHaWNb4AhgF+BJ4ApJx+bzInUpcrrOmcA38schwNnA4fXuyMxsOE06Xed1wP0RsTQi1gI/BA5opJ4is9JHAbOARyPifcAMYJtGdmZmVk2C3h4VetTwELCfpD5lXdBZNHj5cpGh9OqIeF7SOknjgceBlzayMzOzoTRj8iUibpN0JXAHsA6YC/Q30laRYJwjaQLwbbKZ6meAWxrZmZnZUJo1KR0RZwJnbmo7Ra6Vnp0//Zaka4HxEXHnpu7YzAyy2xqU7VrpkW6Gtc9I2yLijtaUZGZdpc0r5xQxUo/xSyNsC+DQJtfSdFN22I7j/tk3M+wkH7zcg5FO8uCK1U1pp2PuKx0Rh7SzEDPrTgJ6OyUYzczapWQLeDsYzSw9B6OZWYXstgXlSsYilwRK0rGSPp2/3lHSq1tfmpl1i2atx9i0egp85jxgf+Do/PXTwDdbVpGZdZ2OuxkWsG9E7CNpLkBErJC0WYvrMrMuIWBMyYbSRYJxraResnMXkTQZeL6lVZlZVylZLhYKxq8DVwHbSTqLbLWdM1palZl1DamDLgkcEBHflXQ72RI+Ao6MiIaW8jEzG0rJcrF2MEraEVgFXF35XkQ81MrCzKx7dOJ5jD9hw02xtiBbNvxuYM8W1mVmXUJQZBHatioylH5l5et81Z3Zw3zczKw+bT5HsYi6r3yJiDsk7duKYsysO6nIHV3aqMgxxo9UvOwB9qHBe7WamVWr8/apbVGkxziu4vk6smOOP2hNOWbWjToqGPMTu8dFxEfbVI+ZdaGyLSIx0q0NxkTEOkkHtrMgM+su2e1TU1exsZF6jL8lO544T9KPgSuAZwc2RsQPW1ybmXWJjrvyhezcxSfI7vEycD5jAA5GM9tknTb5sl0+I72ADYE4IFpalZl1lZJ1GEcMxl5gaxjyBCMHo5k1iehp0nmMkiYA5wPTyXLquIi4pd52RgrGRyLicw3WZ2ZWiGhqj/FrwLURcVS+bmxfI42MFIwl69ya2agkGNOEg4yStgEOAt4LEBFrgDWNtDXSJPmsRho0M6vHQI+x4K0NJkmaU/E4oaKpXYClwHckzZV0vqStGqlp2B5jRCxvpEEzs3rVcbrOsoiYOcy2MWSnGJ4SEbdJ+hrwceBTdddT7xfMzJqtSTfDWgIsiYjb8tdXkgVl3RyMZpaUyIKoyGMkEfEosFjS1PytWcCiRmqqe9kxM7OmUlOvfDkF+G4+I/1H4H2NNOJgNLOksitfmhOMETEPGO4YZGEORjNLrmznBjoYzSy5Trok0MysDdQ56zGambXDwKx0mTgYzSy5TlyP0cysddRBtzYwM2sHD6XNzIbgHqOZWZVyxaKD0cwSE9DrHqOZ2cZKlosORjNLTahkg2kHo5kl5x6jmVmF7HSdciWjg9HM0iq2OndbORjNLDlfEmhmViFbqDZ1FRtzMJpZcp6VNjOrUrKRtIOxkyxfuoKfXPazF16vXL6SA163H/scuHfCqmwks/aYxGt2mUgAf1r5HBf/djHrno/UZZVO1/QYJa0Hfp/v437g3RHxpKTtga9HxFE1vv9MRGw9xPtHAvdEREO3RexkEydvy7tPeRcAzz//PP1fuJDdpu2auCobzoQtx3DobpP4zHV3s3Z98IH9d+TPd5zALQ+sSF1aqZTxGGMrV/tZHRF7RcR0YDlwEkBEPFwrFGs4EpjWjAI72UP3LWbCxG0Yv+341KXYCHp6YGxvDz2CzXp7eHL12tQllY9ET8FHu7RrGbRbgB0AJO0saUH+vE/S5ZIWSbpK0m2SXrj1oaSzJM2XdKukKZIOAA4HzpE0T1LXdpfuvvNeps7YI3UZNoInV6/jhruX8i9vfjlnv3Uaq9eu567HnkldVimp4KNdWh6MknqBWcCPh9g8G1gREdOATwF/VrFtK+DWiJgB3Ah8ICJ+k7fzsbw3et8Q+ztB0hxJc1Y9NTqHLOvXree+u/7IHtN3T12KjaBvbC8ztt+GT/70D5x+9SI2H9PDvjtOSF1W6QzcV7pbeoxbSpoHPApMAW4Y4jOvAS4DiIgFwJ0V29YA1+TPbwd2LrLTiOiPiJkRMbNv/LYNll5u99/zAFO2n8xW4/pSl2IjePmUrVn27Bqe+b/1PB8wd8lKXjbJf7OhNLPHKKlX0lxJ19T+9NBafowR2InsZzqpzu+vjYiB6bv1eAb9BXfPv4epM6amLsNqWL5qDS97UR9je7P/0i+fsjWPPvV/iasqqeaOpT8E3LUp5bR8KB0Rq4BTgdMkVYfbzcA7ASRNA15ZoMmngXFNLbKDrF2zlgf/dzG779m1h1c7xgPLV3PHkpWc8Ze78+k37IEQN/1xeeqySqlZQ2lJLwHeDJy/KfW0pRcWEXMl3QkcDdxUsek84GJJi4A/AAuBlTWauwz4tqRTgaOGOs44mo3dbCyzP3VC6jKsoKsXPsbVCx9LXUbpNfHo4VeB09nEzlPLgrH6HMSIeGvFy+n5v88Bx0bEc/kM88+BB6u/HxFXAlfmz2/Gp+uYjS7Fk3GSpDkVr/sjoh9A0luAxyPidkkHb0o5qY/b9QG/lDSW7FczOyLWJK7JzNooO3xYOBmXRcTMYbYdCBwu6U3AFsB4SZdExLH11pQ0GCPiaWC4H9LMukGT1mOMiE8AnwDIe4wfbSQUIX2P0cysZFdKOxjNLDmhJp+8HRG/An7V6PcdjGaWnJcdMzOr0O7roItwMJpZeiVLRgejmSXXNQvVmpkV5WOMZmaVfF9pM7PBPJQ2M6sg3GM0MxukZLnoYDSzEihZMjoYzSy5dt7PpQgHo5klV65YdDCaWRmULBkdjGaWVJ0L1baFg9HM0vIJ3mZmg5UsFx2MZpZa8xeq3VQORjNLrmS56GA0s7S8UK2Z2VBKlowORjNLzqfrmJlV8TFGM7NKgh4Ho5lZtXIlo4PRzJIq40K1PakLMDNTwceIbUgvlfRLSYskLZT0oUbrcY/RzJJrUo9xHXBaRNwhaRxwu6QbImJRvQ05GM0suWZcEhgRjwCP5M+flnQXsAPgYDSzzlNHLE6SNKfidX9E9A9qT9oZ2Bu4rZF6HIxmlpTqW3ZsWUTMHLk9bQ38APj7iHiqkZocjGaWXLOufJE0liwUvxsRP2y0HQejmaXXhFxUdqDyAuCuiPjyprTl03XMLLlmnK4DHAi8GzhU0rz88aZG6nGP0cwSU1NunxoRv6ZJl9A4GM0sKV/5YmbWAdxjNLPkytZjdDCaWXJeqNbMrJLvK21mtrEyTr44GM0sOQ+lzcyquMdoZlalZLnoYDSzEihZMjoYzSwpQVMuCWwmRUTqGlpG0lLgwdR1tMAkYFnqIqwuo/VvtlNETN6UBiRdS/b7KWJZRBy2KfsrYlQH42glaU6txTqtXPw36yy+VtrMrIqD0cysioOxMw26+Y+Vnv9mHcTHGM3MqrjHaGZWxcFoZlbFwVgykp6p47OTJd0maa6k10qa3craLCNpfX6jpQWSrpY0IX9/e0lXFvj+kH9jSUdKmtbseq1+DsbONgv4fUTsDSwGHIztsToi9oqI6cBy4CSAiHg4Io7ahHaPBByMJeBg7ACSdpV0raTbJd0k6eWS9gLOBo6QNA/4V2DXvCdzTtqKu8otwA4AknaWtCB/3ifpckmLJF2V9+xfOMFb0lmS5ku6VdIUSQcAhwPn5H/DXZP8NAb4WulO0Q+cGBH3StoXOC8iDpX0aWBmRJwsaWdgz4jYK2Wh3URSL1mv/YIhNs8GVkTENEnTgXkV27YCbo2IT0o6G/hARHxe0o+BayKi5nDcWsvBWHKStgYOAK7QhgvtN09XkQFb5r30HYC7gBuG+MxrgK8BRMQCSXdWbFsDXJM/vx34yxbWag3wULr8eoAn82NaA49XpC6qy63Oe+Y7kS0Oc1Kd318bG04gXo87KKXjYCy5iHgKuF/SOwCUmTHER58GxrW1uC4XEauAU4HTJFWH283AOwHymeZXFmjSf8OScDCWT5+kJRWPjwDHAMdLmg8sBI6o/lJEPAHcnJ9C4smXNomIucCdwNFVm84DJktaBHye7O+2skZzlwEfy0+/8uRLQr4k0KwF8omZsRHxXB5yPwemRsSaxKVZAT62YdYafcAvJY0lOw4526HYOdxjNDOr4mOMZmZVHIxmZlUcjGZmVRyMXaxqlZgrJPVtQlsXSToqf37+SKvESDo4vza43n08IGnQ3eSGe7/qM4VXLco//xlJH623RhsdHIzdrXKVmDXAiZUbhzhpuZCIeH9ELBrhIweTXeZoVkoORhtwE7Bb3pu7KV/QYJGkXknnSPqdpDslfRBeuALnXEl3S/o5sN1AQ5J+NbCSjKTDJN2RryTzi3yxixOBD+e91dfm60r+IN/H7yQdmH/3RZKul7RQ0vlkp72MSNJ/5asQLZR0QtW2r+Tv/0LS5Py9QSsXNeOXaZ3N5zHaQM/wjcC1+Vv7ANMj4v48XFZGxJ9L2pzs6prrgb2BqWTrB04BFgEXVrU7Gfg2cFDe1sSIWC7pW8AzEfHF/HPfA74SEb+WtCNwHfAK4Ezg1xHxOUlvBo4v8OMcl+9jS+B3kn6QXxW0FTAnIj6cr0p0JnAyQ6xcBBzawK/RRhEHY3cbWCUGsh7jBWRD3N9GxP35+68HXjVw/BDYBtgdOAi4NCLWAw9L+u8h2t8PuHGgrYhYPkwdrwOmVaweND5fVegg4K/y7/5E0ooCP9Opkt6WP39pXusTwPPA9/P3LwF+6JWLbDgOxu42sErMC/KAeLbyLeCUiLiu6nNvamIdPcB+EfHcELUUJulgspDdPyJWSfoVsMUwHw8qVi6qt2Ab3XyM0Wq5Dvi7/NI2JO0haSvgRuCv82OQLwYOGeK7twIHSdol/+7E/P3qVWSuB04ZeKFsdXLyfbwrf++NwLY1at2GbHHYVfmxwv0qtvUAA73ed5EN0YuuXGRdxsFotZxPdvzwDmXL9v872UjjKuDefNt/kC3xv5GIWAqcQDZsnc+GoezVwNsGJl/Ilu6amU/uLGLD7PhnyYJ1IdmQ+qEatV4LjJF0F/AFsmAe8Czw6vxnOBT4XP5+zZWLrPv4WmkzsyruMZqZVXEwmplVcTCamVVxMJqZVXEwmplVcTCamVVxMJqZVfl/RiKy9LiiX54AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7333333492279053\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fold4"
      ],
      "metadata": {
        "id": "34jgeoKtxNxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=10, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=200,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(4,5):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-7rfB9hrxO8Z",
        "outputId": "f74307fe-9618-4c92-bc72-24e8bff9c8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 4\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_16 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_17 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_8 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_16 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_17 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_9[0][0]']                \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.4811 - decoder_loss: 26.2856 - encoder_loss: 3.7897 - classifier_loss: 0.6279 - decoder_accuracy: 0.0181 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5500\n",
            "Epoch 1: val_loss improved from inf to 1068.83301, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.4811 - decoder_loss: 26.2856 - encoder_loss: 3.7897 - classifier_loss: 0.6279 - decoder_accuracy: 0.0181 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5500 - val_loss: 1068.8330 - val_decoder_loss: 24.8300 - val_encoder_loss: 1066.2393 - val_classifier_loss: 1.1069 - val_decoder_accuracy: 0.0137 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.2246 - decoder_loss: 26.2792 - encoder_loss: 1.5284 - classifier_loss: 0.6828 - decoder_accuracy: 0.0169 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.5750\n",
            "Epoch 2: val_loss improved from 1068.83301 to 6.74726, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 4.2246 - decoder_loss: 26.2792 - encoder_loss: 1.5284 - classifier_loss: 0.6828 - decoder_accuracy: 0.0169 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.5750 - val_loss: 6.7473 - val_decoder_loss: 24.7610 - val_encoder_loss: 4.2023 - val_classifier_loss: 0.6884 - val_decoder_accuracy: 0.0137 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.6124 - decoder_loss: 26.2676 - encoder_loss: 1.9289 - classifier_loss: 0.5673 - decoder_accuracy: 0.0186 - encoder_accuracy: 0.0500 - classifier_accuracy: 0.8250\n",
            "Epoch 3: val_loss did not improve from 6.74726\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.6124 - decoder_loss: 26.2676 - encoder_loss: 1.9289 - classifier_loss: 0.5673 - decoder_accuracy: 0.0186 - encoder_accuracy: 0.0500 - classifier_accuracy: 0.8250 - val_loss: 27.1650 - val_decoder_loss: 24.8843 - val_encoder_loss: 24.5896 - val_classifier_loss: 0.8696 - val_decoder_accuracy: 0.0177 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.3000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.7608 - decoder_loss: 26.2889 - encoder_loss: 6.0809 - classifier_loss: 0.5095 - decoder_accuracy: 0.0203 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000\n",
            "Epoch 4: val_loss improved from 6.74726 to 5.54061, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 8.7608 - decoder_loss: 26.2889 - encoder_loss: 6.0809 - classifier_loss: 0.5095 - decoder_accuracy: 0.0203 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000 - val_loss: 5.5406 - val_decoder_loss: 24.7618 - val_encoder_loss: 2.9529 - val_classifier_loss: 1.1149 - val_decoder_accuracy: 0.0135 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.9972 - decoder_loss: 26.2413 - encoder_loss: 4.3197 - classifier_loss: 0.5338 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7250\n",
            "Epoch 5: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.9972 - decoder_loss: 26.2413 - encoder_loss: 4.3197 - classifier_loss: 0.5338 - decoder_accuracy: 0.0180 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7250 - val_loss: 11.4981 - val_decoder_loss: 24.6540 - val_encoder_loss: 8.9290 - val_classifier_loss: 1.0366 - val_decoder_accuracy: 0.0167 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.3000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.0609 - decoder_loss: 26.1610 - encoder_loss: 5.3862 - classifier_loss: 0.5853 - decoder_accuracy: 0.0195 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750\n",
            "Epoch 6: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.0609 - decoder_loss: 26.1610 - encoder_loss: 5.3862 - classifier_loss: 0.5853 - decoder_accuracy: 0.0195 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750 - val_loss: 53.2652 - val_decoder_loss: 24.5736 - val_encoder_loss: 50.7174 - val_classifier_loss: 0.9049 - val_decoder_accuracy: 0.0103 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.3000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 12.6138 - decoder_loss: 25.8954 - encoder_loss: 9.9822 - classifier_loss: 0.4206 - decoder_accuracy: 0.0178 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 7: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 12.6138 - decoder_loss: 25.8954 - encoder_loss: 9.9822 - classifier_loss: 0.4206 - decoder_accuracy: 0.0178 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 8.9156 - val_decoder_loss: 25.2682 - val_encoder_loss: 6.2621 - val_classifier_loss: 1.2667 - val_decoder_accuracy: 0.0145 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7648 - decoder_loss: 26.3390 - encoder_loss: 1.0854 - classifier_loss: 0.4548 - decoder_accuracy: 0.0174 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000\n",
            "Epoch 8: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3.7648 - decoder_loss: 26.3390 - encoder_loss: 1.0854 - classifier_loss: 0.4548 - decoder_accuracy: 0.0174 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000 - val_loss: 21.5619 - val_decoder_loss: 24.5183 - val_encoder_loss: 18.9911 - val_classifier_loss: 1.1896 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.6363 - decoder_loss: 25.8909 - encoder_loss: 6.0063 - classifier_loss: 0.4093 - decoder_accuracy: 0.0299 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 9: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.6363 - decoder_loss: 25.8909 - encoder_loss: 6.0063 - classifier_loss: 0.4093 - decoder_accuracy: 0.0299 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 12.7560 - val_decoder_loss: 24.3460 - val_encoder_loss: 10.2618 - val_classifier_loss: 0.5966 - val_decoder_accuracy: 0.0297 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9344 - decoder_loss: 25.6032 - encoder_loss: 0.3568 - classifier_loss: 0.1725 - decoder_accuracy: 0.0377 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 10: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.9344 - decoder_loss: 25.6032 - encoder_loss: 0.3568 - classifier_loss: 0.1725 - decoder_accuracy: 0.0377 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 10.8551 - val_decoder_loss: 24.2798 - val_encoder_loss: 8.3660 - val_classifier_loss: 0.6112 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6683 - decoder_loss: 25.5052 - encoder_loss: 0.1045 - classifier_loss: 0.1328 - decoder_accuracy: 0.0431 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 11: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.6683 - decoder_loss: 25.5052 - encoder_loss: 0.1045 - classifier_loss: 0.1328 - decoder_accuracy: 0.0431 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 11.4495 - val_decoder_loss: 24.2772 - val_encoder_loss: 8.9519 - val_classifier_loss: 0.6982 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5694 - decoder_loss: 25.4532 - encoder_loss: 0.0143 - classifier_loss: 0.0981 - decoder_accuracy: 0.0438 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 12: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5694 - decoder_loss: 25.4532 - encoder_loss: 0.0143 - classifier_loss: 0.0981 - decoder_accuracy: 0.0438 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 7.4296 - val_decoder_loss: 24.2685 - val_encoder_loss: 4.9395 - val_classifier_loss: 0.6324 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5579 - decoder_loss: 25.4253 - encoder_loss: 0.0085 - classifier_loss: 0.0687 - decoder_accuracy: 0.0461 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5579 - decoder_loss: 25.4253 - encoder_loss: 0.0085 - classifier_loss: 0.0687 - decoder_accuracy: 0.0461 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0435 - val_decoder_loss: 24.3447 - val_encoder_loss: 5.5457 - val_classifier_loss: 0.6331 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5626 - decoder_loss: 25.5052 - encoder_loss: 0.0068 - classifier_loss: 0.0524 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5626 - decoder_loss: 25.5052 - encoder_loss: 0.0068 - classifier_loss: 0.0524 - decoder_accuracy: 0.0405 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 6.3983 - val_decoder_loss: 24.2986 - val_encoder_loss: 3.9022 - val_classifier_loss: 0.6621 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5546 - decoder_loss: 25.4836 - encoder_loss: 0.0023 - classifier_loss: 0.0391 - decoder_accuracy: 0.0471 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5546 - decoder_loss: 25.4836 - encoder_loss: 0.0023 - classifier_loss: 0.0391 - decoder_accuracy: 0.0471 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 6.8630 - val_decoder_loss: 24.2548 - val_encoder_loss: 4.3717 - val_classifier_loss: 0.6577 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0025\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5317 - decoder_loss: 25.2738 - encoder_loss: 8.2005e-04 - classifier_loss: 0.0353 - decoder_accuracy: 0.0474 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5317 - decoder_loss: 25.2738 - encoder_loss: 8.2005e-04 - classifier_loss: 0.0353 - decoder_accuracy: 0.0474 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 6.9267 - val_decoder_loss: 24.2560 - val_encoder_loss: 4.4350 - val_classifier_loss: 0.6612 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5298 - decoder_loss: 25.2292 - encoder_loss: 0.0037 - classifier_loss: 0.0321 - decoder_accuracy: 0.0465 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5298 - decoder_loss: 25.2292 - encoder_loss: 0.0037 - classifier_loss: 0.0321 - decoder_accuracy: 0.0465 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9565 - val_decoder_loss: 24.2452 - val_encoder_loss: 5.4647 - val_classifier_loss: 0.6729 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5232 - decoder_loss: 25.1983 - encoder_loss: 4.7355e-04 - classifier_loss: 0.0286 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5232 - decoder_loss: 25.1983 - encoder_loss: 4.7355e-04 - classifier_loss: 0.0286 - decoder_accuracy: 0.0459 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.6446 - val_decoder_loss: 24.2435 - val_encoder_loss: 5.1529 - val_classifier_loss: 0.6731 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5195 - decoder_loss: 25.1631 - encoder_loss: 5.6484e-04 - classifier_loss: 0.0264 - decoder_accuracy: 0.0463 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5195 - decoder_loss: 25.1631 - encoder_loss: 5.6484e-04 - classifier_loss: 0.0264 - decoder_accuracy: 0.0463 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9404 - val_decoder_loss: 24.2358 - val_encoder_loss: 5.4493 - val_classifier_loss: 0.6748 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0025\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5150 - decoder_loss: 25.1259 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0245 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5150 - decoder_loss: 25.1259 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0245 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9500 - val_decoder_loss: 24.2331 - val_encoder_loss: 5.4590 - val_classifier_loss: 0.6768 - val_decoder_accuracy: 0.0353 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5147 - decoder_loss: 25.1070 - encoder_loss: 0.0017 - classifier_loss: 0.0236 - decoder_accuracy: 0.0468 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5147 - decoder_loss: 25.1070 - encoder_loss: 0.0017 - classifier_loss: 0.0236 - decoder_accuracy: 0.0468 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.8651 - val_decoder_loss: 24.2306 - val_encoder_loss: 5.3744 - val_classifier_loss: 0.6761 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5112 - decoder_loss: 25.0892 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0227 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.5112 - decoder_loss: 25.0892 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0227 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9265 - val_decoder_loss: 24.2266 - val_encoder_loss: 5.4360 - val_classifier_loss: 0.6782 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5092 - decoder_loss: 25.0695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0220 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5092 - decoder_loss: 25.0695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0220 - decoder_accuracy: 0.0470 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9452 - val_decoder_loss: 24.2227 - val_encoder_loss: 5.4550 - val_classifier_loss: 0.6799 - val_decoder_accuracy: 0.0347 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5071 - decoder_loss: 25.0495 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0213 - decoder_accuracy: 0.0473 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5071 - decoder_loss: 25.0495 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0213 - decoder_accuracy: 0.0473 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9611 - val_decoder_loss: 24.2184 - val_encoder_loss: 5.4711 - val_classifier_loss: 0.6815 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0012\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5050 - decoder_loss: 25.0290 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0207 - decoder_accuracy: 0.0473 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.5050 - decoder_loss: 25.0290 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0207 - decoder_accuracy: 0.0473 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9601 - val_decoder_loss: 24.2161 - val_encoder_loss: 5.4702 - val_classifier_loss: 0.6822 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5039 - decoder_loss: 25.0186 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0204 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5039 - decoder_loss: 25.0186 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0204 - decoder_accuracy: 0.0475 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9675 - val_decoder_loss: 24.2137 - val_encoder_loss: 5.4778 - val_classifier_loss: 0.6830 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5028 - decoder_loss: 25.0079 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0201 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5028 - decoder_loss: 25.0079 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0201 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9750 - val_decoder_loss: 24.2112 - val_encoder_loss: 5.4855 - val_classifier_loss: 0.6838 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5017 - decoder_loss: 24.9971 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0199 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.5017 - decoder_loss: 24.9971 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0199 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9820 - val_decoder_loss: 24.2085 - val_encoder_loss: 5.4927 - val_classifier_loss: 0.6845 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5006 - decoder_loss: 24.9862 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0196 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.5006 - decoder_loss: 24.9862 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0196 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9891 - val_decoder_loss: 24.2058 - val_encoder_loss: 5.5000 - val_classifier_loss: 0.6853 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 6.2500e-04\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4995 - decoder_loss: 24.9752 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0194 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4995 - decoder_loss: 24.9752 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0194 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9900 - val_decoder_loss: 24.2044 - val_encoder_loss: 5.5010 - val_classifier_loss: 0.6856 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4989 - decoder_loss: 24.9696 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0192 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4989 - decoder_loss: 24.9696 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0192 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9933 - val_decoder_loss: 24.2029 - val_encoder_loss: 5.5044 - val_classifier_loss: 0.6860 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4983 - decoder_loss: 24.9640 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0191 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4983 - decoder_loss: 24.9640 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0191 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9966 - val_decoder_loss: 24.2014 - val_encoder_loss: 5.5078 - val_classifier_loss: 0.6863 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4977 - decoder_loss: 24.9583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0190 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.4977 - decoder_loss: 24.9583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0190 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 7.9997 - val_decoder_loss: 24.1998 - val_encoder_loss: 5.5110 - val_classifier_loss: 0.6867 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4971 - decoder_loss: 24.9525 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0189 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 34: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.4971 - decoder_loss: 24.9525 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0189 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0025 - val_decoder_loss: 24.1982 - val_encoder_loss: 5.5140 - val_classifier_loss: 0.6871 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 3.1250e-04\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4965 - decoder_loss: 24.9467 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0188 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2.4965 - decoder_loss: 24.9467 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0188 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0029 - val_decoder_loss: 24.1974 - val_encoder_loss: 5.5144 - val_classifier_loss: 0.6872 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4962 - decoder_loss: 24.9438 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0187 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.4962 - decoder_loss: 24.9438 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0187 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0040 - val_decoder_loss: 24.1966 - val_encoder_loss: 5.5156 - val_classifier_loss: 0.6874 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4959 - decoder_loss: 24.9408 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0187 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2.4959 - decoder_loss: 24.9408 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0187 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0051 - val_decoder_loss: 24.1958 - val_encoder_loss: 5.5168 - val_classifier_loss: 0.6876 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4956 - decoder_loss: 24.9378 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0186 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.4956 - decoder_loss: 24.9378 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0186 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0062 - val_decoder_loss: 24.1949 - val_encoder_loss: 5.5179 - val_classifier_loss: 0.6878 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4953 - decoder_loss: 24.9348 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0186 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 5.54061\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.4953 - decoder_loss: 24.9348 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0186 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0072 - val_decoder_loss: 24.1940 - val_encoder_loss: 5.5190 - val_classifier_loss: 0.6880 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4950 - decoder_loss: 24.9317 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.4950 - decoder_loss: 24.9317 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0075 - val_decoder_loss: 24.1935 - val_encoder_loss: 5.5194 - val_classifier_loss: 0.6881 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4948 - decoder_loss: 24.9298 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4948 - decoder_loss: 24.9298 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0081 - val_decoder_loss: 24.1929 - val_encoder_loss: 5.5200 - val_classifier_loss: 0.6882 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4946 - decoder_loss: 24.9278 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.4946 - decoder_loss: 24.9278 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0185 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0086 - val_decoder_loss: 24.1923 - val_encoder_loss: 5.5205 - val_classifier_loss: 0.6883 - val_decoder_accuracy: 0.0337 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4944 - decoder_loss: 24.9258 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.4944 - decoder_loss: 24.9258 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0091 - val_decoder_loss: 24.1917 - val_encoder_loss: 5.5211 - val_classifier_loss: 0.6884 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4942 - decoder_loss: 24.9238 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.4942 - decoder_loss: 24.9238 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0095 - val_decoder_loss: 24.1911 - val_encoder_loss: 5.5216 - val_classifier_loss: 0.6885 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4940 - decoder_loss: 24.9218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4940 - decoder_loss: 24.9218 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0184 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0099 - val_decoder_loss: 24.1905 - val_encoder_loss: 5.5220 - val_classifier_loss: 0.6887 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4938 - decoder_loss: 24.9198 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 2.4938 - decoder_loss: 24.9198 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0104 - val_decoder_loss: 24.1899 - val_encoder_loss: 5.5225 - val_classifier_loss: 0.6888 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4936 - decoder_loss: 24.9178 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.4936 - decoder_loss: 24.9178 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0107 - val_decoder_loss: 24.1893 - val_encoder_loss: 5.5229 - val_classifier_loss: 0.6889 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4934 - decoder_loss: 24.9158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.4934 - decoder_loss: 24.9158 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0183 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0111 - val_decoder_loss: 24.1887 - val_encoder_loss: 5.5233 - val_classifier_loss: 0.6890 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4932 - decoder_loss: 24.9137 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 49: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4932 - decoder_loss: 24.9137 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0114 - val_decoder_loss: 24.1881 - val_encoder_loss: 5.5237 - val_classifier_loss: 0.6891 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4930 - decoder_loss: 24.9117 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4930 - decoder_loss: 24.9117 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0118 - val_decoder_loss: 24.1875 - val_encoder_loss: 5.5241 - val_classifier_loss: 0.6892 - val_decoder_accuracy: 0.0333 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4928 - decoder_loss: 24.9096 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4928 - decoder_loss: 24.9096 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0182 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0121 - val_decoder_loss: 24.1869 - val_encoder_loss: 5.5244 - val_classifier_loss: 0.6894 - val_decoder_accuracy: 0.0335 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4926 - decoder_loss: 24.9076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.4926 - decoder_loss: 24.9076 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0123 - val_decoder_loss: 24.1862 - val_encoder_loss: 5.5248 - val_classifier_loss: 0.6895 - val_decoder_accuracy: 0.0338 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4924 - decoder_loss: 24.9055 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4924 - decoder_loss: 24.9055 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0126 - val_decoder_loss: 24.1856 - val_encoder_loss: 5.5251 - val_classifier_loss: 0.6896 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4921 - decoder_loss: 24.9034 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4921 - decoder_loss: 24.9034 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0181 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0129 - val_decoder_loss: 24.1849 - val_encoder_loss: 5.5254 - val_classifier_loss: 0.6897 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4919 - decoder_loss: 24.9013 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.4919 - decoder_loss: 24.9013 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0131 - val_decoder_loss: 24.1843 - val_encoder_loss: 5.5257 - val_classifier_loss: 0.6898 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4917 - decoder_loss: 24.8992 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.4917 - decoder_loss: 24.8992 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0134 - val_decoder_loss: 24.1836 - val_encoder_loss: 5.5260 - val_classifier_loss: 0.6900 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4915 - decoder_loss: 24.8971 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.4915 - decoder_loss: 24.8971 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0136 - val_decoder_loss: 24.1830 - val_encoder_loss: 5.5263 - val_classifier_loss: 0.6901 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4913 - decoder_loss: 24.8950 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 58: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.4913 - decoder_loss: 24.8950 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0180 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0138 - val_decoder_loss: 24.1823 - val_encoder_loss: 5.5266 - val_classifier_loss: 0.6902 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4911 - decoder_loss: 24.8929 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 59: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4911 - decoder_loss: 24.8929 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0140 - val_decoder_loss: 24.1817 - val_encoder_loss: 5.5269 - val_classifier_loss: 0.6903 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4909 - decoder_loss: 24.8908 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 60: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4909 - decoder_loss: 24.8908 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0143 - val_decoder_loss: 24.1810 - val_encoder_loss: 5.5271 - val_classifier_loss: 0.6904 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4907 - decoder_loss: 24.8887 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 61: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4907 - decoder_loss: 24.8887 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0179 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0144 - val_decoder_loss: 24.1803 - val_encoder_loss: 5.5274 - val_classifier_loss: 0.6906 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4904 - decoder_loss: 24.8865 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 62: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4904 - decoder_loss: 24.8865 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0146 - val_decoder_loss: 24.1796 - val_encoder_loss: 5.5276 - val_classifier_loss: 0.6907 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4902 - decoder_loss: 24.8844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 63: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4902 - decoder_loss: 24.8844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0148 - val_decoder_loss: 24.1789 - val_encoder_loss: 5.5278 - val_classifier_loss: 0.6908 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4900 - decoder_loss: 24.8822 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4900 - decoder_loss: 24.8822 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0178 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0150 - val_decoder_loss: 24.1782 - val_encoder_loss: 5.5281 - val_classifier_loss: 0.6909 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4898 - decoder_loss: 24.8801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 65: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4898 - decoder_loss: 24.8801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0152 - val_decoder_loss: 24.1776 - val_encoder_loss: 5.5283 - val_classifier_loss: 0.6911 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4896 - decoder_loss: 24.8779 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 66: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4896 - decoder_loss: 24.8779 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0153 - val_decoder_loss: 24.1769 - val_encoder_loss: 5.5285 - val_classifier_loss: 0.6912 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4893 - decoder_loss: 24.8758 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 67: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4893 - decoder_loss: 24.8758 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0155 - val_decoder_loss: 24.1761 - val_encoder_loss: 5.5287 - val_classifier_loss: 0.6913 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4891 - decoder_loss: 24.8736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 68: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4891 - decoder_loss: 24.8736 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0177 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0156 - val_decoder_loss: 24.1754 - val_encoder_loss: 5.5290 - val_classifier_loss: 0.6914 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4889 - decoder_loss: 24.8714 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 69: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4889 - decoder_loss: 24.8714 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0158 - val_decoder_loss: 24.1747 - val_encoder_loss: 5.5292 - val_classifier_loss: 0.6915 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4887 - decoder_loss: 24.8693 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 70: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4887 - decoder_loss: 24.8693 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0159 - val_decoder_loss: 24.1740 - val_encoder_loss: 5.5294 - val_classifier_loss: 0.6917 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4885 - decoder_loss: 24.8671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 71: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4885 - decoder_loss: 24.8671 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0176 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0161 - val_decoder_loss: 24.1733 - val_encoder_loss: 5.5296 - val_classifier_loss: 0.6918 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4882 - decoder_loss: 24.8649 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 72: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.4882 - decoder_loss: 24.8649 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0162 - val_decoder_loss: 24.1726 - val_encoder_loss: 5.5298 - val_classifier_loss: 0.6919 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4880 - decoder_loss: 24.8627 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 73: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4880 - decoder_loss: 24.8627 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0163 - val_decoder_loss: 24.1718 - val_encoder_loss: 5.5300 - val_classifier_loss: 0.6920 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4878 - decoder_loss: 24.8605 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 74: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4878 - decoder_loss: 24.8605 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0175 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0165 - val_decoder_loss: 24.1711 - val_encoder_loss: 5.5301 - val_classifier_loss: 0.6922 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4876 - decoder_loss: 24.8583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 75: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4876 - decoder_loss: 24.8583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0166 - val_decoder_loss: 24.1703 - val_encoder_loss: 5.5303 - val_classifier_loss: 0.6923 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4873 - decoder_loss: 24.8561 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 76: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4873 - decoder_loss: 24.8561 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0167 - val_decoder_loss: 24.1696 - val_encoder_loss: 5.5305 - val_classifier_loss: 0.6924 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4871 - decoder_loss: 24.8539 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 77: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4871 - decoder_loss: 24.8539 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0174 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0168 - val_decoder_loss: 24.1688 - val_encoder_loss: 5.5307 - val_classifier_loss: 0.6926 - val_decoder_accuracy: 0.0340 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4869 - decoder_loss: 24.8516 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 78: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4869 - decoder_loss: 24.8516 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0169 - val_decoder_loss: 24.1681 - val_encoder_loss: 5.5309 - val_classifier_loss: 0.6927 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4867 - decoder_loss: 24.8494 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 79: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4867 - decoder_loss: 24.8494 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0170 - val_decoder_loss: 24.1673 - val_encoder_loss: 5.5310 - val_classifier_loss: 0.6928 - val_decoder_accuracy: 0.0342 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4864 - decoder_loss: 24.8472 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 80: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4864 - decoder_loss: 24.8472 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0173 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0171 - val_decoder_loss: 24.1665 - val_encoder_loss: 5.5312 - val_classifier_loss: 0.6929 - val_decoder_accuracy: 0.0343 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4862 - decoder_loss: 24.8449 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 81: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4862 - decoder_loss: 24.8449 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0172 - val_decoder_loss: 24.1658 - val_encoder_loss: 5.5314 - val_classifier_loss: 0.6931 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4860 - decoder_loss: 24.8427 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 82: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4860 - decoder_loss: 24.8427 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0173 - val_decoder_loss: 24.1650 - val_encoder_loss: 5.5315 - val_classifier_loss: 0.6932 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4858 - decoder_loss: 24.8405 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 83: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4858 - decoder_loss: 24.8405 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0174 - val_decoder_loss: 24.1642 - val_encoder_loss: 5.5317 - val_classifier_loss: 0.6933 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4855 - decoder_loss: 24.8382 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 84: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4855 - decoder_loss: 24.8382 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0172 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0175 - val_decoder_loss: 24.1634 - val_encoder_loss: 5.5318 - val_classifier_loss: 0.6934 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4853 - decoder_loss: 24.8360 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 85: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4853 - decoder_loss: 24.8360 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0176 - val_decoder_loss: 24.1626 - val_encoder_loss: 5.5320 - val_classifier_loss: 0.6936 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4851 - decoder_loss: 24.8337 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 86: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4851 - decoder_loss: 24.8337 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0177 - val_decoder_loss: 24.1618 - val_encoder_loss: 5.5321 - val_classifier_loss: 0.6937 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4848 - decoder_loss: 24.8314 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 87: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4848 - decoder_loss: 24.8314 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0171 - decoder_accuracy: 0.0479 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0177 - val_decoder_loss: 24.1610 - val_encoder_loss: 5.5323 - val_classifier_loss: 0.6938 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4846 - decoder_loss: 24.8291 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4846 - decoder_loss: 24.8291 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0178 - val_decoder_loss: 24.1602 - val_encoder_loss: 5.5324 - val_classifier_loss: 0.6940 - val_decoder_accuracy: 0.0348 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4844 - decoder_loss: 24.8269 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4844 - decoder_loss: 24.8269 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0179 - val_decoder_loss: 24.1594 - val_encoder_loss: 5.5325 - val_classifier_loss: 0.6941 - val_decoder_accuracy: 0.0350 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4842 - decoder_loss: 24.8246 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4842 - decoder_loss: 24.8246 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0170 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0179 - val_decoder_loss: 24.1586 - val_encoder_loss: 5.5327 - val_classifier_loss: 0.6942 - val_decoder_accuracy: 0.0352 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4839 - decoder_loss: 24.8223 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4839 - decoder_loss: 24.8223 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0476 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0180 - val_decoder_loss: 24.1578 - val_encoder_loss: 5.5328 - val_classifier_loss: 0.6943 - val_decoder_accuracy: 0.0353 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4837 - decoder_loss: 24.8200 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.4837 - decoder_loss: 24.8200 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0181 - val_decoder_loss: 24.1569 - val_encoder_loss: 5.5329 - val_classifier_loss: 0.6945 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4835 - decoder_loss: 24.8177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 93: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.4835 - decoder_loss: 24.8177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0169 - decoder_accuracy: 0.0477 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0181 - val_decoder_loss: 24.1561 - val_encoder_loss: 5.5330 - val_classifier_loss: 0.6946 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4832 - decoder_loss: 24.8154 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 94: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4832 - decoder_loss: 24.8154 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0181 - val_decoder_loss: 24.1552 - val_encoder_loss: 5.5332 - val_classifier_loss: 0.6947 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4830 - decoder_loss: 24.8131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4830 - decoder_loss: 24.8131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0478 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1544 - val_encoder_loss: 5.5333 - val_classifier_loss: 0.6949 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4828 - decoder_loss: 24.8108 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 96: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4828 - decoder_loss: 24.8108 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0480 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1535 - val_encoder_loss: 5.5334 - val_classifier_loss: 0.6950 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4825 - decoder_loss: 24.8084 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 97: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4825 - decoder_loss: 24.8084 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0168 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1527 - val_encoder_loss: 5.5335 - val_classifier_loss: 0.6951 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4823 - decoder_loss: 24.8061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 98: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4823 - decoder_loss: 24.8061 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1518 - val_encoder_loss: 5.5336 - val_classifier_loss: 0.6952 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4820 - decoder_loss: 24.8038 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 99: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4820 - decoder_loss: 24.8038 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1509 - val_encoder_loss: 5.5337 - val_classifier_loss: 0.6954 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4818 - decoder_loss: 24.8014 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4818 - decoder_loss: 24.8014 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0167 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1501 - val_encoder_loss: 5.5338 - val_classifier_loss: 0.6955 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4816 - decoder_loss: 24.7991 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4816 - decoder_loss: 24.7991 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1492 - val_encoder_loss: 5.5339 - val_classifier_loss: 0.6956 - val_decoder_accuracy: 0.0355 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4813 - decoder_loss: 24.7967 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.4813 - decoder_loss: 24.7967 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0184 - val_decoder_loss: 24.1483 - val_encoder_loss: 5.5340 - val_classifier_loss: 0.6958 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4811 - decoder_loss: 24.7944 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4811 - decoder_loss: 24.7944 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0166 - decoder_accuracy: 0.0481 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0184 - val_decoder_loss: 24.1474 - val_encoder_loss: 5.5340 - val_classifier_loss: 0.6959 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4809 - decoder_loss: 24.7920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4809 - decoder_loss: 24.7920 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0184 - val_decoder_loss: 24.1465 - val_encoder_loss: 5.5341 - val_classifier_loss: 0.6960 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4806 - decoder_loss: 24.7897 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4806 - decoder_loss: 24.7897 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0184 - val_decoder_loss: 24.1456 - val_encoder_loss: 5.5342 - val_classifier_loss: 0.6961 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4804 - decoder_loss: 24.7873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4804 - decoder_loss: 24.7873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0165 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0184 - val_decoder_loss: 24.1447 - val_encoder_loss: 5.5343 - val_classifier_loss: 0.6963 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4801 - decoder_loss: 24.7849 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4801 - decoder_loss: 24.7849 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1438 - val_encoder_loss: 5.5343 - val_classifier_loss: 0.6964 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4799 - decoder_loss: 24.7825 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4799 - decoder_loss: 24.7825 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1428 - val_encoder_loss: 5.5344 - val_classifier_loss: 0.6965 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4797 - decoder_loss: 24.7801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 109: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4797 - decoder_loss: 24.7801 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0164 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1419 - val_encoder_loss: 5.5344 - val_classifier_loss: 0.6967 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4794 - decoder_loss: 24.7777 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4794 - decoder_loss: 24.7777 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0183 - val_decoder_loss: 24.1410 - val_encoder_loss: 5.5345 - val_classifier_loss: 0.6968 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4792 - decoder_loss: 24.7753 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4792 - decoder_loss: 24.7753 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1400 - val_encoder_loss: 5.5346 - val_classifier_loss: 0.6969 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4789 - decoder_loss: 24.7729 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4789 - decoder_loss: 24.7729 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1391 - val_encoder_loss: 5.5346 - val_classifier_loss: 0.6970 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4787 - decoder_loss: 24.7705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4787 - decoder_loss: 24.7705 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0163 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0182 - val_decoder_loss: 24.1381 - val_encoder_loss: 5.5346 - val_classifier_loss: 0.6972 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4784 - decoder_loss: 24.7681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4784 - decoder_loss: 24.7681 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0181 - val_decoder_loss: 24.1371 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6973 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4782 - decoder_loss: 24.7657 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4782 - decoder_loss: 24.7657 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0181 - val_decoder_loss: 24.1362 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6974 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4779 - decoder_loss: 24.7632 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4779 - decoder_loss: 24.7632 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0162 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0180 - val_decoder_loss: 24.1352 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6976 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4777 - decoder_loss: 24.7608 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4777 - decoder_loss: 24.7608 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0179 - val_decoder_loss: 24.1342 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6977 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4774 - decoder_loss: 24.7583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.4774 - decoder_loss: 24.7583 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0179 - val_decoder_loss: 24.1332 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6978 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4772 - decoder_loss: 24.7559 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4772 - decoder_loss: 24.7559 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0161 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0178 - val_decoder_loss: 24.1322 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6979 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4769 - decoder_loss: 24.7534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4769 - decoder_loss: 24.7534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0177 - val_decoder_loss: 24.1312 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6981 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4767 - decoder_loss: 24.7510 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 121: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4767 - decoder_loss: 24.7510 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0176 - val_decoder_loss: 24.1302 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6982 - val_decoder_accuracy: 0.0367 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4764 - decoder_loss: 24.7485 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4764 - decoder_loss: 24.7485 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0175 - val_decoder_loss: 24.1292 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6983 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4762 - decoder_loss: 24.7460 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4762 - decoder_loss: 24.7460 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0160 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0175 - val_decoder_loss: 24.1282 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6984 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4759 - decoder_loss: 24.7436 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4759 - decoder_loss: 24.7436 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0174 - val_decoder_loss: 24.1272 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6986 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4757 - decoder_loss: 24.7411 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4757 - decoder_loss: 24.7411 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0173 - val_decoder_loss: 24.1261 - val_encoder_loss: 5.5348 - val_classifier_loss: 0.6987 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4754 - decoder_loss: 24.7386 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4754 - decoder_loss: 24.7386 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0159 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0171 - val_decoder_loss: 24.1251 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6988 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4752 - decoder_loss: 24.7361 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4752 - decoder_loss: 24.7361 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0170 - val_decoder_loss: 24.1240 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6990 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4749 - decoder_loss: 24.7336 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4749 - decoder_loss: 24.7336 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0169 - val_decoder_loss: 24.1230 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6991 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4747 - decoder_loss: 24.7311 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4747 - decoder_loss: 24.7311 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0158 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0168 - val_decoder_loss: 24.1219 - val_encoder_loss: 5.5347 - val_classifier_loss: 0.6992 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4744 - decoder_loss: 24.7285 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4744 - decoder_loss: 24.7285 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0166 - val_decoder_loss: 24.1209 - val_encoder_loss: 5.5346 - val_classifier_loss: 0.6993 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4742 - decoder_loss: 24.7260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4742 - decoder_loss: 24.7260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0165 - val_decoder_loss: 24.1198 - val_encoder_loss: 5.5346 - val_classifier_loss: 0.6995 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4739 - decoder_loss: 24.7235 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4739 - decoder_loss: 24.7235 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0164 - val_decoder_loss: 24.1187 - val_encoder_loss: 5.5345 - val_classifier_loss: 0.6996 - val_decoder_accuracy: 0.0357 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4737 - decoder_loss: 24.7210 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4737 - decoder_loss: 24.7210 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0157 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0162 - val_decoder_loss: 24.1176 - val_encoder_loss: 5.5345 - val_classifier_loss: 0.6997 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4734 - decoder_loss: 24.7184 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4734 - decoder_loss: 24.7184 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0160 - val_decoder_loss: 24.1165 - val_encoder_loss: 5.5344 - val_classifier_loss: 0.6998 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4731 - decoder_loss: 24.7159 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4731 - decoder_loss: 24.7159 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0159 - val_decoder_loss: 24.1154 - val_encoder_loss: 5.5343 - val_classifier_loss: 0.7000 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4729 - decoder_loss: 24.7133 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4729 - decoder_loss: 24.7133 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0156 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0157 - val_decoder_loss: 24.1143 - val_encoder_loss: 5.5343 - val_classifier_loss: 0.7001 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4726 - decoder_loss: 24.7107 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4726 - decoder_loss: 24.7107 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0155 - val_decoder_loss: 24.1132 - val_encoder_loss: 5.5342 - val_classifier_loss: 0.7002 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4724 - decoder_loss: 24.7082 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4724 - decoder_loss: 24.7082 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0154 - val_decoder_loss: 24.1121 - val_encoder_loss: 5.5341 - val_classifier_loss: 0.7003 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4721 - decoder_loss: 24.7056 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4721 - decoder_loss: 24.7056 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0155 - decoder_accuracy: 0.0482 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0152 - val_decoder_loss: 24.1109 - val_encoder_loss: 5.5340 - val_classifier_loss: 0.7004 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4718 - decoder_loss: 24.7030 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4718 - decoder_loss: 24.7030 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0150 - val_decoder_loss: 24.1098 - val_encoder_loss: 5.5339 - val_classifier_loss: 0.7006 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4716 - decoder_loss: 24.7004 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 141: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4716 - decoder_loss: 24.7004 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0148 - val_decoder_loss: 24.1087 - val_encoder_loss: 5.5338 - val_classifier_loss: 0.7007 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4713 - decoder_loss: 24.6978 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4713 - decoder_loss: 24.6978 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0146 - val_decoder_loss: 24.1075 - val_encoder_loss: 5.5337 - val_classifier_loss: 0.7008 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4711 - decoder_loss: 24.6952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4711 - decoder_loss: 24.6952 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0154 - decoder_accuracy: 0.0483 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0144 - val_decoder_loss: 24.1064 - val_encoder_loss: 5.5336 - val_classifier_loss: 0.7009 - val_decoder_accuracy: 0.0358 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4708 - decoder_loss: 24.6926 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4708 - decoder_loss: 24.6926 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0141 - val_decoder_loss: 24.1052 - val_encoder_loss: 5.5335 - val_classifier_loss: 0.7011 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4705 - decoder_loss: 24.6900 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4705 - decoder_loss: 24.6900 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0486 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0139 - val_decoder_loss: 24.1040 - val_encoder_loss: 5.5334 - val_classifier_loss: 0.7012 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4703 - decoder_loss: 24.6873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4703 - decoder_loss: 24.6873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0153 - decoder_accuracy: 0.0485 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0137 - val_decoder_loss: 24.1029 - val_encoder_loss: 5.5333 - val_classifier_loss: 0.7013 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4700 - decoder_loss: 24.6847 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0152 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4700 - decoder_loss: 24.6847 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0152 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0134 - val_decoder_loss: 24.1017 - val_encoder_loss: 5.5331 - val_classifier_loss: 0.7014 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4697 - decoder_loss: 24.6821 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0152 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4697 - decoder_loss: 24.6821 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0152 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0132 - val_decoder_loss: 24.1005 - val_encoder_loss: 5.5330 - val_classifier_loss: 0.7015 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4695 - decoder_loss: 24.6794 - encoder_loss: 6.8183e-05 - classifier_loss: 0.0152 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4695 - decoder_loss: 24.6794 - encoder_loss: 6.8183e-05 - classifier_loss: 0.0152 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0158 - val_decoder_loss: 24.0992 - val_encoder_loss: 5.5357 - val_classifier_loss: 0.7012 - val_decoder_accuracy: 0.0360 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4692 - decoder_loss: 24.6774 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4692 - decoder_loss: 24.6774 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0163 - val_decoder_loss: 24.0981 - val_encoder_loss: 5.5364 - val_classifier_loss: 0.7013 - val_decoder_accuracy: 0.0362 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4690 - decoder_loss: 24.6747 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4690 - decoder_loss: 24.6747 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0151 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0164 - val_decoder_loss: 24.0969 - val_encoder_loss: 5.5366 - val_classifier_loss: 0.7014 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4687 - decoder_loss: 24.6721 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4687 - decoder_loss: 24.6721 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0487 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0163 - val_decoder_loss: 24.0957 - val_encoder_loss: 5.5366 - val_classifier_loss: 0.7015 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4684 - decoder_loss: 24.6695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4684 - decoder_loss: 24.6695 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0163 - val_decoder_loss: 24.0945 - val_encoder_loss: 5.5367 - val_classifier_loss: 0.7016 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4682 - decoder_loss: 24.6668 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4682 - decoder_loss: 24.6668 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0150 - decoder_accuracy: 0.0488 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0162 - val_decoder_loss: 24.0932 - val_encoder_loss: 5.5367 - val_classifier_loss: 0.7017 - val_decoder_accuracy: 0.0363 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4679 - decoder_loss: 24.6642 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4679 - decoder_loss: 24.6642 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0161 - val_decoder_loss: 24.0920 - val_encoder_loss: 5.5367 - val_classifier_loss: 0.7018 - val_decoder_accuracy: 0.0365 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4676 - decoder_loss: 24.6615 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.4676 - decoder_loss: 24.6615 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0489 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0159 - val_decoder_loss: 24.0908 - val_encoder_loss: 5.5366 - val_classifier_loss: 0.7019 - val_decoder_accuracy: 0.0368 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4674 - decoder_loss: 24.6588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4674 - decoder_loss: 24.6588 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0158 - val_decoder_loss: 24.0895 - val_encoder_loss: 5.5366 - val_classifier_loss: 0.7020 - val_decoder_accuracy: 0.0370 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4671 - decoder_loss: 24.6561 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4671 - decoder_loss: 24.6561 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0149 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0156 - val_decoder_loss: 24.0883 - val_encoder_loss: 5.5365 - val_classifier_loss: 0.7021 - val_decoder_accuracy: 0.0372 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4668 - decoder_loss: 24.6534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4668 - decoder_loss: 24.6534 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0154 - val_decoder_loss: 24.0870 - val_encoder_loss: 5.5365 - val_classifier_loss: 0.7022 - val_decoder_accuracy: 0.0373 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4666 - decoder_loss: 24.6507 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4666 - decoder_loss: 24.6507 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0152 - val_decoder_loss: 24.0858 - val_encoder_loss: 5.5364 - val_classifier_loss: 0.7023 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4663 - decoder_loss: 24.6480 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4663 - decoder_loss: 24.6480 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0148 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0149 - val_decoder_loss: 24.0845 - val_encoder_loss: 5.5362 - val_classifier_loss: 0.7024 - val_decoder_accuracy: 0.0375 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4660 - decoder_loss: 24.6453 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 162: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4660 - decoder_loss: 24.6453 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0147 - val_decoder_loss: 24.0832 - val_encoder_loss: 5.5361 - val_classifier_loss: 0.7025 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4657 - decoder_loss: 24.6426 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 163: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4657 - decoder_loss: 24.6426 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0144 - val_decoder_loss: 24.0819 - val_encoder_loss: 5.5360 - val_classifier_loss: 0.7026 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4655 - decoder_loss: 24.6398 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4655 - decoder_loss: 24.6398 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0147 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0142 - val_decoder_loss: 24.0806 - val_encoder_loss: 5.5358 - val_classifier_loss: 0.7027 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4652 - decoder_loss: 24.6371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4652 - decoder_loss: 24.6371 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0139 - val_decoder_loss: 24.0793 - val_encoder_loss: 5.5357 - val_classifier_loss: 0.7028 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4649 - decoder_loss: 24.6343 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 166: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.4649 - decoder_loss: 24.6343 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0136 - val_decoder_loss: 24.0780 - val_encoder_loss: 5.5355 - val_classifier_loss: 0.7029 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4646 - decoder_loss: 24.6315 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4646 - decoder_loss: 24.6315 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0133 - val_decoder_loss: 24.0767 - val_encoder_loss: 5.5353 - val_classifier_loss: 0.7030 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4643 - decoder_loss: 24.6288 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4643 - decoder_loss: 24.6288 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0146 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0129 - val_decoder_loss: 24.0753 - val_encoder_loss: 5.5351 - val_classifier_loss: 0.7032 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4641 - decoder_loss: 24.6260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4641 - decoder_loss: 24.6260 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0126 - val_decoder_loss: 24.0740 - val_encoder_loss: 5.5349 - val_classifier_loss: 0.7033 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4638 - decoder_loss: 24.6232 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4638 - decoder_loss: 24.6232 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0372 - val_decoder_loss: 24.0726 - val_encoder_loss: 5.5596 - val_classifier_loss: 0.7034 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4635 - decoder_loss: 24.6205 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4635 - decoder_loss: 24.6205 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0367 - val_decoder_loss: 24.0713 - val_encoder_loss: 5.5593 - val_classifier_loss: 0.7035 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4632 - decoder_loss: 24.6177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4632 - decoder_loss: 24.6177 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0145 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0363 - val_decoder_loss: 24.0699 - val_encoder_loss: 5.5589 - val_classifier_loss: 0.7036 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4629 - decoder_loss: 24.6149 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.4629 - decoder_loss: 24.6149 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0358 - val_decoder_loss: 24.0685 - val_encoder_loss: 5.5586 - val_classifier_loss: 0.7037 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4627 - decoder_loss: 24.6122 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4627 - decoder_loss: 24.6122 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0353 - val_decoder_loss: 24.0672 - val_encoder_loss: 5.5582 - val_classifier_loss: 0.7038 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4624 - decoder_loss: 24.6094 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4624 - decoder_loss: 24.6094 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0144 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0348 - val_decoder_loss: 24.0658 - val_encoder_loss: 5.5579 - val_classifier_loss: 0.7039 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4621 - decoder_loss: 24.6067 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4621 - decoder_loss: 24.6067 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0343 - val_decoder_loss: 24.0644 - val_encoder_loss: 5.5575 - val_classifier_loss: 0.7040 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4618 - decoder_loss: 24.6039 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4618 - decoder_loss: 24.6039 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0338 - val_decoder_loss: 24.0631 - val_encoder_loss: 5.5571 - val_classifier_loss: 0.7041 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4615 - decoder_loss: 24.6012 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4615 - decoder_loss: 24.6012 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0333 - val_decoder_loss: 24.0617 - val_encoder_loss: 5.5567 - val_classifier_loss: 0.7042 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4613 - decoder_loss: 24.5984 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4613 - decoder_loss: 24.5984 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0143 - decoder_accuracy: 0.0490 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0328 - val_decoder_loss: 24.0603 - val_encoder_loss: 5.5564 - val_classifier_loss: 0.7043 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4610 - decoder_loss: 24.5956 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.4610 - decoder_loss: 24.5956 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0491 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0323 - val_decoder_loss: 24.0589 - val_encoder_loss: 5.5560 - val_classifier_loss: 0.7044 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4607 - decoder_loss: 24.5928 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.4607 - decoder_loss: 24.5928 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0492 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0318 - val_decoder_loss: 24.0575 - val_encoder_loss: 5.5555 - val_classifier_loss: 0.7045 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4604 - decoder_loss: 24.5900 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4604 - decoder_loss: 24.5900 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0312 - val_decoder_loss: 24.0561 - val_encoder_loss: 5.5551 - val_classifier_loss: 0.7046 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4601 - decoder_loss: 24.5873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4601 - decoder_loss: 24.5873 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0142 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0307 - val_decoder_loss: 24.0547 - val_encoder_loss: 5.5547 - val_classifier_loss: 0.7047 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4599 - decoder_loss: 24.5844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.4599 - decoder_loss: 24.5844 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0301 - val_decoder_loss: 24.0533 - val_encoder_loss: 5.5543 - val_classifier_loss: 0.7049 - val_decoder_accuracy: 0.0387 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4596 - decoder_loss: 24.5816 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4596 - decoder_loss: 24.5816 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0295 - val_decoder_loss: 24.0518 - val_encoder_loss: 5.5539 - val_classifier_loss: 0.7050 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4593 - decoder_loss: 24.5788 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4593 - decoder_loss: 24.5788 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0494 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0290 - val_decoder_loss: 24.0504 - val_encoder_loss: 5.5534 - val_classifier_loss: 0.7051 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4590 - decoder_loss: 24.5760 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4590 - decoder_loss: 24.5760 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0141 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0284 - val_decoder_loss: 24.0489 - val_encoder_loss: 5.5530 - val_classifier_loss: 0.7052 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4587 - decoder_loss: 24.5732 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4587 - decoder_loss: 24.5732 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0278 - val_decoder_loss: 24.0475 - val_encoder_loss: 5.5525 - val_classifier_loss: 0.7053 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4584 - decoder_loss: 24.5703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4584 - decoder_loss: 24.5703 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0272 - val_decoder_loss: 24.0460 - val_encoder_loss: 5.5521 - val_classifier_loss: 0.7054 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4581 - decoder_loss: 24.5675 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4581 - decoder_loss: 24.5675 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0498 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0266 - val_decoder_loss: 24.0446 - val_encoder_loss: 5.5516 - val_classifier_loss: 0.7055 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4579 - decoder_loss: 24.5646 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4579 - decoder_loss: 24.5646 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0140 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0260 - val_decoder_loss: 24.0431 - val_encoder_loss: 5.5512 - val_classifier_loss: 0.7056 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4576 - decoder_loss: 24.5617 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4576 - decoder_loss: 24.5617 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0255 - val_decoder_loss: 24.0416 - val_encoder_loss: 5.5507 - val_classifier_loss: 0.7057 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4573 - decoder_loss: 24.5589 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4573 - decoder_loss: 24.5589 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0252 - val_decoder_loss: 24.0401 - val_encoder_loss: 5.5506 - val_classifier_loss: 0.7058 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4570 - decoder_loss: 24.5560 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.4570 - decoder_loss: 24.5560 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0249 - val_decoder_loss: 24.0386 - val_encoder_loss: 5.5504 - val_classifier_loss: 0.7059 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4567 - decoder_loss: 24.5531 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4567 - decoder_loss: 24.5531 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0139 - decoder_accuracy: 0.0496 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0245 - val_decoder_loss: 24.0371 - val_encoder_loss: 5.5502 - val_classifier_loss: 0.7060 - val_decoder_accuracy: 0.0380 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4564 - decoder_loss: 24.5502 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.4564 - decoder_loss: 24.5502 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0242 - val_decoder_loss: 24.0356 - val_encoder_loss: 5.5500 - val_classifier_loss: 0.7061 - val_decoder_accuracy: 0.0377 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4561 - decoder_loss: 24.5473 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4561 - decoder_loss: 24.5473 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0239 - val_decoder_loss: 24.0341 - val_encoder_loss: 5.5499 - val_classifier_loss: 0.7062 - val_decoder_accuracy: 0.0378 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4558 - decoder_loss: 24.5444 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4558 - decoder_loss: 24.5444 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0236 - val_decoder_loss: 24.0326 - val_encoder_loss: 5.5497 - val_classifier_loss: 0.7063 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4555 - decoder_loss: 24.5415 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4555 - decoder_loss: 24.5415 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0138 - decoder_accuracy: 0.0493 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0232 - val_decoder_loss: 24.0310 - val_encoder_loss: 5.5495 - val_classifier_loss: 0.7064 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4552 - decoder_loss: 24.5385 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4552 - decoder_loss: 24.5385 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0229 - val_decoder_loss: 24.0295 - val_encoder_loss: 5.5493 - val_classifier_loss: 0.7065 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4549 - decoder_loss: 24.5356 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4549 - decoder_loss: 24.5356 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0225 - val_decoder_loss: 24.0280 - val_encoder_loss: 5.5491 - val_classifier_loss: 0.7066 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4546 - decoder_loss: 24.5326 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.4546 - decoder_loss: 24.5326 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0222 - val_decoder_loss: 24.0264 - val_encoder_loss: 5.5489 - val_classifier_loss: 0.7067 - val_decoder_accuracy: 0.0382 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4544 - decoder_loss: 24.5297 - encoder_loss: 9.1292e-05 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 203: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.4544 - decoder_loss: 24.5297 - encoder_loss: 9.1292e-05 - classifier_loss: 0.0137 - decoder_accuracy: 0.0495 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0240 - val_decoder_loss: 24.0249 - val_encoder_loss: 5.5509 - val_classifier_loss: 0.7062 - val_decoder_accuracy: 0.0383 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4541 - decoder_loss: 24.5275 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 204: val_loss did not improve from 5.54061\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.4541 - decoder_loss: 24.5275 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0136 - decoder_accuracy: 0.0497 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 8.0275 - val_decoder_loss: 24.0233 - val_encoder_loss: 5.5546 - val_classifier_loss: 0.7063 - val_decoder_accuracy: 0.0385 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 204: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfBUlEQVR4nO3de5hddX3v8fcnF8idXBhCSAITFSSAQMKAUSjlEUshXELlElpASmlTPXgAtWqserDWc4raI5VWwSjU4EEuBinRg0VALscHiCSYhECQBEyaCbkMIVdyIZN8zx/7N8metfZkTybZe89kPq/nmWfW/q219v7Omj37M+v3WxdFBGZmZnvSo9YFmJlZ5+ewMDOzshwWZmZWlsPCzMzKcliYmVlZDgszMyvLYWG2H0n6kaSvt3PZJZI+uq/PY1YNDgszMyvLYWFmZmU5LKzbSd0/n5M0X9I7ku6UNFzSLyVtlPS4pCFFy18k6WVJ6yQ9JWls0bxxkl5M690P9Mm81gWS5qZ1n5V0Ygdr/htJiyW9LWmmpCNSuyTdKmm1pA2SXpJ0Qpo3UdIrqbblkv6uQxvMDIeFdV+XAH8CHANcCPwS+HugjsLfxQ0Ako4B7gVuSvMeAX4u6SBJBwH/AfwYGAr8ND0vad1xwF3A3wLDgO8DMyUdvDeFSvoI8E/A5cAIYClwX5p9DnBm+jkOScusSfPuBP42IgYCJwC/3pvXNSvmsLDu6l8jYlVELAf+HzArIn4XEVuBh4BxabnJwP+NiMciYjvwz0Bf4MPABKA38C8RsT0iZgAvFL3GFOD7ETErInZExHRgW1pvb1wJ3BURL0bENuCLwIck1QPbgYHAsYAiYmFErEjrbQeOkzQoItZGxIt7+bpmuzgsrLtaVTS9pcTjAWn6CAr/yQMQETuBZcDING95tL4a59Ki6aOAz6YuqHWS1gGj03p7I1vDJgp7DyMj4tfAvwHfBVZLmiZpUFr0EmAisFTS05I+tJeva7aLw8Jsz96k8KEPFMYIKHzgLwdWACNTW4sji6aXAf8zIgYXffWLiHv3sYb+FLq1lgNExG0RcQpwHIXuqM+l9hciYhJwGIXusgf28nXNdnFYmO3ZA8D5ks6W1Bv4LIWupGeB54Bm4AZJvSV9DDitaN0fAJ+Q9ME0EN1f0vmSBu5lDfcC10o6OY13/C8K3WZLJJ2anr838A6wFdiZxlSulHRI6j7bAOzch+1g3ZzDwmwPIuL3wFXAvwJvURgMvzAi3o2Id4GPAX8JvE1hfONnRevOBv6GQjfRWmBxWnZva3gc+ArwIIW9mfcCV6TZgyiE0loKXVVrgG+leVcDSyRtAD5BYezDrEPkmx+ZmVk53rMwM7OyHBZmZlaWw8LMzMpyWJiZWVm9al1AJRx66KFRX19f6zLMzLqUOXPmvBURdaXmHZBhUV9fz+zZs2tdhplZlyJpaVvz3A1lZmZlOSzMzKwsh4WZmZV1QI5ZlLJ9+3YaGxvZunVrrUupuD59+jBq1Ch69+5d61LM7ADRbcKisbGRgQMHUl9fT+uLhB5YIoI1a9bQ2NjImDFjal2OmR0guk031NatWxk2bNgBHRQAkhg2bFi32IMys+rpNmEBHPBB0aK7/JxmVj3dKizKan4XNqyA7f6v3MysmMOi2M7tsGkl7NhWkadft24d3/ve9/Z6vYkTJ7Ju3boKVGRm1j4Oi1Yq233TVlg0Nzfvcb1HHnmEwYMHV6osM7Oyus3RUHulQjeEmjp1Kq+//jonn3wyvXv3pk+fPgwZMoRXX32V1157jYsvvphly5axdetWbrzxRqZMmQLsvnzJpk2bOO+88zjjjDN49tlnGTlyJA8//DB9+/atSL1mZi26ZVj8w89f5pU3N+RnxE7Yvhl6bYIee7dpjjtiEDdfePwel7nllltYsGABc+fO5amnnuL8889nwYIFuw5xveuuuxg6dChbtmzh1FNP5ZJLLmHYsGGtnmPRokXce++9/OAHP+Dyyy/nwQcf5KqrrtqrWs3M9la3DIvO4rTTTmt1LsRtt93GQw89BMCyZctYtGhRLizGjBnDySefDMApp5zCkiVLqlavmXVf3TIs2twD2L4Fml6FIfXQd0jF6+jfv/+u6aeeeorHH3+c5557jn79+nHWWWeVPFfi4IMP3jXds2dPtmzZUvE6zcw8wN1KZQe4Bw4cyMaNG0vOW79+PUOGDKFfv368+uqrPP/88xWtxcxsb3TLPYuyKjTAPWzYME4//XROOOEE+vbty/Dhw3fNO/fcc7njjjsYO3Ys73//+5kwYUJFajAz6whFhT4Ya6mhoSGyNz9auHAhY8eO3fOKzVth9UIYfBT0G1rBCiuvXT+vmVkRSXMioqHUPHdDteLLZJiZlVKxsJB0l6TVkhYUtQ2V9JikRen7kNQuSbdJWixpvqTxRetck5ZfJOmaStXb2oG3t2Vmti8quWfxI+DcTNtU4ImIOBp4Ij0GOA84On1NAW6HQrgANwMfBE4Dbm4JGDMzq56KhUVEPAO8nWmeBExP09OBi4va746C54HBkkYAfwo8FhFvR8Ra4DHyAbQfqaX4yr2EmVkXVO0xi+ERsSJNrwRaDgcaCSwrWq4xtbXVniNpiqTZkmY3NTV1rDoPWZiZlVSzAe4oHIa13/6Fj4hpEdEQEQ11dXUdfBanhZlZKdUOi1Wpe4n0fXVqXw6MLlpuVGprq73COkc31IABAwB48803ufTSS0suc9ZZZ5E9TNjMbH+rdljMBFqOaLoGeLio/ePpqKgJwPrUXfUocI6kIWlg+5zU1q0cccQRzJgxo9ZlmFk3VrEzuCXdC5wFHCqpkcJRTbcAD0i6DlgKXJ4WfwSYCCwGNgPXAkTE25L+EXghLfe1iMgOmu/PqgvfKrRjMXXqVEaPHs31118PwFe/+lV69erFk08+ydq1a9m+fTtf//rXmTRpUqv1lixZwgUXXMCCBQvYsmUL1157LfPmzePYY4/1taHMrCoqFhYR8edtzDq7xLIBXN/G89wF3LUfS4NfToWVL5V6NXh3E/Q8GHoetHfPefgH4Lxb9rjI5MmTuemmm3aFxQMPPMCjjz7KDTfcwKBBg3jrrbeYMGECF110UZv30b799tvp168fCxcuZP78+YwfP77kcmZm+5OvDVVF48aNY/Xq1bz55ps0NTUxZMgQDj/8cD796U/zzDPP0KNHD5YvX86qVas4/PDDSz7HM888ww033ADAiSeeyIknnljNH8HMuqnuGRZt7QHs3AEr58OgkTDgsIq89GWXXcaMGTNYuXIlkydP5p577qGpqYk5c+bQu3dv6uvrS16a3MyslnxtqJIqdzTU5MmTue+++5gxYwaXXXYZ69ev57DDDqN37948+eSTLF26dI/rn3nmmfzkJz8BYMGCBcyfP79itZqZteieexblVPDI2eOPP56NGzcycuRIRowYwZVXXsmFF17IBz7wARoaGjj22GP3uP4nP/lJrr32WsaOHcvYsWM55ZRTKlesmVnisGilZVC5sudZvPTS7sH1Qw89lOeee67kcps2bQKgvr6eBQsK12Ps27cv9913X0XrMzPLcjdUMZ/AbWZWksOiFaeFmVkp3Sos2n9XwM5xuY+OOhDvfmhmtdVtwqJPnz6sWbOmfR+kXfizNiJYs2YNffr0qXUpZnYA6TYD3KNGjaKxsZGyly9ftxr6bIM+66pTWAX06dOHUaNG1boMMzuAdJuw6N27N2PGjCm/4D+cDmd8Gs7+SuWLMjPrIrpNN1S7qQfEzlpXYWbWqTgsshwWZmY5Dossh4WZWY7DIsthYWaW47DIUg/weQpmZq04LLK8Z2FmluOwyJIcFmZmGQ6LLPWgS5/CbWZWAQ6LLO9ZmJnlOCyyPGZhZpbjsMhyWJiZ5TgsshwWZmY5Dossh4WZWY7DIssn5ZmZ5Tgssnw0lJlZjsMiy91QZmY5Dossh4WZWU5NwkLSpyW9LGmBpHsl9ZE0RtIsSYsl3S/poLTswenx4jS/vrLFOSzMzLKqHhaSRgI3AA0RcQLQE7gC+AZwa0S8D1gLXJdWuQ5Ym9pvTctVsECHhZlZVq26oXoBfSX1AvoBK4CPADPS/OnAxWl6UnpMmn+2JFWsMoeFmVlO1cMiIpYD/wz8F4WQWA/MAdZFRHNarBEYmaZHAsvSus1p+WHZ55U0RdJsSbObmpo6XqDDwswspxbdUEMo7C2MAY4A+gPn7uvzRsS0iGiIiIa6urp9KNDnWZiZZdWiG+qjwB8ioikitgM/A04HBqduKYBRwPI0vRwYDZDmHwKsqVh1Ps/CzCynFmHxX8AESf3S2MPZwCvAk8ClaZlrgIfT9Mz0mDT/1xEV/Nff3VBmZjm1GLOYRWGg+kXgpVTDNOALwGckLaYwJnFnWuVOYFhq/wwwtaIFOizMzHJ6lV9k/4uIm4GbM81vAKeVWHYrcFk16gI8ZmFmVoLP4M7ynoWZWY7DIscD3GZmWQ6LLO9ZmJnlOCyyHBZmZjkOiywPcJuZ5TgssnxSnplZjsMiy91QZmY5Dossh4WZWY7DIsthYWaW47DIcliYmeU4LLIcFmZmOQ6LLIeFmVmOwyLL51mYmeU4LLJ8noWZWY7DIsvdUGZmOQ6LLIeFmVmOwyLLYWFmluOwyHJYmJnlOCyy1APw0VBmZsUcFlneszAzy3FYZPnQWTOzHIdFlk/KMzPLcVhkec/CzCzHYZHlMQszsxyHRZbDwswsx2GR5bAwM8txWGQ5LMzMchwWWQ4LM7OcmoSFpMGSZkh6VdJCSR+SNFTSY5IWpe9D0rKSdJukxZLmSxpf2eIcFmZmWbXas/gO8J8RcSxwErAQmAo8ERFHA0+kxwDnAUenrynA7RWtzOdZmJnlVD0sJB0CnAncCRAR70bEOmASMD0tNh24OE1PAu6OgueBwZJGVK5A71mYmWXVYs9iDNAE/Luk30n6oaT+wPCIWJGWWQkMT9MjgWVF6zemtlYkTZE0W9Lspqamjlfnk/LMzHJqERa9gPHA7RExDniH3V1OAEREsJeXfo2IaRHREBENdXV1Ha/OexZmZjm1CItGoDEiZqXHMyiEx6qW7qX0fXWavxwYXbT+qNRWGQ4LM7OcqodFRKwElkl6f2o6G3gFmAlck9quAR5O0zOBj6ejoiYA64u6q/Y/h4WZWU6vGr3ufwfukXQQ8AZwLYXgekDSdcBS4PK07CPARGAxsDktWzkOCzOznJqERUTMBRpKzDq7xLIBXF/xolr40Fkzs5x2dUNJulHSoNQVdKekFyWdU+niaqLltqoODDOzXdo7ZvFXEbEBOAcYAlwN3FKxqmpJaZM4LMzMdmlvWCh9nwj8OCJeLmo7wKQfy+MWZma7tDcs5kj6FYWweFTSQODA/DSVw8LMLKu9A9zXAScDb0TEZklDqfRRSbWyqxvKYWFm1qK9exYfAn4fEeskXQV8GVhfubJqyGFhZpbT3rC4Hdgs6STgs8DrwN0Vq6qWHBZmZjntDYvmdL7DJODfIuK7wMDKlVVDDgszs5z2jllslPRFCofM/pGkHkDvypVVQw4LM7Oc9u5ZTAa2UTjfYiWFi/l9q2JV1ZLDwswsp11hkQLiHuAQSRcAWyPiAB+z8El5ZmYt2nu5j8uB3wKXUbjA3yxJl1aysJrxeRZmZjntHbP4EnBqRKwGkFQHPE7hXhQHFndDmZnltHfMokdLUCRr9mLdrsVhYWaW0949i/+U9Chwb3o8mcJ9Jg48Dgszs5x2hUVEfE7SJcDpqWlaRDxUubJqyGFhZpbT7psfRcSDwIMVrKVzcFiYmeXsMSwkbQRKHUMqCjexG1SRqmrJYWFmlrPHsIiIA/OSHnvSEhYlM9LMrHs6MI9o2hc+Kc/MLMdhkeWT8szMchwWWR6zMDPLcVhkec/CzCzHYZHlPQszsxyHRZbDwswsx2GR5bAwM8txWGQ5LMzMchwWWQ4LM7OcmoWFpJ6SfifpF+nxGEmzJC2WdL+kg1L7wenx4jS/vrKF+aQ8M7OsWu5Z3AgsLHr8DeDWiHgfsBa4LrVfB6xN7bem5SrHh86ameXUJCwkjQLOB36YHgv4CLvvvDcduDhNT0qPSfPPTstXqDh3Q5mZZdVqz+JfgM8DLZ/Iw4B1EdGcHjcCI9P0SGAZQJq/Pi3fiqQpkmZLmt3U1NTxyhwWZmY5VQ8LSRcAqyNizv583oiYFhENEdFQV1fX8SdyWJiZ5bT75kf70enARZImAn2AQcB3gMGSeqW9h1HA8rT8cmA00CipF3AIhXuAV4bDwswsp+p7FhHxxYgYFRH1wBXAryPiSuBJ4NK02DXAw2l6ZnpMmv/riAoequSwMDPL6UznWXwB+IykxRTGJO5M7XcCw1L7Z4CpFa3CYWFmllOLbqhdIuIp4Kk0/QZwWolltgKXVa0on2dhZpbTmfYsOgeHhZlZjsMiyyflmZnlOCyyPGZhZpbjsMhyWJiZ5TgsctwNZWaW5bDI8p6FmVmOwyLLYWFmluOwyHJYmJnlOCyyHBZmZjkOiyyflGdmluOwyPJJeWZmOQ6LLHdDmZnlOCyyHBZmZjkOiyyHhZlZjsMiy2FhZpbjsMhyWJiZ5TgsshwWZmY5DouslrDA51mYmbVwWGT5pDwzsxyHRZZPyjMzy3FYZHnMwswsx2GR5bAwM8txWGQ5LMzMchwWWR6zMDPLcVhkec/CzCzHYZHlsDAzy3FYZDkszMxyHBZZPinPzCyn6mEhabSkJyW9IullSTem9qGSHpO0KH0fktol6TZJiyXNlzS+sgV6z8LMLKsWexbNwGcj4jhgAnC9pOOAqcATEXE08ER6DHAecHT6mgLcXtHqfDSUmVlO1cMiIlZExItpeiOwEBgJTAKmp8WmAxen6UnA3VHwPDBY0oiKFqkeDgszsyI1HbOQVA+MA2YBwyNiRZq1EhiepkcCy4pWa0xt2eeaImm2pNlNTU37WJjDwsysWM3CQtIA4EHgpojYUDwvIoK9vEZ4REyLiIaIaKirq9vH4hwWZmbFahIWknpTCIp7IuJnqXlVS/dS+r46tS8HRhetPiq1VbBAh4WZWbFaHA0l4E5gYUR8u2jWTOCaNH0N8HBR+8fTUVETgPVF3VUVKtJhYWZWrFcNXvN04GrgJUlzU9vfA7cAD0i6DlgKXJ7mPQJMBBYDm4FrK16hevg8CzOzIlUPi4j4DaA2Zp9dYvkArq9oUVkOCzOzVnwGdymSu6HMzIo4LErxmIWZWSsOi1IcFmZmrTgsSnFYmJm14rAoxWFhZtaKw6IUh4WZWSsOi5J8NJSZWTGHRSk+z8LMrBWHRSnuhjIza8VhUYpPyjMza8VhUYr3LMzMWnFYlOKwMDNrxWFRisPCzKwVh0UpDgszs1YcFqU4LMzMWnFYlOKwMDNrxWFRik/KMzNrxWFRigQ4LMzMWjgsSnE3lJlZKw6LUhwWZmatOCxKaSsstqyFd9ZUvx4zsxpzWJTSVlj8x3+D+/6i+vWYmdVYr1oX0CmVCosIWDYLtm2CHc3Q05vOzLoP71mUUiosNiyHzWtgxzZYs6g2dZmZ1YjDopRS51msmLd7etXL1a3HzKzGHBalSLCzGRb+AnZsL7StmF8IkR69YeVLta3PzKzKHBalSIXxifuvhBfvLrStmAfDjoa6Y2HVAli7FJpeq22dZmZV4rAopXjMYt69he8r5sGIk+DwE+DNufDv58G0P4ZlL9SuTjOzKukyh/RIOhf4DtAT+GFE3FK5F0sZesiR0PgCvPE0bHwTRpzIkjWbqd/8FoHQoCPgnkth/NUwaBQ0b4HjLoahYypWmplZLXSJsJDUE/gu8CdAI/CCpJkR8cr+fJ31m7fztV+8wuc3vsth6sFvxn+bDz95OXH3nyF68KnnBrF+zWZ+chD8tOdENr7vrznpd19m3HO30zOaC0/yxD/C8ONh+2Y49BjoXwdb16evdYVDb3seBD16FA7B3dkMsaN8cd3+wobd/Ofv9r9/a7djzoWJ39zvT9slwgI4DVgcEW8ASLoPmATs17B4/a1NPL5wFYe8O4bDNJhbfvkuP+x/OuN6LOKWfp9j25DjOOuUD/HGjmF885nDeOvZLRwz/J9YuupthvdpZmCvnVwZP2fM6uW8qzrGvD2PAbzDRgawSf3ZpP5s0WH0jGZ6sJMd9KJZPQl6tOujMND+/HG7oO798++PuJC69zbsDppXDuC8Cjyvogv8xyLpUuDciPjr9Phq4IMR8amiZaYAUwCOPPLIU5YuXdqh19qxM5jfuI5VG7ZxSN/enHrkIHr16pWuRLvbwhUb2LStmYajhvCL+SuY9Yc17NgJO3bupHln0Lyj82/Xzl8hdIX3J3SNbdk1irR9Nf6oIVx3Rse6wiXNiYiGUvO6yp5FWRExDZgG0NDQ0OE/i549xLgjh5RdbuyIQbumLzzpCC486YiOvqSZWafXVY6GWg6MLno8KrWZmVkVdJWweAE4WtIYSQcBVwAza1yTmVm30SW6oSKiWdKngEcpHDp7V0T4mhtmZlXSJcICICIeAR6pdR1mZt1RV+mGMjOzGnJYmJlZWQ4LMzMry2FhZmZldYkzuPeWpCagY6dwFxwKvLWfytlfOmNN0Dnrck3t1xnr6ow1Qeesa3/XdFRE1JWacUCGxb6SNLutU95rpTPWBJ2zLtfUfp2xrs5YE3TOuqpZk7uhzMysLIeFmZmV5bAobVqtCyihM9YEnbMu19R+nbGuzlgTdM66qlaTxyzMzKws71mYmVlZDgszMyvLYVFE0rmSfi9psaSpNaphtKQnJb0i6WVJN6b2r0paLmlu+ppYg9qWSHopvf7s1DZU0mOSFqXv5e8ctf/qeX/R9pgraYOkm2qxrSTdJWm1pAVFbSW3jQpuS++z+ZLGV7mub0l6Nb32Q5IGp/Z6SVuKttsdVaypzd+ZpC+mbfV7SX9axZruL6pniaS5qb0q2ym9VlufB9V/b0WEvwrjNj2B14H3AAcB84DjalDHCGB8mh4IvAYcB3wV+Lsab6MlwKGZtm8CU9P0VOAbNfz9rQSOqsW2As4ExgMLym0bYCLwSwo3FZ8AzKpyXecAvdL0N4rqqi9erso1lfydpff+POBgYEz6G+1ZjZoy8/838D+quZ3Sa7X1eVD195b3LHY7DVgcEW9ExLvAfcCkahcRESsi4sU0vRFYCIysdh17YRIwPU1PBy6uUR1nA69HxL6cud9hEfEM8Hamua1tMwm4OwqeBwZLGlGtuiLiVxHRnB4+T+HOk1XTxrZqyyTgvojYFhF/ABZT+FutWk2SBFwO3Lu/X7ecPXweVP295bDYbSSwrOhxIzX+kJZUD4wDZqWmT6Vdy7uq2d1TJIBfSZojaUpqGx4RK9L0SmB4DeqCwt0Ti/+Ya72toO1t05nea39F4T/RFmMk/U7S05L+qMq1lPqddYZt9UfAqohYVNRW9e2U+Tyo+nvLYdFJSRoAPAjcFBEbgNuB9wInAyso7BZX2xkRMR44D7he0pnFM6OwH1z1Y7FVuNXuRcBPU1Nn2Fat1Grb7ImkLwHNwD2paQVwZESMAz4D/ETSoCqV0+l+Z0X+nNb/iFR9O5X4PNilWu8th8Vuy4HRRY9Hpbaqk9Sbwhvjnoj4GUBErIqIHRGxE/gBFdgVLycilqfvq4GHUg2rWnZz0/fV1a6LQni9GBGrUn0131ZJW9um5u81SX8JXABcmT5sSF09a9L0HArjA8dUo549/M5quq0k9QI+BtxfVGtVt1OpzwNq8N5yWOz2AnC0pDHpP9UrgJnVLiL1j94JLIyIbxe1F/c7/hmwILtuhevqL2lgyzSFQdIFFLbRNWmxa4CHq1lX0uo/v1pvqyJtbZuZwMfTkSsTgPVFXQoVJ+lc4PPARRGxuai9TlLPNP0e4GjgjSrV1NbvbCZwhaSDJY1JNf22GjUlHwVejYjGloZqbqe2Pg+oxXurGiP6XeWLwpEEr1H4T+FLNarhDAq7lPOBuelrIvBj4KXUPhMYUeW63kPhqJR5wMst2wcYBjwBLAIeB4ZWua7+wBrgkKK2qm8rCmG1AthOoZ/4ura2DYUjVb6b3mcvAQ1VrmsxhX7tlvfXHWnZS9Lvdi7wInBhFWtq83cGfCltq98D51WrptT+I+ATmWWrsp3Sa7X1eVD195Yv92FmZmW5G8rMzMpyWJiZWVkOCzMzK8thYWZmZTkszMysLIeFWScj6SxJv6h1HWbFHBZmZlaWw8KsgyRdJem36Z4G35fUU9ImSbemew88IakuLXuypOe1+x4SLfcfeJ+kxyXNk/SipPempx8gaYYK9524J53Ja1YzDguzDpA0FpgMnB4RJwM7gCspnFE+OyKOB54Gbk6r3A18ISJOpHBmbUv7PcB3I+Ik4MMUziKGwtVFb6Jw74L3AKdX/Icy24NetS7ArIs6GzgFeCH909+XwsXcdrL7onP/B/iZpEOAwRHxdGqfDvw0XWtrZEQ8BBARWwHS8/020vWIVLhDWz3wm8r/WGalOSzMOkbA9Ij4YqtG6SuZ5Tp6PZ1tRdM78N+q1Zi7ocw65gngUkmHwa57Ih9F4W/q0rTMXwC/iYj1wNqim+RcDTwdhTufNUq6OD3HwZL6VfWnMGsn/7di1gER8YqkL1O4c2APClcrvR54BzgtzVtNYVwDCpeRviOFwRvAtan9auD7kr6WnuOyKv4YZu3mq86a7UeSNkXEgFrXYba/uRvKzMzK8p6FmZmV5T0LMzMry2FhZmZlOSzMzKwsh4WZmZXlsDAzs7L+P7kcZI1pVa0rAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_18 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_19 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_9 (Reshape)         (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_18 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_19 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f97da6ae3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 28.0709 - decoder_loss: 26.8003 - encoder_loss: 25.3246 - classifier_loss: 0.6629 - decoder_accuracy: 0.0177 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6333\n",
            "F1-score is computed based on binary\n",
            "(loss: 28.070941925048828, accuracy: 0.6333333253860474)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.87      0.70        15\n",
            "         1.0       0.75      0.40      0.52        15\n",
            "\n",
            "    accuracy                           0.63        30\n",
            "   macro avg       0.67      0.63      0.61        30\n",
            "weighted avg       0.67      0.63      0.61        30\n",
            "\n",
            "Accuracy: 0.6333333253860474\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6333333253860474\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fold5"
      ],
      "metadata": {
        "id": "G5BOBv-zxVPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from min2net.utils import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=10, \n",
        "                    data_format='NTCD', # for MIN2Net\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Input, Reshape, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from min2net.loss import mean_squared_error, triplet_loss, SparseCategoricalCrossentropy\n",
        "from min2net.utils import TimeHistory, compute_class_weight\n",
        "\n",
        "class MIN2Net:\n",
        "    def __init__(self,\n",
        "                input_shape=(1,400,20), \n",
        "                num_class=2, \n",
        "                loss=[mean_squared_error, triplet_loss(margin=1.0), 'sparse_categorical_crossentropy'],  #\n",
        "                loss_weights=[0.1, 1, 0.1], \n",
        "                latent_dim = None,\n",
        "                epochs=1000,\n",
        "                batch_size=100,\n",
        "                optimizer=Nadam(beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
        "                lr=1e-2,\n",
        "                min_lr=1e-4,\n",
        "                factor=0.5,\n",
        "                patience=5, \n",
        "                es_patience=200,\n",
        "                verbose=1,\n",
        "                log_path='logs',\n",
        "                model_name='MIN2Net', \n",
        "                **kwargs):\n",
        "        D, T, C = input_shape\n",
        "        self.latent_dim = latent_dim if latent_dim is not None else C if num_class==2 else 64\n",
        "        self.num_class = num_class\n",
        "        self.input_shape = input_shape\n",
        "        self.loss = loss\n",
        "        self.loss_weights = loss_weights\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.optimizer.lr = lr\n",
        "        self.lr = lr\n",
        "        self.min_lr = min_lr\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.es_patience = es_patience\n",
        "        self.verbose = verbose\n",
        "        self.log_path = log_path\n",
        "        self.model_name = model_name\n",
        "        self.weights_dir = log_path+'/'+model_name+'_out_weights.h5'\n",
        "        self.csv_dir = log_path+'/'+model_name+'_out_log.log'\n",
        "        self.time_log = log_path+'/'+model_name+'_time_log.csv'\n",
        "\n",
        "        # use **kwargs to set the new value of below args.\n",
        "        self.f1_average = 'binary' if self.num_class == 2 else 'macro'\n",
        "        self.data_format = 'channels_last'\n",
        "        self.shuffle = False\n",
        "        self.metrics = 'accuracy'\n",
        "        self.monitor = 'val_loss'\n",
        "        self.mode = 'min'\n",
        "        self.save_best_only = True\n",
        "        self.save_weight_only = True\n",
        "        self.seed = 1234\n",
        "        self.class_balancing = False\n",
        "        # 'set params'\n",
        "        self.subsampling_size = 100\n",
        "        self.pool_size_1 = (1,T//self.subsampling_size)\n",
        "        self.pool_size_2 = (1,4)\n",
        "        self.filter_1 = C\n",
        "        self.filter_2 = 10\n",
        "        \n",
        "        for k in kwargs.keys():\n",
        "            self.__setattr__(k, kwargs[k])\n",
        "        \n",
        "        self.flatten_size = T//self.pool_size_1[1]//self.pool_size_2[1]\n",
        "        \n",
        "        np.random.seed(self.seed)\n",
        "        tf.random.set_seed(self.seed)\n",
        "        K.set_image_data_format(self.data_format)\n",
        "        if not os.path.exists(self.log_path):\n",
        "            os.makedirs(self.log_path)\n",
        "\n",
        "    def build(self):\n",
        "        'encoder'\n",
        "        encoder_input  = Input(self.input_shape)\n",
        "        en_conv        = Conv2D(self.filter_1, (1, 64), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(encoder_input)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_1)(en_conv)  \n",
        "        en_conv        = Conv2D(self.filter_2, (1, 32), activation='elu', padding=\"same\", \n",
        "                                kernel_constraint=max_norm(2., axis=(0, 1, 2)))(en_conv)\n",
        "        en_conv        = BatchNormalization(axis=3, epsilon=1e-05, momentum=0.1)(en_conv)\n",
        "        en_conv        = AveragePooling2D(pool_size=self.pool_size_2)(en_conv)\n",
        "        en_conv        = Flatten()(en_conv)\n",
        "        encoder_output = Dense(self.latent_dim, kernel_constraint=max_norm(0.5))(en_conv)\n",
        "        encoder        = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n",
        "        encoder.summary()\n",
        "        \n",
        "        'decoder'\n",
        "        decoder_input  = Input(shape=(self.latent_dim,), name='decoder_input')\n",
        "        de_conv        = Dense(1*self.flatten_size*self.filter_2, activation='elu', \n",
        "                               kernel_constraint=max_norm(0.5))(decoder_input)\n",
        "        de_conv        = Reshape((1, self.flatten_size, self.filter_2))(de_conv)\n",
        "        de_conv        = Conv2DTranspose(filters=self.filter_2, kernel_size=(1, 64), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_2, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder_output = Conv2DTranspose(filters=self.filter_1, kernel_size=(1, 32), \n",
        "                                         activation='elu', padding='same', strides=self.pool_size_1, \n",
        "                                         kernel_constraint=max_norm(2., axis=(0, 1, 2)))(de_conv)\n",
        "        decoder        = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "        decoder.summary()\n",
        "\n",
        "        'Build the computation graph for training'\n",
        "        latent         = encoder(encoder_input)\n",
        "        train_xr       = decoder(latent)\n",
        "        z              = Dense(self.num_class, activation='softmax', kernel_constraint=max_norm(0.5), \n",
        "                               name='classifier')(latent)\n",
        "\n",
        "        return Model(inputs=encoder_input, outputs=[train_xr, latent, z], \n",
        "                            name='MIN2Net')\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "            \n",
        "        if X_train.ndim != 4:\n",
        "            raise Exception('ValueError: `X_train` is incompatible: expected ndim=4, found ndim='+str(X_train.ndim))\n",
        "        elif X_val.ndim != 4:\n",
        "            raise Exception('ValueError: `X_val` is incompatible: expected ndim=4, found ndim='+str(X_val.ndim))\n",
        "\n",
        "        csv_logger    = CSVLogger(self.csv_dir)\n",
        "        time_callback = TimeHistory(self.time_log)\n",
        "        checkpointer  = ModelCheckpoint(monitor=self.monitor, filepath=self.weights_dir, \n",
        "                                        verbose=self.verbose, save_best_only=self.save_best_only, \n",
        "                                        save_weight_only=self.save_weight_only)\n",
        "        reduce_lr     = ReduceLROnPlateau(monitor=self.monitor, patience=self.patience, \n",
        "                                          factor=self.factor, mode=self.mode, verbose=self.verbose, \n",
        "                                          min_lr=self.min_lr)\n",
        "        es            = EarlyStopping(monitor=self.monitor, mode=self.mode, verbose=self.verbose, \n",
        "                                      patience=self.es_patience)\n",
        "        model = self.build()     \n",
        "        model.summary()\n",
        "        \n",
        "        if self.class_balancing: # compute_class_weight if class_balancing is True\n",
        "            class_weight  = compute_class_weight(y_train)\n",
        "            self.loss[-1] = SparseCategoricalCrossentropy(class_weight=class_weight)\n",
        "        \n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        history = model.fit(x=X_train, y=[X_train,y_train,y_train],\n",
        "                          batch_size=self.batch_size, shuffle=self.shuffle,\n",
        "                          epochs=self.epochs, validation_data=(X_val, [X_val,y_val,y_val]),\n",
        "                          callbacks=[checkpointer,csv_logger,reduce_lr,es, time_callback])\n",
        "        return history\n",
        "    def predict(self, X_test, y_test):\n",
        "\n",
        "        if X_test.ndim != 4:\n",
        "            raise Exception('ValueError: `X_test` is incompatible: expected ndim=4, found ndim='+str(X_test.ndim))\n",
        "\n",
        "        model = self.build()\n",
        "        model.summary()\n",
        "        model.load_weights(self.weights_dir)\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics, loss_weights=self.loss_weights)\n",
        "\n",
        "        start = time.time()\n",
        "        y_pred_decoder, y_pred_trip, y_pred_clf = model.predict(X_test)\n",
        "        end = time.time()\n",
        "        loss, decoder_loss, trip_loss, classifier_loss, decoder_acc, trip_acc, classifier_acc  = model.evaluate(x=X_test,\n",
        "                                                                                                                y=[X_test,y_test,y_test],\n",
        "                                                                                                                batch_size=self.batch_size, \n",
        "                                                                                                                verbose=self.verbose)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "        f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "        print('(loss: {}, accuracy: {})'.format(loss, classifier_acc))\n",
        "        print(classification_report(y_test, y_pred_argm))\n",
        "        evaluation = {'loss': loss, \n",
        "                      'decoder_loss': decoder_loss, \n",
        "                      'triplet_loss':trip_loss, \n",
        "                      'classifier_loss': classifier_loss, \n",
        "                      'accuracy': classifier_acc,\n",
        "                      'f1-score': f1 ,\n",
        "                      'prediction_time': end-start}\n",
        "        Y = {'y_true': y_test,\n",
        "             'y_pred': y_pred_argm,\n",
        "             'y_pred_decoder': y_pred_decoder}\n",
        "        cm = confusion_matrix(y_test, y_pred_argm)\n",
        "        labels = [\"Left\", \"Right\"]\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        return Y, evaluation, disp\n",
        "\n",
        "\n",
        "import shutil\n",
        "for k in range(5,6):\n",
        "  # k=1\n",
        "  X_train, y_train = loader.load_train_set(fold=k)\n",
        "  X_val, y_val = loader.load_val_set(fold=k)\n",
        "  X_test, y_test = loader.load_test_set(fold=k)\n",
        "\n",
        "  # load dataset\n",
        "  test_accuracy=[]\n",
        "\n",
        "  log_path=str(k)\n",
        "  print('log :', log_path)\n",
        "  model = MIN2Net(input_shape=(1, 600, 63), num_class=2, monitor='val_loss')\n",
        "\n",
        "  # model.fit(X_train, y_train, X_val, y_val)\n",
        "  history=model.fit(X_train, y_train, X_val, y_val)\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['classifier_accuracy'])\n",
        "  plt.plot(history.history['val_classifier_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  Y, evaluation,disp = model.predict(X_test, y_test)\n",
        "  Accuracy=evaluation.get('accuracy')\n",
        "  # test_accuracy=[test_accuracy k]\n",
        "\n",
        "  print('Accuracy:',Accuracy)\n",
        "\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "\n",
        "  if os.path.exists('/content/logs'):\n",
        "    shutil.rmtree('/content/logs')\n",
        "  print('Accuracy:',evaluation.get('accuracy'))\n",
        "  # Y = {'y_true': y_test,\n",
        "  #              'y_pred': y_pred_argm,\n",
        "  #              'y_pred_decoder': y_pred_decoder}\n",
        "  y_true=Y.get('y_true')\n",
        "  y_pred=Y.get('y_pred')\n",
        "  print(y_true)\n",
        "  print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gdf415qQxWaq",
        "outputId": "8286584f-9305-4974-cda6-29011d410a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NTCD', new dimention is (40, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (10, 1, 600, 63)\n",
            "change data_format to 'NTCD', new dimention is (30, 1, 600, 63)\n",
            "log : 5\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_20 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_21 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_10 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_20 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_21 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.4839 - decoder_loss: 24.4660 - encoder_loss: 1.9593 - classifier_loss: 0.7794 - decoder_accuracy: 0.0167 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5500\n",
            "Epoch 1: val_loss improved from inf to 1540.75745, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.4839 - decoder_loss: 24.4660 - encoder_loss: 1.9593 - classifier_loss: 0.7794 - decoder_accuracy: 0.0167 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5500 - val_loss: 1540.7574 - val_decoder_loss: 32.1374 - val_encoder_loss: 1537.0436 - val_classifier_loss: 5.0008 - val_decoder_accuracy: 0.0162 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3919 - decoder_loss: 24.4613 - encoder_loss: 0.8710 - classifier_loss: 0.7476 - decoder_accuracy: 0.0172 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.3750\n",
            "Epoch 2: val_loss improved from 1540.75745 to 32.32583, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 3.3919 - decoder_loss: 24.4613 - encoder_loss: 0.8710 - classifier_loss: 0.7476 - decoder_accuracy: 0.0172 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.3750 - val_loss: 32.3258 - val_decoder_loss: 32.0073 - val_encoder_loss: 29.0591 - val_classifier_loss: 0.6601 - val_decoder_accuracy: 0.0157 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.2505 - decoder_loss: 24.4303 - encoder_loss: 5.7397 - classifier_loss: 0.6777 - decoder_accuracy: 0.0204 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5250\n",
            "Epoch 3: val_loss did not improve from 32.32583\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.2505 - decoder_loss: 24.4303 - encoder_loss: 5.7397 - classifier_loss: 0.6777 - decoder_accuracy: 0.0204 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5250 - val_loss: 116.0804 - val_decoder_loss: 32.0644 - val_encoder_loss: 112.8023 - val_classifier_loss: 0.7167 - val_decoder_accuracy: 0.0185 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 26.0857 - decoder_loss: 24.4220 - encoder_loss: 23.5599 - classifier_loss: 0.8358 - decoder_accuracy: 0.0220 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4250\n",
            "Epoch 4: val_loss did not improve from 32.32583\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 26.0857 - decoder_loss: 24.4220 - encoder_loss: 23.5599 - classifier_loss: 0.8358 - decoder_accuracy: 0.0220 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4250 - val_loss: 68.2840 - val_decoder_loss: 32.5103 - val_encoder_loss: 64.9375 - val_classifier_loss: 0.9540 - val_decoder_accuracy: 0.0147 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 15.1497 - decoder_loss: 24.6905 - encoder_loss: 12.6028 - classifier_loss: 0.7790 - decoder_accuracy: 0.0183 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4500\n",
            "Epoch 5: val_loss improved from 32.32583 to 20.64065, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 15.1497 - decoder_loss: 24.6905 - encoder_loss: 12.6028 - classifier_loss: 0.7790 - decoder_accuracy: 0.0183 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.4500 - val_loss: 20.6406 - val_decoder_loss: 31.7061 - val_encoder_loss: 17.4115 - val_classifier_loss: 0.5856 - val_decoder_accuracy: 0.0293 - val_encoder_accuracy: 0.2000 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.9795 - decoder_loss: 24.3425 - encoder_loss: 4.4594 - classifier_loss: 0.8587 - decoder_accuracy: 0.0267 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.3500\n",
            "Epoch 6: val_loss did not improve from 20.64065\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 6.9795 - decoder_loss: 24.3425 - encoder_loss: 4.4594 - classifier_loss: 0.8587 - decoder_accuracy: 0.0267 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.3500 - val_loss: 34.5337 - val_decoder_loss: 31.8757 - val_encoder_loss: 31.2590 - val_classifier_loss: 0.8716 - val_decoder_accuracy: 0.0275 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.3000 - lr: 0.0100\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 17.7256 - decoder_loss: 24.2336 - encoder_loss: 15.2360 - classifier_loss: 0.6618 - decoder_accuracy: 0.0284 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6000\n",
            "Epoch 7: val_loss did not improve from 20.64065\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 17.7256 - decoder_loss: 24.2336 - encoder_loss: 15.2360 - classifier_loss: 0.6618 - decoder_accuracy: 0.0284 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6000 - val_loss: 30.7139 - val_decoder_loss: 33.1447 - val_encoder_loss: 27.3447 - val_classifier_loss: 0.5474 - val_decoder_accuracy: 0.0125 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.6377 - decoder_loss: 24.5800 - encoder_loss: 5.1072 - classifier_loss: 0.7256 - decoder_accuracy: 0.0273 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750\n",
            "Epoch 8: val_loss improved from 20.64065 to 15.67732, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 7.6377 - decoder_loss: 24.5800 - encoder_loss: 5.1072 - classifier_loss: 0.7256 - decoder_accuracy: 0.0273 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750 - val_loss: 15.6773 - val_decoder_loss: 32.1896 - val_encoder_loss: 12.4056 - val_classifier_loss: 0.5278 - val_decoder_accuracy: 0.0182 - val_encoder_accuracy: 0.1000 - val_classifier_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 25.1510 - decoder_loss: 24.4430 - encoder_loss: 22.6389 - classifier_loss: 0.6781 - decoder_accuracy: 0.0308 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750\n",
            "Epoch 9: val_loss improved from 15.67732 to 3.85952, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 25.1510 - decoder_loss: 24.4430 - encoder_loss: 22.6389 - classifier_loss: 0.6781 - decoder_accuracy: 0.0308 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5750 - val_loss: 3.8595 - val_decoder_loss: 31.7478 - val_encoder_loss: 0.6275 - val_classifier_loss: 0.5723 - val_decoder_accuracy: 0.0262 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.0865 - decoder_loss: 24.2391 - encoder_loss: 1.5992 - classifier_loss: 0.6344 - decoder_accuracy: 0.0248 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6750\n",
            "Epoch 10: val_loss did not improve from 3.85952\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4.0865 - decoder_loss: 24.2391 - encoder_loss: 1.5992 - classifier_loss: 0.6344 - decoder_accuracy: 0.0248 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.6750 - val_loss: 5.2617 - val_decoder_loss: 31.6122 - val_encoder_loss: 2.0450 - val_classifier_loss: 0.5551 - val_decoder_accuracy: 0.0282 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8138 - decoder_loss: 24.0072 - encoder_loss: 0.3516 - classifier_loss: 0.6157 - decoder_accuracy: 0.0348 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000\n",
            "Epoch 11: val_loss did not improve from 3.85952\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.8138 - decoder_loss: 24.0072 - encoder_loss: 0.3516 - classifier_loss: 0.6157 - decoder_accuracy: 0.0348 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7000 - val_loss: 5.0369 - val_decoder_loss: 31.1197 - val_encoder_loss: 1.8675 - val_classifier_loss: 0.5742 - val_decoder_accuracy: 0.0345 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7684 - decoder_loss: 23.7856 - encoder_loss: 0.3325 - classifier_loss: 0.5739 - decoder_accuracy: 0.0352 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750\n",
            "Epoch 12: val_loss did not improve from 3.85952\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.7684 - decoder_loss: 23.7856 - encoder_loss: 0.3325 - classifier_loss: 0.5739 - decoder_accuracy: 0.0352 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.7750 - val_loss: 4.5758 - val_decoder_loss: 30.9663 - val_encoder_loss: 1.4210 - val_classifier_loss: 0.5820 - val_decoder_accuracy: 0.0415 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8825 - decoder_loss: 23.7219 - encoder_loss: 0.4564 - classifier_loss: 0.5394 - decoder_accuracy: 0.0418 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250\n",
            "Epoch 13: val_loss improved from 3.85952 to 3.40258, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.8825 - decoder_loss: 23.7219 - encoder_loss: 0.4564 - classifier_loss: 0.5394 - decoder_accuracy: 0.0418 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8250 - val_loss: 3.4026 - val_decoder_loss: 30.6226 - val_encoder_loss: 0.2791 - val_classifier_loss: 0.6116 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7822 - decoder_loss: 23.5396 - encoder_loss: 0.3776 - classifier_loss: 0.5064 - decoder_accuracy: 0.0386 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 14: val_loss did not improve from 3.40258\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.7822 - decoder_loss: 23.5396 - encoder_loss: 0.3776 - classifier_loss: 0.5064 - decoder_accuracy: 0.0386 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 10.6931 - val_decoder_loss: 30.5927 - val_encoder_loss: 7.5495 - val_classifier_loss: 0.8434 - val_decoder_accuracy: 0.0567 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7565 - decoder_loss: 23.5453 - encoder_loss: 1.3537 - classifier_loss: 0.4828 - decoder_accuracy: 0.0420 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 15: val_loss improved from 3.40258 to 3.35074, saving model to logs/MIN2Net_out_weights.h5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 3.7565 - decoder_loss: 23.5453 - encoder_loss: 1.3537 - classifier_loss: 0.4828 - decoder_accuracy: 0.0420 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 3.3507 - val_decoder_loss: 30.5359 - val_encoder_loss: 0.2453 - val_classifier_loss: 0.5181 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.9997 - decoder_loss: 23.6237 - encoder_loss: 1.5938 - classifier_loss: 0.4350 - decoder_accuracy: 0.0341 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000\n",
            "Epoch 16: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3.9997 - decoder_loss: 23.6237 - encoder_loss: 1.5938 - classifier_loss: 0.4350 - decoder_accuracy: 0.0341 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8000 - val_loss: 24.3520 - val_decoder_loss: 30.7501 - val_encoder_loss: 21.1510 - val_classifier_loss: 1.2596 - val_decoder_accuracy: 0.0643 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.7322 - decoder_loss: 23.5006 - encoder_loss: 2.3397 - classifier_loss: 0.4244 - decoder_accuracy: 0.0457 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 17: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4.7322 - decoder_loss: 23.5006 - encoder_loss: 2.3397 - classifier_loss: 0.4244 - decoder_accuracy: 0.0457 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 4.2437 - val_decoder_loss: 30.2329 - val_encoder_loss: 1.1516 - val_classifier_loss: 0.6881 - val_decoder_accuracy: 0.0612 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8527 - decoder_loss: 23.2589 - encoder_loss: 0.4909 - classifier_loss: 0.3590 - decoder_accuracy: 0.0505 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500\n",
            "Epoch 18: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.8527 - decoder_loss: 23.2589 - encoder_loss: 0.4909 - classifier_loss: 0.3590 - decoder_accuracy: 0.0505 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.8500 - val_loss: 10.4811 - val_decoder_loss: 30.6402 - val_encoder_loss: 7.3271 - val_classifier_loss: 0.8991 - val_decoder_accuracy: 0.0607 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3731 - decoder_loss: 23.1338 - encoder_loss: 0.0294 - classifier_loss: 0.3027 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000\n",
            "Epoch 19: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3731 - decoder_loss: 23.1338 - encoder_loss: 0.0294 - classifier_loss: 0.3027 - decoder_accuracy: 0.0484 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9000 - val_loss: 13.5870 - val_decoder_loss: 30.1233 - val_encoder_loss: 10.4710 - val_classifier_loss: 1.0368 - val_decoder_accuracy: 0.0520 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3940 - decoder_loss: 23.0684 - encoder_loss: 0.0616 - classifier_loss: 0.2559 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500\n",
            "Epoch 20: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.3940 - decoder_loss: 23.0684 - encoder_loss: 0.0616 - classifier_loss: 0.2559 - decoder_accuracy: 0.0547 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9500 - val_loss: 16.1342 - val_decoder_loss: 30.6328 - val_encoder_loss: 12.9529 - val_classifier_loss: 1.1807 - val_decoder_accuracy: 0.0600 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3703 - decoder_loss: 23.1426 - encoder_loss: 0.0343 - classifier_loss: 0.2173 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500\n",
            "Epoch 21: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3703 - decoder_loss: 23.1426 - encoder_loss: 0.0343 - classifier_loss: 0.2173 - decoder_accuracy: 0.0555 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500 - val_loss: 16.6070 - val_decoder_loss: 30.1945 - val_encoder_loss: 13.4559 - val_classifier_loss: 1.3158 - val_decoder_accuracy: 0.0622 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3551 - decoder_loss: 22.9823 - encoder_loss: 0.0366 - classifier_loss: 0.2028 - decoder_accuracy: 0.0641 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500\n",
            "Epoch 22: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.3551 - decoder_loss: 22.9823 - encoder_loss: 0.0366 - classifier_loss: 0.2028 - decoder_accuracy: 0.0641 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500 - val_loss: 19.9366 - val_decoder_loss: 30.1818 - val_encoder_loss: 16.7859 - val_classifier_loss: 1.3258 - val_decoder_accuracy: 0.0528 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3722 - decoder_loss: 22.9787 - encoder_loss: 0.0560 - classifier_loss: 0.1830 - decoder_accuracy: 0.0640 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500\n",
            "Epoch 23: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3722 - decoder_loss: 22.9787 - encoder_loss: 0.0560 - classifier_loss: 0.1830 - decoder_accuracy: 0.0640 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500 - val_loss: 22.0152 - val_decoder_loss: 30.1234 - val_encoder_loss: 18.8601 - val_classifier_loss: 1.4276 - val_decoder_accuracy: 0.0527 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3460 - decoder_loss: 23.0108 - encoder_loss: 0.0286 - classifier_loss: 0.1638 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500\n",
            "Epoch 24: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3460 - decoder_loss: 23.0108 - encoder_loss: 0.0286 - classifier_loss: 0.1638 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9500 - val_loss: 22.6918 - val_decoder_loss: 30.0548 - val_encoder_loss: 19.5396 - val_classifier_loss: 1.4673 - val_decoder_accuracy: 0.0497 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3473 - decoder_loss: 22.9978 - encoder_loss: 0.0319 - classifier_loss: 0.1559 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9750\n",
            "Epoch 25: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.3473 - decoder_loss: 22.9978 - encoder_loss: 0.0319 - classifier_loss: 0.1559 - decoder_accuracy: 0.0597 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9750 - val_loss: 22.2331 - val_decoder_loss: 30.0275 - val_encoder_loss: 19.0874 - val_classifier_loss: 1.4295 - val_decoder_accuracy: 0.0505 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3690 - decoder_loss: 22.9954 - encoder_loss: 0.0551 - classifier_loss: 0.1434 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9750\n",
            "Epoch 26: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3690 - decoder_loss: 22.9954 - encoder_loss: 0.0551 - classifier_loss: 0.1434 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0250 - classifier_accuracy: 0.9750 - val_loss: 22.7170 - val_decoder_loss: 30.0154 - val_encoder_loss: 19.5675 - val_classifier_loss: 1.4796 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3363 - decoder_loss: 22.9657 - encoder_loss: 0.0264 - classifier_loss: 0.1327 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 27: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3363 - decoder_loss: 22.9657 - encoder_loss: 0.0264 - classifier_loss: 0.1327 - decoder_accuracy: 0.0617 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 23.1889 - val_decoder_loss: 29.9564 - val_encoder_loss: 20.0408 - val_classifier_loss: 1.5248 - val_decoder_accuracy: 0.0468 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3242 - decoder_loss: 22.9388 - encoder_loss: 0.0176 - classifier_loss: 0.1267 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 28: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3242 - decoder_loss: 22.9388 - encoder_loss: 0.0176 - classifier_loss: 0.1267 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 23.7812 - val_decoder_loss: 29.9265 - val_encoder_loss: 20.6344 - val_classifier_loss: 1.5417 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3253 - decoder_loss: 22.9148 - encoder_loss: 0.0218 - classifier_loss: 0.1198 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 29: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3253 - decoder_loss: 22.9148 - encoder_loss: 0.0218 - classifier_loss: 0.1198 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.5864 - val_decoder_loss: 29.8854 - val_encoder_loss: 21.4384 - val_classifier_loss: 1.5944 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3193 - decoder_loss: 22.8837 - encoder_loss: 0.0198 - classifier_loss: 0.1117 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 30: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.3193 - decoder_loss: 22.8837 - encoder_loss: 0.0198 - classifier_loss: 0.1117 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.4863 - val_decoder_loss: 29.8638 - val_encoder_loss: 21.3386 - val_classifier_loss: 1.6141 - val_decoder_accuracy: 0.0430 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0025\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3098 - decoder_loss: 22.8632 - encoder_loss: 0.0129 - classifier_loss: 0.1057 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 31: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.3098 - decoder_loss: 22.8632 - encoder_loss: 0.0129 - classifier_loss: 0.1057 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.3070 - val_decoder_loss: 29.8514 - val_encoder_loss: 21.1620 - val_classifier_loss: 1.5983 - val_decoder_accuracy: 0.0430 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3081 - decoder_loss: 22.8521 - encoder_loss: 0.0125 - classifier_loss: 0.1034 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 32: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3081 - decoder_loss: 22.8521 - encoder_loss: 0.0125 - classifier_loss: 0.1034 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.2003 - val_decoder_loss: 29.8440 - val_encoder_loss: 21.0560 - val_classifier_loss: 1.5988 - val_decoder_accuracy: 0.0428 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3077 - decoder_loss: 22.8436 - encoder_loss: 0.0133 - classifier_loss: 0.1002 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 33: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3077 - decoder_loss: 22.8436 - encoder_loss: 0.0133 - classifier_loss: 0.1002 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 24.0707 - val_decoder_loss: 29.8359 - val_encoder_loss: 20.9280 - val_classifier_loss: 1.5906 - val_decoder_accuracy: 0.0432 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3093 - decoder_loss: 22.8307 - encoder_loss: 0.0165 - classifier_loss: 0.0966 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750\n",
            "Epoch 34: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3093 - decoder_loss: 22.8307 - encoder_loss: 0.0165 - classifier_loss: 0.0966 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.9750 - val_loss: 23.9481 - val_decoder_loss: 29.8275 - val_encoder_loss: 20.8062 - val_classifier_loss: 1.5919 - val_decoder_accuracy: 0.0440 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3034 - decoder_loss: 22.8168 - encoder_loss: 0.0124 - classifier_loss: 0.0930 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.3034 - decoder_loss: 22.8168 - encoder_loss: 0.0124 - classifier_loss: 0.0930 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0069 - val_decoder_loss: 29.8198 - val_encoder_loss: 20.8649 - val_classifier_loss: 1.6000 - val_decoder_accuracy: 0.0445 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 0.0012\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2976 - decoder_loss: 22.8067 - encoder_loss: 0.0078 - classifier_loss: 0.0905 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.2976 - decoder_loss: 22.8067 - encoder_loss: 0.0078 - classifier_loss: 0.0905 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.7913 - val_decoder_loss: 29.8125 - val_encoder_loss: 20.6503 - val_classifier_loss: 1.5975 - val_decoder_accuracy: 0.0445 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2960 - decoder_loss: 22.7997 - encoder_loss: 0.0071 - classifier_loss: 0.0897 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2960 - decoder_loss: 22.7997 - encoder_loss: 0.0071 - classifier_loss: 0.0897 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.7771 - val_decoder_loss: 29.8073 - val_encoder_loss: 20.6365 - val_classifier_loss: 1.5989 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3002 - decoder_loss: 22.7934 - encoder_loss: 0.0120 - classifier_loss: 0.0887 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3002 - decoder_loss: 22.7934 - encoder_loss: 0.0120 - classifier_loss: 0.0887 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.6736 - val_decoder_loss: 29.8056 - val_encoder_loss: 20.5331 - val_classifier_loss: 1.5989 - val_decoder_accuracy: 0.0445 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3009 - decoder_loss: 22.7880 - encoder_loss: 0.0133 - classifier_loss: 0.0873 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3009 - decoder_loss: 22.7880 - encoder_loss: 0.0133 - classifier_loss: 0.0873 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9335 - val_decoder_loss: 29.7997 - val_encoder_loss: 20.7919 - val_classifier_loss: 1.6155 - val_decoder_accuracy: 0.0448 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2990 - decoder_loss: 22.7822 - encoder_loss: 0.0122 - classifier_loss: 0.0853 - decoder_accuracy: 0.0639 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2990 - decoder_loss: 22.7822 - encoder_loss: 0.0122 - classifier_loss: 0.0853 - decoder_accuracy: 0.0639 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.8026 - val_decoder_loss: 29.7944 - val_encoder_loss: 20.6618 - val_classifier_loss: 1.6145 - val_decoder_accuracy: 0.0450 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 6.2500e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2948 - decoder_loss: 22.7757 - encoder_loss: 0.0088 - classifier_loss: 0.0843 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2948 - decoder_loss: 22.7757 - encoder_loss: 0.0088 - classifier_loss: 0.0843 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.8947 - val_decoder_loss: 29.7910 - val_encoder_loss: 20.7535 - val_classifier_loss: 1.6215 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2940 - decoder_loss: 22.7733 - encoder_loss: 0.0083 - classifier_loss: 0.0837 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2940 - decoder_loss: 22.7733 - encoder_loss: 0.0083 - classifier_loss: 0.0837 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.8837 - val_decoder_loss: 29.7873 - val_encoder_loss: 20.7425 - val_classifier_loss: 1.6245 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2928 - decoder_loss: 22.7699 - encoder_loss: 0.0074 - classifier_loss: 0.0834 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2928 - decoder_loss: 22.7699 - encoder_loss: 0.0074 - classifier_loss: 0.0834 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.8841 - val_decoder_loss: 29.7844 - val_encoder_loss: 20.7431 - val_classifier_loss: 1.6259 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2938 - decoder_loss: 22.7664 - encoder_loss: 0.0088 - classifier_loss: 0.0829 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2938 - decoder_loss: 22.7664 - encoder_loss: 0.0088 - classifier_loss: 0.0829 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0049 - val_decoder_loss: 29.7812 - val_encoder_loss: 20.8634 - val_classifier_loss: 1.6343 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2944 - decoder_loss: 22.7632 - encoder_loss: 0.0098 - classifier_loss: 0.0823 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2944 - decoder_loss: 22.7632 - encoder_loss: 0.0098 - classifier_loss: 0.0823 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9378 - val_decoder_loss: 29.7795 - val_encoder_loss: 20.7965 - val_classifier_loss: 1.6338 - val_decoder_accuracy: 0.0452 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 3.1250e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2930 - decoder_loss: 22.7600 - encoder_loss: 0.0088 - classifier_loss: 0.0816 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2930 - decoder_loss: 22.7600 - encoder_loss: 0.0088 - classifier_loss: 0.0816 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9630 - val_decoder_loss: 29.7781 - val_encoder_loss: 20.8217 - val_classifier_loss: 1.6343 - val_decoder_accuracy: 0.0453 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.5625e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2905 - decoder_loss: 22.7587 - encoder_loss: 0.0065 - classifier_loss: 0.0814 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2905 - decoder_loss: 22.7587 - encoder_loss: 0.0065 - classifier_loss: 0.0814 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9657 - val_decoder_loss: 29.7767 - val_encoder_loss: 20.8245 - val_classifier_loss: 1.6351 - val_decoder_accuracy: 0.0455 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.5625e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2895 - decoder_loss: 22.7570 - encoder_loss: 0.0056 - classifier_loss: 0.0812 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2895 - decoder_loss: 22.7570 - encoder_loss: 0.0056 - classifier_loss: 0.0812 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 23.9869 - val_decoder_loss: 29.7748 - val_encoder_loss: 20.8457 - val_classifier_loss: 1.6367 - val_decoder_accuracy: 0.0455 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2894 - decoder_loss: 22.7552 - encoder_loss: 0.0058 - classifier_loss: 0.0810 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 49: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2894 - decoder_loss: 22.7552 - encoder_loss: 0.0058 - classifier_loss: 0.0810 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0065 - val_decoder_loss: 29.7732 - val_encoder_loss: 20.8653 - val_classifier_loss: 1.6384 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.7000 - lr: 1.5625e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2909 - decoder_loss: 22.7534 - encoder_loss: 0.0075 - classifier_loss: 0.0807 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 3.35074\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2909 - decoder_loss: 22.7534 - encoder_loss: 0.0075 - classifier_loss: 0.0807 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0060 - val_decoder_loss: 29.7714 - val_encoder_loss: 20.8647 - val_classifier_loss: 1.6414 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.5625e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2931 - decoder_loss: 22.7518 - encoder_loss: 0.0099 - classifier_loss: 0.0804 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2931 - decoder_loss: 22.7518 - encoder_loss: 0.0099 - classifier_loss: 0.0804 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0247 - val_decoder_loss: 29.7706 - val_encoder_loss: 20.8834 - val_classifier_loss: 1.6431 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2926 - decoder_loss: 22.7507 - encoder_loss: 0.0095 - classifier_loss: 0.0802 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2926 - decoder_loss: 22.7507 - encoder_loss: 0.0095 - classifier_loss: 0.0802 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0331 - val_decoder_loss: 29.7697 - val_encoder_loss: 20.8917 - val_classifier_loss: 1.6440 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2920 - decoder_loss: 22.7497 - encoder_loss: 0.0090 - classifier_loss: 0.0799 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2920 - decoder_loss: 22.7497 - encoder_loss: 0.0090 - classifier_loss: 0.0799 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0705 - val_decoder_loss: 29.7684 - val_encoder_loss: 20.9291 - val_classifier_loss: 1.6457 - val_decoder_accuracy: 0.0457 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2910 - decoder_loss: 22.7485 - encoder_loss: 0.0082 - classifier_loss: 0.0797 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2910 - decoder_loss: 22.7485 - encoder_loss: 0.0082 - classifier_loss: 0.0797 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0740 - val_decoder_loss: 29.7668 - val_encoder_loss: 20.9325 - val_classifier_loss: 1.6482 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2886 - decoder_loss: 22.7472 - encoder_loss: 0.0060 - classifier_loss: 0.0795 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2886 - decoder_loss: 22.7472 - encoder_loss: 0.0060 - classifier_loss: 0.0795 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0797 - val_decoder_loss: 29.7654 - val_encoder_loss: 20.9383 - val_classifier_loss: 1.6491 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2867 - decoder_loss: 22.7458 - encoder_loss: 0.0042 - classifier_loss: 0.0793 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2867 - decoder_loss: 22.7458 - encoder_loss: 0.0042 - classifier_loss: 0.0793 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0776 - val_decoder_loss: 29.7637 - val_encoder_loss: 20.9362 - val_classifier_loss: 1.6502 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2865 - decoder_loss: 22.7443 - encoder_loss: 0.0042 - classifier_loss: 0.0792 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2865 - decoder_loss: 22.7443 - encoder_loss: 0.0042 - classifier_loss: 0.0792 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0786 - val_decoder_loss: 29.7622 - val_encoder_loss: 20.9373 - val_classifier_loss: 1.6510 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2862 - decoder_loss: 22.7429 - encoder_loss: 0.0040 - classifier_loss: 0.0790 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 58: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2862 - decoder_loss: 22.7429 - encoder_loss: 0.0040 - classifier_loss: 0.0790 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0662 - val_decoder_loss: 29.7609 - val_encoder_loss: 20.9250 - val_classifier_loss: 1.6511 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2853 - decoder_loss: 22.7415 - encoder_loss: 0.0033 - classifier_loss: 0.0789 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 59: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2853 - decoder_loss: 22.7415 - encoder_loss: 0.0033 - classifier_loss: 0.0789 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0649 - val_decoder_loss: 29.7595 - val_encoder_loss: 20.9238 - val_classifier_loss: 1.6518 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2866 - decoder_loss: 22.7398 - encoder_loss: 0.0048 - classifier_loss: 0.0787 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 60: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2866 - decoder_loss: 22.7398 - encoder_loss: 0.0048 - classifier_loss: 0.0787 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0476 - val_decoder_loss: 29.7581 - val_encoder_loss: 20.9065 - val_classifier_loss: 1.6519 - val_decoder_accuracy: 0.0467 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2852 - decoder_loss: 22.7383 - encoder_loss: 0.0035 - classifier_loss: 0.0786 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 61: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2852 - decoder_loss: 22.7383 - encoder_loss: 0.0035 - classifier_loss: 0.0786 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0443 - val_decoder_loss: 29.7567 - val_encoder_loss: 20.9034 - val_classifier_loss: 1.6523 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2849 - decoder_loss: 22.7367 - encoder_loss: 0.0034 - classifier_loss: 0.0784 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 62: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2849 - decoder_loss: 22.7367 - encoder_loss: 0.0034 - classifier_loss: 0.0784 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0482 - val_decoder_loss: 29.7552 - val_encoder_loss: 20.9073 - val_classifier_loss: 1.6534 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2847 - decoder_loss: 22.7352 - encoder_loss: 0.0033 - classifier_loss: 0.0783 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 63: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2847 - decoder_loss: 22.7352 - encoder_loss: 0.0033 - classifier_loss: 0.0783 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0447 - val_decoder_loss: 29.7540 - val_encoder_loss: 20.9039 - val_classifier_loss: 1.6543 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2848 - decoder_loss: 22.7337 - encoder_loss: 0.0036 - classifier_loss: 0.0782 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2848 - decoder_loss: 22.7337 - encoder_loss: 0.0036 - classifier_loss: 0.0782 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0540 - val_decoder_loss: 29.7527 - val_encoder_loss: 20.9131 - val_classifier_loss: 1.6559 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2839 - decoder_loss: 22.7322 - encoder_loss: 0.0029 - classifier_loss: 0.0780 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 65: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2839 - decoder_loss: 22.7322 - encoder_loss: 0.0029 - classifier_loss: 0.0780 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0787 - val_decoder_loss: 29.7514 - val_encoder_loss: 20.9378 - val_classifier_loss: 1.6582 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2832 - decoder_loss: 22.7307 - encoder_loss: 0.0023 - classifier_loss: 0.0779 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 66: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2832 - decoder_loss: 22.7307 - encoder_loss: 0.0023 - classifier_loss: 0.0779 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0900 - val_decoder_loss: 29.7503 - val_encoder_loss: 20.9489 - val_classifier_loss: 1.6601 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2870 - decoder_loss: 22.7293 - encoder_loss: 0.0063 - classifier_loss: 0.0777 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 67: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.2870 - decoder_loss: 22.7293 - encoder_loss: 0.0063 - classifier_loss: 0.0777 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.0968 - val_decoder_loss: 29.7489 - val_encoder_loss: 20.9558 - val_classifier_loss: 1.6613 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2876 - decoder_loss: 22.7279 - encoder_loss: 0.0071 - classifier_loss: 0.0776 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 68: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2876 - decoder_loss: 22.7279 - encoder_loss: 0.0071 - classifier_loss: 0.0776 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1099 - val_decoder_loss: 29.7477 - val_encoder_loss: 20.9688 - val_classifier_loss: 1.6632 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2855 - decoder_loss: 22.7265 - encoder_loss: 0.0051 - classifier_loss: 0.0774 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 69: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2855 - decoder_loss: 22.7265 - encoder_loss: 0.0051 - classifier_loss: 0.0774 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1113 - val_decoder_loss: 29.7464 - val_encoder_loss: 20.9701 - val_classifier_loss: 1.6650 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2867 - decoder_loss: 22.7251 - encoder_loss: 0.0065 - classifier_loss: 0.0773 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 70: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2867 - decoder_loss: 22.7251 - encoder_loss: 0.0065 - classifier_loss: 0.0773 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1444 - val_decoder_loss: 29.7456 - val_encoder_loss: 21.0031 - val_classifier_loss: 1.6672 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2878 - decoder_loss: 22.7238 - encoder_loss: 0.0077 - classifier_loss: 0.0771 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 71: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2878 - decoder_loss: 22.7238 - encoder_loss: 0.0077 - classifier_loss: 0.0771 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1701 - val_decoder_loss: 29.7446 - val_encoder_loss: 21.0286 - val_classifier_loss: 1.6697 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2862 - decoder_loss: 22.7225 - encoder_loss: 0.0063 - classifier_loss: 0.0769 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 72: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2862 - decoder_loss: 22.7225 - encoder_loss: 0.0063 - classifier_loss: 0.0769 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1815 - val_decoder_loss: 29.7435 - val_encoder_loss: 21.0400 - val_classifier_loss: 1.6713 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2850 - decoder_loss: 22.7212 - encoder_loss: 0.0052 - classifier_loss: 0.0768 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 73: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2850 - decoder_loss: 22.7212 - encoder_loss: 0.0052 - classifier_loss: 0.0768 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1923 - val_decoder_loss: 29.7420 - val_encoder_loss: 21.0508 - val_classifier_loss: 1.6733 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2847 - decoder_loss: 22.7198 - encoder_loss: 0.0050 - classifier_loss: 0.0767 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 74: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2847 - decoder_loss: 22.7198 - encoder_loss: 0.0050 - classifier_loss: 0.0767 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1942 - val_decoder_loss: 29.7410 - val_encoder_loss: 21.0527 - val_classifier_loss: 1.6744 - val_decoder_accuracy: 0.0458 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2842 - decoder_loss: 22.7188 - encoder_loss: 0.0047 - classifier_loss: 0.0765 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 75: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2842 - decoder_loss: 22.7188 - encoder_loss: 0.0047 - classifier_loss: 0.0765 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2118 - val_decoder_loss: 29.7399 - val_encoder_loss: 21.0702 - val_classifier_loss: 1.6759 - val_decoder_accuracy: 0.0460 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2830 - decoder_loss: 22.7176 - encoder_loss: 0.0036 - classifier_loss: 0.0764 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 76: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.2830 - decoder_loss: 22.7176 - encoder_loss: 0.0036 - classifier_loss: 0.0764 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1935 - val_decoder_loss: 29.7390 - val_encoder_loss: 21.0521 - val_classifier_loss: 1.6749 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2833 - decoder_loss: 22.7165 - encoder_loss: 0.0040 - classifier_loss: 0.0762 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 77: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2833 - decoder_loss: 22.7165 - encoder_loss: 0.0040 - classifier_loss: 0.0762 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2039 - val_decoder_loss: 29.7378 - val_encoder_loss: 21.0625 - val_classifier_loss: 1.6765 - val_decoder_accuracy: 0.0462 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2868 - decoder_loss: 22.7152 - encoder_loss: 0.0076 - classifier_loss: 0.0761 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 78: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2868 - decoder_loss: 22.7152 - encoder_loss: 0.0076 - classifier_loss: 0.0761 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.1842 - val_decoder_loss: 29.7367 - val_encoder_loss: 21.0427 - val_classifier_loss: 1.6780 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2864 - decoder_loss: 22.7140 - encoder_loss: 0.0075 - classifier_loss: 0.0759 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 79: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2864 - decoder_loss: 22.7140 - encoder_loss: 0.0075 - classifier_loss: 0.0759 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2063 - val_decoder_loss: 29.7348 - val_encoder_loss: 21.0646 - val_classifier_loss: 1.6817 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2884 - decoder_loss: 22.7127 - encoder_loss: 0.0095 - classifier_loss: 0.0757 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 80: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.2884 - decoder_loss: 22.7127 - encoder_loss: 0.0095 - classifier_loss: 0.0757 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2176 - val_decoder_loss: 29.7332 - val_encoder_loss: 21.0761 - val_classifier_loss: 1.6819 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2864 - decoder_loss: 22.7114 - encoder_loss: 0.0077 - classifier_loss: 0.0756 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 81: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2864 - decoder_loss: 22.7114 - encoder_loss: 0.0077 - classifier_loss: 0.0756 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2409 - val_decoder_loss: 29.7317 - val_encoder_loss: 21.0993 - val_classifier_loss: 1.6841 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2881 - decoder_loss: 22.7099 - encoder_loss: 0.0096 - classifier_loss: 0.0754 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 82: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.2881 - decoder_loss: 22.7099 - encoder_loss: 0.0096 - classifier_loss: 0.0754 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2832 - val_decoder_loss: 29.7309 - val_encoder_loss: 21.1414 - val_classifier_loss: 1.6869 - val_decoder_accuracy: 0.0463 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2858 - decoder_loss: 22.7089 - encoder_loss: 0.0074 - classifier_loss: 0.0752 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 83: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2858 - decoder_loss: 22.7089 - encoder_loss: 0.0074 - classifier_loss: 0.0752 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2742 - val_decoder_loss: 29.7300 - val_encoder_loss: 21.1324 - val_classifier_loss: 1.6875 - val_decoder_accuracy: 0.0465 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2852 - decoder_loss: 22.7080 - encoder_loss: 0.0069 - classifier_loss: 0.0750 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 84: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2852 - decoder_loss: 22.7080 - encoder_loss: 0.0069 - classifier_loss: 0.0750 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2515 - val_decoder_loss: 29.7287 - val_encoder_loss: 21.1098 - val_classifier_loss: 1.6881 - val_decoder_accuracy: 0.0470 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2838 - decoder_loss: 22.7068 - encoder_loss: 0.0056 - classifier_loss: 0.0749 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 85: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2838 - decoder_loss: 22.7068 - encoder_loss: 0.0056 - classifier_loss: 0.0749 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2463 - val_decoder_loss: 29.7274 - val_encoder_loss: 21.1046 - val_classifier_loss: 1.6893 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2837 - decoder_loss: 22.7054 - encoder_loss: 0.0057 - classifier_loss: 0.0748 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 86: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2837 - decoder_loss: 22.7054 - encoder_loss: 0.0057 - classifier_loss: 0.0748 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2516 - val_decoder_loss: 29.7258 - val_encoder_loss: 21.1099 - val_classifier_loss: 1.6916 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2854 - decoder_loss: 22.7040 - encoder_loss: 0.0076 - classifier_loss: 0.0746 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 87: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2854 - decoder_loss: 22.7040 - encoder_loss: 0.0076 - classifier_loss: 0.0746 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2803 - val_decoder_loss: 29.7240 - val_encoder_loss: 21.1383 - val_classifier_loss: 1.6956 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2871 - decoder_loss: 22.7024 - encoder_loss: 0.0094 - classifier_loss: 0.0744 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2871 - decoder_loss: 22.7024 - encoder_loss: 0.0094 - classifier_loss: 0.0744 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2559 - val_decoder_loss: 29.7227 - val_encoder_loss: 21.1142 - val_classifier_loss: 1.6948 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2823 - decoder_loss: 22.7010 - encoder_loss: 0.0048 - classifier_loss: 0.0743 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2823 - decoder_loss: 22.7010 - encoder_loss: 0.0048 - classifier_loss: 0.0743 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2630 - val_decoder_loss: 29.7211 - val_encoder_loss: 21.1211 - val_classifier_loss: 1.6977 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2815 - decoder_loss: 22.6995 - encoder_loss: 0.0041 - classifier_loss: 0.0741 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2815 - decoder_loss: 22.6995 - encoder_loss: 0.0041 - classifier_loss: 0.0741 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2473 - val_decoder_loss: 29.7204 - val_encoder_loss: 21.1055 - val_classifier_loss: 1.6975 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2807 - decoder_loss: 22.6981 - encoder_loss: 0.0035 - classifier_loss: 0.0740 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2807 - decoder_loss: 22.6981 - encoder_loss: 0.0035 - classifier_loss: 0.0740 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2540 - val_decoder_loss: 29.7191 - val_encoder_loss: 21.1122 - val_classifier_loss: 1.6990 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2799 - decoder_loss: 22.6967 - encoder_loss: 0.0028 - classifier_loss: 0.0738 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2799 - decoder_loss: 22.6967 - encoder_loss: 0.0028 - classifier_loss: 0.0738 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2610 - val_decoder_loss: 29.7176 - val_encoder_loss: 21.1191 - val_classifier_loss: 1.7007 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2811 - decoder_loss: 22.6950 - encoder_loss: 0.0043 - classifier_loss: 0.0737 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 93: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2811 - decoder_loss: 22.6950 - encoder_loss: 0.0043 - classifier_loss: 0.0737 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2604 - val_decoder_loss: 29.7159 - val_encoder_loss: 21.1188 - val_classifier_loss: 1.7007 - val_decoder_accuracy: 0.0473 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2805 - decoder_loss: 22.6934 - encoder_loss: 0.0039 - classifier_loss: 0.0735 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 94: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2805 - decoder_loss: 22.6934 - encoder_loss: 0.0039 - classifier_loss: 0.0735 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2955 - val_decoder_loss: 29.7142 - val_encoder_loss: 21.1537 - val_classifier_loss: 1.7032 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2798 - decoder_loss: 22.6916 - encoder_loss: 0.0033 - classifier_loss: 0.0734 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2798 - decoder_loss: 22.6916 - encoder_loss: 0.0033 - classifier_loss: 0.0734 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3132 - val_decoder_loss: 29.7129 - val_encoder_loss: 21.1713 - val_classifier_loss: 1.7055 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2813 - decoder_loss: 22.6902 - encoder_loss: 0.0049 - classifier_loss: 0.0733 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 96: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2813 - decoder_loss: 22.6902 - encoder_loss: 0.0049 - classifier_loss: 0.0733 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3326 - val_decoder_loss: 29.7116 - val_encoder_loss: 21.1907 - val_classifier_loss: 1.7076 - val_decoder_accuracy: 0.0472 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2804 - decoder_loss: 22.6887 - encoder_loss: 0.0042 - classifier_loss: 0.0731 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 97: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2804 - decoder_loss: 22.6887 - encoder_loss: 0.0042 - classifier_loss: 0.0731 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3243 - val_decoder_loss: 29.7102 - val_encoder_loss: 21.1826 - val_classifier_loss: 1.7074 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2776 - decoder_loss: 22.6872 - encoder_loss: 0.0016 - classifier_loss: 0.0729 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 98: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2776 - decoder_loss: 22.6872 - encoder_loss: 0.0016 - classifier_loss: 0.0729 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3275 - val_decoder_loss: 29.7087 - val_encoder_loss: 21.1857 - val_classifier_loss: 1.7088 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2762 - decoder_loss: 22.6857 - encoder_loss: 3.3540e-04 - classifier_loss: 0.0728 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 99: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2762 - decoder_loss: 22.6857 - encoder_loss: 3.3540e-04 - classifier_loss: 0.0728 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3272 - val_decoder_loss: 29.7072 - val_encoder_loss: 21.1856 - val_classifier_loss: 1.7093 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2769 - decoder_loss: 22.6842 - encoder_loss: 0.0012 - classifier_loss: 0.0727 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2769 - decoder_loss: 22.6842 - encoder_loss: 0.0012 - classifier_loss: 0.0727 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3175 - val_decoder_loss: 29.7057 - val_encoder_loss: 21.1759 - val_classifier_loss: 1.7101 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2764 - decoder_loss: 22.6826 - encoder_loss: 8.7121e-04 - classifier_loss: 0.0726 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2764 - decoder_loss: 22.6826 - encoder_loss: 8.7121e-04 - classifier_loss: 0.0726 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3073 - val_decoder_loss: 29.7042 - val_encoder_loss: 21.1657 - val_classifier_loss: 1.7109 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2772 - decoder_loss: 22.6809 - encoder_loss: 0.0019 - classifier_loss: 0.0726 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2772 - decoder_loss: 22.6809 - encoder_loss: 0.0019 - classifier_loss: 0.0726 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3015 - val_decoder_loss: 29.7030 - val_encoder_loss: 21.1601 - val_classifier_loss: 1.7114 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2766 - decoder_loss: 22.6794 - encoder_loss: 0.0014 - classifier_loss: 0.0724 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2766 - decoder_loss: 22.6794 - encoder_loss: 0.0014 - classifier_loss: 0.0724 - decoder_accuracy: 0.0624 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2891 - val_decoder_loss: 29.7017 - val_encoder_loss: 21.1477 - val_classifier_loss: 1.7122 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2786 - decoder_loss: 22.6779 - encoder_loss: 0.0036 - classifier_loss: 0.0724 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2786 - decoder_loss: 22.6779 - encoder_loss: 0.0036 - classifier_loss: 0.0724 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2960 - val_decoder_loss: 29.7004 - val_encoder_loss: 21.1546 - val_classifier_loss: 1.7129 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2777 - decoder_loss: 22.6763 - encoder_loss: 0.0029 - classifier_loss: 0.0722 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2777 - decoder_loss: 22.6763 - encoder_loss: 0.0029 - classifier_loss: 0.0722 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2969 - val_decoder_loss: 29.6990 - val_encoder_loss: 21.1556 - val_classifier_loss: 1.7140 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2794 - decoder_loss: 22.6749 - encoder_loss: 0.0047 - classifier_loss: 0.0721 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2794 - decoder_loss: 22.6749 - encoder_loss: 0.0047 - classifier_loss: 0.0721 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.2957 - val_decoder_loss: 29.6980 - val_encoder_loss: 21.1545 - val_classifier_loss: 1.7147 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2789 - decoder_loss: 22.6735 - encoder_loss: 0.0044 - classifier_loss: 0.0719 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2789 - decoder_loss: 22.6735 - encoder_loss: 0.0044 - classifier_loss: 0.0719 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3228 - val_decoder_loss: 29.6970 - val_encoder_loss: 21.1815 - val_classifier_loss: 1.7163 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2783 - decoder_loss: 22.6723 - encoder_loss: 0.0039 - classifier_loss: 0.0718 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2783 - decoder_loss: 22.6723 - encoder_loss: 0.0039 - classifier_loss: 0.0718 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.3711 - val_decoder_loss: 29.6959 - val_encoder_loss: 21.2297 - val_classifier_loss: 1.7177 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2770 - decoder_loss: 22.6709 - encoder_loss: 0.0027 - classifier_loss: 0.0716 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 109: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2770 - decoder_loss: 22.6709 - encoder_loss: 0.0027 - classifier_loss: 0.0716 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4243 - val_decoder_loss: 29.6947 - val_encoder_loss: 21.2828 - val_classifier_loss: 1.7199 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2774 - decoder_loss: 22.6695 - encoder_loss: 0.0033 - classifier_loss: 0.0714 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2774 - decoder_loss: 22.6695 - encoder_loss: 0.0033 - classifier_loss: 0.0714 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4537 - val_decoder_loss: 29.6931 - val_encoder_loss: 21.3121 - val_classifier_loss: 1.7227 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2773 - decoder_loss: 22.6679 - encoder_loss: 0.0034 - classifier_loss: 0.0713 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2773 - decoder_loss: 22.6679 - encoder_loss: 0.0034 - classifier_loss: 0.0713 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4869 - val_decoder_loss: 29.6913 - val_encoder_loss: 21.3452 - val_classifier_loss: 1.7254 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2801 - decoder_loss: 22.6663 - encoder_loss: 0.0063 - classifier_loss: 0.0711 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2801 - decoder_loss: 22.6663 - encoder_loss: 0.0063 - classifier_loss: 0.0711 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5175 - val_decoder_loss: 29.6905 - val_encoder_loss: 21.3758 - val_classifier_loss: 1.7268 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2777 - decoder_loss: 22.6651 - encoder_loss: 0.0041 - classifier_loss: 0.0710 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2777 - decoder_loss: 22.6651 - encoder_loss: 0.0041 - classifier_loss: 0.0710 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5636 - val_decoder_loss: 29.6897 - val_encoder_loss: 21.4216 - val_classifier_loss: 1.7297 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2777 - decoder_loss: 22.6638 - encoder_loss: 0.0042 - classifier_loss: 0.0709 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2777 - decoder_loss: 22.6638 - encoder_loss: 0.0042 - classifier_loss: 0.0709 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5725 - val_decoder_loss: 29.6889 - val_encoder_loss: 21.4304 - val_classifier_loss: 1.7319 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2781 - decoder_loss: 22.6626 - encoder_loss: 0.0048 - classifier_loss: 0.0708 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2781 - decoder_loss: 22.6626 - encoder_loss: 0.0048 - classifier_loss: 0.0708 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6345 - val_decoder_loss: 29.6881 - val_encoder_loss: 21.4922 - val_classifier_loss: 1.7347 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2756 - decoder_loss: 22.6615 - encoder_loss: 0.0024 - classifier_loss: 0.0706 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2756 - decoder_loss: 22.6615 - encoder_loss: 0.0024 - classifier_loss: 0.0706 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6048 - val_decoder_loss: 29.6869 - val_encoder_loss: 21.4627 - val_classifier_loss: 1.7335 - val_decoder_accuracy: 0.0475 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2758 - decoder_loss: 22.6602 - encoder_loss: 0.0028 - classifier_loss: 0.0705 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2758 - decoder_loss: 22.6602 - encoder_loss: 0.0028 - classifier_loss: 0.0705 - decoder_accuracy: 0.0626 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6534 - val_decoder_loss: 29.6856 - val_encoder_loss: 21.5112 - val_classifier_loss: 1.7360 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2750 - decoder_loss: 22.6587 - encoder_loss: 0.0021 - classifier_loss: 0.0704 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2750 - decoder_loss: 22.6587 - encoder_loss: 0.0021 - classifier_loss: 0.0704 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6473 - val_decoder_loss: 29.6844 - val_encoder_loss: 21.5052 - val_classifier_loss: 1.7366 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2743 - decoder_loss: 22.6572 - encoder_loss: 0.0016 - classifier_loss: 0.0703 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2743 - decoder_loss: 22.6572 - encoder_loss: 0.0016 - classifier_loss: 0.0703 - decoder_accuracy: 0.0625 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6434 - val_decoder_loss: 29.6832 - val_encoder_loss: 21.5013 - val_classifier_loss: 1.7381 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2739 - decoder_loss: 22.6557 - encoder_loss: 0.0013 - classifier_loss: 0.0702 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2739 - decoder_loss: 22.6557 - encoder_loss: 0.0013 - classifier_loss: 0.0702 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6401 - val_decoder_loss: 29.6821 - val_encoder_loss: 21.4980 - val_classifier_loss: 1.7386 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2733 - decoder_loss: 22.6543 - encoder_loss: 8.8730e-04 - classifier_loss: 0.0701 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 121: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2733 - decoder_loss: 22.6543 - encoder_loss: 8.8730e-04 - classifier_loss: 0.0701 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6446 - val_decoder_loss: 29.6810 - val_encoder_loss: 21.5025 - val_classifier_loss: 1.7400 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2728 - decoder_loss: 22.6528 - encoder_loss: 5.0005e-04 - classifier_loss: 0.0700 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2728 - decoder_loss: 22.6528 - encoder_loss: 5.0005e-04 - classifier_loss: 0.0700 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6481 - val_decoder_loss: 29.6798 - val_encoder_loss: 21.5060 - val_classifier_loss: 1.7414 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2736 - decoder_loss: 22.6513 - encoder_loss: 0.0015 - classifier_loss: 0.0699 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2736 - decoder_loss: 22.6513 - encoder_loss: 0.0015 - classifier_loss: 0.0699 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6385 - val_decoder_loss: 29.6782 - val_encoder_loss: 21.4965 - val_classifier_loss: 1.7424 - val_decoder_accuracy: 0.0478 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2742 - decoder_loss: 22.6496 - encoder_loss: 0.0023 - classifier_loss: 0.0698 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2742 - decoder_loss: 22.6496 - encoder_loss: 0.0023 - classifier_loss: 0.0698 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6447 - val_decoder_loss: 29.6765 - val_encoder_loss: 21.5026 - val_classifier_loss: 1.7441 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2737 - decoder_loss: 22.6480 - encoder_loss: 0.0019 - classifier_loss: 0.0697 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2737 - decoder_loss: 22.6480 - encoder_loss: 0.0019 - classifier_loss: 0.0697 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6215 - val_decoder_loss: 29.6756 - val_encoder_loss: 21.4797 - val_classifier_loss: 1.7427 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2730 - decoder_loss: 22.6465 - encoder_loss: 0.0014 - classifier_loss: 0.0696 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2730 - decoder_loss: 22.6465 - encoder_loss: 0.0014 - classifier_loss: 0.0696 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6278 - val_decoder_loss: 29.6741 - val_encoder_loss: 21.4860 - val_classifier_loss: 1.7441 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2723 - decoder_loss: 22.6449 - encoder_loss: 8.7520e-04 - classifier_loss: 0.0695 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2723 - decoder_loss: 22.6449 - encoder_loss: 8.7520e-04 - classifier_loss: 0.0695 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6322 - val_decoder_loss: 29.6726 - val_encoder_loss: 21.4904 - val_classifier_loss: 1.7455 - val_decoder_accuracy: 0.0477 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2720 - decoder_loss: 22.6434 - encoder_loss: 7.0492e-04 - classifier_loss: 0.0694 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2720 - decoder_loss: 22.6434 - encoder_loss: 7.0492e-04 - classifier_loss: 0.0694 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6138 - val_decoder_loss: 29.6715 - val_encoder_loss: 21.4722 - val_classifier_loss: 1.7443 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2716 - decoder_loss: 22.6416 - encoder_loss: 5.4275e-04 - classifier_loss: 0.0693 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2716 - decoder_loss: 22.6416 - encoder_loss: 5.4275e-04 - classifier_loss: 0.0693 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6179 - val_decoder_loss: 29.6703 - val_encoder_loss: 21.4763 - val_classifier_loss: 1.7452 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2713 - decoder_loss: 22.6400 - encoder_loss: 3.9155e-04 - classifier_loss: 0.0692 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2713 - decoder_loss: 22.6400 - encoder_loss: 3.9155e-04 - classifier_loss: 0.0692 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6212 - val_decoder_loss: 29.6690 - val_encoder_loss: 21.4797 - val_classifier_loss: 1.7460 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2723 - decoder_loss: 22.6383 - encoder_loss: 0.0015 - classifier_loss: 0.0691 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2723 - decoder_loss: 22.6383 - encoder_loss: 0.0015 - classifier_loss: 0.0691 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6243 - val_decoder_loss: 29.6677 - val_encoder_loss: 21.4828 - val_classifier_loss: 1.7472 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2727 - decoder_loss: 22.6367 - encoder_loss: 0.0022 - classifier_loss: 0.0690 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2727 - decoder_loss: 22.6367 - encoder_loss: 0.0022 - classifier_loss: 0.0690 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6323 - val_decoder_loss: 29.6667 - val_encoder_loss: 21.4907 - val_classifier_loss: 1.7486 - val_decoder_accuracy: 0.0482 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2748 - decoder_loss: 22.6352 - encoder_loss: 0.0044 - classifier_loss: 0.0689 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2748 - decoder_loss: 22.6352 - encoder_loss: 0.0044 - classifier_loss: 0.0689 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7032 - val_decoder_loss: 29.6661 - val_encoder_loss: 21.5613 - val_classifier_loss: 1.7526 - val_decoder_accuracy: 0.0480 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2732 - decoder_loss: 22.6339 - encoder_loss: 0.0029 - classifier_loss: 0.0688 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2732 - decoder_loss: 22.6339 - encoder_loss: 0.0029 - classifier_loss: 0.0688 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7145 - val_decoder_loss: 29.6652 - val_encoder_loss: 21.5726 - val_classifier_loss: 1.7539 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2726 - decoder_loss: 22.6326 - encoder_loss: 0.0025 - classifier_loss: 0.0687 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2726 - decoder_loss: 22.6326 - encoder_loss: 0.0025 - classifier_loss: 0.0687 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7169 - val_decoder_loss: 29.6641 - val_encoder_loss: 21.5751 - val_classifier_loss: 1.7540 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2728 - decoder_loss: 22.6312 - encoder_loss: 0.0028 - classifier_loss: 0.0685 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2728 - decoder_loss: 22.6312 - encoder_loss: 0.0028 - classifier_loss: 0.0685 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7428 - val_decoder_loss: 29.6629 - val_encoder_loss: 21.6010 - val_classifier_loss: 1.7550 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2744 - decoder_loss: 22.6297 - encoder_loss: 0.0046 - classifier_loss: 0.0684 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2744 - decoder_loss: 22.6297 - encoder_loss: 0.0046 - classifier_loss: 0.0684 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7081 - val_decoder_loss: 29.6617 - val_encoder_loss: 21.5664 - val_classifier_loss: 1.7549 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2740 - decoder_loss: 22.6281 - encoder_loss: 0.0044 - classifier_loss: 0.0683 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2740 - decoder_loss: 22.6281 - encoder_loss: 0.0044 - classifier_loss: 0.0683 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7225 - val_decoder_loss: 29.6607 - val_encoder_loss: 21.5809 - val_classifier_loss: 1.7559 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2718 - decoder_loss: 22.6266 - encoder_loss: 0.0024 - classifier_loss: 0.0681 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2718 - decoder_loss: 22.6266 - encoder_loss: 0.0024 - classifier_loss: 0.0681 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6740 - val_decoder_loss: 29.6600 - val_encoder_loss: 21.5324 - val_classifier_loss: 1.7555 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2728 - decoder_loss: 22.6252 - encoder_loss: 0.0035 - classifier_loss: 0.0680 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2728 - decoder_loss: 22.6252 - encoder_loss: 0.0035 - classifier_loss: 0.0680 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6849 - val_decoder_loss: 29.6591 - val_encoder_loss: 21.5433 - val_classifier_loss: 1.7562 - val_decoder_accuracy: 0.0483 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2722 - decoder_loss: 22.6237 - encoder_loss: 0.0031 - classifier_loss: 0.0679 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 141: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2722 - decoder_loss: 22.6237 - encoder_loss: 0.0031 - classifier_loss: 0.0679 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6671 - val_decoder_loss: 29.6581 - val_encoder_loss: 21.5256 - val_classifier_loss: 1.7563 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2706 - decoder_loss: 22.6224 - encoder_loss: 0.0016 - classifier_loss: 0.0678 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2706 - decoder_loss: 22.6224 - encoder_loss: 0.0016 - classifier_loss: 0.0678 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6711 - val_decoder_loss: 29.6570 - val_encoder_loss: 21.5297 - val_classifier_loss: 1.7569 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2707 - decoder_loss: 22.6209 - encoder_loss: 0.0018 - classifier_loss: 0.0676 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2707 - decoder_loss: 22.6209 - encoder_loss: 0.0018 - classifier_loss: 0.0676 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6616 - val_decoder_loss: 29.6561 - val_encoder_loss: 21.5204 - val_classifier_loss: 1.7562 - val_decoder_accuracy: 0.0485 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2698 - decoder_loss: 22.6195 - encoder_loss: 0.0011 - classifier_loss: 0.0675 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2698 - decoder_loss: 22.6195 - encoder_loss: 0.0011 - classifier_loss: 0.0675 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6620 - val_decoder_loss: 29.6550 - val_encoder_loss: 21.5208 - val_classifier_loss: 1.7562 - val_decoder_accuracy: 0.0487 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2692 - decoder_loss: 22.6180 - encoder_loss: 7.0942e-04 - classifier_loss: 0.0674 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2692 - decoder_loss: 22.6180 - encoder_loss: 7.0942e-04 - classifier_loss: 0.0674 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6732 - val_decoder_loss: 29.6538 - val_encoder_loss: 21.5322 - val_classifier_loss: 1.7565 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2687 - decoder_loss: 22.6163 - encoder_loss: 3.3444e-04 - classifier_loss: 0.0673 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2687 - decoder_loss: 22.6163 - encoder_loss: 3.3444e-04 - classifier_loss: 0.0673 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6837 - val_decoder_loss: 29.6526 - val_encoder_loss: 21.5428 - val_classifier_loss: 1.7568 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2682 - decoder_loss: 22.6147 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0671 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2682 - decoder_loss: 22.6147 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0671 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6840 - val_decoder_loss: 29.6513 - val_encoder_loss: 21.5431 - val_classifier_loss: 1.7574 - val_decoder_accuracy: 0.0490 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2680 - decoder_loss: 22.6131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0671 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2680 - decoder_loss: 22.6131 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0671 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6849 - val_decoder_loss: 29.6500 - val_encoder_loss: 21.5441 - val_classifier_loss: 1.7580 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2678 - decoder_loss: 22.6114 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0670 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2678 - decoder_loss: 22.6114 - encoder_loss: 0.0000e+00 - classifier_loss: 0.0670 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6858 - val_decoder_loss: 29.6486 - val_encoder_loss: 21.5451 - val_classifier_loss: 1.7587 - val_decoder_accuracy: 0.0493 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2702 - decoder_loss: 22.6098 - encoder_loss: 0.0025 - classifier_loss: 0.0669 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2702 - decoder_loss: 22.6098 - encoder_loss: 0.0025 - classifier_loss: 0.0669 - decoder_accuracy: 0.0637 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6853 - val_decoder_loss: 29.6473 - val_encoder_loss: 21.5446 - val_classifier_loss: 1.7597 - val_decoder_accuracy: 0.0493 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2758 - decoder_loss: 22.6081 - encoder_loss: 0.0083 - classifier_loss: 0.0668 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2758 - decoder_loss: 22.6081 - encoder_loss: 0.0083 - classifier_loss: 0.0668 - decoder_accuracy: 0.0636 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6461 - val_decoder_loss: 29.6467 - val_encoder_loss: 21.5056 - val_classifier_loss: 1.7583 - val_decoder_accuracy: 0.0493 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2715 - decoder_loss: 22.6069 - encoder_loss: 0.0041 - classifier_loss: 0.0666 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2715 - decoder_loss: 22.6069 - encoder_loss: 0.0041 - classifier_loss: 0.0666 - decoder_accuracy: 0.0635 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5758 - val_decoder_loss: 29.6460 - val_encoder_loss: 21.4354 - val_classifier_loss: 1.7572 - val_decoder_accuracy: 0.0492 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2716 - decoder_loss: 22.6059 - encoder_loss: 0.0044 - classifier_loss: 0.0664 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2716 - decoder_loss: 22.6059 - encoder_loss: 0.0044 - classifier_loss: 0.0664 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5537 - val_decoder_loss: 29.6448 - val_encoder_loss: 21.4135 - val_classifier_loss: 1.7567 - val_decoder_accuracy: 0.0498 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2702 - decoder_loss: 22.6045 - encoder_loss: 0.0031 - classifier_loss: 0.0663 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2702 - decoder_loss: 22.6045 - encoder_loss: 0.0031 - classifier_loss: 0.0663 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5476 - val_decoder_loss: 29.6435 - val_encoder_loss: 21.4076 - val_classifier_loss: 1.7569 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2705 - decoder_loss: 22.6029 - encoder_loss: 0.0036 - classifier_loss: 0.0662 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2705 - decoder_loss: 22.6029 - encoder_loss: 0.0036 - classifier_loss: 0.0662 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5381 - val_decoder_loss: 29.6423 - val_encoder_loss: 21.3982 - val_classifier_loss: 1.7568 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2709 - decoder_loss: 22.6013 - encoder_loss: 0.0042 - classifier_loss: 0.0660 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2709 - decoder_loss: 22.6013 - encoder_loss: 0.0042 - classifier_loss: 0.0660 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5105 - val_decoder_loss: 29.6410 - val_encoder_loss: 21.3707 - val_classifier_loss: 1.7566 - val_decoder_accuracy: 0.0502 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2694 - decoder_loss: 22.5999 - encoder_loss: 0.0028 - classifier_loss: 0.0659 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2694 - decoder_loss: 22.5999 - encoder_loss: 0.0028 - classifier_loss: 0.0659 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5152 - val_decoder_loss: 29.6396 - val_encoder_loss: 21.3754 - val_classifier_loss: 1.7581 - val_decoder_accuracy: 0.0502 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2682 - decoder_loss: 22.5984 - encoder_loss: 0.0017 - classifier_loss: 0.0658 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2682 - decoder_loss: 22.5984 - encoder_loss: 0.0017 - classifier_loss: 0.0658 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5191 - val_decoder_loss: 29.6382 - val_encoder_loss: 21.3793 - val_classifier_loss: 1.7597 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2705 - decoder_loss: 22.5969 - encoder_loss: 0.0042 - classifier_loss: 0.0656 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2705 - decoder_loss: 22.5969 - encoder_loss: 0.0042 - classifier_loss: 0.0656 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5240 - val_decoder_loss: 29.6370 - val_encoder_loss: 21.3841 - val_classifier_loss: 1.7618 - val_decoder_accuracy: 0.0502 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2683 - decoder_loss: 22.5956 - encoder_loss: 0.0022 - classifier_loss: 0.0655 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2683 - decoder_loss: 22.5956 - encoder_loss: 0.0022 - classifier_loss: 0.0655 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5152 - val_decoder_loss: 29.6361 - val_encoder_loss: 21.3755 - val_classifier_loss: 1.7616 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2686 - decoder_loss: 22.5942 - encoder_loss: 0.0027 - classifier_loss: 0.0654 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2686 - decoder_loss: 22.5942 - encoder_loss: 0.0027 - classifier_loss: 0.0654 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5012 - val_decoder_loss: 29.6348 - val_encoder_loss: 21.3615 - val_classifier_loss: 1.7616 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2699 - decoder_loss: 22.5924 - encoder_loss: 0.0041 - classifier_loss: 0.0653 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 162: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2699 - decoder_loss: 22.5924 - encoder_loss: 0.0041 - classifier_loss: 0.0653 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4951 - val_decoder_loss: 29.6334 - val_encoder_loss: 21.3555 - val_classifier_loss: 1.7617 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2697 - decoder_loss: 22.5906 - encoder_loss: 0.0041 - classifier_loss: 0.0651 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 163: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2697 - decoder_loss: 22.5906 - encoder_loss: 0.0041 - classifier_loss: 0.0651 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5004 - val_decoder_loss: 29.6322 - val_encoder_loss: 21.3608 - val_classifier_loss: 1.7633 - val_decoder_accuracy: 0.0498 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2700 - decoder_loss: 22.5895 - encoder_loss: 0.0045 - classifier_loss: 0.0650 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2700 - decoder_loss: 22.5895 - encoder_loss: 0.0045 - classifier_loss: 0.0650 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.4976 - val_decoder_loss: 29.6311 - val_encoder_loss: 21.3581 - val_classifier_loss: 1.7640 - val_decoder_accuracy: 0.0500 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2709 - decoder_loss: 22.5879 - encoder_loss: 0.0056 - classifier_loss: 0.0649 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2709 - decoder_loss: 22.5879 - encoder_loss: 0.0056 - classifier_loss: 0.0649 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5462 - val_decoder_loss: 29.6299 - val_encoder_loss: 21.4064 - val_classifier_loss: 1.7676 - val_decoder_accuracy: 0.0502 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2676 - decoder_loss: 22.5864 - encoder_loss: 0.0025 - classifier_loss: 0.0648 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 166: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2676 - decoder_loss: 22.5864 - encoder_loss: 0.0025 - classifier_loss: 0.0648 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5841 - val_decoder_loss: 29.6289 - val_encoder_loss: 21.4442 - val_classifier_loss: 1.7700 - val_decoder_accuracy: 0.0503 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2664 - decoder_loss: 22.5851 - encoder_loss: 0.0014 - classifier_loss: 0.0647 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2664 - decoder_loss: 22.5851 - encoder_loss: 0.0014 - classifier_loss: 0.0647 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5797 - val_decoder_loss: 29.6280 - val_encoder_loss: 21.4399 - val_classifier_loss: 1.7695 - val_decoder_accuracy: 0.0507 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2668 - decoder_loss: 22.5838 - encoder_loss: 0.0020 - classifier_loss: 0.0645 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2668 - decoder_loss: 22.5838 - encoder_loss: 0.0020 - classifier_loss: 0.0645 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5894 - val_decoder_loss: 29.6268 - val_encoder_loss: 21.4496 - val_classifier_loss: 1.7709 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2658 - decoder_loss: 22.5825 - encoder_loss: 0.0011 - classifier_loss: 0.0644 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2658 - decoder_loss: 22.5825 - encoder_loss: 0.0011 - classifier_loss: 0.0644 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6001 - val_decoder_loss: 29.6256 - val_encoder_loss: 21.4603 - val_classifier_loss: 1.7723 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2665 - decoder_loss: 22.5811 - encoder_loss: 0.0020 - classifier_loss: 0.0643 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2665 - decoder_loss: 22.5811 - encoder_loss: 0.0020 - classifier_loss: 0.0643 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6034 - val_decoder_loss: 29.6245 - val_encoder_loss: 21.4636 - val_classifier_loss: 1.7735 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2659 - decoder_loss: 22.5796 - encoder_loss: 0.0016 - classifier_loss: 0.0642 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2659 - decoder_loss: 22.5796 - encoder_loss: 0.0016 - classifier_loss: 0.0642 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6071 - val_decoder_loss: 29.6232 - val_encoder_loss: 21.4673 - val_classifier_loss: 1.7748 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2667 - decoder_loss: 22.5781 - encoder_loss: 0.0024 - classifier_loss: 0.0641 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2667 - decoder_loss: 22.5781 - encoder_loss: 0.0024 - classifier_loss: 0.0641 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6128 - val_decoder_loss: 29.6221 - val_encoder_loss: 21.4730 - val_classifier_loss: 1.7753 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2659 - decoder_loss: 22.5766 - encoder_loss: 0.0019 - classifier_loss: 0.0640 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2659 - decoder_loss: 22.5766 - encoder_loss: 0.0019 - classifier_loss: 0.0640 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6224 - val_decoder_loss: 29.6208 - val_encoder_loss: 21.4826 - val_classifier_loss: 1.7766 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2677 - decoder_loss: 22.5750 - encoder_loss: 0.0038 - classifier_loss: 0.0639 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2677 - decoder_loss: 22.5750 - encoder_loss: 0.0038 - classifier_loss: 0.0639 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6463 - val_decoder_loss: 29.6196 - val_encoder_loss: 21.5066 - val_classifier_loss: 1.7780 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2672 - decoder_loss: 22.5732 - encoder_loss: 0.0035 - classifier_loss: 0.0638 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2672 - decoder_loss: 22.5732 - encoder_loss: 0.0035 - classifier_loss: 0.0638 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6416 - val_decoder_loss: 29.6183 - val_encoder_loss: 21.5019 - val_classifier_loss: 1.7788 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2665 - decoder_loss: 22.5719 - encoder_loss: 0.0029 - classifier_loss: 0.0636 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2665 - decoder_loss: 22.5719 - encoder_loss: 0.0029 - classifier_loss: 0.0636 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6693 - val_decoder_loss: 29.6168 - val_encoder_loss: 21.5295 - val_classifier_loss: 1.7805 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - decoder_loss: 22.5703 - encoder_loss: 0.0022 - classifier_loss: 0.0635 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2656 - decoder_loss: 22.5703 - encoder_loss: 0.0022 - classifier_loss: 0.0635 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6368 - val_decoder_loss: 29.6161 - val_encoder_loss: 21.4972 - val_classifier_loss: 1.7796 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - decoder_loss: 22.5692 - encoder_loss: 0.0023 - classifier_loss: 0.0634 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2656 - decoder_loss: 22.5692 - encoder_loss: 0.0023 - classifier_loss: 0.0634 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6539 - val_decoder_loss: 29.6153 - val_encoder_loss: 21.5143 - val_classifier_loss: 1.7809 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2645 - decoder_loss: 22.5678 - encoder_loss: 0.0014 - classifier_loss: 0.0633 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2645 - decoder_loss: 22.5678 - encoder_loss: 0.0014 - classifier_loss: 0.0633 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6541 - val_decoder_loss: 29.6141 - val_encoder_loss: 21.5144 - val_classifier_loss: 1.7824 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2666 - decoder_loss: 22.5665 - encoder_loss: 0.0036 - classifier_loss: 0.0632 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2666 - decoder_loss: 22.5665 - encoder_loss: 0.0036 - classifier_loss: 0.0632 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6739 - val_decoder_loss: 29.6129 - val_encoder_loss: 21.5341 - val_classifier_loss: 1.7848 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2652 - decoder_loss: 22.5650 - encoder_loss: 0.0024 - classifier_loss: 0.0631 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2652 - decoder_loss: 22.5650 - encoder_loss: 0.0024 - classifier_loss: 0.0631 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6845 - val_decoder_loss: 29.6116 - val_encoder_loss: 21.5447 - val_classifier_loss: 1.7868 - val_decoder_accuracy: 0.0510 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2644 - decoder_loss: 22.5635 - encoder_loss: 0.0017 - classifier_loss: 0.0630 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2644 - decoder_loss: 22.5635 - encoder_loss: 0.0017 - classifier_loss: 0.0630 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6695 - val_decoder_loss: 29.6105 - val_encoder_loss: 21.5298 - val_classifier_loss: 1.7865 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2646 - decoder_loss: 22.5622 - encoder_loss: 0.0020 - classifier_loss: 0.0629 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2646 - decoder_loss: 22.5622 - encoder_loss: 0.0020 - classifier_loss: 0.0629 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6903 - val_decoder_loss: 29.6095 - val_encoder_loss: 21.5504 - val_classifier_loss: 1.7891 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2663 - decoder_loss: 22.5608 - encoder_loss: 0.0039 - classifier_loss: 0.0628 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2663 - decoder_loss: 22.5608 - encoder_loss: 0.0039 - classifier_loss: 0.0628 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7043 - val_decoder_loss: 29.6085 - val_encoder_loss: 21.5644 - val_classifier_loss: 1.7914 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - decoder_loss: 22.5595 - encoder_loss: 0.0034 - classifier_loss: 0.0627 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2656 - decoder_loss: 22.5595 - encoder_loss: 0.0034 - classifier_loss: 0.0627 - decoder_accuracy: 0.0634 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6656 - val_decoder_loss: 29.6077 - val_encoder_loss: 21.5259 - val_classifier_loss: 1.7899 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - decoder_loss: 22.5585 - encoder_loss: 0.0035 - classifier_loss: 0.0627 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2656 - decoder_loss: 22.5585 - encoder_loss: 0.0035 - classifier_loss: 0.0627 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6848 - val_decoder_loss: 29.6071 - val_encoder_loss: 21.5449 - val_classifier_loss: 1.7917 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2651 - decoder_loss: 22.5573 - encoder_loss: 0.0031 - classifier_loss: 0.0626 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2651 - decoder_loss: 22.5573 - encoder_loss: 0.0031 - classifier_loss: 0.0626 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6904 - val_decoder_loss: 29.6063 - val_encoder_loss: 21.5504 - val_classifier_loss: 1.7933 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2669 - decoder_loss: 22.5562 - encoder_loss: 0.0050 - classifier_loss: 0.0625 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.2669 - decoder_loss: 22.5562 - encoder_loss: 0.0050 - classifier_loss: 0.0625 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7058 - val_decoder_loss: 29.6052 - val_encoder_loss: 21.5658 - val_classifier_loss: 1.7947 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2648 - decoder_loss: 22.5552 - encoder_loss: 0.0030 - classifier_loss: 0.0624 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2648 - decoder_loss: 22.5552 - encoder_loss: 0.0030 - classifier_loss: 0.0624 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7190 - val_decoder_loss: 29.6038 - val_encoder_loss: 21.5790 - val_classifier_loss: 1.7966 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2667 - decoder_loss: 22.5541 - encoder_loss: 0.0051 - classifier_loss: 0.0623 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2667 - decoder_loss: 22.5541 - encoder_loss: 0.0051 - classifier_loss: 0.0623 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7321 - val_decoder_loss: 29.6032 - val_encoder_loss: 21.5920 - val_classifier_loss: 1.7980 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2671 - decoder_loss: 22.5530 - encoder_loss: 0.0056 - classifier_loss: 0.0622 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2671 - decoder_loss: 22.5530 - encoder_loss: 0.0056 - classifier_loss: 0.0622 - decoder_accuracy: 0.0633 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7982 - val_decoder_loss: 29.6023 - val_encoder_loss: 21.6578 - val_classifier_loss: 1.8017 - val_decoder_accuracy: 0.0520 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2650 - decoder_loss: 22.5519 - encoder_loss: 0.0036 - classifier_loss: 0.0622 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2650 - decoder_loss: 22.5519 - encoder_loss: 0.0036 - classifier_loss: 0.0622 - decoder_accuracy: 0.0632 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7916 - val_decoder_loss: 29.6016 - val_encoder_loss: 21.6512 - val_classifier_loss: 1.8027 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2641 - decoder_loss: 22.5508 - encoder_loss: 0.0028 - classifier_loss: 0.0621 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2641 - decoder_loss: 22.5508 - encoder_loss: 0.0028 - classifier_loss: 0.0621 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7957 - val_decoder_loss: 29.6008 - val_encoder_loss: 21.6552 - val_classifier_loss: 1.8045 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2639 - decoder_loss: 22.5495 - encoder_loss: 0.0027 - classifier_loss: 0.0620 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2639 - decoder_loss: 22.5495 - encoder_loss: 0.0027 - classifier_loss: 0.0620 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.8076 - val_decoder_loss: 29.6005 - val_encoder_loss: 21.6669 - val_classifier_loss: 1.8062 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2646 - decoder_loss: 22.5483 - encoder_loss: 0.0036 - classifier_loss: 0.0620 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2646 - decoder_loss: 22.5483 - encoder_loss: 0.0036 - classifier_loss: 0.0620 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.8025 - val_decoder_loss: 29.6000 - val_encoder_loss: 21.6617 - val_classifier_loss: 1.8074 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2645 - decoder_loss: 22.5473 - encoder_loss: 0.0036 - classifier_loss: 0.0619 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2645 - decoder_loss: 22.5473 - encoder_loss: 0.0036 - classifier_loss: 0.0619 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7806 - val_decoder_loss: 29.5995 - val_encoder_loss: 21.6399 - val_classifier_loss: 1.8073 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2649 - decoder_loss: 22.5464 - encoder_loss: 0.0041 - classifier_loss: 0.0618 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.2649 - decoder_loss: 22.5464 - encoder_loss: 0.0041 - classifier_loss: 0.0618 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.8069 - val_decoder_loss: 29.5983 - val_encoder_loss: 21.6661 - val_classifier_loss: 1.8096 - val_decoder_accuracy: 0.0517 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2641 - decoder_loss: 22.5453 - encoder_loss: 0.0034 - classifier_loss: 0.0617 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2641 - decoder_loss: 22.5453 - encoder_loss: 0.0034 - classifier_loss: 0.0617 - decoder_accuracy: 0.0631 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.8182 - val_decoder_loss: 29.5971 - val_encoder_loss: 21.6774 - val_classifier_loss: 1.8110 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2631 - decoder_loss: 22.5442 - encoder_loss: 0.0025 - classifier_loss: 0.0616 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2631 - decoder_loss: 22.5442 - encoder_loss: 0.0025 - classifier_loss: 0.0616 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7975 - val_decoder_loss: 29.5960 - val_encoder_loss: 21.6569 - val_classifier_loss: 1.8100 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2620 - decoder_loss: 22.5429 - encoder_loss: 0.0016 - classifier_loss: 0.0615 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2620 - decoder_loss: 22.5429 - encoder_loss: 0.0016 - classifier_loss: 0.0615 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7890 - val_decoder_loss: 29.5948 - val_encoder_loss: 21.6485 - val_classifier_loss: 1.8101 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2630 - decoder_loss: 22.5414 - encoder_loss: 0.0027 - classifier_loss: 0.0614 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2630 - decoder_loss: 22.5414 - encoder_loss: 0.0027 - classifier_loss: 0.0614 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7587 - val_decoder_loss: 29.5942 - val_encoder_loss: 21.6183 - val_classifier_loss: 1.8097 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2640 - decoder_loss: 22.5400 - encoder_loss: 0.0039 - classifier_loss: 0.0613 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2640 - decoder_loss: 22.5400 - encoder_loss: 0.0039 - classifier_loss: 0.0613 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7280 - val_decoder_loss: 29.5933 - val_encoder_loss: 21.5877 - val_classifier_loss: 1.8099 - val_decoder_accuracy: 0.0518 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2622 - decoder_loss: 22.5386 - encoder_loss: 0.0023 - classifier_loss: 0.0612 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 203: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2622 - decoder_loss: 22.5386 - encoder_loss: 0.0023 - classifier_loss: 0.0612 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6878 - val_decoder_loss: 29.5927 - val_encoder_loss: 21.5475 - val_classifier_loss: 1.8097 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2606 - decoder_loss: 22.5372 - encoder_loss: 7.3981e-04 - classifier_loss: 0.0611 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 204: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2606 - decoder_loss: 22.5372 - encoder_loss: 7.3981e-04 - classifier_loss: 0.0611 - decoder_accuracy: 0.0627 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6771 - val_decoder_loss: 29.5915 - val_encoder_loss: 21.5369 - val_classifier_loss: 1.8107 - val_decoder_accuracy: 0.0515 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2616 - decoder_loss: 22.5358 - encoder_loss: 0.0019 - classifier_loss: 0.0610 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 205: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2616 - decoder_loss: 22.5358 - encoder_loss: 0.0019 - classifier_loss: 0.0610 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6663 - val_decoder_loss: 29.5905 - val_encoder_loss: 21.5263 - val_classifier_loss: 1.8102 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2620 - decoder_loss: 22.5345 - encoder_loss: 0.0024 - classifier_loss: 0.0609 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 206: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2620 - decoder_loss: 22.5345 - encoder_loss: 0.0024 - classifier_loss: 0.0609 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6704 - val_decoder_loss: 29.5895 - val_encoder_loss: 21.5303 - val_classifier_loss: 1.8113 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2647 - decoder_loss: 22.5331 - encoder_loss: 0.0053 - classifier_loss: 0.0608 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 207: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2647 - decoder_loss: 22.5331 - encoder_loss: 0.0053 - classifier_loss: 0.0608 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6921 - val_decoder_loss: 29.5885 - val_encoder_loss: 21.5519 - val_classifier_loss: 1.8133 - val_decoder_accuracy: 0.0513 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2637 - decoder_loss: 22.5318 - encoder_loss: 0.0044 - classifier_loss: 0.0607 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 208: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.2637 - decoder_loss: 22.5318 - encoder_loss: 0.0044 - classifier_loss: 0.0607 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7083 - val_decoder_loss: 29.5874 - val_encoder_loss: 21.5680 - val_classifier_loss: 1.8153 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2616 - decoder_loss: 22.5307 - encoder_loss: 0.0024 - classifier_loss: 0.0606 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 209: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2616 - decoder_loss: 22.5307 - encoder_loss: 0.0024 - classifier_loss: 0.0606 - decoder_accuracy: 0.0630 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.7056 - val_decoder_loss: 29.5866 - val_encoder_loss: 21.5654 - val_classifier_loss: 1.8154 - val_decoder_accuracy: 0.0512 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2605 - decoder_loss: 22.5296 - encoder_loss: 0.0015 - classifier_loss: 0.0605 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 210: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2605 - decoder_loss: 22.5296 - encoder_loss: 0.0015 - classifier_loss: 0.0605 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6889 - val_decoder_loss: 29.5856 - val_encoder_loss: 21.5488 - val_classifier_loss: 1.8150 - val_decoder_accuracy: 0.0507 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2627 - decoder_loss: 22.5282 - encoder_loss: 0.0038 - classifier_loss: 0.0604 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 211: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.2627 - decoder_loss: 22.5282 - encoder_loss: 0.0038 - classifier_loss: 0.0604 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6757 - val_decoder_loss: 29.5848 - val_encoder_loss: 21.5357 - val_classifier_loss: 1.8149 - val_decoder_accuracy: 0.0508 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2612 - decoder_loss: 22.5267 - encoder_loss: 0.0025 - classifier_loss: 0.0602 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 212: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2612 - decoder_loss: 22.5267 - encoder_loss: 0.0025 - classifier_loss: 0.0602 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6352 - val_decoder_loss: 29.5843 - val_encoder_loss: 21.4954 - val_classifier_loss: 1.8136 - val_decoder_accuracy: 0.0508 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2613 - decoder_loss: 22.5254 - encoder_loss: 0.0027 - classifier_loss: 0.0601 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 213: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.2613 - decoder_loss: 22.5254 - encoder_loss: 0.0027 - classifier_loss: 0.0601 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6324 - val_decoder_loss: 29.5834 - val_encoder_loss: 21.4926 - val_classifier_loss: 1.8146 - val_decoder_accuracy: 0.0508 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2614 - decoder_loss: 22.5241 - encoder_loss: 0.0030 - classifier_loss: 0.0600 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 214: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.2614 - decoder_loss: 22.5241 - encoder_loss: 0.0030 - classifier_loss: 0.0600 - decoder_accuracy: 0.0628 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.6220 - val_decoder_loss: 29.5826 - val_encoder_loss: 21.4822 - val_classifier_loss: 1.8150 - val_decoder_accuracy: 0.0507 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2604 - decoder_loss: 22.5229 - encoder_loss: 0.0021 - classifier_loss: 0.0598 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000\n",
            "Epoch 215: val_loss did not improve from 3.35074\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2604 - decoder_loss: 22.5229 - encoder_loss: 0.0021 - classifier_loss: 0.0598 - decoder_accuracy: 0.0629 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 1.0000 - val_loss: 24.5915 - val_decoder_loss: 29.5820 - val_encoder_loss: 21.4519 - val_classifier_loss: 1.8142 - val_decoder_accuracy: 0.0507 - val_encoder_accuracy: 0.0000e+00 - val_classifier_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 215: early stopping\n",
            "dict_keys(['loss', 'decoder_loss', 'encoder_loss', 'classifier_loss', 'decoder_accuracy', 'encoder_accuracy', 'classifier_accuracy', 'val_loss', 'val_decoder_loss', 'val_encoder_loss', 'val_classifier_loss', 'val_decoder_accuracy', 'val_encoder_accuracy', 'val_classifier_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 1, 600, 63)]      0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 1, 600, 63)        254079    \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 1, 600, 63)       252       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_22 (Avera  (None, 1, 100, 63)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 1, 100, 10)        20170     \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 1, 100, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " average_pooling2d_23 (Avera  (None, 1, 25, 10)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 250)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 63)                15813     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 290,354\n",
            "Trainable params: 290,208\n",
            "Non-trainable params: 146\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 63)]              0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 250)               16000     \n",
            "                                                                 \n",
            " reshape_11 (Reshape)        (None, 1, 25, 10)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_22 (Conv2D  (None, 1, 100, 10)       6410      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_23 (Conv2D  (None, 1, 600, 63)       20223     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,633\n",
            "Trainable params: 42,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MIN2Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 1, 600, 63)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, 63)           290354      ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, 1, 600, 63)   42633       ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            128         ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,115\n",
            "Trainable params: 332,969\n",
            "Non-trainable params: 146\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f97c29360d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 1s 572ms/step - loss: 8.3060 - decoder_loss: 25.9992 - encoder_loss: 5.6282 - classifier_loss: 0.7787 - decoder_accuracy: 0.0323 - encoder_accuracy: 0.0000e+00 - classifier_accuracy: 0.5667\n",
            "F1-score is computed based on binary\n",
            "(loss: 8.305989265441895, accuracy: 0.5666666626930237)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.53      0.55        15\n",
            "         1.0       0.56      0.60      0.58        15\n",
            "\n",
            "    accuracy                           0.57        30\n",
            "   macro avg       0.57      0.57      0.57        30\n",
            "weighted avg       0.57      0.57      0.57        30\n",
            "\n",
            "Accuracy: 0.5666666626930237\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5666666626930237\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "[1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset='SMR_BCI', \n",
        "                    train_type='subject_dependent', \n",
        "                    subject=1, \n",
        "                    data_format='NCTD', # for EEGNet and DeepConvNet (our paper and the original paper set data_format='NDCT')\n",
        "                    data_type='time_domain', \n",
        "                    dataset_path='datasets')"
      ],
      "metadata": {
        "id": "iOYB3YKBU_bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "X_train, y_train = loader.load_train_set(fold=1)\n",
        "X_val, y_val = loader.load_val_set(fold=1)\n",
        "X_test, y_test = loader.load_test_set(fold=1)\n",
        "\n",
        "from min2net.model import EEGNet\n",
        "# (our paper and the original paper set input_shape=(1,20,400), data_format='channels_first')\n",
        "model = EEGNet(input_shape=(20,400,1), num_class=2, dropout_rate=0.25, shuffle=True, data_format='channels_last')\n",
        "model.fit(X_train, y_train, X_val, y_val)\n",
        "Y, evaluation = model.predict(X_test, y_test)"
      ],
      "metadata": {
        "id": "V5kWzJ9QX19j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e658b1-9267-4b73-942a-20a9fd0cf825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NCTD', new dimention is (40, 63, 600, 1)\n",
            "change data_format to 'NCTD', new dimention is (10, 63, 600, 1)\n",
            "change data_format to 'NCTD', new dimention is (30, 63, 600, 1)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 63, 600, 1)]      0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 63, 600, 8)        1600      \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 63, 600, 8)       32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " depthwise_conv2d (Depthwise  (None, 1, 600, 16)       1008      \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 1, 600, 16)       64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1, 600, 16)        0         \n",
            "                                                                 \n",
            " average_pooling2d_24 (Avera  (None, 1, 150, 16)       0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 150, 16)        0         \n",
            "                                                                 \n",
            " separable_conv2d (Separable  (None, 1, 150, 16)       1056      \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 1, 150, 16)       64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1, 150, 16)        0         \n",
            "                                                                 \n",
            " average_pooling2d_25 (Avera  (None, 1, 18, 16)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 18, 16)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 288)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 578       \n",
            "                                                                 \n",
            " softmax (Activation)        (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,402\n",
            "Trainable params: 4,322\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n",
            "The first kernel size is (1, 200)\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.7000\n",
            "Epoch 1: val_loss improved from inf to 0.64065, saving model to logs/EEGNet_out_weights.h5\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6110 - accuracy: 0.7000 - val_loss: 0.6407 - val_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6692 - accuracy: 0.5750\n",
            "Epoch 2: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6692 - accuracy: 0.5750 - val_loss: 0.6660 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.7250\n",
            "Epoch 3: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5694 - accuracy: 0.7250 - val_loss: 0.6937 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.9250\n",
            "Epoch 4: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4301 - accuracy: 0.9250 - val_loss: 0.9111 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.9000\n",
            "Epoch 5: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.3804 - accuracy: 0.9000 - val_loss: 1.3232 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.9250\n",
            "Epoch 6: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3062 - accuracy: 0.9250 - val_loss: 1.5774 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2531 - accuracy: 0.9250\n",
            "Epoch 7: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2531 - accuracy: 0.9250 - val_loss: 1.7418 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9500\n",
            "Epoch 8: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2339 - accuracy: 0.9500 - val_loss: 1.8391 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9250\n",
            "Epoch 9: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2221 - accuracy: 0.9250 - val_loss: 1.8537 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1816 - accuracy: 0.9750\n",
            "Epoch 10: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1816 - accuracy: 0.9750 - val_loss: 1.7970 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 1.0000\n",
            "Epoch 11: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1663 - accuracy: 1.0000 - val_loss: 1.7034 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 1.0000\n",
            "Epoch 12: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1526 - accuracy: 1.0000 - val_loss: 1.7240 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1398 - accuracy: 1.0000 - val_loss: 1.7806 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1320 - accuracy: 1.0000 - val_loss: 1.8350 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 1.8906 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1052 - accuracy: 1.0000 - val_loss: 1.9686 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 2.0758 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 2.1552 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 2.1165 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 2.0087 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 0.64065\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 1.9259 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 21: early stopping\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.6597 - accuracy: 0.6667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.80      0.71        15\n",
            "         1.0       0.73      0.53      0.62        15\n",
            "\n",
            "    accuracy                           0.67        30\n",
            "   macro avg       0.68      0.67      0.66        30\n",
            "weighted avg       0.68      0.67      0.66        30\n",
            "\n",
            "F1-score is computed based on binary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "X_train, y_train = loader.load_train_set(fold=1)\n",
        "X_val, y_val = loader.load_val_set(fold=1)\n",
        "X_test, y_test = loader.load_test_set(fold=1)\n",
        "\n",
        "from min2net.model import DeepConvNet\n",
        "# (our paper and the original paper set input_shape=(1,20,400), data_format='channels_first')\n",
        "model = DeepConvNet(input_shape=(20,400,1), num_class=2, dropout_rate=0.25, shuffle=True, data_format='channels_last')\n",
        "model.fit(X_train, y_train, X_val, y_val)\n",
        "Y, evaluation = model.predict(X_test, y_test)"
      ],
      "metadata": {
        "id": "5Z3ugkEfUPIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f388f318-e14e-4a7c-a7a1-7c6570f374e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change data_format to 'NCTD', new dimention is (40, 63, 600, 1)\n",
            "change data_format to 'NCTD', new dimention is (10, 63, 600, 1)\n",
            "change data_format to 'NCTD', new dimention is (30, 63, 600, 1)\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 63, 600, 1)]      0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 63, 596, 25)       150       \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 1, 596, 25)        39400     \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 1, 596, 25)       4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 1, 596, 25)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 1, 298, 25)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1, 298, 25)        0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 1, 294, 50)        6300      \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 1, 294, 50)       4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 1, 294, 50)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 1, 147, 50)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1, 147, 50)        0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 1, 143, 100)       25100     \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 1, 143, 100)      4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 1, 143, 100)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 1, 71, 100)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 1, 71, 100)        0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 1, 67, 200)        100200    \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 1, 67, 200)       4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 1, 67, 200)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 33, 200)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 1, 33, 200)        0         \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 6600)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 2)                 13202     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 184,368\n",
            "Trainable params: 184,360\n",
            "Non-trainable params: 8\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9778 - accuracy: 0.6250\n",
            "Epoch 1: val_loss improved from inf to 58.42058, saving model to logs/DeepConvNet_out_weights.h5\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9778 - accuracy: 0.6250 - val_loss: 58.4206 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.9184 - accuracy: 0.5000\n",
            "Epoch 2: val_loss improved from 58.42058 to 33.71478, saving model to logs/DeepConvNet_out_weights.h5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 7.9184 - accuracy: 0.5000 - val_loss: 33.7148 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 15.1319 - accuracy: 0.5000\n",
            "Epoch 3: val_loss improved from 33.71478 to 2.36411, saving model to logs/DeepConvNet_out_weights.h5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 15.1319 - accuracy: 0.5000 - val_loss: 2.3641 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0725 - accuracy: 0.7000\n",
            "Epoch 4: val_loss did not improve from 2.36411\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.0725 - accuracy: 0.7000 - val_loss: 11.1783 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.3334 - accuracy: 0.5000\n",
            "Epoch 5: val_loss improved from 2.36411 to 2.17003, saving model to logs/DeepConvNet_out_weights.h5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 7.3334 - accuracy: 0.5000 - val_loss: 2.1700 - val_accuracy: 0.5000 - lr: 0.0100\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9502 - accuracy: 0.5000\n",
            "Epoch 6: val_loss did not improve from 2.17003\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.9502 - accuracy: 0.5000 - val_loss: 3.0425 - val_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9611 - accuracy: 0.6750\n",
            "Epoch 7: val_loss did not improve from 2.17003\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.9611 - accuracy: 0.6750 - val_loss: 3.6495 - val_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7122 - accuracy: 0.6750\n",
            "Epoch 8: val_loss did not improve from 2.17003\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7122 - accuracy: 0.6750 - val_loss: 2.6172 - val_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1660 - accuracy: 0.7250\n",
            "Epoch 9: val_loss improved from 2.17003 to 1.31274, saving model to logs/DeepConvNet_out_weights.h5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.1660 - accuracy: 0.7250 - val_loss: 1.3127 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3327 - accuracy: 0.7750\n",
            "Epoch 10: val_loss improved from 1.31274 to 0.53878, saving model to logs/DeepConvNet_out_weights.h5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.3327 - accuracy: 0.7750 - val_loss: 0.5388 - val_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.8500\n",
            "Epoch 11: val_loss did not improve from 0.53878\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4324 - accuracy: 0.8500 - val_loss: 0.6858 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.6500\n",
            "Epoch 12: val_loss did not improve from 0.53878\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6028 - accuracy: 0.6500 - val_loss: 1.1635 - val_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8768 - accuracy: 0.7000\n",
            "Epoch 13: val_loss did not improve from 0.53878\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8768 - accuracy: 0.7000 - val_loss: 1.3437 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.7750\n",
            "Epoch 14: val_loss did not improve from 0.53878\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4842 - accuracy: 0.7750 - val_loss: 1.1333 - val_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8000\n",
            "Epoch 15: val_loss did not improve from 0.53878\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3786 - accuracy: 0.8000 - val_loss: 0.7251 - val_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.8250\n",
            "Epoch 16: val_loss improved from 0.53878 to 0.42627, saving model to logs/DeepConvNet_out_weights.h5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.3422 - accuracy: 0.8250 - val_loss: 0.4263 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3688 - accuracy: 0.8750\n",
            "Epoch 17: val_loss improved from 0.42627 to 0.32101, saving model to logs/DeepConvNet_out_weights.h5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.3688 - accuracy: 0.8750 - val_loss: 0.3210 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3267 - accuracy: 0.9000\n",
            "Epoch 18: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3267 - accuracy: 0.9000 - val_loss: 0.3685 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.8500\n",
            "Epoch 19: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3049 - accuracy: 0.8500 - val_loss: 0.5780 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.8750\n",
            "Epoch 20: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2479 - accuracy: 0.8750 - val_loss: 0.7863 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.8500\n",
            "Epoch 21: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2593 - accuracy: 0.8500 - val_loss: 0.7991 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.9000\n",
            "Epoch 22: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2588 - accuracy: 0.9000 - val_loss: 0.6580 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9500\n",
            "Epoch 23: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1591 - accuracy: 0.9500 - val_loss: 0.5558 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9500\n",
            "Epoch 24: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1621 - accuracy: 0.9500 - val_loss: 0.5274 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.9250\n",
            "Epoch 25: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1947 - accuracy: 0.9250 - val_loss: 0.6088 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.8500\n",
            "Epoch 26: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2152 - accuracy: 0.8500 - val_loss: 0.8029 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.9500\n",
            "Epoch 27: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1719 - accuracy: 0.9500 - val_loss: 0.9288 - val_accuracy: 0.7000 - lr: 0.0100\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9750\n",
            "Epoch 28: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1504 - accuracy: 0.9750 - val_loss: 0.9667 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9750\n",
            "Epoch 29: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1469 - accuracy: 0.9750 - val_loss: 0.9099 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.9750\n",
            "Epoch 31: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1364 - accuracy: 0.9750 - val_loss: 0.8442 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9750\n",
            "Epoch 32: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1295 - accuracy: 0.9750 - val_loss: 0.8862 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.9496 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9750\n",
            "Epoch 34: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1216 - accuracy: 0.9750 - val_loss: 1.0280 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 1.1308 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1033 - accuracy: 1.0000 - val_loss: 1.1879 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 0.32101\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1085 - accuracy: 1.0000 - val_loss: 1.2138 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 37: early stopping\n",
            "1/1 [==============================] - 1s 512ms/step\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 1.5252 - accuracy: 0.5000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.60      0.55        15\n",
            "         1.0       0.50      0.40      0.44        15\n",
            "\n",
            "    accuracy                           0.50        30\n",
            "   macro avg       0.50      0.50      0.49        30\n",
            "weighted avg       0.50      0.50      0.49        30\n",
            "\n",
            "F1-score is computed based on binary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this model requires spectral-spatial-mapping\n",
        "# see https://min2net.github.io/docs/preprocessing/BCIC2a/#spectral-spatial-mapping\n",
        "\n",
        "# generate fake data\n",
        "import numpy as np\n",
        "X_train = np.random.rand(100,20,28,28,1)\n",
        "y_train = np.concatenate(([0]*50, [1]*50))\n",
        "X_val = np.random.rand(40,20,28,28,1)\n",
        "y_val = np.concatenate(([0]*20, [1]*20))\n",
        "X_test = np.random.rand(40,20,28,28,1)\n",
        "y_test = np.concatenate(([0]*20, [1]*20))\n",
        "\n",
        "from min2net.model import SpectralSpatialCNN\n",
        "model = SpectralSpatialCNN(input_shape=(28, 28, 1), num_class=2, epochs=10, dropout_rate=0.25, shuffle=True)\n",
        "model.fit(X_train, y_train, X_val, y_val)\n",
        "Y, evaluation = model.predict(X_test, y_test)"
      ],
      "metadata": {
        "id": "qxIdFYxTadhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d2172c-7d46-4ee0-d9df-1fa06cb48ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_17 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_18 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_19 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_21 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_22 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_23 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_24 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_25 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_26 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_27 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_28 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_29 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_30 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_31 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_32 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_33 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_34 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_35 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_36 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 28, 28, 10)   100         ['input_17[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 28, 28, 10)   100         ['input_18[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 28, 28, 10)   100         ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 28, 28, 10)   100         ['input_20[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 28, 28, 10)   100         ['input_21[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 28, 28, 10)   100         ['input_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 28, 28, 10)   100         ['input_23[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 28, 28, 10)   100         ['input_24[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 28, 28, 10)   100         ['input_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 28, 28, 10)   100         ['input_26[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 28, 28, 10)   100         ['input_27[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 28, 28, 10)   100         ['input_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 28, 28, 10)   100         ['input_29[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 28, 28, 10)   100         ['input_30[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 28, 28, 10)   100         ['input_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 28, 28, 10)   100         ['input_32[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 28, 28, 10)   100         ['input_33[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 28, 28, 10)   100         ['input_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 28, 28, 10)   100         ['input_35[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 28, 28, 10)   100         ['input_36[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_36[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_48[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_51[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_60[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_63[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_66[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_69[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_72[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_75[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_81[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_84[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_87[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 28, 28, 14)   1274        ['conv2d_93[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_52[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_55[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_64[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_67[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_73[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_76[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_79[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_85[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_88[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 28, 28, 18)   2286        ['conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_14 (Flatten)           (None, 14112)        0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_15 (Flatten)           (None, 14112)        0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_16 (Flatten)           (None, 14112)        0           ['conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_17 (Flatten)           (None, 14112)        0           ['conv2d_47[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_18 (Flatten)           (None, 14112)        0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_19 (Flatten)           (None, 14112)        0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_20 (Flatten)           (None, 14112)        0           ['conv2d_56[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_21 (Flatten)           (None, 14112)        0           ['conv2d_59[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_22 (Flatten)           (None, 14112)        0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_23 (Flatten)           (None, 14112)        0           ['conv2d_65[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_24 (Flatten)           (None, 14112)        0           ['conv2d_68[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_25 (Flatten)           (None, 14112)        0           ['conv2d_71[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_26 (Flatten)           (None, 14112)        0           ['conv2d_74[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_27 (Flatten)           (None, 14112)        0           ['conv2d_77[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_28 (Flatten)           (None, 14112)        0           ['conv2d_80[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_29 (Flatten)           (None, 14112)        0           ['conv2d_83[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_30 (Flatten)           (None, 14112)        0           ['conv2d_86[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_31 (Flatten)           (None, 14112)        0           ['conv2d_89[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_32 (Flatten)           (None, 14112)        0           ['conv2d_92[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_33 (Flatten)           (None, 14112)        0           ['conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 256)          3612928     ['flatten_14[0][0]']             \n",
            "                                                                                                  \n",
            " dense_27 (Dense)               (None, 256)          3612928     ['flatten_15[0][0]']             \n",
            "                                                                                                  \n",
            " dense_28 (Dense)               (None, 256)          3612928     ['flatten_16[0][0]']             \n",
            "                                                                                                  \n",
            " dense_29 (Dense)               (None, 256)          3612928     ['flatten_17[0][0]']             \n",
            "                                                                                                  \n",
            " dense_30 (Dense)               (None, 256)          3612928     ['flatten_18[0][0]']             \n",
            "                                                                                                  \n",
            " dense_31 (Dense)               (None, 256)          3612928     ['flatten_19[0][0]']             \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 256)          3612928     ['flatten_20[0][0]']             \n",
            "                                                                                                  \n",
            " dense_33 (Dense)               (None, 256)          3612928     ['flatten_21[0][0]']             \n",
            "                                                                                                  \n",
            " dense_34 (Dense)               (None, 256)          3612928     ['flatten_22[0][0]']             \n",
            "                                                                                                  \n",
            " dense_35 (Dense)               (None, 256)          3612928     ['flatten_23[0][0]']             \n",
            "                                                                                                  \n",
            " dense_36 (Dense)               (None, 256)          3612928     ['flatten_24[0][0]']             \n",
            "                                                                                                  \n",
            " dense_37 (Dense)               (None, 256)          3612928     ['flatten_25[0][0]']             \n",
            "                                                                                                  \n",
            " dense_38 (Dense)               (None, 256)          3612928     ['flatten_26[0][0]']             \n",
            "                                                                                                  \n",
            " dense_39 (Dense)               (None, 256)          3612928     ['flatten_27[0][0]']             \n",
            "                                                                                                  \n",
            " dense_40 (Dense)               (None, 256)          3612928     ['flatten_28[0][0]']             \n",
            "                                                                                                  \n",
            " dense_41 (Dense)               (None, 256)          3612928     ['flatten_29[0][0]']             \n",
            "                                                                                                  \n",
            " dense_42 (Dense)               (None, 256)          3612928     ['flatten_30[0][0]']             \n",
            "                                                                                                  \n",
            " dense_43 (Dense)               (None, 256)          3612928     ['flatten_31[0][0]']             \n",
            "                                                                                                  \n",
            " dense_44 (Dense)               (None, 256)          3612928     ['flatten_32[0][0]']             \n",
            "                                                                                                  \n",
            " dense_45 (Dense)               (None, 256)          3612928     ['flatten_33[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 5120)         0           ['dense_26[0][0]',               \n",
            "                                                                  'dense_27[0][0]',               \n",
            "                                                                  'dense_28[0][0]',               \n",
            "                                                                  'dense_29[0][0]',               \n",
            "                                                                  'dense_30[0][0]',               \n",
            "                                                                  'dense_31[0][0]',               \n",
            "                                                                  'dense_32[0][0]',               \n",
            "                                                                  'dense_33[0][0]',               \n",
            "                                                                  'dense_34[0][0]',               \n",
            "                                                                  'dense_35[0][0]',               \n",
            "                                                                  'dense_36[0][0]',               \n",
            "                                                                  'dense_37[0][0]',               \n",
            "                                                                  'dense_38[0][0]',               \n",
            "                                                                  'dense_39[0][0]',               \n",
            "                                                                  'dense_40[0][0]',               \n",
            "                                                                  'dense_41[0][0]',               \n",
            "                                                                  'dense_42[0][0]',               \n",
            "                                                                  'dense_43[0][0]',               \n",
            "                                                                  'dense_44[0][0]',               \n",
            "                                                                  'dense_45[0][0]']               \n",
            "                                                                                                  \n",
            " dense_46 (Dense)               (None, 1024)         5243904     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 1024)         0           ['dense_46[0][0]']               \n",
            "                                                                                                  \n",
            " dense_47 (Dense)               (None, 2)            2050        ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 77,577,714\n",
            "Trainable params: 77,577,714\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7022 - accuracy: 0.4500\n",
            "Epoch 1: val_loss improved from inf to 0.68741, saving model to logs/SpectralSpatialCNN_out_weights.h5\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.7022 - accuracy: 0.4500 - val_loss: 0.6874 - val_accuracy: 0.4500 - lr: 1.0000e-05\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.5400\n",
            "Epoch 2: val_loss improved from 0.68741 to 0.68565, saving model to logs/SpectralSpatialCNN_out_weights.h5\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6831 - accuracy: 0.5400 - val_loss: 0.6856 - val_accuracy: 0.5500 - lr: 1.0000e-05\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.6300\n",
            "Epoch 3: val_loss did not improve from 0.68565\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.6690 - accuracy: 0.6300 - val_loss: 0.6874 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6555 - accuracy: 0.6900\n",
            "Epoch 4: val_loss did not improve from 0.68565\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.6555 - accuracy: 0.6900 - val_loss: 0.6866 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.7300\n",
            "Epoch 5: val_loss improved from 0.68565 to 0.68525, saving model to logs/SpectralSpatialCNN_out_weights.h5\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6429 - accuracy: 0.7300 - val_loss: 0.6852 - val_accuracy: 0.5250 - lr: 1.0000e-05\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6339 - accuracy: 0.8300\n",
            "Epoch 6: val_loss did not improve from 0.68525\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.6339 - accuracy: 0.8300 - val_loss: 0.6861 - val_accuracy: 0.5250 - lr: 1.0000e-05\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6278 - accuracy: 0.7300\n",
            "Epoch 7: val_loss did not improve from 0.68525\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.6278 - accuracy: 0.7300 - val_loss: 0.6858 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6087 - accuracy: 0.8400\n",
            "Epoch 8: val_loss improved from 0.68525 to 0.68500, saving model to logs/SpectralSpatialCNN_out_weights.h5\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6087 - accuracy: 0.8400 - val_loss: 0.6850 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5965 - accuracy: 0.9600\n",
            "Epoch 9: val_loss did not improve from 0.68500\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.5965 - accuracy: 0.9600 - val_loss: 0.6853 - val_accuracy: 0.5750 - lr: 1.0000e-05\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.9400\n",
            "Epoch 10: val_loss did not improve from 0.68500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.5769 - accuracy: 0.9400 - val_loss: 0.6857 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "2/2 [==============================] - 1s 57ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7072 - accuracy: 0.4000\n",
            "F1-score is comptured basen on binary\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.60      0.50        20\n",
            "           1       0.33      0.20      0.25        20\n",
            "\n",
            "    accuracy                           0.40        40\n",
            "   macro avg       0.38      0.40      0.38        40\n",
            "weighted avg       0.38      0.40      0.38        40\n",
            "\n"
          ]
        }
      ]
    }
  ]
}